
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-01-26 12:22:02.446767: do_dummy_2d_data_aug: False 
2025-01-26 12:22:02.451875: Using splits from existing split file: /srv/scratch/z5362216/kits19/nnUNet_db/nnUNet_preprocessed/Dataset001_Kits19/splits_final.json 
2025-01-26 12:22:02.455651: The split file contains 5 splits. 
2025-01-26 12:22:02.458857: Desired fold for training: 2 
2025-01-26 12:22:02.461978: This split has 80 training and 20 validation cases. 
2025-01-26 12:22:07.787930: Using torch.compile... 

This is the configuration used by this training:
Configuration name: 3d_lowres
 {'data_identifier': 'nnUNetPlans_3d_lowres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [128, 128, 128], 'median_image_size_in_voxels': [200, 205, 205], 'spacing': [1.9849520718478983, 1.9849270710444444, 1.9849270710444444], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False, 'next_stage': '3d_cascade_fullres'} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset001_Kits19', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [3.0, 0.7939453125, 0.7939453125], 'original_median_shape_after_transp': [104, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [2, 0, 1], 'transpose_backward': [1, 2, 0], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 2553.0, 'mean': 104.46720886230469, 'median': 104.0, 'min': -277.0, 'percentile_00_5': -73.0, 'percentile_99_5': 292.0, 'std': 74.68063354492188}}} 
 
2025-01-26 12:22:10.262244: unpacking dataset... 
2025-01-26 12:22:16.707715: unpacking done... 
2025-01-26 12:22:16.729716: 
printing the network instead:
 
2025-01-26 12:22:16.732072: OptimizedModule(
  (_orig_mod): PlainConvUNet(
    (encoder): PlainConvEncoder(
      (stages): Sequential(
        (0): Sequential(
          (0): StackedConvBlocks(
            (convs): Sequential(
              (0): ConvDropoutNormReLU(
                (conv): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (1): ConvDropoutNormReLU(
                (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
            )
          )
        )
        (1): Sequential(
          (0): StackedConvBlocks(
            (convs): Sequential(
              (0): ConvDropoutNormReLU(
                (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (1): ConvDropoutNormReLU(
                (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
            )
          )
        )
        (2): Sequential(
          (0): StackedConvBlocks(
            (convs): Sequential(
              (0): ConvDropoutNormReLU(
                (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (1): ConvDropoutNormReLU(
                (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
            )
          )
        )
        (3): Sequential(
          (0): StackedConvBlocks(
            (convs): Sequential(
              (0): ConvDropoutNormReLU(
                (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (1): ConvDropoutNormReLU(
                (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
            )
          )
        )
        (4): Sequential(
          (0): StackedConvBlocks(
            (convs): Sequential(
              (0): ConvDropoutNormReLU(
                (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (1): ConvDropoutNormReLU(
                (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
            )
          )
        )
        (5): Sequential(
          (0): StackedConvBlocks(
            (convs): Sequential(
              (0): ConvDropoutNormReLU(
                (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (1): ConvDropoutNormReLU(
                (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
            )
          )
        )
      )
    )
    (decoder): UNetDecoder(
      (encoder): PlainConvEncoder(
        (stages): Sequential(
          (0): Sequential(
            (0): StackedConvBlocks(
              (convs): Sequential(
                (0): ConvDropoutNormReLU(
                  (conv): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                  (all_modules): Sequential(
                    (0): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                    (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                    (2): LeakyReLU(negative_slope=0.01, inplace=True)
                  )
                )
                (1): ConvDropoutNormReLU(
                  (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                  (all_modules): Sequential(
                    (0): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                    (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                    (2): LeakyReLU(negative_slope=0.01, inplace=True)
                  )
                )
              )
            )
          )
          (1): Sequential(
            (0): StackedConvBlocks(
              (convs): Sequential(
                (0): ConvDropoutNormReLU(
                  (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                  (all_modules): Sequential(
                    (0): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                    (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                    (2): LeakyReLU(negative_slope=0.01, inplace=True)
                  )
                )
                (1): ConvDropoutNormReLU(
                  (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                  (all_modules): Sequential(
                    (0): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                    (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                    (2): LeakyReLU(negative_slope=0.01, inplace=True)
                  )
                )
              )
            )
          )
          (2): Sequential(
            (0): StackedConvBlocks(
              (convs): Sequential(
                (0): ConvDropoutNormReLU(
                  (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                  (all_modules): Sequential(
                    (0): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                    (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                    (2): LeakyReLU(negative_slope=0.01, inplace=True)
                  )
                )
                (1): ConvDropoutNormReLU(
                  (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                  (all_modules): Sequential(
                    (0): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                    (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                    (2): LeakyReLU(negative_slope=0.01, inplace=True)
                  )
                )
              )
            )
          )
          (3): Sequential(
            (0): StackedConvBlocks(
              (convs): Sequential(
                (0): ConvDropoutNormReLU(
                  (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                  (all_modules): Sequential(
                    (0): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                    (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                    (2): LeakyReLU(negative_slope=0.01, inplace=True)
                  )
                )
                (1): ConvDropoutNormReLU(
                  (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                  (all_modules): Sequential(
                    (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                    (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                    (2): LeakyReLU(negative_slope=0.01, inplace=True)
                  )
                )
              )
            )
          )
          (4): Sequential(
            (0): StackedConvBlocks(
              (convs): Sequential(
                (0): ConvDropoutNormReLU(
                  (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                  (all_modules): Sequential(
                    (0): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                    (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                    (2): LeakyReLU(negative_slope=0.01, inplace=True)
                  )
                )
                (1): ConvDropoutNormReLU(
                  (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                  (all_modules): Sequential(
                    (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                    (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                    (2): LeakyReLU(negative_slope=0.01, inplace=True)
                  )
                )
              )
            )
          )
          (5): Sequential(
            (0): StackedConvBlocks(
              (convs): Sequential(
                (0): ConvDropoutNormReLU(
                  (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                  (all_modules): Sequential(
                    (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                    (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                    (2): LeakyReLU(negative_slope=0.01, inplace=True)
                  )
                )
                (1): ConvDropoutNormReLU(
                  (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                  (all_modules): Sequential(
                    (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                    (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                    (2): LeakyReLU(negative_slope=0.01, inplace=True)
                  )
                )
              )
            )
          )
        )
      )
      (stages): ModuleList(
        (0): StackedConvBlocks(
          (convs): Sequential(
            (0): ConvDropoutNormReLU(
              (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
              (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (1): ConvDropoutNormReLU(
              (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
              (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
          )
        )
        (1): StackedConvBlocks(
          (convs): Sequential(
            (0): ConvDropoutNormReLU(
              (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
              (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (1): ConvDropoutNormReLU(
              (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
              (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
          )
        )
        (2): StackedConvBlocks(
          (convs): Sequential(
            (0): ConvDropoutNormReLU(
              (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (1): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
          )
        )
        (3): StackedConvBlocks(
          (convs): Sequential(
            (0): ConvDropoutNormReLU(
              (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (1): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
          )
        )
        (4): StackedConvBlocks(
          (convs): Sequential(
            (0): ConvDropoutNormReLU(
              (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (1): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
          )
        )
      )
      (transpconvs): ModuleList(
        (0): ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2))
        (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2))
        (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2))
        (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2))
        (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2))
      )
      (seg_layers): ModuleList(
        (0): Conv3d(320, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1))
        (1): Conv3d(256, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1))
        (2): Conv3d(128, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1))
        (3): Conv3d(64, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1))
        (4): Conv3d(32, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1))
      )
    )
  )
) 
2025-01-26 12:22:16.740094: 
 
2025-01-26 12:22:16.742441: Unable to plot network architecture: nnUNet_compile is enabled! 
2025-01-26 12:22:16.758639:  
2025-01-26 12:22:16.761148: Epoch 0 
2025-01-26 12:22:16.763948: Current learning rate: 0.01 
2025-01-26 12:24:07.900794: train_loss -0.0132 
2025-01-26 12:24:07.905383: val_loss -0.2768 
2025-01-26 12:24:07.908108: Pseudo dice [np.float32(0.7248), np.float32(0.0)] 
2025-01-26 12:24:07.910867: Epoch time: 111.14 s 
2025-01-26 12:24:07.913497: Yayy! New best EMA pseudo Dice: 0.36239999532699585 
2025-01-26 12:24:09.894893:  
2025-01-26 12:24:09.897982: Epoch 1 
2025-01-26 12:24:09.900734: Current learning rate: 0.00999 
2025-01-26 12:24:59.464403: train_loss -0.3046 
2025-01-26 12:24:59.470371: val_loss -0.3667 
2025-01-26 12:24:59.473343: Pseudo dice [np.float32(0.8067), np.float32(0.114)] 
2025-01-26 12:24:59.475914: Epoch time: 49.57 s 
2025-01-26 12:24:59.478137: Yayy! New best EMA pseudo Dice: 0.37220001220703125 
2025-01-26 12:25:01.246640:  
2025-01-26 12:25:01.249923: Epoch 2 
2025-01-26 12:25:01.252970: Current learning rate: 0.00998 
2025-01-26 12:25:50.007421: train_loss -0.3886 
2025-01-26 12:25:50.011660: val_loss -0.4567 
2025-01-26 12:25:50.014382: Pseudo dice [np.float32(0.863), np.float32(0.3248)] 
2025-01-26 12:25:50.016814: Epoch time: 48.76 s 
2025-01-26 12:25:50.019223: Yayy! New best EMA pseudo Dice: 0.3944000005722046 
2025-01-26 12:25:51.787501:  
2025-01-26 12:25:51.791394: Epoch 3 
2025-01-26 12:25:51.794423: Current learning rate: 0.00997 
2025-01-26 12:26:40.517299: train_loss -0.4076 
2025-01-26 12:26:40.524284: val_loss -0.4492 
2025-01-26 12:26:40.527383: Pseudo dice [np.float32(0.8411), np.float32(0.393)] 
2025-01-26 12:26:40.530351: Epoch time: 48.73 s 
2025-01-26 12:26:40.532702: Yayy! New best EMA pseudo Dice: 0.41659998893737793 
2025-01-26 12:26:42.259329:  
2025-01-26 12:26:42.262545: Epoch 4 
2025-01-26 12:26:42.265722: Current learning rate: 0.00996 
2025-01-26 12:27:30.770105: train_loss -0.4289 
2025-01-26 12:27:30.774307: val_loss -0.5101 
2025-01-26 12:27:30.777120: Pseudo dice [np.float32(0.874), np.float32(0.5415)] 
2025-01-26 12:27:30.779504: Epoch time: 48.51 s 
2025-01-26 12:27:30.781764: Yayy! New best EMA pseudo Dice: 0.4458000063896179 
2025-01-26 12:27:32.567938:  
2025-01-26 12:27:32.570782: Epoch 5 
2025-01-26 12:27:32.573684: Current learning rate: 0.00995 
2025-01-26 12:28:21.610381: train_loss -0.4634 
2025-01-26 12:28:21.616595: val_loss -0.4784 
2025-01-26 12:28:21.619526: Pseudo dice [np.float32(0.8679), np.float32(0.4389)] 
2025-01-26 12:28:21.622196: Epoch time: 49.04 s 
2025-01-26 12:28:21.624941: Yayy! New best EMA pseudo Dice: 0.46650001406669617 
2025-01-26 12:28:23.325075:  
2025-01-26 12:28:23.328005: Epoch 6 
2025-01-26 12:28:23.330915: Current learning rate: 0.00995 
2025-01-26 12:29:12.034048: train_loss -0.4896 
2025-01-26 12:29:12.038296: val_loss -0.4763 
2025-01-26 12:29:12.041080: Pseudo dice [np.float32(0.8598), np.float32(0.3978)] 
2025-01-26 12:29:12.043648: Epoch time: 48.71 s 
2025-01-26 12:29:12.046690: Yayy! New best EMA pseudo Dice: 0.482699990272522 
2025-01-26 12:29:13.788534:  
2025-01-26 12:29:13.791899: Epoch 7 
2025-01-26 12:29:13.794836: Current learning rate: 0.00994 
2025-01-26 12:30:02.611812: train_loss -0.4989 
2025-01-26 12:30:02.619645: val_loss -0.5957 
2025-01-26 12:30:02.622408: Pseudo dice [np.float32(0.9131), np.float32(0.5771)] 
2025-01-26 12:30:02.624923: Epoch time: 48.82 s 
2025-01-26 12:30:02.627325: Yayy! New best EMA pseudo Dice: 0.5090000033378601 
2025-01-26 12:30:04.377223:  
2025-01-26 12:30:04.380006: Epoch 8 
2025-01-26 12:30:04.382720: Current learning rate: 0.00993 
2025-01-26 12:30:53.054103: train_loss -0.5407 
2025-01-26 12:30:53.058116: val_loss -0.5549 
2025-01-26 12:30:53.060927: Pseudo dice [np.float32(0.8918), np.float32(0.5772)] 
2025-01-26 12:30:53.063889: Epoch time: 48.68 s 
2025-01-26 12:30:53.066100: Yayy! New best EMA pseudo Dice: 0.531499981880188 
2025-01-26 12:30:54.839415:  
2025-01-26 12:30:54.842550: Epoch 9 
2025-01-26 12:30:54.845587: Current learning rate: 0.00992 
2025-01-26 12:31:43.524739: train_loss -0.5553 
2025-01-26 12:31:43.531622: val_loss -0.5342 
2025-01-26 12:31:43.534590: Pseudo dice [np.float32(0.8977), np.float32(0.4942)] 
2025-01-26 12:31:43.537203: Epoch time: 48.69 s 
2025-01-26 12:31:43.539659: Yayy! New best EMA pseudo Dice: 0.5479999780654907 
2025-01-26 12:31:45.241856:  
2025-01-26 12:31:45.244995: Epoch 10 
2025-01-26 12:31:45.247772: Current learning rate: 0.00991 
2025-01-26 12:32:33.716117: train_loss -0.5635 
2025-01-26 12:32:33.721121: val_loss -0.5764 
2025-01-26 12:32:33.724189: Pseudo dice [np.float32(0.9051), np.float32(0.5348)] 
2025-01-26 12:32:33.726879: Epoch time: 48.48 s 
2025-01-26 12:32:33.729841: Yayy! New best EMA pseudo Dice: 0.5651999711990356 
2025-01-26 12:32:35.436758:  
2025-01-26 12:32:35.440174: Epoch 11 
2025-01-26 12:32:35.443347: Current learning rate: 0.0099 
2025-01-26 12:33:24.256828: train_loss -0.5732 
2025-01-26 12:33:24.263573: val_loss -0.6308 
2025-01-26 12:33:24.266348: Pseudo dice [np.float32(0.9165), np.float32(0.6525)] 
2025-01-26 12:33:24.269158: Epoch time: 48.82 s 
2025-01-26 12:33:24.271717: Yayy! New best EMA pseudo Dice: 0.5871000289916992 
2025-01-26 12:33:25.960469:  
2025-01-26 12:33:25.963648: Epoch 12 
2025-01-26 12:33:25.966471: Current learning rate: 0.00989 
2025-01-26 12:34:14.971506: train_loss -0.5866 
2025-01-26 12:34:14.975657: val_loss -0.664 
2025-01-26 12:34:14.978769: Pseudo dice [np.float32(0.9196), np.float32(0.7431)] 
2025-01-26 12:34:14.981745: Epoch time: 49.01 s 
2025-01-26 12:34:14.984455: Yayy! New best EMA pseudo Dice: 0.6115000247955322 
2025-01-26 12:34:16.709266:  
2025-01-26 12:34:16.711936: Epoch 13 
2025-01-26 12:34:16.714650: Current learning rate: 0.00988 
2025-01-26 12:35:05.382267: train_loss -0.5972 
2025-01-26 12:35:05.388289: val_loss -0.5728 
2025-01-26 12:35:05.391105: Pseudo dice [np.float32(0.9208), np.float32(0.5359)] 
2025-01-26 12:35:05.393896: Epoch time: 48.67 s 
2025-01-26 12:35:05.396576: Yayy! New best EMA pseudo Dice: 0.623199999332428 
2025-01-26 12:35:07.101001:  
2025-01-26 12:35:07.103623: Epoch 14 
2025-01-26 12:35:07.106390: Current learning rate: 0.00987 
2025-01-26 12:35:55.601264: train_loss -0.6064 
2025-01-26 12:35:55.605735: val_loss -0.6031 
2025-01-26 12:35:55.608088: Pseudo dice [np.float32(0.9099), np.float32(0.6294)] 
2025-01-26 12:35:55.610836: Epoch time: 48.5 s 
2025-01-26 12:35:55.613426: Yayy! New best EMA pseudo Dice: 0.6377999782562256 
2025-01-26 12:35:57.347562:  
2025-01-26 12:35:57.350316: Epoch 15 
2025-01-26 12:35:57.352868: Current learning rate: 0.00986 
2025-01-26 12:36:46.432779: train_loss -0.6339 
2025-01-26 12:36:46.439385: val_loss -0.6166 
2025-01-26 12:36:46.442447: Pseudo dice [np.float32(0.9232), np.float32(0.6025)] 
2025-01-26 12:36:46.445183: Epoch time: 49.09 s 
2025-01-26 12:36:46.447778: Yayy! New best EMA pseudo Dice: 0.6503000259399414 
2025-01-26 12:36:48.222037:  
2025-01-26 12:36:48.225511: Epoch 16 
2025-01-26 12:36:48.228641: Current learning rate: 0.00986 
2025-01-26 12:37:37.345638: train_loss -0.6381 
2025-01-26 12:37:37.349973: val_loss -0.6386 
2025-01-26 12:37:37.352623: Pseudo dice [np.float32(0.9136), np.float32(0.6774)] 
2025-01-26 12:37:37.355385: Epoch time: 49.12 s 
2025-01-26 12:37:37.357650: Yayy! New best EMA pseudo Dice: 0.664900004863739 
2025-01-26 12:37:39.109618:  
2025-01-26 12:37:39.112429: Epoch 17 
2025-01-26 12:37:39.115237: Current learning rate: 0.00985 
2025-01-26 12:38:27.924996: train_loss -0.6325 
2025-01-26 12:38:27.930514: val_loss -0.6168 
2025-01-26 12:38:27.933079: Pseudo dice [np.float32(0.92), np.float32(0.6665)] 
2025-01-26 12:38:27.935418: Epoch time: 48.82 s 
2025-01-26 12:38:27.938362: Yayy! New best EMA pseudo Dice: 0.6776999831199646 
2025-01-26 12:38:29.711955:  
2025-01-26 12:38:29.715092: Epoch 18 
2025-01-26 12:38:29.718111: Current learning rate: 0.00984 
2025-01-26 12:39:17.869707: train_loss -0.6108 
2025-01-26 12:39:17.874770: val_loss -0.6626 
2025-01-26 12:39:17.877885: Pseudo dice [np.float32(0.9227), np.float32(0.7729)] 
2025-01-26 12:39:17.880622: Epoch time: 48.16 s 
2025-01-26 12:39:17.883362: Yayy! New best EMA pseudo Dice: 0.6947000026702881 
2025-01-26 12:39:20.205780:  
2025-01-26 12:39:20.208668: Epoch 19 
2025-01-26 12:39:20.211312: Current learning rate: 0.00983 
2025-01-26 12:40:09.211601: train_loss -0.6642 
2025-01-26 12:40:09.217629: val_loss -0.6831 
2025-01-26 12:40:09.220912: Pseudo dice [np.float32(0.9124), np.float32(0.7728)] 
2025-01-26 12:40:09.223324: Epoch time: 49.01 s 
2025-01-26 12:40:09.226055: Yayy! New best EMA pseudo Dice: 0.7095000147819519 
2025-01-26 12:40:11.025752:  
2025-01-26 12:40:11.028277: Epoch 20 
2025-01-26 12:40:11.030984: Current learning rate: 0.00982 
2025-01-26 12:40:59.560311: train_loss -0.6508 
2025-01-26 12:40:59.564751: val_loss -0.686 
2025-01-26 12:40:59.567631: Pseudo dice [np.float32(0.9268), np.float32(0.7219)] 
2025-01-26 12:40:59.570487: Epoch time: 48.54 s 
2025-01-26 12:40:59.573113: Yayy! New best EMA pseudo Dice: 0.7210000157356262 
2025-01-26 12:41:01.336739:  
2025-01-26 12:41:01.339476: Epoch 21 
2025-01-26 12:41:01.341858: Current learning rate: 0.00981 
2025-01-26 12:41:49.935696: train_loss -0.6607 
2025-01-26 12:41:49.941567: val_loss -0.6457 
2025-01-26 12:41:49.944311: Pseudo dice [np.float32(0.9248), np.float32(0.6559)] 
2025-01-26 12:41:49.946413: Epoch time: 48.6 s 
2025-01-26 12:41:49.949035: Yayy! New best EMA pseudo Dice: 0.7279000282287598 
2025-01-26 12:41:51.665069:  
2025-01-26 12:41:51.667685: Epoch 22 
2025-01-26 12:41:51.670549: Current learning rate: 0.0098 
2025-01-26 12:42:41.172810: train_loss -0.6719 
2025-01-26 12:42:41.176824: val_loss -0.6967 
2025-01-26 12:42:41.179727: Pseudo dice [np.float32(0.9371), np.float32(0.7938)] 
2025-01-26 12:42:41.182293: Epoch time: 49.51 s 
2025-01-26 12:42:41.185057: Yayy! New best EMA pseudo Dice: 0.7416999936103821 
2025-01-26 12:42:42.938005:  
2025-01-26 12:42:42.941282: Epoch 23 
2025-01-26 12:42:42.944511: Current learning rate: 0.00979 
2025-01-26 12:43:31.828557: train_loss -0.679 
2025-01-26 12:43:31.835199: val_loss -0.6711 
2025-01-26 12:43:31.838175: Pseudo dice [np.float32(0.9232), np.float32(0.7069)] 
2025-01-26 12:43:31.841221: Epoch time: 48.89 s 
2025-01-26 12:43:31.844219: Yayy! New best EMA pseudo Dice: 0.7490000128746033 
2025-01-26 12:43:33.632518:  
2025-01-26 12:43:33.635419: Epoch 24 
2025-01-26 12:43:33.638508: Current learning rate: 0.00978 
2025-01-26 12:44:22.567585: train_loss -0.6661 
2025-01-26 12:44:22.572337: val_loss -0.6363 
2025-01-26 12:44:22.574998: Pseudo dice [np.float32(0.9289), np.float32(0.7264)] 
2025-01-26 12:44:22.577687: Epoch time: 48.94 s 
2025-01-26 12:44:22.580309: Yayy! New best EMA pseudo Dice: 0.7569000124931335 
2025-01-26 12:44:24.368196:  
2025-01-26 12:44:24.371583: Epoch 25 
2025-01-26 12:44:24.374790: Current learning rate: 0.00977 
2025-01-26 12:45:12.904199: train_loss -0.6686 
2025-01-26 12:45:12.910568: val_loss -0.6351 
2025-01-26 12:45:12.913274: Pseudo dice [np.float32(0.9068), np.float32(0.6446)] 
2025-01-26 12:45:12.916167: Epoch time: 48.54 s 
2025-01-26 12:45:12.918880: Yayy! New best EMA pseudo Dice: 0.7588000297546387 
2025-01-26 12:45:14.682766:  
2025-01-26 12:45:14.685803: Epoch 26 
2025-01-26 12:45:14.688798: Current learning rate: 0.00977 
2025-01-26 12:46:03.225990: train_loss -0.68 
2025-01-26 12:46:03.230642: val_loss -0.6603 
2025-01-26 12:46:03.233299: Pseudo dice [np.float32(0.9243), np.float32(0.6857)] 
2025-01-26 12:46:03.235798: Epoch time: 48.54 s 
2025-01-26 12:46:03.238497: Yayy! New best EMA pseudo Dice: 0.7634000182151794 
2025-01-26 12:46:05.009139:  
2025-01-26 12:46:05.011698: Epoch 27 
2025-01-26 12:46:05.015064: Current learning rate: 0.00976 
2025-01-26 12:46:53.926864: train_loss -0.712 
2025-01-26 12:46:53.932829: val_loss -0.6741 
2025-01-26 12:46:53.935330: Pseudo dice [np.float32(0.9243), np.float32(0.7483)] 
2025-01-26 12:46:53.937696: Epoch time: 48.92 s 
2025-01-26 12:46:53.940154: Yayy! New best EMA pseudo Dice: 0.7706999778747559 
2025-01-26 12:46:55.694862:  
2025-01-26 12:46:55.698296: Epoch 28 
2025-01-26 12:46:55.701541: Current learning rate: 0.00975 
2025-01-26 12:47:44.365449: train_loss -0.6854 
2025-01-26 12:47:44.370301: val_loss -0.7007 
2025-01-26 12:47:44.373593: Pseudo dice [np.float32(0.9332), np.float32(0.8045)] 
2025-01-26 12:47:44.376514: Epoch time: 48.67 s 
2025-01-26 12:47:44.379519: Yayy! New best EMA pseudo Dice: 0.7804999947547913 
2025-01-26 12:47:46.191123:  
2025-01-26 12:47:46.194001: Epoch 29 
2025-01-26 12:47:46.196957: Current learning rate: 0.00974 
2025-01-26 12:48:34.410575: train_loss -0.6895 
2025-01-26 12:48:34.416585: val_loss -0.6584 
2025-01-26 12:48:34.419470: Pseudo dice [np.float32(0.9126), np.float32(0.7282)] 
2025-01-26 12:48:34.422203: Epoch time: 48.22 s 
2025-01-26 12:48:34.424729: Yayy! New best EMA pseudo Dice: 0.784500002861023 
2025-01-26 12:48:36.185552:  
2025-01-26 12:48:36.188950: Epoch 30 
2025-01-26 12:48:36.191913: Current learning rate: 0.00973 
2025-01-26 12:49:24.745062: train_loss -0.7012 
2025-01-26 12:49:24.749992: val_loss -0.7042 
2025-01-26 12:49:24.752584: Pseudo dice [np.float32(0.9266), np.float32(0.7889)] 
2025-01-26 12:49:24.755579: Epoch time: 48.56 s 
2025-01-26 12:49:24.758768: Yayy! New best EMA pseudo Dice: 0.7918000221252441 
2025-01-26 12:49:26.527268:  
2025-01-26 12:49:26.530227: Epoch 31 
2025-01-26 12:49:26.533326: Current learning rate: 0.00972 
2025-01-26 12:50:15.376551: train_loss -0.6989 
2025-01-26 12:50:15.382690: val_loss -0.7225 
2025-01-26 12:50:15.385233: Pseudo dice [np.float32(0.9304), np.float32(0.8019)] 
2025-01-26 12:50:15.387968: Epoch time: 48.85 s 
2025-01-26 12:50:15.390618: Yayy! New best EMA pseudo Dice: 0.7991999983787537 
2025-01-26 12:50:17.188383:  
2025-01-26 12:50:17.191729: Epoch 32 
2025-01-26 12:50:17.194384: Current learning rate: 0.00971 
2025-01-26 12:51:05.788152: train_loss -0.721 
2025-01-26 12:51:05.793200: val_loss -0.7482 
2025-01-26 12:51:05.796217: Pseudo dice [np.float32(0.9458), np.float32(0.8453)] 
2025-01-26 12:51:05.798677: Epoch time: 48.6 s 
2025-01-26 12:51:05.801371: Yayy! New best EMA pseudo Dice: 0.808899998664856 
2025-01-26 12:51:07.604426:  
2025-01-26 12:51:07.609428: Epoch 33 
2025-01-26 12:51:07.612345: Current learning rate: 0.0097 
2025-01-26 12:51:56.926785: train_loss -0.7138 
2025-01-26 12:51:56.932587: val_loss -0.7032 
2025-01-26 12:51:56.935247: Pseudo dice [np.float32(0.9237), np.float32(0.7845)] 
2025-01-26 12:51:56.937855: Epoch time: 49.32 s 
2025-01-26 12:51:56.940660: Yayy! New best EMA pseudo Dice: 0.8133999705314636 
2025-01-26 12:51:58.689509:  
2025-01-26 12:51:58.692776: Epoch 34 
2025-01-26 12:51:58.696188: Current learning rate: 0.00969 
2025-01-26 12:52:47.287557: train_loss -0.7228 
2025-01-26 12:52:47.292089: val_loss -0.7049 
2025-01-26 12:52:47.294771: Pseudo dice [np.float32(0.9355), np.float32(0.7675)] 
2025-01-26 12:52:47.297718: Epoch time: 48.6 s 
2025-01-26 12:52:47.300266: Yayy! New best EMA pseudo Dice: 0.8172000050544739 
2025-01-26 12:52:49.104208:  
2025-01-26 12:52:49.107463: Epoch 35 
2025-01-26 12:52:49.110374: Current learning rate: 0.00968 
2025-01-26 12:53:37.656389: train_loss -0.7081 
2025-01-26 12:53:37.663052: val_loss -0.7138 
2025-01-26 12:53:37.666090: Pseudo dice [np.float32(0.9368), np.float32(0.7885)] 
2025-01-26 12:53:37.669031: Epoch time: 48.55 s 
2025-01-26 12:53:37.671711: Yayy! New best EMA pseudo Dice: 0.8217999935150146 
2025-01-26 12:53:39.473360:  
2025-01-26 12:53:39.476282: Epoch 36 
2025-01-26 12:53:39.479116: Current learning rate: 0.00968 
2025-01-26 12:54:27.889540: train_loss -0.7207 
2025-01-26 12:54:27.894232: val_loss -0.6555 
2025-01-26 12:54:27.897038: Pseudo dice [np.float32(0.9258), np.float32(0.7332)] 
2025-01-26 12:54:27.899336: Epoch time: 48.42 s 
2025-01-26 12:54:27.902064: Yayy! New best EMA pseudo Dice: 0.8224999904632568 
2025-01-26 12:54:30.400216:  
2025-01-26 12:54:30.403520: Epoch 37 
2025-01-26 12:54:30.406713: Current learning rate: 0.00967 
2025-01-26 12:55:19.071757: train_loss -0.7246 
2025-01-26 12:55:19.078755: val_loss -0.7112 
2025-01-26 12:55:19.081741: Pseudo dice [np.float32(0.928), np.float32(0.7699)] 
2025-01-26 12:55:19.084247: Epoch time: 48.67 s 
2025-01-26 12:55:19.087028: Yayy! New best EMA pseudo Dice: 0.8252000212669373 
2025-01-26 12:55:20.905590:  
2025-01-26 12:55:20.908488: Epoch 38 
2025-01-26 12:55:20.911036: Current learning rate: 0.00966 
2025-01-26 12:56:09.505271: train_loss -0.7227 
2025-01-26 12:56:09.509334: val_loss -0.7052 
2025-01-26 12:56:09.511930: Pseudo dice [np.float32(0.9369), np.float32(0.8198)] 
2025-01-26 12:56:09.514487: Epoch time: 48.6 s 
2025-01-26 12:56:09.517215: Yayy! New best EMA pseudo Dice: 0.8305000066757202 
2025-01-26 12:56:11.359693:  
2025-01-26 12:56:11.363150: Epoch 39 
2025-01-26 12:56:11.366469: Current learning rate: 0.00965 
2025-01-26 12:56:59.853368: train_loss -0.738 
2025-01-26 12:56:59.859602: val_loss -0.698 
2025-01-26 12:56:59.862499: Pseudo dice [np.float32(0.9249), np.float32(0.7871)] 
2025-01-26 12:56:59.865158: Epoch time: 48.49 s 
2025-01-26 12:56:59.867510: Yayy! New best EMA pseudo Dice: 0.8330000042915344 
2025-01-26 12:57:01.687082:  
2025-01-26 12:57:01.690745: Epoch 40 
2025-01-26 12:57:01.694272: Current learning rate: 0.00964 
2025-01-26 12:57:50.513880: train_loss -0.7311 
2025-01-26 12:57:50.518295: val_loss -0.7093 
2025-01-26 12:57:50.521044: Pseudo dice [np.float32(0.9326), np.float32(0.7179)] 
2025-01-26 12:57:50.523956: Epoch time: 48.83 s 
2025-01-26 12:57:51.744992:  
2025-01-26 12:57:51.748173: Epoch 41 
2025-01-26 12:57:51.750954: Current learning rate: 0.00963 
2025-01-26 12:58:40.710614: train_loss -0.7255 
2025-01-26 12:58:40.716835: val_loss -0.6988 
2025-01-26 12:58:40.719925: Pseudo dice [np.float32(0.9355), np.float32(0.7778)] 
2025-01-26 12:58:40.722636: Epoch time: 48.97 s 
2025-01-26 12:58:40.725368: Yayy! New best EMA pseudo Dice: 0.8346999883651733 
2025-01-26 12:58:42.458146:  
2025-01-26 12:58:42.461342: Epoch 42 
2025-01-26 12:58:42.464791: Current learning rate: 0.00962 
2025-01-26 12:59:31.242861: train_loss -0.7539 
2025-01-26 12:59:31.247501: val_loss -0.7138 
2025-01-26 12:59:31.250557: Pseudo dice [np.float32(0.9456), np.float32(0.8386)] 
2025-01-26 12:59:31.253605: Epoch time: 48.79 s 
2025-01-26 12:59:31.256494: Yayy! New best EMA pseudo Dice: 0.840399980545044 
2025-01-26 12:59:33.040749:  
2025-01-26 12:59:33.043819: Epoch 43 
2025-01-26 12:59:33.046430: Current learning rate: 0.00961 
2025-01-26 13:00:22.369356: train_loss -0.7416 
2025-01-26 13:00:22.375241: val_loss -0.7131 
2025-01-26 13:00:22.378109: Pseudo dice [np.float32(0.9282), np.float32(0.7764)] 
2025-01-26 13:00:22.380950: Epoch time: 49.33 s 
2025-01-26 13:00:22.383390: Yayy! New best EMA pseudo Dice: 0.8416000008583069 
2025-01-26 13:00:24.156579:  
2025-01-26 13:00:24.159990: Epoch 44 
2025-01-26 13:00:24.163207: Current learning rate: 0.0096 
2025-01-26 13:01:12.886112: train_loss -0.7273 
2025-01-26 13:01:12.890189: val_loss -0.7399 
2025-01-26 13:01:12.893333: Pseudo dice [np.float32(0.9369), np.float32(0.7861)] 
2025-01-26 13:01:12.896104: Epoch time: 48.73 s 
2025-01-26 13:01:12.898678: Yayy! New best EMA pseudo Dice: 0.8435999751091003 
2025-01-26 13:01:14.629030:  
2025-01-26 13:01:14.632130: Epoch 45 
2025-01-26 13:01:14.634625: Current learning rate: 0.00959 
2025-01-26 13:02:03.536151: train_loss -0.7475 
2025-01-26 13:02:03.542681: val_loss -0.7035 
2025-01-26 13:02:03.545562: Pseudo dice [np.float32(0.9353), np.float32(0.8269)] 
2025-01-26 13:02:03.547921: Epoch time: 48.91 s 
2025-01-26 13:02:03.550310: Yayy! New best EMA pseudo Dice: 0.8474000096321106 
2025-01-26 13:02:05.287132:  
2025-01-26 13:02:05.290317: Epoch 46 
2025-01-26 13:02:05.293465: Current learning rate: 0.00959 
2025-01-26 13:02:53.764077: train_loss -0.7563 
2025-01-26 13:02:53.768878: val_loss -0.7319 
2025-01-26 13:02:53.772108: Pseudo dice [np.float32(0.9487), np.float32(0.8371)] 
2025-01-26 13:02:53.774845: Epoch time: 48.48 s 
2025-01-26 13:02:53.777565: Yayy! New best EMA pseudo Dice: 0.8518999814987183 
2025-01-26 13:02:55.518320:  
2025-01-26 13:02:55.521330: Epoch 47 
2025-01-26 13:02:55.524353: Current learning rate: 0.00958 
2025-01-26 13:03:44.135854: train_loss -0.7463 
2025-01-26 13:03:44.141765: val_loss -0.7172 
2025-01-26 13:03:44.144580: Pseudo dice [np.float32(0.9465), np.float32(0.7794)] 
2025-01-26 13:03:44.147476: Epoch time: 48.62 s 
2025-01-26 13:03:44.150508: Yayy! New best EMA pseudo Dice: 0.8529999852180481 
2025-01-26 13:03:45.883925:  
2025-01-26 13:03:45.886983: Epoch 48 
2025-01-26 13:03:45.889843: Current learning rate: 0.00957 
2025-01-26 13:04:34.182960: train_loss -0.7397 
2025-01-26 13:04:34.187767: val_loss -0.7252 
2025-01-26 13:04:34.190969: Pseudo dice [np.float32(0.9372), np.float32(0.8084)] 
2025-01-26 13:04:34.194206: Epoch time: 48.3 s 
2025-01-26 13:04:34.196786: Yayy! New best EMA pseudo Dice: 0.8550000190734863 
2025-01-26 13:04:35.979831:  
2025-01-26 13:04:35.982727: Epoch 49 
2025-01-26 13:04:35.985539: Current learning rate: 0.00956 
2025-01-26 13:05:24.990092: train_loss -0.7523 
2025-01-26 13:05:24.998840: val_loss -0.6979 
2025-01-26 13:05:25.001840: Pseudo dice [np.float32(0.9381), np.float32(0.7843)] 
2025-01-26 13:05:25.005103: Epoch time: 49.01 s 
2025-01-26 13:05:25.520301: Yayy! New best EMA pseudo Dice: 0.8555999994277954 
2025-01-26 13:05:27.297872:  
2025-01-26 13:05:27.300827: Epoch 50 
2025-01-26 13:05:27.303839: Current learning rate: 0.00955 
2025-01-26 13:06:15.958355: train_loss -0.7425 
2025-01-26 13:06:15.961345: val_loss -0.7081 
2025-01-26 13:06:15.964106: Pseudo dice [np.float32(0.9427), np.float32(0.8026)] 
2025-01-26 13:06:15.966888: Epoch time: 48.66 s 
2025-01-26 13:06:15.969654: Yayy! New best EMA pseudo Dice: 0.8572999835014343 
2025-01-26 13:06:17.780170:  
2025-01-26 13:06:17.783018: Epoch 51 
2025-01-26 13:06:17.785788: Current learning rate: 0.00954 
2025-01-26 13:07:06.052459: train_loss -0.7481 
2025-01-26 13:07:06.059058: val_loss -0.7391 
2025-01-26 13:07:06.061596: Pseudo dice [np.float32(0.9375), np.float32(0.7987)] 
2025-01-26 13:07:06.064262: Epoch time: 48.27 s 
2025-01-26 13:07:06.067048: Yayy! New best EMA pseudo Dice: 0.8583999872207642 
2025-01-26 13:07:07.806593:  
2025-01-26 13:07:07.809699: Epoch 52 
2025-01-26 13:07:07.813176: Current learning rate: 0.00953 
2025-01-26 13:07:56.918828: train_loss -0.7568 
2025-01-26 13:07:56.922883: val_loss -0.6963 
2025-01-26 13:07:56.925627: Pseudo dice [np.float32(0.9346), np.float32(0.8302)] 
2025-01-26 13:07:56.928417: Epoch time: 49.11 s 
2025-01-26 13:07:56.931543: Yayy! New best EMA pseudo Dice: 0.86080002784729 
2025-01-26 13:07:58.648342:  
2025-01-26 13:07:58.651564: Epoch 53 
2025-01-26 13:07:58.654651: Current learning rate: 0.00952 
2025-01-26 13:08:47.693707: train_loss -0.7454 
2025-01-26 13:08:47.700325: val_loss -0.6405 
2025-01-26 13:08:47.702677: Pseudo dice [np.float32(0.9288), np.float32(0.728)] 
2025-01-26 13:08:47.705099: Epoch time: 49.05 s 
2025-01-26 13:08:48.875199:  
2025-01-26 13:08:48.878525: Epoch 54 
2025-01-26 13:08:48.881529: Current learning rate: 0.00951 
2025-01-26 13:09:37.374115: train_loss -0.7313 
2025-01-26 13:09:37.377418: val_loss -0.7028 
2025-01-26 13:09:37.380586: Pseudo dice [np.float32(0.9175), np.float32(0.7572)] 
2025-01-26 13:09:37.383312: Epoch time: 48.5 s 
2025-01-26 13:09:39.180245:  
2025-01-26 13:09:39.184049: Epoch 55 
2025-01-26 13:09:39.187052: Current learning rate: 0.0095 
2025-01-26 13:10:27.990161: train_loss -0.7339 
2025-01-26 13:10:27.997411: val_loss -0.6823 
2025-01-26 13:10:28.000156: Pseudo dice [np.float32(0.9474), np.float32(0.8509)] 
2025-01-26 13:10:28.002579: Epoch time: 48.81 s 
2025-01-26 13:10:29.171207:  
2025-01-26 13:10:29.174030: Epoch 56 
2025-01-26 13:10:29.176915: Current learning rate: 0.00949 
2025-01-26 13:11:17.514927: train_loss -0.7626 
2025-01-26 13:11:17.518904: val_loss -0.7177 
2025-01-26 13:11:17.522096: Pseudo dice [np.float32(0.9272), np.float32(0.808)] 
2025-01-26 13:11:17.525522: Epoch time: 48.35 s 
2025-01-26 13:11:18.696427:  
2025-01-26 13:11:18.699162: Epoch 57 
2025-01-26 13:11:18.701737: Current learning rate: 0.00949 
2025-01-26 13:12:07.618714: train_loss -0.7307 
2025-01-26 13:12:07.625960: val_loss -0.7064 
2025-01-26 13:12:07.628681: Pseudo dice [np.float32(0.933), np.float32(0.8184)] 
2025-01-26 13:12:07.631399: Epoch time: 48.92 s 
2025-01-26 13:12:07.634276: Yayy! New best EMA pseudo Dice: 0.8622000217437744 
2025-01-26 13:12:09.438263:  
2025-01-26 13:12:09.441423: Epoch 58 
2025-01-26 13:12:09.444471: Current learning rate: 0.00948 
2025-01-26 13:12:58.342598: train_loss -0.744 
2025-01-26 13:12:58.346348: val_loss -0.721 
2025-01-26 13:12:58.349348: Pseudo dice [np.float32(0.9363), np.float32(0.8156)] 
2025-01-26 13:12:58.352116: Epoch time: 48.91 s 
2025-01-26 13:12:58.354724: Yayy! New best EMA pseudo Dice: 0.8636000156402588 
2025-01-26 13:13:00.124965:  
2025-01-26 13:13:00.128312: Epoch 59 
2025-01-26 13:13:00.130921: Current learning rate: 0.00947 
2025-01-26 13:13:49.311316: train_loss -0.7284 
2025-01-26 13:13:49.318215: val_loss -0.7268 
2025-01-26 13:13:49.320822: Pseudo dice [np.float32(0.937), np.float32(0.7573)] 
2025-01-26 13:13:49.323289: Epoch time: 49.19 s 
2025-01-26 13:13:50.560913:  
2025-01-26 13:13:50.564387: Epoch 60 
2025-01-26 13:13:50.567280: Current learning rate: 0.00946 
2025-01-26 13:14:39.037716: train_loss -0.7565 
2025-01-26 13:14:39.041703: val_loss -0.7416 
2025-01-26 13:14:39.044421: Pseudo dice [np.float32(0.9443), np.float32(0.8137)] 
2025-01-26 13:14:39.047121: Epoch time: 48.48 s 
2025-01-26 13:14:39.049773: Yayy! New best EMA pseudo Dice: 0.8636000156402588 
2025-01-26 13:14:40.817186:  
2025-01-26 13:14:40.820342: Epoch 61 
2025-01-26 13:14:40.823183: Current learning rate: 0.00945 
2025-01-26 13:15:29.960690: train_loss -0.7513 
2025-01-26 13:15:29.967910: val_loss -0.7622 
2025-01-26 13:15:29.970970: Pseudo dice [np.float32(0.9455), np.float32(0.8115)] 
2025-01-26 13:15:29.973615: Epoch time: 49.14 s 
2025-01-26 13:15:29.976191: Yayy! New best EMA pseudo Dice: 0.8651000261306763 
2025-01-26 13:15:31.777116:  
2025-01-26 13:15:31.780776: Epoch 62 
2025-01-26 13:15:31.783378: Current learning rate: 0.00944 
2025-01-26 13:16:20.178683: train_loss -0.7762 
2025-01-26 13:16:20.182938: val_loss -0.7388 
2025-01-26 13:16:20.185963: Pseudo dice [np.float32(0.9419), np.float32(0.8451)] 
2025-01-26 13:16:20.189107: Epoch time: 48.4 s 
2025-01-26 13:16:20.192432: Yayy! New best EMA pseudo Dice: 0.8679999709129333 
2025-01-26 13:16:21.983541:  
2025-01-26 13:16:21.986696: Epoch 63 
2025-01-26 13:16:21.989792: Current learning rate: 0.00943 
2025-01-26 13:17:10.974628: train_loss -0.7711 
2025-01-26 13:17:10.980637: val_loss -0.7669 
2025-01-26 13:17:10.983283: Pseudo dice [np.float32(0.9508), np.float32(0.802)] 
2025-01-26 13:17:10.985667: Epoch time: 48.99 s 
2025-01-26 13:17:10.988046: Yayy! New best EMA pseudo Dice: 0.8687999844551086 
2025-01-26 13:17:12.728860:  
2025-01-26 13:17:12.732147: Epoch 64 
2025-01-26 13:17:12.735002: Current learning rate: 0.00942 
2025-01-26 13:18:01.154116: train_loss -0.7673 
2025-01-26 13:18:01.158128: val_loss -0.6768 
2025-01-26 13:18:01.161497: Pseudo dice [np.float32(0.9235), np.float32(0.8243)] 
2025-01-26 13:18:01.164371: Epoch time: 48.43 s 
2025-01-26 13:18:01.167072: Yayy! New best EMA pseudo Dice: 0.8693000078201294 
2025-01-26 13:18:02.982861:  
2025-01-26 13:18:02.986161: Epoch 65 
2025-01-26 13:18:02.989388: Current learning rate: 0.00941 
2025-01-26 13:18:52.001909: train_loss -0.7734 
2025-01-26 13:18:52.009422: val_loss -0.72 
2025-01-26 13:18:52.012471: Pseudo dice [np.float32(0.925), np.float32(0.8193)] 
2025-01-26 13:18:52.015099: Epoch time: 49.02 s 
2025-01-26 13:18:52.017699: Yayy! New best EMA pseudo Dice: 0.8695999979972839 
2025-01-26 13:18:53.788181:  
2025-01-26 13:18:53.790708: Epoch 66 
2025-01-26 13:18:53.793526: Current learning rate: 0.0094 
2025-01-26 13:19:42.335632: train_loss -0.7695 
2025-01-26 13:19:42.339578: val_loss -0.7668 
2025-01-26 13:19:42.342510: Pseudo dice [np.float32(0.9521), np.float32(0.8461)] 
2025-01-26 13:19:42.345272: Epoch time: 48.55 s 
2025-01-26 13:19:42.347866: Yayy! New best EMA pseudo Dice: 0.8725000023841858 
2025-01-26 13:19:44.138102:  
2025-01-26 13:19:44.141381: Epoch 67 
2025-01-26 13:19:44.144219: Current learning rate: 0.00939 
2025-01-26 13:20:32.795384: train_loss -0.7468 
2025-01-26 13:20:32.801767: val_loss -0.6825 
2025-01-26 13:20:32.804502: Pseudo dice [np.float32(0.9431), np.float32(0.7647)] 
2025-01-26 13:20:32.806773: Epoch time: 48.66 s 
2025-01-26 13:20:34.011810:  
2025-01-26 13:20:34.015085: Epoch 68 
2025-01-26 13:20:34.018229: Current learning rate: 0.00939 
2025-01-26 13:21:23.260800: train_loss -0.7664 
2025-01-26 13:21:23.264800: val_loss -0.7335 
2025-01-26 13:21:23.268286: Pseudo dice [np.float32(0.9522), np.float32(0.7993)] 
2025-01-26 13:21:23.271253: Epoch time: 49.25 s 
2025-01-26 13:21:24.492786:  
2025-01-26 13:21:24.497338: Epoch 69 
2025-01-26 13:21:24.500354: Current learning rate: 0.00938 
2025-01-26 13:22:13.302177: train_loss -0.7749 
2025-01-26 13:22:13.311540: val_loss -0.7616 
2025-01-26 13:22:13.314303: Pseudo dice [np.float32(0.9547), np.float32(0.8442)] 
2025-01-26 13:22:13.316840: Epoch time: 48.81 s 
2025-01-26 13:22:13.319323: Yayy! New best EMA pseudo Dice: 0.8740000128746033 
2025-01-26 13:22:15.092081:  
2025-01-26 13:22:15.095306: Epoch 70 
2025-01-26 13:22:15.098085: Current learning rate: 0.00937 
2025-01-26 13:23:04.938451: train_loss -0.7712 
2025-01-26 13:23:04.941975: val_loss -0.723 
2025-01-26 13:23:04.944955: Pseudo dice [np.float32(0.9358), np.float32(0.8273)] 
2025-01-26 13:23:04.947778: Epoch time: 49.85 s 
2025-01-26 13:23:04.950473: Yayy! New best EMA pseudo Dice: 0.8748000264167786 
2025-01-26 13:23:06.755142:  
2025-01-26 13:23:06.758378: Epoch 71 
2025-01-26 13:23:06.761918: Current learning rate: 0.00936 
2025-01-26 13:23:55.489962: train_loss -0.7652 
2025-01-26 13:23:55.496644: val_loss -0.7494 
2025-01-26 13:23:55.499506: Pseudo dice [np.float32(0.9411), np.float32(0.8307)] 
2025-01-26 13:23:55.502303: Epoch time: 48.74 s 
2025-01-26 13:23:55.504928: Yayy! New best EMA pseudo Dice: 0.8758999705314636 
2025-01-26 13:23:57.261729:  
2025-01-26 13:23:57.265100: Epoch 72 
2025-01-26 13:23:57.268088: Current learning rate: 0.00935 
2025-01-26 13:24:45.948863: train_loss -0.7569 
2025-01-26 13:24:45.952733: val_loss -0.6704 
2025-01-26 13:24:45.956241: Pseudo dice [np.float32(0.9196), np.float32(0.7846)] 
2025-01-26 13:24:45.959158: Epoch time: 48.69 s 
2025-01-26 13:24:47.760559:  
2025-01-26 13:24:47.763638: Epoch 73 
2025-01-26 13:24:47.766429: Current learning rate: 0.00934 
2025-01-26 13:25:36.719783: train_loss -0.7503 
2025-01-26 13:25:36.729512: val_loss -0.6969 
2025-01-26 13:25:36.732225: Pseudo dice [np.float32(0.9371), np.float32(0.7881)] 
2025-01-26 13:25:36.735220: Epoch time: 48.96 s 
2025-01-26 13:25:37.940130:  
2025-01-26 13:25:37.943433: Epoch 74 
2025-01-26 13:25:37.946181: Current learning rate: 0.00933 
2025-01-26 13:26:26.410098: train_loss -0.7806 
2025-01-26 13:26:26.414325: val_loss -0.7616 
2025-01-26 13:26:26.417714: Pseudo dice [np.float32(0.9548), np.float32(0.8479)] 
2025-01-26 13:26:26.420710: Epoch time: 48.47 s 
2025-01-26 13:26:27.630385:  
2025-01-26 13:26:27.634117: Epoch 75 
2025-01-26 13:26:27.637561: Current learning rate: 0.00932 
2025-01-26 13:27:15.974942: train_loss -0.7828 
2025-01-26 13:27:15.983934: val_loss -0.7051 
2025-01-26 13:27:15.987618: Pseudo dice [np.float32(0.9247), np.float32(0.777)] 
2025-01-26 13:27:15.990933: Epoch time: 48.35 s 
2025-01-26 13:27:17.210432:  
2025-01-26 13:27:17.213505: Epoch 76 
2025-01-26 13:27:17.216575: Current learning rate: 0.00931 
2025-01-26 13:28:05.650963: train_loss -0.7378 
2025-01-26 13:28:05.654539: val_loss -0.7333 
2025-01-26 13:28:05.657526: Pseudo dice [np.float32(0.9387), np.float32(0.7552)] 
2025-01-26 13:28:05.660306: Epoch time: 48.44 s 
2025-01-26 13:28:06.865731:  
2025-01-26 13:28:06.868893: Epoch 77 
2025-01-26 13:28:06.871701: Current learning rate: 0.0093 
2025-01-26 13:28:55.526753: train_loss -0.7438 
2025-01-26 13:28:55.534492: val_loss -0.7182 
2025-01-26 13:28:55.537537: Pseudo dice [np.float32(0.931), np.float32(0.8341)] 
2025-01-26 13:28:55.540372: Epoch time: 48.66 s 
2025-01-26 13:28:56.805490:  
2025-01-26 13:28:56.808640: Epoch 78 
2025-01-26 13:28:56.812229: Current learning rate: 0.0093 
2025-01-26 13:29:45.193248: train_loss -0.788 
2025-01-26 13:29:45.197204: val_loss -0.7763 
2025-01-26 13:29:45.199628: Pseudo dice [np.float32(0.9471), np.float32(0.8619)] 
2025-01-26 13:29:45.202569: Epoch time: 48.39 s 
2025-01-26 13:29:46.431020:  
2025-01-26 13:29:46.434590: Epoch 79 
2025-01-26 13:29:46.438085: Current learning rate: 0.00929 
2025-01-26 13:30:34.900650: train_loss -0.7585 
2025-01-26 13:30:34.907361: val_loss -0.71 
2025-01-26 13:30:34.909885: Pseudo dice [np.float32(0.9385), np.float32(0.831)] 
2025-01-26 13:30:34.912322: Epoch time: 48.47 s 
2025-01-26 13:30:36.136350:  
2025-01-26 13:30:36.139325: Epoch 80 
2025-01-26 13:30:36.142052: Current learning rate: 0.00928 
2025-01-26 13:31:24.610995: train_loss -0.7939 
2025-01-26 13:31:24.615107: val_loss -0.7157 
2025-01-26 13:31:24.618115: Pseudo dice [np.float32(0.9474), np.float32(0.8595)] 
2025-01-26 13:31:24.620539: Epoch time: 48.48 s 
2025-01-26 13:31:24.623296: Yayy! New best EMA pseudo Dice: 0.878600001335144 
2025-01-26 13:31:26.427084:  
2025-01-26 13:31:26.430070: Epoch 81 
2025-01-26 13:31:26.432651: Current learning rate: 0.00927 
2025-01-26 13:32:15.160575: train_loss -0.787 
2025-01-26 13:32:15.167276: val_loss -0.7049 
2025-01-26 13:32:15.169827: Pseudo dice [np.float32(0.9406), np.float32(0.8361)] 
2025-01-26 13:32:15.172840: Epoch time: 48.73 s 
2025-01-26 13:32:15.175388: Yayy! New best EMA pseudo Dice: 0.8794999718666077 
2025-01-26 13:32:16.981317:  
2025-01-26 13:32:16.984586: Epoch 82 
2025-01-26 13:32:16.987446: Current learning rate: 0.00926 
2025-01-26 13:33:05.974217: train_loss -0.7655 
2025-01-26 13:33:05.978633: val_loss -0.7425 
2025-01-26 13:33:05.981790: Pseudo dice [np.float32(0.9496), np.float32(0.871)] 
2025-01-26 13:33:05.984919: Epoch time: 48.99 s 
2025-01-26 13:33:05.987861: Yayy! New best EMA pseudo Dice: 0.8826000094413757 
2025-01-26 13:33:07.758898:  
2025-01-26 13:33:07.761987: Epoch 83 
2025-01-26 13:33:07.764770: Current learning rate: 0.00925 
2025-01-26 13:33:56.120041: train_loss -0.7865 
2025-01-26 13:33:56.127120: val_loss -0.7359 
2025-01-26 13:33:56.129711: Pseudo dice [np.float32(0.9495), np.float32(0.8613)] 
2025-01-26 13:33:56.132389: Epoch time: 48.36 s 
2025-01-26 13:33:56.134957: Yayy! New best EMA pseudo Dice: 0.8848999738693237 
2025-01-26 13:33:57.926711:  
2025-01-26 13:33:57.929704: Epoch 84 
2025-01-26 13:33:57.932552: Current learning rate: 0.00924 
2025-01-26 13:34:46.275193: train_loss -0.7818 
2025-01-26 13:34:46.278853: val_loss -0.7137 
2025-01-26 13:34:46.281859: Pseudo dice [np.float32(0.9406), np.float32(0.7928)] 
2025-01-26 13:34:46.284867: Epoch time: 48.35 s 
2025-01-26 13:34:47.484725:  
2025-01-26 13:34:47.488071: Epoch 85 
2025-01-26 13:34:47.490809: Current learning rate: 0.00923 
2025-01-26 13:35:36.063100: train_loss -0.7741 
2025-01-26 13:35:36.070229: val_loss -0.7498 
2025-01-26 13:35:36.073319: Pseudo dice [np.float32(0.9502), np.float32(0.8505)] 
2025-01-26 13:35:36.076022: Epoch time: 48.58 s 
2025-01-26 13:35:37.276822:  
2025-01-26 13:35:37.279825: Epoch 86 
2025-01-26 13:35:37.282918: Current learning rate: 0.00922 
2025-01-26 13:36:25.950134: train_loss -0.7875 
2025-01-26 13:36:25.954175: val_loss -0.7346 
2025-01-26 13:36:25.957209: Pseudo dice [np.float32(0.9549), np.float32(0.8345)] 
2025-01-26 13:36:25.959961: Epoch time: 48.67 s 
2025-01-26 13:36:25.962687: Yayy! New best EMA pseudo Dice: 0.8858000040054321 
2025-01-26 13:36:27.722412:  
2025-01-26 13:36:27.725519: Epoch 87 
2025-01-26 13:36:27.728496: Current learning rate: 0.00921 
2025-01-26 13:37:16.337002: train_loss -0.779 
2025-01-26 13:37:16.343993: val_loss -0.7305 
2025-01-26 13:37:16.346776: Pseudo dice [np.float32(0.9398), np.float32(0.8391)] 
2025-01-26 13:37:16.349544: Epoch time: 48.62 s 
2025-01-26 13:37:16.352143: Yayy! New best EMA pseudo Dice: 0.8862000107765198 
2025-01-26 13:37:18.108930:  
2025-01-26 13:37:18.112211: Epoch 88 
2025-01-26 13:37:18.115155: Current learning rate: 0.0092 
2025-01-26 13:38:06.452219: train_loss -0.7838 
2025-01-26 13:38:06.455404: val_loss -0.7318 
2025-01-26 13:38:06.458102: Pseudo dice [np.float32(0.9514), np.float32(0.86)] 
2025-01-26 13:38:06.460571: Epoch time: 48.34 s 
2025-01-26 13:38:06.462958: Yayy! New best EMA pseudo Dice: 0.8881000280380249 
2025-01-26 13:38:08.201629:  
2025-01-26 13:38:08.204746: Epoch 89 
2025-01-26 13:38:08.207316: Current learning rate: 0.0092 
2025-01-26 13:38:57.397676: train_loss -0.7803 
2025-01-26 13:38:57.405209: val_loss -0.7535 
2025-01-26 13:38:57.407845: Pseudo dice [np.float32(0.948), np.float32(0.832)] 
2025-01-26 13:38:57.410628: Epoch time: 49.2 s 
2025-01-26 13:38:57.413424: Yayy! New best EMA pseudo Dice: 0.8883000016212463 
2025-01-26 13:38:59.871703:  
2025-01-26 13:38:59.880463: Epoch 90 
2025-01-26 13:38:59.883629: Current learning rate: 0.00919 
2025-01-26 13:39:48.213129: train_loss -0.7925 
2025-01-26 13:39:48.216857: val_loss -0.7575 
2025-01-26 13:39:48.220069: Pseudo dice [np.float32(0.9434), np.float32(0.8516)] 
2025-01-26 13:39:48.223126: Epoch time: 48.34 s 
2025-01-26 13:39:48.225514: Yayy! New best EMA pseudo Dice: 0.88919997215271 
2025-01-26 13:39:49.949646:  
2025-01-26 13:39:49.952786: Epoch 91 
2025-01-26 13:39:49.955645: Current learning rate: 0.00918 
2025-01-26 13:40:38.701653: train_loss -0.7804 
2025-01-26 13:40:38.708174: val_loss -0.7384 
2025-01-26 13:40:38.710853: Pseudo dice [np.float32(0.9444), np.float32(0.8545)] 
2025-01-26 13:40:38.713399: Epoch time: 48.75 s 
2025-01-26 13:40:38.715996: Yayy! New best EMA pseudo Dice: 0.8902000188827515 
2025-01-26 13:40:40.465558:  
2025-01-26 13:40:40.468551: Epoch 92 
2025-01-26 13:40:40.471622: Current learning rate: 0.00917 
2025-01-26 13:41:28.849906: train_loss -0.7894 
2025-01-26 13:41:28.853879: val_loss -0.7326 
2025-01-26 13:41:28.857033: Pseudo dice [np.float32(0.9512), np.float32(0.8594)] 
2025-01-26 13:41:28.859988: Epoch time: 48.39 s 
2025-01-26 13:41:28.862681: Yayy! New best EMA pseudo Dice: 0.8917999863624573 
2025-01-26 13:41:30.563897:  
2025-01-26 13:41:30.567112: Epoch 93 
2025-01-26 13:41:30.569762: Current learning rate: 0.00916 
2025-01-26 13:42:18.945000: train_loss -0.7893 
2025-01-26 13:42:18.952421: val_loss -0.744 
2025-01-26 13:42:18.955813: Pseudo dice [np.float32(0.9529), np.float32(0.8715)] 
2025-01-26 13:42:18.959140: Epoch time: 48.38 s 
2025-01-26 13:42:18.961922: Yayy! New best EMA pseudo Dice: 0.8938000202178955 
2025-01-26 13:42:20.709065:  
2025-01-26 13:42:20.712355: Epoch 94 
2025-01-26 13:42:20.715678: Current learning rate: 0.00915 
2025-01-26 13:43:09.172201: train_loss -0.7992 
2025-01-26 13:43:09.176227: val_loss -0.754 
2025-01-26 13:43:09.179700: Pseudo dice [np.float32(0.9457), np.float32(0.8696)] 
2025-01-26 13:43:09.182870: Epoch time: 48.46 s 
2025-01-26 13:43:09.185903: Yayy! New best EMA pseudo Dice: 0.8952000141143799 
2025-01-26 13:43:10.938851:  
2025-01-26 13:43:10.941976: Epoch 95 
2025-01-26 13:43:10.944580: Current learning rate: 0.00914 
2025-01-26 13:43:59.674982: train_loss -0.7712 
2025-01-26 13:43:59.682272: val_loss -0.7476 
2025-01-26 13:43:59.685005: Pseudo dice [np.float32(0.9512), np.float32(0.8305)] 
2025-01-26 13:43:59.687603: Epoch time: 48.74 s 
2025-01-26 13:44:00.866319:  
2025-01-26 13:44:00.870416: Epoch 96 
2025-01-26 13:44:00.873340: Current learning rate: 0.00913 
2025-01-26 13:44:49.363703: train_loss -0.7638 
2025-01-26 13:44:49.367570: val_loss -0.7768 
2025-01-26 13:44:49.370477: Pseudo dice [np.float32(0.9479), np.float32(0.8617)] 
2025-01-26 13:44:49.372980: Epoch time: 48.5 s 
2025-01-26 13:44:49.375388: Yayy! New best EMA pseudo Dice: 0.895799994468689 
2025-01-26 13:44:51.149173:  
2025-01-26 13:44:51.152478: Epoch 97 
2025-01-26 13:44:51.155799: Current learning rate: 0.00912 
2025-01-26 13:45:40.056020: train_loss -0.782 
2025-01-26 13:45:40.063353: val_loss -0.7305 
2025-01-26 13:45:40.066189: Pseudo dice [np.float32(0.9411), np.float32(0.8382)] 
2025-01-26 13:45:40.068744: Epoch time: 48.91 s 
2025-01-26 13:45:41.255751:  
2025-01-26 13:45:41.259224: Epoch 98 
2025-01-26 13:45:41.261888: Current learning rate: 0.00911 
2025-01-26 13:46:29.853555: train_loss -0.7999 
2025-01-26 13:46:29.856726: val_loss -0.7759 
2025-01-26 13:46:29.859555: Pseudo dice [np.float32(0.9498), np.float32(0.8328)] 
2025-01-26 13:46:29.862223: Epoch time: 48.6 s 
2025-01-26 13:46:31.046257:  
2025-01-26 13:46:31.049258: Epoch 99 
2025-01-26 13:46:31.051822: Current learning rate: 0.0091 
2025-01-26 13:47:19.972245: train_loss -0.7974 
2025-01-26 13:47:19.980844: val_loss -0.7699 
2025-01-26 13:47:19.983002: Pseudo dice [np.float32(0.9515), np.float32(0.8438)] 
2025-01-26 13:47:19.985445: Epoch time: 48.93 s 
2025-01-26 13:47:21.699979:  
2025-01-26 13:47:21.702794: Epoch 100 
2025-01-26 13:47:21.705885: Current learning rate: 0.0091 
2025-01-26 13:48:10.222953: train_loss -0.7792 
2025-01-26 13:48:10.226609: val_loss -0.7579 
2025-01-26 13:48:10.229041: Pseudo dice [np.float32(0.9527), np.float32(0.8753)] 
2025-01-26 13:48:10.231865: Epoch time: 48.52 s 
2025-01-26 13:48:10.234528: Yayy! New best EMA pseudo Dice: 0.8968999981880188 
2025-01-26 13:48:12.044554:  
2025-01-26 13:48:12.047297: Epoch 101 
2025-01-26 13:48:12.050066: Current learning rate: 0.00909 
2025-01-26 13:49:00.573349: train_loss -0.7907 
2025-01-26 13:49:00.579684: val_loss -0.7559 
2025-01-26 13:49:00.582650: Pseudo dice [np.float32(0.9543), np.float32(0.8685)] 
2025-01-26 13:49:00.585140: Epoch time: 48.53 s 
2025-01-26 13:49:00.587500: Yayy! New best EMA pseudo Dice: 0.8984000086784363 
2025-01-26 13:49:02.291605:  
2025-01-26 13:49:02.295197: Epoch 102 
2025-01-26 13:49:02.298433: Current learning rate: 0.00908 
2025-01-26 13:49:50.746443: train_loss -0.7957 
2025-01-26 13:49:50.750236: val_loss -0.7789 
2025-01-26 13:49:50.753212: Pseudo dice [np.float32(0.9514), np.float32(0.8729)] 
2025-01-26 13:49:50.755790: Epoch time: 48.46 s 
2025-01-26 13:49:50.758403: Yayy! New best EMA pseudo Dice: 0.8998000025749207 
2025-01-26 13:49:52.567641:  
2025-01-26 13:49:52.571079: Epoch 103 
2025-01-26 13:49:52.574762: Current learning rate: 0.00907 
2025-01-26 13:50:41.312261: train_loss -0.7975 
2025-01-26 13:50:41.319872: val_loss -0.7486 
2025-01-26 13:50:41.322734: Pseudo dice [np.float32(0.945), np.float32(0.828)] 
2025-01-26 13:50:41.325838: Epoch time: 48.75 s 
2025-01-26 13:50:42.509798:  
2025-01-26 13:50:42.513033: Epoch 104 
2025-01-26 13:50:42.515966: Current learning rate: 0.00906 
2025-01-26 13:51:31.040454: train_loss -0.7827 
2025-01-26 13:51:31.043840: val_loss -0.7384 
2025-01-26 13:51:31.047169: Pseudo dice [np.float32(0.946), np.float32(0.8675)] 
2025-01-26 13:51:31.049908: Epoch time: 48.53 s 
2025-01-26 13:51:32.263777:  
2025-01-26 13:51:32.266665: Epoch 105 
2025-01-26 13:51:32.269454: Current learning rate: 0.00905 
2025-01-26 13:52:20.820933: train_loss -0.7914 
2025-01-26 13:52:20.826606: val_loss -0.7362 
2025-01-26 13:52:20.829241: Pseudo dice [np.float32(0.9526), np.float32(0.7822)] 
2025-01-26 13:52:20.831872: Epoch time: 48.56 s 
2025-01-26 13:52:22.015519:  
2025-01-26 13:52:22.018779: Epoch 106 
2025-01-26 13:52:22.021856: Current learning rate: 0.00904 
2025-01-26 13:53:10.630780: train_loss -0.789 
2025-01-26 13:53:10.634337: val_loss -0.7877 
2025-01-26 13:53:10.637419: Pseudo dice [np.float32(0.9515), np.float32(0.8632)] 
2025-01-26 13:53:10.640273: Epoch time: 48.62 s 
2025-01-26 13:53:11.829013:  
2025-01-26 13:53:11.834120: Epoch 107 
2025-01-26 13:53:11.836712: Current learning rate: 0.00903 
2025-01-26 13:54:00.464990: train_loss -0.7802 
2025-01-26 13:54:00.471894: val_loss -0.7577 
2025-01-26 13:54:00.474699: Pseudo dice [np.float32(0.955), np.float32(0.8624)] 
2025-01-26 13:54:00.477315: Epoch time: 48.64 s 
2025-01-26 13:54:01.663220:  
2025-01-26 13:54:01.666523: Epoch 108 
2025-01-26 13:54:01.669804: Current learning rate: 0.00902 
2025-01-26 13:54:50.142219: train_loss -0.7777 
2025-01-26 13:54:50.145571: val_loss -0.768 
2025-01-26 13:54:50.148162: Pseudo dice [np.float32(0.946), np.float32(0.8585)] 
2025-01-26 13:54:50.150669: Epoch time: 48.48 s 
2025-01-26 13:54:52.016424:  
2025-01-26 13:54:52.019721: Epoch 109 
2025-01-26 13:54:52.022609: Current learning rate: 0.00901 
2025-01-26 13:55:40.887802: train_loss -0.8004 
2025-01-26 13:55:40.894447: val_loss -0.7639 
2025-01-26 13:55:40.897156: Pseudo dice [np.float32(0.95), np.float32(0.8675)] 
2025-01-26 13:55:40.899846: Epoch time: 48.87 s 
2025-01-26 13:55:42.084158:  
2025-01-26 13:55:42.087003: Epoch 110 
2025-01-26 13:55:42.089913: Current learning rate: 0.009 
2025-01-26 13:56:30.884853: train_loss -0.7923 
2025-01-26 13:56:30.887961: val_loss -0.7281 
2025-01-26 13:56:30.890891: Pseudo dice [np.float32(0.9452), np.float32(0.8474)] 
2025-01-26 13:56:30.893816: Epoch time: 48.8 s 
2025-01-26 13:56:32.082691:  
2025-01-26 13:56:32.086219: Epoch 111 
2025-01-26 13:56:32.089030: Current learning rate: 0.009 
2025-01-26 13:57:20.453168: train_loss -0.7924 
2025-01-26 13:57:20.460392: val_loss -0.7652 
2025-01-26 13:57:20.463212: Pseudo dice [np.float32(0.9504), np.float32(0.84)] 
2025-01-26 13:57:20.466071: Epoch time: 48.37 s 
2025-01-26 13:57:21.653659:  
2025-01-26 13:57:21.656900: Epoch 112 
2025-01-26 13:57:21.660373: Current learning rate: 0.00899 
2025-01-26 13:58:09.879305: train_loss -0.7869 
2025-01-26 13:58:09.882405: val_loss -0.7574 
2025-01-26 13:58:09.885129: Pseudo dice [np.float32(0.9522), np.float32(0.8716)] 
2025-01-26 13:58:09.887888: Epoch time: 48.23 s 
2025-01-26 13:58:09.890481: Yayy! New best EMA pseudo Dice: 0.9003000259399414 
2025-01-26 13:58:11.633548:  
2025-01-26 13:58:11.636589: Epoch 113 
2025-01-26 13:58:11.639419: Current learning rate: 0.00898 
2025-01-26 13:59:00.576030: train_loss -0.7705 
2025-01-26 13:59:00.582118: val_loss -0.7126 
2025-01-26 13:59:00.584851: Pseudo dice [np.float32(0.9501), np.float32(0.7887)] 
2025-01-26 13:59:00.587147: Epoch time: 48.94 s 
2025-01-26 13:59:01.780945:  
2025-01-26 13:59:01.784091: Epoch 114 
2025-01-26 13:59:01.787280: Current learning rate: 0.00897 
2025-01-26 13:59:50.093024: train_loss -0.7825 
2025-01-26 13:59:50.097277: val_loss -0.7667 
2025-01-26 13:59:50.100596: Pseudo dice [np.float32(0.942), np.float32(0.8635)] 
2025-01-26 13:59:50.103195: Epoch time: 48.31 s 
2025-01-26 13:59:51.286206:  
2025-01-26 13:59:51.289177: Epoch 115 
2025-01-26 13:59:51.291992: Current learning rate: 0.00896 
2025-01-26 14:00:39.861166: train_loss -0.8003 
2025-01-26 14:00:39.867594: val_loss -0.6933 
2025-01-26 14:00:39.870212: Pseudo dice [np.float32(0.9338), np.float32(0.859)] 
2025-01-26 14:00:39.872776: Epoch time: 48.58 s 
2025-01-26 14:00:41.079931:  
2025-01-26 14:00:41.083041: Epoch 116 
2025-01-26 14:00:41.085973: Current learning rate: 0.00895 
2025-01-26 14:01:29.484765: train_loss -0.7902 
2025-01-26 14:01:29.488686: val_loss -0.766 
2025-01-26 14:01:29.491571: Pseudo dice [np.float32(0.9469), np.float32(0.8769)] 
2025-01-26 14:01:29.494568: Epoch time: 48.41 s 
2025-01-26 14:01:30.696018:  
2025-01-26 14:01:30.699165: Epoch 117 
2025-01-26 14:01:30.702000: Current learning rate: 0.00894 
2025-01-26 14:02:19.444505: train_loss -0.782 
2025-01-26 14:02:19.451367: val_loss -0.7242 
2025-01-26 14:02:19.454176: Pseudo dice [np.float32(0.9448), np.float32(0.8421)] 
2025-01-26 14:02:19.456712: Epoch time: 48.75 s 
2025-01-26 14:02:20.659652:  
2025-01-26 14:02:20.662983: Epoch 118 
2025-01-26 14:02:20.665984: Current learning rate: 0.00893 
2025-01-26 14:03:09.966056: train_loss -0.7791 
2025-01-26 14:03:09.969840: val_loss -0.7351 
2025-01-26 14:03:09.972781: Pseudo dice [np.float32(0.9485), np.float32(0.8454)] 
2025-01-26 14:03:09.975128: Epoch time: 49.31 s 
2025-01-26 14:03:11.169906:  
2025-01-26 14:03:11.173310: Epoch 119 
2025-01-26 14:03:11.176349: Current learning rate: 0.00892 
2025-01-26 14:03:59.985752: train_loss -0.7759 
2025-01-26 14:03:59.993693: val_loss -0.7465 
2025-01-26 14:03:59.996858: Pseudo dice [np.float32(0.951), np.float32(0.8606)] 
2025-01-26 14:03:59.999757: Epoch time: 48.82 s 
2025-01-26 14:04:01.207982:  
2025-01-26 14:04:01.210774: Epoch 120 
2025-01-26 14:04:01.213638: Current learning rate: 0.00891 
2025-01-26 14:04:50.184296: train_loss -0.7937 
2025-01-26 14:04:50.187826: val_loss -0.7442 
2025-01-26 14:04:50.190706: Pseudo dice [np.float32(0.9544), np.float32(0.8596)] 
2025-01-26 14:04:50.193481: Epoch time: 48.98 s 
2025-01-26 14:04:51.401151:  
2025-01-26 14:04:51.404313: Epoch 121 
2025-01-26 14:04:51.407539: Current learning rate: 0.0089 
2025-01-26 14:05:39.907095: train_loss -0.7782 
2025-01-26 14:05:39.913923: val_loss -0.7444 
2025-01-26 14:05:39.916752: Pseudo dice [np.float32(0.9486), np.float32(0.8463)] 
2025-01-26 14:05:39.919249: Epoch time: 48.51 s 
2025-01-26 14:05:41.116943:  
2025-01-26 14:05:41.120117: Epoch 122 
2025-01-26 14:05:41.122954: Current learning rate: 0.00889 
2025-01-26 14:06:30.054250: train_loss -0.7886 
2025-01-26 14:06:30.059565: val_loss -0.7684 
2025-01-26 14:06:30.062384: Pseudo dice [np.float32(0.9521), np.float32(0.8772)] 
2025-01-26 14:06:30.065063: Epoch time: 48.94 s 
2025-01-26 14:06:30.067805: Yayy! New best EMA pseudo Dice: 0.9010999798774719 
2025-01-26 14:06:31.816595:  
2025-01-26 14:06:31.819029: Epoch 123 
2025-01-26 14:06:31.821671: Current learning rate: 0.00889 
2025-01-26 14:07:20.513238: train_loss -0.7782 
2025-01-26 14:07:20.520557: val_loss -0.7798 
2025-01-26 14:07:20.523176: Pseudo dice [np.float32(0.9545), np.float32(0.8629)] 
2025-01-26 14:07:20.526137: Epoch time: 48.7 s 
2025-01-26 14:07:20.528879: Yayy! New best EMA pseudo Dice: 0.9018999934196472 
2025-01-26 14:07:22.264293:  
2025-01-26 14:07:22.267403: Epoch 124 
2025-01-26 14:07:22.270498: Current learning rate: 0.00888 
2025-01-26 14:08:11.473365: train_loss -0.78 
2025-01-26 14:08:11.476941: val_loss -0.7422 
2025-01-26 14:08:11.479972: Pseudo dice [np.float32(0.9314), np.float32(0.7968)] 
2025-01-26 14:08:11.482556: Epoch time: 49.21 s 
2025-01-26 14:08:12.681784:  
2025-01-26 14:08:12.686810: Epoch 125 
2025-01-26 14:08:12.690006: Current learning rate: 0.00887 
2025-01-26 14:09:01.484600: train_loss -0.7636 
2025-01-26 14:09:01.491273: val_loss -0.7044 
2025-01-26 14:09:01.494166: Pseudo dice [np.float32(0.9493), np.float32(0.852)] 
2025-01-26 14:09:01.496801: Epoch time: 48.8 s 
2025-01-26 14:09:02.701893:  
2025-01-26 14:09:02.706619: Epoch 126 
2025-01-26 14:09:02.710092: Current learning rate: 0.00886 
2025-01-26 14:09:51.222192: train_loss -0.7942 
2025-01-26 14:09:51.225818: val_loss -0.7451 
2025-01-26 14:09:51.228792: Pseudo dice [np.float32(0.945), np.float32(0.8739)] 
2025-01-26 14:09:51.231481: Epoch time: 48.52 s 
2025-01-26 14:09:53.121690:  
2025-01-26 14:09:53.125751: Epoch 127 
2025-01-26 14:09:53.128503: Current learning rate: 0.00885 
2025-01-26 14:10:42.065394: train_loss -0.7837 
2025-01-26 14:10:42.072026: val_loss -0.7429 
2025-01-26 14:10:42.074496: Pseudo dice [np.float32(0.9463), np.float32(0.8616)] 
2025-01-26 14:10:42.077132: Epoch time: 48.94 s 
2025-01-26 14:10:43.275344:  
2025-01-26 14:10:43.278781: Epoch 128 
2025-01-26 14:10:43.281405: Current learning rate: 0.00884 
2025-01-26 14:11:31.926627: train_loss -0.8012 
2025-01-26 14:11:31.930117: val_loss -0.7462 
2025-01-26 14:11:31.933177: Pseudo dice [np.float32(0.9488), np.float32(0.8393)] 
2025-01-26 14:11:31.935982: Epoch time: 48.65 s 
2025-01-26 14:11:33.138697:  
2025-01-26 14:11:33.141746: Epoch 129 
2025-01-26 14:11:33.144488: Current learning rate: 0.00883 
2025-01-26 14:12:22.337602: train_loss -0.7858 
2025-01-26 14:12:22.344545: val_loss -0.75 
2025-01-26 14:12:22.346991: Pseudo dice [np.float32(0.9554), np.float32(0.8636)] 
2025-01-26 14:12:22.349539: Epoch time: 49.2 s 
2025-01-26 14:12:23.557781:  
2025-01-26 14:12:23.561016: Epoch 130 
2025-01-26 14:12:23.563715: Current learning rate: 0.00882 
2025-01-26 14:13:12.408817: train_loss -0.7865 
2025-01-26 14:13:12.412197: val_loss -0.758 
2025-01-26 14:13:12.415204: Pseudo dice [np.float32(0.9425), np.float32(0.8768)] 
2025-01-26 14:13:12.418179: Epoch time: 48.85 s 
2025-01-26 14:13:13.621689:  
2025-01-26 14:13:13.626743: Epoch 131 
2025-01-26 14:13:13.630024: Current learning rate: 0.00881 
2025-01-26 14:14:02.262454: train_loss -0.7898 
2025-01-26 14:14:02.269888: val_loss -0.7622 
2025-01-26 14:14:02.272749: Pseudo dice [np.float32(0.944), np.float32(0.8675)] 
2025-01-26 14:14:02.275553: Epoch time: 48.64 s 
2025-01-26 14:14:03.490830:  
2025-01-26 14:14:03.495089: Epoch 132 
2025-01-26 14:14:03.498171: Current learning rate: 0.0088 
2025-01-26 14:14:51.961632: train_loss -0.7862 
2025-01-26 14:14:51.965328: val_loss -0.7709 
2025-01-26 14:14:51.968412: Pseudo dice [np.float32(0.9543), np.float32(0.8786)] 
2025-01-26 14:14:51.970780: Epoch time: 48.47 s 
2025-01-26 14:14:51.973375: Yayy! New best EMA pseudo Dice: 0.9031999707221985 
2025-01-26 14:14:53.782375:  
2025-01-26 14:14:53.785361: Epoch 133 
2025-01-26 14:14:53.789121: Current learning rate: 0.00879 
2025-01-26 14:15:42.559101: train_loss -0.7756 
2025-01-26 14:15:42.566536: val_loss -0.7218 
2025-01-26 14:15:42.569407: Pseudo dice [np.float32(0.9443), np.float32(0.8476)] 
2025-01-26 14:15:42.572347: Epoch time: 48.78 s 
2025-01-26 14:15:43.771287:  
2025-01-26 14:15:43.774175: Epoch 134 
2025-01-26 14:15:43.779100: Current learning rate: 0.00879 
2025-01-26 14:16:32.678127: train_loss -0.7725 
2025-01-26 14:16:32.682187: val_loss -0.7105 
2025-01-26 14:16:32.685005: Pseudo dice [np.float32(0.9484), np.float32(0.8187)] 
2025-01-26 14:16:32.687497: Epoch time: 48.91 s 
2025-01-26 14:16:33.917044:  
2025-01-26 14:16:33.919986: Epoch 135 
2025-01-26 14:16:33.922399: Current learning rate: 0.00878 
2025-01-26 14:17:22.553910: train_loss -0.7746 
2025-01-26 14:17:22.560937: val_loss -0.6855 
2025-01-26 14:17:22.563616: Pseudo dice [np.float32(0.9499), np.float32(0.8633)] 
2025-01-26 14:17:22.566281: Epoch time: 48.64 s 
2025-01-26 14:17:23.781586:  
2025-01-26 14:17:23.784549: Epoch 136 
2025-01-26 14:17:23.787398: Current learning rate: 0.00877 
2025-01-26 14:18:12.490535: train_loss -0.7694 
2025-01-26 14:18:12.494208: val_loss -0.6672 
2025-01-26 14:18:12.497115: Pseudo dice [np.float32(0.9451), np.float32(0.8155)] 
2025-01-26 14:18:12.500206: Epoch time: 48.71 s 
2025-01-26 14:18:13.720924:  
2025-01-26 14:18:13.723702: Epoch 137 
2025-01-26 14:18:13.726491: Current learning rate: 0.00876 
2025-01-26 14:19:03.182114: train_loss -0.789 
2025-01-26 14:19:03.188797: val_loss -0.7016 
2025-01-26 14:19:03.191325: Pseudo dice [np.float32(0.9425), np.float32(0.8268)] 
2025-01-26 14:19:03.193693: Epoch time: 49.46 s 
2025-01-26 14:19:04.419024:  
2025-01-26 14:19:04.423008: Epoch 138 
2025-01-26 14:19:04.426035: Current learning rate: 0.00875 
2025-01-26 14:19:53.392912: train_loss -0.7798 
2025-01-26 14:19:53.396112: val_loss -0.7281 
2025-01-26 14:19:53.398873: Pseudo dice [np.float32(0.9479), np.float32(0.8686)] 
2025-01-26 14:19:53.401493: Epoch time: 48.97 s 
2025-01-26 14:19:54.627416:  
2025-01-26 14:19:54.630403: Epoch 139 
2025-01-26 14:19:54.633135: Current learning rate: 0.00874 
2025-01-26 14:20:42.996854: train_loss -0.7996 
2025-01-26 14:20:43.003570: val_loss -0.7177 
2025-01-26 14:20:43.006305: Pseudo dice [np.float32(0.9542), np.float32(0.8842)] 
2025-01-26 14:20:43.008808: Epoch time: 48.37 s 
2025-01-26 14:20:44.229491:  
2025-01-26 14:20:44.232559: Epoch 140 
2025-01-26 14:20:44.235582: Current learning rate: 0.00873 
2025-01-26 14:21:32.487818: train_loss -0.7839 
2025-01-26 14:21:32.491351: val_loss -0.7557 
2025-01-26 14:21:32.494710: Pseudo dice [np.float32(0.9547), np.float32(0.8595)] 
2025-01-26 14:21:32.497226: Epoch time: 48.26 s 
2025-01-26 14:21:33.711920:  
2025-01-26 14:21:33.714464: Epoch 141 
2025-01-26 14:21:33.717160: Current learning rate: 0.00872 
2025-01-26 14:22:22.223623: train_loss -0.7564 
2025-01-26 14:22:22.230534: val_loss -0.6991 
2025-01-26 14:22:22.232908: Pseudo dice [np.float32(0.9351), np.float32(0.7424)] 
2025-01-26 14:22:22.235634: Epoch time: 48.51 s 
2025-01-26 14:22:23.462775:  
2025-01-26 14:22:23.465919: Epoch 142 
2025-01-26 14:22:23.468619: Current learning rate: 0.00871 
2025-01-26 14:23:12.184131: train_loss -0.748 
2025-01-26 14:23:12.187859: val_loss -0.6625 
2025-01-26 14:23:12.190593: Pseudo dice [np.float32(0.9356), np.float32(0.7397)] 
2025-01-26 14:23:12.193231: Epoch time: 48.72 s 
2025-01-26 14:23:13.423010:  
2025-01-26 14:23:13.425781: Epoch 143 
2025-01-26 14:23:13.428275: Current learning rate: 0.0087 
2025-01-26 14:24:01.969395: train_loss -0.7477 
2025-01-26 14:24:01.976474: val_loss -0.7508 
2025-01-26 14:24:01.979130: Pseudo dice [np.float32(0.9398), np.float32(0.8594)] 
2025-01-26 14:24:01.981648: Epoch time: 48.55 s 
2025-01-26 14:24:03.838086:  
2025-01-26 14:24:03.841664: Epoch 144 
2025-01-26 14:24:03.844890: Current learning rate: 0.00869 
2025-01-26 14:24:52.112361: train_loss -0.7711 
2025-01-26 14:24:52.116103: val_loss -0.7021 
2025-01-26 14:24:52.118672: Pseudo dice [np.float32(0.9467), np.float32(0.7471)] 
2025-01-26 14:24:52.121667: Epoch time: 48.28 s 
2025-01-26 14:24:53.359212:  
2025-01-26 14:24:53.362370: Epoch 145 
2025-01-26 14:24:53.365459: Current learning rate: 0.00868 
2025-01-26 14:25:41.841157: train_loss -0.7735 
2025-01-26 14:25:41.847857: val_loss -0.7621 
2025-01-26 14:25:41.850542: Pseudo dice [np.float32(0.9521), np.float32(0.8823)] 
2025-01-26 14:25:41.853035: Epoch time: 48.48 s 
2025-01-26 14:25:43.080592:  
2025-01-26 14:25:43.083736: Epoch 146 
2025-01-26 14:25:43.086383: Current learning rate: 0.00868 
2025-01-26 14:26:31.641776: train_loss -0.7826 
2025-01-26 14:26:31.645808: val_loss -0.6758 
2025-01-26 14:26:31.648449: Pseudo dice [np.float32(0.9394), np.float32(0.8153)] 
2025-01-26 14:26:31.650697: Epoch time: 48.56 s 
2025-01-26 14:26:32.870823:  
2025-01-26 14:26:32.873904: Epoch 147 
2025-01-26 14:26:32.876581: Current learning rate: 0.00867 
2025-01-26 14:27:21.283903: train_loss -0.7745 
2025-01-26 14:27:21.290632: val_loss -0.7484 
2025-01-26 14:27:21.293080: Pseudo dice [np.float32(0.9495), np.float32(0.8722)] 
2025-01-26 14:27:21.297229: Epoch time: 48.41 s 
2025-01-26 14:27:22.521523:  
2025-01-26 14:27:22.524461: Epoch 148 
2025-01-26 14:27:22.527283: Current learning rate: 0.00866 
2025-01-26 14:28:11.156130: train_loss -0.7904 
2025-01-26 14:28:11.159294: val_loss -0.7278 
2025-01-26 14:28:11.161773: Pseudo dice [np.float32(0.9508), np.float32(0.8809)] 
2025-01-26 14:28:11.164514: Epoch time: 48.64 s 
2025-01-26 14:28:12.390604:  
2025-01-26 14:28:12.393687: Epoch 149 
2025-01-26 14:28:12.396501: Current learning rate: 0.00865 
2025-01-26 14:29:00.499976: train_loss -0.785 
2025-01-26 14:29:00.506322: val_loss -0.7443 
2025-01-26 14:29:00.508816: Pseudo dice [np.float32(0.9526), np.float32(0.8673)] 
2025-01-26 14:29:00.511351: Epoch time: 48.11 s 
2025-01-26 14:29:02.332832:  
2025-01-26 14:29:02.336042: Epoch 150 
2025-01-26 14:29:02.339433: Current learning rate: 0.00864 
2025-01-26 14:29:50.832718: train_loss -0.806 
2025-01-26 14:29:50.837679: val_loss -0.7576 
2025-01-26 14:29:50.840082: Pseudo dice [np.float32(0.9524), np.float32(0.8591)] 
2025-01-26 14:29:50.842643: Epoch time: 48.5 s 
2025-01-26 14:29:52.059137:  
2025-01-26 14:29:52.062285: Epoch 151 
2025-01-26 14:29:52.065058: Current learning rate: 0.00863 
2025-01-26 14:30:40.947938: train_loss -0.7795 
2025-01-26 14:30:40.955089: val_loss -0.7805 
2025-01-26 14:30:40.957879: Pseudo dice [np.float32(0.9489), np.float32(0.8842)] 
2025-01-26 14:30:40.960907: Epoch time: 48.89 s 
2025-01-26 14:30:42.183080:  
2025-01-26 14:30:42.186369: Epoch 152 
2025-01-26 14:30:42.189432: Current learning rate: 0.00862 
2025-01-26 14:31:30.982941: train_loss -0.8022 
2025-01-26 14:31:30.986732: val_loss -0.7635 
2025-01-26 14:31:30.989472: Pseudo dice [np.float32(0.9555), np.float32(0.8904)] 
2025-01-26 14:31:30.991885: Epoch time: 48.8 s 
2025-01-26 14:31:32.225857:  
2025-01-26 14:31:32.229000: Epoch 153 
2025-01-26 14:31:32.232019: Current learning rate: 0.00861 
2025-01-26 14:32:20.934485: train_loss -0.7958 
2025-01-26 14:32:20.940893: val_loss -0.757 
2025-01-26 14:32:20.943154: Pseudo dice [np.float32(0.9485), np.float32(0.8878)] 
2025-01-26 14:32:20.945785: Epoch time: 48.71 s 
2025-01-26 14:32:22.183250:  
2025-01-26 14:32:22.186224: Epoch 154 
2025-01-26 14:32:22.189177: Current learning rate: 0.0086 
2025-01-26 14:33:10.667294: train_loss -0.7957 
2025-01-26 14:33:10.670899: val_loss -0.762 
2025-01-26 14:33:10.673422: Pseudo dice [np.float32(0.9495), np.float32(0.8838)] 
2025-01-26 14:33:10.676022: Epoch time: 48.49 s 
2025-01-26 14:33:10.678575: Yayy! New best EMA pseudo Dice: 0.9035000205039978 
2025-01-26 14:33:12.441215:  
2025-01-26 14:33:12.444082: Epoch 155 
2025-01-26 14:33:12.446599: Current learning rate: 0.00859 
2025-01-26 14:34:01.186201: train_loss -0.7954 
2025-01-26 14:34:01.193264: val_loss -0.7529 
2025-01-26 14:34:01.195894: Pseudo dice [np.float32(0.9503), np.float32(0.838)] 
2025-01-26 14:34:01.198665: Epoch time: 48.75 s 
2025-01-26 14:34:02.449061:  
2025-01-26 14:34:02.451754: Epoch 156 
2025-01-26 14:34:02.454433: Current learning rate: 0.00858 
2025-01-26 14:34:51.133369: train_loss -0.7875 
2025-01-26 14:34:51.137569: val_loss -0.745 
2025-01-26 14:34:51.140686: Pseudo dice [np.float32(0.9575), np.float32(0.8694)] 
2025-01-26 14:34:51.143605: Epoch time: 48.69 s 
2025-01-26 14:34:51.146227: Yayy! New best EMA pseudo Dice: 0.9036999940872192 
2025-01-26 14:34:52.915910:  
2025-01-26 14:34:52.918826: Epoch 157 
2025-01-26 14:34:52.921619: Current learning rate: 0.00858 
2025-01-26 14:35:41.288710: train_loss -0.8147 
2025-01-26 14:35:41.295659: val_loss -0.738 
2025-01-26 14:35:41.298658: Pseudo dice [np.float32(0.958), np.float32(0.8711)] 
2025-01-26 14:35:41.301121: Epoch time: 48.37 s 
2025-01-26 14:35:41.303693: Yayy! New best EMA pseudo Dice: 0.9047999978065491 
2025-01-26 14:35:43.136115:  
2025-01-26 14:35:43.139203: Epoch 158 
2025-01-26 14:35:43.141864: Current learning rate: 0.00857 
2025-01-26 14:36:31.942535: train_loss -0.7884 
2025-01-26 14:36:31.946187: val_loss -0.7108 
2025-01-26 14:36:31.949245: Pseudo dice [np.float32(0.948), np.float32(0.832)] 
2025-01-26 14:36:31.952052: Epoch time: 48.81 s 
2025-01-26 14:36:33.183559:  
2025-01-26 14:36:33.186525: Epoch 159 
2025-01-26 14:36:33.189610: Current learning rate: 0.00856 
2025-01-26 14:37:22.086223: train_loss -0.791 
2025-01-26 14:37:22.093474: val_loss -0.7864 
2025-01-26 14:37:22.096500: Pseudo dice [np.float32(0.9576), np.float32(0.8454)] 
2025-01-26 14:37:22.099220: Epoch time: 48.9 s 
2025-01-26 14:37:23.336622:  
2025-01-26 14:37:23.339400: Epoch 160 
2025-01-26 14:37:23.342078: Current learning rate: 0.00855 
2025-01-26 14:38:11.867817: train_loss -0.799 
2025-01-26 14:38:11.871651: val_loss -0.7268 
2025-01-26 14:38:11.874608: Pseudo dice [np.float32(0.9501), np.float32(0.8566)] 
2025-01-26 14:38:11.877642: Epoch time: 48.53 s 
2025-01-26 14:38:13.114941:  
2025-01-26 14:38:13.117880: Epoch 161 
2025-01-26 14:38:13.120822: Current learning rate: 0.00854 
2025-01-26 14:39:01.739269: train_loss -0.8005 
2025-01-26 14:39:01.746867: val_loss -0.7729 
2025-01-26 14:39:01.749852: Pseudo dice [np.float32(0.9522), np.float32(0.9027)] 
2025-01-26 14:39:01.752529: Epoch time: 48.63 s 
2025-01-26 14:39:01.755195: Yayy! New best EMA pseudo Dice: 0.9056000113487244 
2025-01-26 14:39:04.215606:  
2025-01-26 14:39:04.218704: Epoch 162 
2025-01-26 14:39:04.221456: Current learning rate: 0.00853 
2025-01-26 14:39:52.661994: train_loss -0.81 
2025-01-26 14:39:52.665488: val_loss -0.782 
2025-01-26 14:39:52.667932: Pseudo dice [np.float32(0.9588), np.float32(0.9106)] 
2025-01-26 14:39:52.670619: Epoch time: 48.45 s 
2025-01-26 14:39:52.672978: Yayy! New best EMA pseudo Dice: 0.9085000157356262 
2025-01-26 14:39:54.467589:  
2025-01-26 14:39:54.470612: Epoch 163 
2025-01-26 14:39:54.473421: Current learning rate: 0.00852 
2025-01-26 14:40:42.517172: train_loss -0.7935 
2025-01-26 14:40:42.523677: val_loss -0.7732 
2025-01-26 14:40:42.526405: Pseudo dice [np.float32(0.9556), np.float32(0.8501)] 
2025-01-26 14:40:42.528681: Epoch time: 48.05 s 
2025-01-26 14:40:43.765988:  
2025-01-26 14:40:43.768845: Epoch 164 
2025-01-26 14:40:43.771850: Current learning rate: 0.00851 
2025-01-26 14:41:32.387802: train_loss -0.8011 
2025-01-26 14:41:32.390997: val_loss -0.7519 
2025-01-26 14:41:32.393781: Pseudo dice [np.float32(0.9569), np.float32(0.8889)] 
2025-01-26 14:41:32.396581: Epoch time: 48.62 s 
2025-01-26 14:41:32.399242: Yayy! New best EMA pseudo Dice: 0.9093999862670898 
2025-01-26 14:41:34.187850:  
2025-01-26 14:41:34.191052: Epoch 165 
2025-01-26 14:41:34.193800: Current learning rate: 0.0085 
2025-01-26 14:42:23.450762: train_loss -0.8126 
2025-01-26 14:42:23.456598: val_loss -0.7241 
2025-01-26 14:42:23.458958: Pseudo dice [np.float32(0.9506), np.float32(0.8628)] 
2025-01-26 14:42:23.461519: Epoch time: 49.26 s 
2025-01-26 14:42:24.664516:  
2025-01-26 14:42:24.667592: Epoch 166 
2025-01-26 14:42:24.670313: Current learning rate: 0.00849 
2025-01-26 14:43:13.581959: train_loss -0.8099 
2025-01-26 14:43:13.585782: val_loss -0.7872 
2025-01-26 14:43:13.588799: Pseudo dice [np.float32(0.954), np.float32(0.892)] 
2025-01-26 14:43:13.591552: Epoch time: 48.92 s 
2025-01-26 14:43:13.594430: Yayy! New best EMA pseudo Dice: 0.9104999899864197 
2025-01-26 14:43:15.353832:  
2025-01-26 14:43:15.358450: Epoch 167 
2025-01-26 14:43:15.360843: Current learning rate: 0.00848 
2025-01-26 14:44:04.448805: train_loss -0.7777 
2025-01-26 14:44:04.455718: val_loss -0.751 
2025-01-26 14:44:04.458261: Pseudo dice [np.float32(0.9451), np.float32(0.8709)] 
2025-01-26 14:44:04.460687: Epoch time: 49.1 s 
2025-01-26 14:44:05.676809:  
2025-01-26 14:44:05.681062: Epoch 168 
2025-01-26 14:44:05.684028: Current learning rate: 0.00847 
2025-01-26 14:44:54.470581: train_loss -0.7953 
2025-01-26 14:44:54.474472: val_loss -0.7512 
2025-01-26 14:44:54.476972: Pseudo dice [np.float32(0.9564), np.float32(0.8358)] 
2025-01-26 14:44:54.479659: Epoch time: 48.79 s 
2025-01-26 14:44:55.700270:  
2025-01-26 14:44:55.702973: Epoch 169 
2025-01-26 14:44:55.706005: Current learning rate: 0.00847 
2025-01-26 14:45:44.871589: train_loss -0.7901 
2025-01-26 14:45:44.878308: val_loss -0.7913 
2025-01-26 14:45:44.881284: Pseudo dice [np.float32(0.9465), np.float32(0.8654)] 
2025-01-26 14:45:44.883893: Epoch time: 49.17 s 
2025-01-26 14:45:46.105685:  
2025-01-26 14:45:46.108605: Epoch 170 
2025-01-26 14:45:46.111523: Current learning rate: 0.00846 
2025-01-26 14:46:34.719338: train_loss -0.781 
2025-01-26 14:46:34.722716: val_loss -0.7582 
2025-01-26 14:46:34.725592: Pseudo dice [np.float32(0.9418), np.float32(0.8832)] 
2025-01-26 14:46:34.728270: Epoch time: 48.61 s 
2025-01-26 14:46:35.952340:  
2025-01-26 14:46:35.955873: Epoch 171 
2025-01-26 14:46:35.958894: Current learning rate: 0.00845 
2025-01-26 14:47:24.536208: train_loss -0.7816 
2025-01-26 14:47:24.542525: val_loss -0.7612 
2025-01-26 14:47:24.545030: Pseudo dice [np.float32(0.9451), np.float32(0.8555)] 
2025-01-26 14:47:24.547817: Epoch time: 48.58 s 
2025-01-26 14:47:25.779284:  
2025-01-26 14:47:25.782263: Epoch 172 
2025-01-26 14:47:25.785474: Current learning rate: 0.00844 
2025-01-26 14:48:14.200545: train_loss -0.7695 
2025-01-26 14:48:14.204659: val_loss -0.7459 
2025-01-26 14:48:14.207358: Pseudo dice [np.float32(0.9488), np.float32(0.8142)] 
2025-01-26 14:48:14.210090: Epoch time: 48.42 s 
2025-01-26 14:48:15.446767:  
2025-01-26 14:48:15.449639: Epoch 173 
2025-01-26 14:48:15.452260: Current learning rate: 0.00843 
2025-01-26 14:49:04.070254: train_loss -0.7784 
2025-01-26 14:49:04.076698: val_loss -0.775 
2025-01-26 14:49:04.079666: Pseudo dice [np.float32(0.9561), np.float32(0.8994)] 
2025-01-26 14:49:04.082303: Epoch time: 48.62 s 
2025-01-26 14:49:05.302425:  
2025-01-26 14:49:05.305182: Epoch 174 
2025-01-26 14:49:05.307924: Current learning rate: 0.00842 
2025-01-26 14:49:53.842080: train_loss -0.8031 
2025-01-26 14:49:53.847518: val_loss -0.7603 
2025-01-26 14:49:53.849820: Pseudo dice [np.float32(0.945), np.float32(0.8335)] 
2025-01-26 14:49:53.852339: Epoch time: 48.54 s 
2025-01-26 14:49:55.071335:  
2025-01-26 14:49:55.073822: Epoch 175 
2025-01-26 14:49:55.076284: Current learning rate: 0.00841 
2025-01-26 14:50:43.740284: train_loss -0.7672 
2025-01-26 14:50:43.746551: val_loss -0.7328 
2025-01-26 14:50:43.749253: Pseudo dice [np.float32(0.9379), np.float32(0.8184)] 
2025-01-26 14:50:43.751807: Epoch time: 48.67 s 
2025-01-26 14:50:44.983698:  
2025-01-26 14:50:44.986541: Epoch 176 
2025-01-26 14:50:44.989383: Current learning rate: 0.0084 
2025-01-26 14:51:34.031236: train_loss -0.7683 
2025-01-26 14:51:34.034696: val_loss -0.7245 
2025-01-26 14:51:34.037875: Pseudo dice [np.float32(0.9485), np.float32(0.8353)] 
2025-01-26 14:51:34.040573: Epoch time: 49.05 s 
2025-01-26 14:51:35.260127:  
2025-01-26 14:51:35.262945: Epoch 177 
2025-01-26 14:51:35.265386: Current learning rate: 0.00839 
2025-01-26 14:52:24.036646: train_loss -0.8062 
2025-01-26 14:52:24.043150: val_loss -0.7205 
2025-01-26 14:52:24.045659: Pseudo dice [np.float32(0.9587), np.float32(0.7817)] 
2025-01-26 14:52:24.048055: Epoch time: 48.78 s 
2025-01-26 14:52:25.271283:  
2025-01-26 14:52:25.274300: Epoch 178 
2025-01-26 14:52:25.277287: Current learning rate: 0.00838 
2025-01-26 14:53:14.042462: train_loss -0.7822 
2025-01-26 14:53:14.046283: val_loss -0.7562 
2025-01-26 14:53:14.049062: Pseudo dice [np.float32(0.9508), np.float32(0.8478)] 
2025-01-26 14:53:14.051745: Epoch time: 48.77 s 
2025-01-26 14:53:15.844064:  
2025-01-26 14:53:15.849409: Epoch 179 
2025-01-26 14:53:15.852692: Current learning rate: 0.00837 
2025-01-26 14:54:04.226312: train_loss -0.7806 
2025-01-26 14:54:04.232573: val_loss -0.7725 
2025-01-26 14:54:04.235125: Pseudo dice [np.float32(0.9557), np.float32(0.8557)] 
2025-01-26 14:54:04.237641: Epoch time: 48.38 s 
2025-01-26 14:54:05.458779:  
2025-01-26 14:54:05.461614: Epoch 180 
2025-01-26 14:54:05.464292: Current learning rate: 0.00836 
2025-01-26 14:54:54.012584: train_loss -0.7813 
2025-01-26 14:54:54.016382: val_loss -0.7625 
2025-01-26 14:54:54.019312: Pseudo dice [np.float32(0.9492), np.float32(0.858)] 
2025-01-26 14:54:54.022122: Epoch time: 48.55 s 
2025-01-26 14:54:55.246371:  
2025-01-26 14:54:55.250355: Epoch 181 
2025-01-26 14:54:55.253588: Current learning rate: 0.00836 
2025-01-26 14:55:43.633114: train_loss -0.7945 
2025-01-26 14:55:43.639204: val_loss -0.7441 
2025-01-26 14:55:43.641605: Pseudo dice [np.float32(0.9542), np.float32(0.8894)] 
2025-01-26 14:55:43.644255: Epoch time: 48.39 s 
2025-01-26 14:55:44.866469:  
2025-01-26 14:55:44.869419: Epoch 182 
2025-01-26 14:55:44.872159: Current learning rate: 0.00835 
2025-01-26 14:56:33.515045: train_loss -0.7948 
2025-01-26 14:56:33.518140: val_loss -0.774 
2025-01-26 14:56:33.520733: Pseudo dice [np.float32(0.9532), np.float32(0.8582)] 
2025-01-26 14:56:33.523191: Epoch time: 48.65 s 
2025-01-26 14:56:34.746464:  
2025-01-26 14:56:34.749358: Epoch 183 
2025-01-26 14:56:34.751935: Current learning rate: 0.00834 
2025-01-26 14:57:23.554410: train_loss -0.7879 
2025-01-26 14:57:23.562628: val_loss -0.7444 
2025-01-26 14:57:23.566050: Pseudo dice [np.float32(0.9435), np.float32(0.8484)] 
2025-01-26 14:57:23.569164: Epoch time: 48.81 s 
2025-01-26 14:57:24.790412:  
2025-01-26 14:57:24.793507: Epoch 184 
2025-01-26 14:57:24.796265: Current learning rate: 0.00833 
2025-01-26 14:58:13.177136: train_loss -0.7864 
2025-01-26 14:58:13.180501: val_loss -0.772 
2025-01-26 14:58:13.183379: Pseudo dice [np.float32(0.9456), np.float32(0.8735)] 
2025-01-26 14:58:13.186028: Epoch time: 48.39 s 
2025-01-26 14:58:14.396765:  
2025-01-26 14:58:14.399397: Epoch 185 
2025-01-26 14:58:14.402205: Current learning rate: 0.00832 
2025-01-26 14:59:02.954281: train_loss -0.8063 
2025-01-26 14:59:02.961650: val_loss -0.7425 
2025-01-26 14:59:02.964560: Pseudo dice [np.float32(0.9526), np.float32(0.8733)] 
2025-01-26 14:59:02.967025: Epoch time: 48.56 s 
2025-01-26 14:59:04.182898:  
2025-01-26 14:59:04.186120: Epoch 186 
2025-01-26 14:59:04.189437: Current learning rate: 0.00831 
2025-01-26 14:59:52.572468: train_loss -0.7927 
2025-01-26 14:59:52.576057: val_loss -0.731 
2025-01-26 14:59:52.578880: Pseudo dice [np.float32(0.9516), np.float32(0.8728)] 
2025-01-26 14:59:52.581512: Epoch time: 48.39 s 
2025-01-26 14:59:53.798039:  
2025-01-26 14:59:53.800703: Epoch 187 
2025-01-26 14:59:53.803209: Current learning rate: 0.0083 
2025-01-26 15:00:42.327022: train_loss -0.7821 
2025-01-26 15:00:42.333045: val_loss -0.777 
2025-01-26 15:00:42.335590: Pseudo dice [np.float32(0.9467), np.float32(0.898)] 
2025-01-26 15:00:42.338135: Epoch time: 48.53 s 
2025-01-26 15:00:43.554819:  
2025-01-26 15:00:43.557635: Epoch 188 
2025-01-26 15:00:43.560622: Current learning rate: 0.00829 
2025-01-26 15:01:32.253264: train_loss -0.7862 
2025-01-26 15:01:32.256715: val_loss -0.7531 
2025-01-26 15:01:32.259273: Pseudo dice [np.float32(0.9511), np.float32(0.8401)] 
2025-01-26 15:01:32.261538: Epoch time: 48.7 s 
2025-01-26 15:01:33.484495:  
2025-01-26 15:01:33.486983: Epoch 189 
2025-01-26 15:01:33.489464: Current learning rate: 0.00828 
2025-01-26 15:02:22.064964: train_loss -0.802 
2025-01-26 15:02:22.082731: val_loss -0.7805 
2025-01-26 15:02:22.086764: Pseudo dice [np.float32(0.9525), np.float32(0.8985)] 
2025-01-26 15:02:22.090866: Epoch time: 48.58 s 
2025-01-26 15:02:23.309238:  
2025-01-26 15:02:23.311899: Epoch 190 
2025-01-26 15:02:23.315565: Current learning rate: 0.00827 
2025-01-26 15:03:11.547914: train_loss -0.8205 
2025-01-26 15:03:11.551175: val_loss -0.7535 
2025-01-26 15:03:11.553692: Pseudo dice [np.float32(0.9493), np.float32(0.8826)] 
2025-01-26 15:03:11.556198: Epoch time: 48.24 s 
2025-01-26 15:03:12.767534:  
2025-01-26 15:03:12.770223: Epoch 191 
2025-01-26 15:03:12.772799: Current learning rate: 0.00826 
2025-01-26 15:04:01.189059: train_loss -0.8041 
2025-01-26 15:04:01.195963: val_loss -0.7801 
2025-01-26 15:04:01.198778: Pseudo dice [np.float32(0.946), np.float32(0.8932)] 
2025-01-26 15:04:01.201328: Epoch time: 48.42 s 
2025-01-26 15:04:02.440065:  
2025-01-26 15:04:02.442705: Epoch 192 
2025-01-26 15:04:02.445666: Current learning rate: 0.00825 
2025-01-26 15:04:51.218942: train_loss -0.7909 
2025-01-26 15:04:51.222518: val_loss -0.7705 
2025-01-26 15:04:51.225457: Pseudo dice [np.float32(0.9532), np.float32(0.8608)] 
2025-01-26 15:04:51.228168: Epoch time: 48.78 s 
2025-01-26 15:04:52.453980:  
2025-01-26 15:04:52.456997: Epoch 193 
2025-01-26 15:04:52.459904: Current learning rate: 0.00824 
2025-01-26 15:05:41.280877: train_loss -0.7606 
2025-01-26 15:05:41.288022: val_loss -0.7674 
2025-01-26 15:05:41.290982: Pseudo dice [np.float32(0.9459), np.float32(0.8492)] 
2025-01-26 15:05:41.293863: Epoch time: 48.83 s 
2025-01-26 15:05:42.527848:  
2025-01-26 15:05:42.530466: Epoch 194 
2025-01-26 15:05:42.532986: Current learning rate: 0.00824 
2025-01-26 15:06:30.915311: train_loss -0.7746 
2025-01-26 15:06:30.919150: val_loss -0.7567 
2025-01-26 15:06:30.922011: Pseudo dice [np.float32(0.9436), np.float32(0.8157)] 
2025-01-26 15:06:30.924799: Epoch time: 48.39 s 
2025-01-26 15:06:32.150844:  
2025-01-26 15:06:32.153503: Epoch 195 
2025-01-26 15:06:32.156173: Current learning rate: 0.00823 
2025-01-26 15:07:20.799894: train_loss -0.7631 
2025-01-26 15:07:20.806112: val_loss -0.7482 
2025-01-26 15:07:20.809243: Pseudo dice [np.float32(0.9527), np.float32(0.8144)] 
2025-01-26 15:07:20.811601: Epoch time: 48.65 s 
2025-01-26 15:07:22.053429:  
2025-01-26 15:07:22.056219: Epoch 196 
2025-01-26 15:07:22.059218: Current learning rate: 0.00822 
2025-01-26 15:08:10.435659: train_loss -0.7749 
2025-01-26 15:08:10.439305: val_loss -0.7433 
2025-01-26 15:08:10.442328: Pseudo dice [np.float32(0.9432), np.float32(0.8179)] 
2025-01-26 15:08:10.445316: Epoch time: 48.38 s 
2025-01-26 15:08:12.257812:  
2025-01-26 15:08:12.260944: Epoch 197 
2025-01-26 15:08:12.264038: Current learning rate: 0.00821 
2025-01-26 15:09:00.713059: train_loss -0.7832 
2025-01-26 15:09:00.719297: val_loss -0.7418 
2025-01-26 15:09:00.722408: Pseudo dice [np.float32(0.9435), np.float32(0.8568)] 
2025-01-26 15:09:00.725234: Epoch time: 48.46 s 
2025-01-26 15:09:01.959559:  
2025-01-26 15:09:01.962544: Epoch 198 
2025-01-26 15:09:01.965743: Current learning rate: 0.0082 
2025-01-26 15:09:50.772940: train_loss -0.8036 
2025-01-26 15:09:50.776262: val_loss -0.7823 
2025-01-26 15:09:50.779138: Pseudo dice [np.float32(0.9554), np.float32(0.8522)] 
2025-01-26 15:09:50.781992: Epoch time: 48.81 s 
2025-01-26 15:09:52.014850:  
2025-01-26 15:09:52.017738: Epoch 199 
2025-01-26 15:09:52.020802: Current learning rate: 0.00819 
2025-01-26 15:10:40.451738: train_loss -0.7824 
2025-01-26 15:10:40.458622: val_loss -0.7373 
2025-01-26 15:10:40.461285: Pseudo dice [np.float32(0.9505), np.float32(0.8278)] 
2025-01-26 15:10:40.464145: Epoch time: 48.44 s 
2025-01-26 15:10:42.228772:  
2025-01-26 15:10:42.231830: Epoch 200 
2025-01-26 15:10:42.234524: Current learning rate: 0.00818 
2025-01-26 15:11:30.551461: train_loss -0.7801 
2025-01-26 15:11:30.556845: val_loss -0.7514 
2025-01-26 15:11:30.559638: Pseudo dice [np.float32(0.9567), np.float32(0.8587)] 
2025-01-26 15:11:30.562388: Epoch time: 48.32 s 
2025-01-26 15:11:31.806592:  
2025-01-26 15:11:31.809718: Epoch 201 
2025-01-26 15:11:31.812527: Current learning rate: 0.00817 
2025-01-26 15:12:20.597735: train_loss -0.807 
2025-01-26 15:12:20.604407: val_loss -0.7988 
2025-01-26 15:12:20.607162: Pseudo dice [np.float32(0.9558), np.float32(0.8723)] 
2025-01-26 15:12:20.609716: Epoch time: 48.79 s 
2025-01-26 15:12:21.847530:  
2025-01-26 15:12:21.850611: Epoch 202 
2025-01-26 15:12:21.853273: Current learning rate: 0.00816 
2025-01-26 15:13:10.635107: train_loss -0.7914 
2025-01-26 15:13:10.641431: val_loss -0.7247 
2025-01-26 15:13:10.644360: Pseudo dice [np.float32(0.9509), np.float32(0.8702)] 
2025-01-26 15:13:10.646832: Epoch time: 48.79 s 
2025-01-26 15:13:11.885164:  
2025-01-26 15:13:11.887869: Epoch 203 
2025-01-26 15:13:11.890565: Current learning rate: 0.00815 
2025-01-26 15:14:00.257656: train_loss -0.797 
2025-01-26 15:14:00.263604: val_loss -0.7389 
2025-01-26 15:14:00.265951: Pseudo dice [np.float32(0.9562), np.float32(0.8793)] 
2025-01-26 15:14:00.268568: Epoch time: 48.37 s 
2025-01-26 15:14:01.516026:  
2025-01-26 15:14:01.519651: Epoch 204 
2025-01-26 15:14:01.522419: Current learning rate: 0.00814 
2025-01-26 15:14:50.184413: train_loss -0.7924 
2025-01-26 15:14:50.188230: val_loss -0.7846 
2025-01-26 15:14:50.191580: Pseudo dice [np.float32(0.9592), np.float32(0.9061)] 
2025-01-26 15:14:50.194466: Epoch time: 48.67 s 
2025-01-26 15:14:51.431892:  
2025-01-26 15:14:51.434773: Epoch 205 
2025-01-26 15:14:51.437636: Current learning rate: 0.00813 
2025-01-26 15:15:40.164927: train_loss -0.7951 
2025-01-26 15:15:40.172670: val_loss -0.7735 
2025-01-26 15:15:40.175608: Pseudo dice [np.float32(0.9469), np.float32(0.868)] 
2025-01-26 15:15:40.178749: Epoch time: 48.73 s 
2025-01-26 15:15:41.361414:  
2025-01-26 15:15:41.364413: Epoch 206 
2025-01-26 15:15:41.367261: Current learning rate: 0.00813 
2025-01-26 15:16:30.321661: train_loss -0.8012 
2025-01-26 15:16:30.325303: val_loss -0.7785 
2025-01-26 15:16:30.328094: Pseudo dice [np.float32(0.9461), np.float32(0.877)] 
2025-01-26 15:16:30.330756: Epoch time: 48.96 s 
2025-01-26 15:16:31.503309:  
2025-01-26 15:16:31.505970: Epoch 207 
2025-01-26 15:16:31.508764: Current learning rate: 0.00812 
2025-01-26 15:17:19.961522: train_loss -0.8148 
2025-01-26 15:17:19.968425: val_loss -0.7862 
2025-01-26 15:17:19.970914: Pseudo dice [np.float32(0.9393), np.float32(0.8526)] 
2025-01-26 15:17:19.973525: Epoch time: 48.46 s 
2025-01-26 15:17:21.150780:  
2025-01-26 15:17:21.153718: Epoch 208 
2025-01-26 15:17:21.156772: Current learning rate: 0.00811 
2025-01-26 15:18:10.228337: train_loss -0.813 
2025-01-26 15:18:10.232044: val_loss -0.7761 
2025-01-26 15:18:10.234730: Pseudo dice [np.float32(0.9559), np.float32(0.902)] 
2025-01-26 15:18:10.237485: Epoch time: 49.08 s 
2025-01-26 15:18:11.413670:  
2025-01-26 15:18:11.416342: Epoch 209 
2025-01-26 15:18:11.418711: Current learning rate: 0.0081 
2025-01-26 15:19:00.486795: train_loss -0.8184 
2025-01-26 15:19:00.492751: val_loss -0.7967 
2025-01-26 15:19:00.495243: Pseudo dice [np.float32(0.9482), np.float32(0.884)] 
2025-01-26 15:19:00.497788: Epoch time: 49.07 s 
2025-01-26 15:19:01.669578:  
2025-01-26 15:19:01.672915: Epoch 210 
2025-01-26 15:19:01.675932: Current learning rate: 0.00809 
2025-01-26 15:19:50.595999: train_loss -0.8101 
2025-01-26 15:19:50.599260: val_loss -0.7807 
2025-01-26 15:19:50.601803: Pseudo dice [np.float32(0.9567), np.float32(0.891)] 
2025-01-26 15:19:50.604403: Epoch time: 48.93 s 
2025-01-26 15:19:50.606848: Yayy! New best EMA pseudo Dice: 0.9108999967575073 
2025-01-26 15:19:52.324854:  
2025-01-26 15:19:52.327448: Epoch 211 
2025-01-26 15:19:52.329901: Current learning rate: 0.00808 
2025-01-26 15:20:40.458225: train_loss -0.809 
2025-01-26 15:20:40.469208: val_loss -0.8002 
2025-01-26 15:20:40.471946: Pseudo dice [np.float32(0.9517), np.float32(0.8889)] 
2025-01-26 15:20:40.474779: Epoch time: 48.13 s 
2025-01-26 15:20:40.477357: Yayy! New best EMA pseudo Dice: 0.9118000268936157 
2025-01-26 15:20:42.361201:  
2025-01-26 15:20:42.363966: Epoch 212 
2025-01-26 15:20:42.366850: Current learning rate: 0.00807 
2025-01-26 15:21:30.751423: train_loss -0.7726 
2025-01-26 15:21:30.756314: val_loss -0.7232 
2025-01-26 15:21:30.759062: Pseudo dice [np.float32(0.95), np.float32(0.8301)] 
2025-01-26 15:21:30.761726: Epoch time: 48.39 s 
2025-01-26 15:21:31.945091:  
2025-01-26 15:21:31.947929: Epoch 213 
2025-01-26 15:21:31.950504: Current learning rate: 0.00806 
2025-01-26 15:22:20.903309: train_loss -0.791 
2025-01-26 15:22:20.910644: val_loss -0.7511 
2025-01-26 15:22:20.913318: Pseudo dice [np.float32(0.9564), np.float32(0.8697)] 
2025-01-26 15:22:20.915974: Epoch time: 48.96 s 
2025-01-26 15:22:22.662988:  
2025-01-26 15:22:22.665947: Epoch 214 
2025-01-26 15:22:22.668725: Current learning rate: 0.00805 
2025-01-26 15:23:11.403165: train_loss -0.7939 
2025-01-26 15:23:11.406771: val_loss -0.7466 
2025-01-26 15:23:11.409872: Pseudo dice [np.float32(0.9486), np.float32(0.8477)] 
2025-01-26 15:23:11.412812: Epoch time: 48.74 s 
2025-01-26 15:23:12.585902:  
2025-01-26 15:23:12.588961: Epoch 215 
2025-01-26 15:23:12.591695: Current learning rate: 0.00804 
2025-01-26 15:24:01.213852: train_loss -0.7837 
2025-01-26 15:24:01.219788: val_loss -0.7538 
2025-01-26 15:24:01.222329: Pseudo dice [np.float32(0.9455), np.float32(0.8625)] 
2025-01-26 15:24:01.224625: Epoch time: 48.63 s 
2025-01-26 15:24:02.414884:  
2025-01-26 15:24:02.418358: Epoch 216 
2025-01-26 15:24:02.421526: Current learning rate: 0.00803 
2025-01-26 15:24:50.598540: train_loss -0.811 
2025-01-26 15:24:50.603167: val_loss -0.7534 
2025-01-26 15:24:50.605866: Pseudo dice [np.float32(0.9529), np.float32(0.8618)] 
2025-01-26 15:24:50.608149: Epoch time: 48.18 s 
2025-01-26 15:24:51.789631:  
2025-01-26 15:24:51.792347: Epoch 217 
2025-01-26 15:24:51.794913: Current learning rate: 0.00802 
2025-01-26 15:25:40.465096: train_loss -0.7998 
2025-01-26 15:25:40.471501: val_loss -0.792 
2025-01-26 15:25:40.474231: Pseudo dice [np.float32(0.9551), np.float32(0.8955)] 
2025-01-26 15:25:40.476660: Epoch time: 48.68 s 
2025-01-26 15:25:41.656609:  
2025-01-26 15:25:41.659643: Epoch 218 
2025-01-26 15:25:41.662573: Current learning rate: 0.00801 
2025-01-26 15:26:30.070594: train_loss -0.803 
2025-01-26 15:26:30.074027: val_loss -0.7455 
2025-01-26 15:26:30.076830: Pseudo dice [np.float32(0.9561), np.float32(0.8825)] 
2025-01-26 15:26:30.079531: Epoch time: 48.42 s 
2025-01-26 15:26:31.261316:  
2025-01-26 15:26:31.264076: Epoch 219 
2025-01-26 15:26:31.266555: Current learning rate: 0.00801 
2025-01-26 15:27:19.645240: train_loss -0.8032 
2025-01-26 15:27:19.651963: val_loss -0.8042 
2025-01-26 15:27:19.654515: Pseudo dice [np.float32(0.9545), np.float32(0.8964)] 
2025-01-26 15:27:19.656926: Epoch time: 48.38 s 
2025-01-26 15:27:19.660047: Yayy! New best EMA pseudo Dice: 0.9122999906539917 
2025-01-26 15:27:21.412438:  
2025-01-26 15:27:21.415185: Epoch 220 
2025-01-26 15:27:21.418185: Current learning rate: 0.008 
2025-01-26 15:28:09.882982: train_loss -0.8062 
2025-01-26 15:28:09.887654: val_loss -0.7654 
2025-01-26 15:28:09.890412: Pseudo dice [np.float32(0.9552), np.float32(0.8625)] 
2025-01-26 15:28:09.893115: Epoch time: 48.47 s 
2025-01-26 15:28:11.144916:  
2025-01-26 15:28:11.148209: Epoch 221 
2025-01-26 15:28:11.151081: Current learning rate: 0.00799 
2025-01-26 15:29:00.082123: train_loss -0.8087 
2025-01-26 15:29:00.090124: val_loss -0.7652 
2025-01-26 15:29:00.092690: Pseudo dice [np.float32(0.9474), np.float32(0.8856)] 
2025-01-26 15:29:00.095288: Epoch time: 48.94 s 
2025-01-26 15:29:00.097988: Yayy! New best EMA pseudo Dice: 0.9124000072479248 
2025-01-26 15:29:01.812425:  
2025-01-26 15:29:01.815129: Epoch 222 
2025-01-26 15:29:01.818045: Current learning rate: 0.00798 
2025-01-26 15:29:50.418513: train_loss -0.8167 
2025-01-26 15:29:50.421556: val_loss -0.7296 
2025-01-26 15:29:50.424245: Pseudo dice [np.float32(0.9518), np.float32(0.8605)] 
2025-01-26 15:29:50.426494: Epoch time: 48.61 s 
2025-01-26 15:29:51.599862:  
2025-01-26 15:29:51.602611: Epoch 223 
2025-01-26 15:29:51.605287: Current learning rate: 0.00797 
2025-01-26 15:30:40.466491: train_loss -0.7924 
2025-01-26 15:30:40.474403: val_loss -0.7958 
2025-01-26 15:30:40.477980: Pseudo dice [np.float32(0.9536), np.float32(0.8873)] 
2025-01-26 15:30:40.480444: Epoch time: 48.87 s 
2025-01-26 15:30:40.482988: Yayy! New best EMA pseudo Dice: 0.9126999974250793 
2025-01-26 15:30:42.231592:  
2025-01-26 15:30:42.234592: Epoch 224 
2025-01-26 15:30:42.237019: Current learning rate: 0.00796 
2025-01-26 15:31:30.816330: train_loss -0.795 
2025-01-26 15:31:30.823549: val_loss -0.7796 
2025-01-26 15:31:30.827150: Pseudo dice [np.float32(0.9534), np.float32(0.8732)] 
2025-01-26 15:31:30.829969: Epoch time: 48.59 s 
2025-01-26 15:31:30.832512: Yayy! New best EMA pseudo Dice: 0.9126999974250793 
2025-01-26 15:31:32.558045:  
2025-01-26 15:31:32.560909: Epoch 225 
2025-01-26 15:31:32.563421: Current learning rate: 0.00795 
2025-01-26 15:32:21.075676: train_loss -0.8019 
2025-01-26 15:32:21.082197: val_loss -0.7666 
2025-01-26 15:32:21.085050: Pseudo dice [np.float32(0.9514), np.float32(0.8807)] 
2025-01-26 15:32:21.087287: Epoch time: 48.52 s 
2025-01-26 15:32:21.089976: Yayy! New best EMA pseudo Dice: 0.913100004196167 
2025-01-26 15:32:22.844749:  
2025-01-26 15:32:22.848053: Epoch 226 
2025-01-26 15:32:22.850925: Current learning rate: 0.00794 
2025-01-26 15:33:11.200907: train_loss -0.799 
2025-01-26 15:33:11.204590: val_loss -0.724 
2025-01-26 15:33:11.207273: Pseudo dice [np.float32(0.9519), np.float32(0.8056)] 
2025-01-26 15:33:11.210284: Epoch time: 48.36 s 
2025-01-26 15:33:12.383399:  
2025-01-26 15:33:12.386206: Epoch 227 
2025-01-26 15:33:12.388874: Current learning rate: 0.00793 
2025-01-26 15:34:01.102031: train_loss -0.7881 
2025-01-26 15:34:01.108617: val_loss -0.7028 
2025-01-26 15:34:01.111365: Pseudo dice [np.float32(0.9478), np.float32(0.706)] 
2025-01-26 15:34:01.113952: Epoch time: 48.72 s 
2025-01-26 15:34:02.290654:  
2025-01-26 15:34:02.294070: Epoch 228 
2025-01-26 15:34:02.296871: Current learning rate: 0.00792 
2025-01-26 15:34:50.771708: train_loss -0.8071 
2025-01-26 15:34:50.775260: val_loss -0.7409 
2025-01-26 15:34:50.778060: Pseudo dice [np.float32(0.9507), np.float32(0.8212)] 
2025-01-26 15:34:50.780880: Epoch time: 48.48 s 
2025-01-26 15:34:51.946097:  
2025-01-26 15:34:51.949409: Epoch 229 
2025-01-26 15:34:51.952505: Current learning rate: 0.00791 
2025-01-26 15:35:40.365157: train_loss -0.8124 
2025-01-26 15:35:40.373477: val_loss -0.7245 
2025-01-26 15:35:40.376749: Pseudo dice [np.float32(0.9482), np.float32(0.8712)] 
2025-01-26 15:35:40.379820: Epoch time: 48.42 s 
2025-01-26 15:35:41.554119:  
2025-01-26 15:35:41.557032: Epoch 230 
2025-01-26 15:35:41.559848: Current learning rate: 0.0079 
2025-01-26 15:36:30.260133: train_loss -0.7808 
2025-01-26 15:36:30.266716: val_loss -0.7124 
2025-01-26 15:36:30.269673: Pseudo dice [np.float32(0.9593), np.float32(0.8983)] 
2025-01-26 15:36:30.272009: Epoch time: 48.71 s 
2025-01-26 15:36:31.433889:  
2025-01-26 15:36:31.437176: Epoch 231 
2025-01-26 15:36:31.441602: Current learning rate: 0.00789 
2025-01-26 15:37:19.656340: train_loss -0.7961 
2025-01-26 15:37:19.666007: val_loss -0.7444 
2025-01-26 15:37:19.669452: Pseudo dice [np.float32(0.9521), np.float32(0.8505)] 
2025-01-26 15:37:19.672690: Epoch time: 48.22 s 
2025-01-26 15:37:20.834013:  
2025-01-26 15:37:20.837114: Epoch 232 
2025-01-26 15:37:20.839746: Current learning rate: 0.00789 
2025-01-26 15:38:09.708318: train_loss -0.7951 
2025-01-26 15:38:09.715281: val_loss -0.7553 
2025-01-26 15:38:09.718394: Pseudo dice [np.float32(0.9427), np.float32(0.8131)] 
2025-01-26 15:38:09.721388: Epoch time: 48.88 s 
2025-01-26 15:38:11.456602:  
2025-01-26 15:38:11.459647: Epoch 233 
2025-01-26 15:38:11.462354: Current learning rate: 0.00788 
2025-01-26 15:38:59.967212: train_loss -0.7783 
2025-01-26 15:38:59.975246: val_loss -0.7176 
2025-01-26 15:38:59.978390: Pseudo dice [np.float32(0.9495), np.float32(0.8535)] 
2025-01-26 15:38:59.981184: Epoch time: 48.51 s 
2025-01-26 15:39:01.149611:  
2025-01-26 15:39:01.152791: Epoch 234 
2025-01-26 15:39:01.155880: Current learning rate: 0.00787 
2025-01-26 15:39:49.675386: train_loss -0.8023 
2025-01-26 15:39:49.678807: val_loss -0.7411 
2025-01-26 15:39:49.681579: Pseudo dice [np.float32(0.949), np.float32(0.8203)] 
2025-01-26 15:39:49.684282: Epoch time: 48.53 s 
2025-01-26 15:39:50.851337:  
2025-01-26 15:39:50.854285: Epoch 235 
2025-01-26 15:39:50.857192: Current learning rate: 0.00786 
2025-01-26 15:40:39.294443: train_loss -0.7865 
2025-01-26 15:40:39.300822: val_loss -0.7333 
2025-01-26 15:40:39.304051: Pseudo dice [np.float32(0.9521), np.float32(0.8822)] 
2025-01-26 15:40:39.307071: Epoch time: 48.44 s 
2025-01-26 15:40:40.489841:  
2025-01-26 15:40:40.492503: Epoch 236 
2025-01-26 15:40:40.495042: Current learning rate: 0.00785 
2025-01-26 15:41:28.796080: train_loss -0.8045 
2025-01-26 15:41:28.800021: val_loss -0.8145 
2025-01-26 15:41:28.802845: Pseudo dice [np.float32(0.9537), np.float32(0.9071)] 
2025-01-26 15:41:28.805658: Epoch time: 48.31 s 
2025-01-26 15:41:29.982519:  
2025-01-26 15:41:29.985405: Epoch 237 
2025-01-26 15:41:29.988495: Current learning rate: 0.00784 
2025-01-26 15:42:18.683185: train_loss -0.8011 
2025-01-26 15:42:18.690909: val_loss -0.7654 
2025-01-26 15:42:18.693917: Pseudo dice [np.float32(0.9569), np.float32(0.846)] 
2025-01-26 15:42:18.696625: Epoch time: 48.7 s 
2025-01-26 15:42:19.866817:  
2025-01-26 15:42:19.870466: Epoch 238 
2025-01-26 15:42:19.873513: Current learning rate: 0.00783 
2025-01-26 15:43:08.538296: train_loss -0.7998 
2025-01-26 15:43:08.541883: val_loss -0.7506 
2025-01-26 15:43:08.545242: Pseudo dice [np.float32(0.9492), np.float32(0.8534)] 
2025-01-26 15:43:08.548058: Epoch time: 48.67 s 
2025-01-26 15:43:09.720193:  
2025-01-26 15:43:09.723726: Epoch 239 
2025-01-26 15:43:09.726819: Current learning rate: 0.00782 
2025-01-26 15:43:58.247411: train_loss -0.7918 
2025-01-26 15:43:58.253864: val_loss -0.772 
2025-01-26 15:43:58.256474: Pseudo dice [np.float32(0.957), np.float32(0.8737)] 
2025-01-26 15:43:58.259045: Epoch time: 48.53 s 
2025-01-26 15:43:59.445894:  
2025-01-26 15:43:59.449020: Epoch 240 
2025-01-26 15:43:59.451746: Current learning rate: 0.00781 
2025-01-26 15:44:48.235975: train_loss -0.8071 
2025-01-26 15:44:48.241459: val_loss -0.7944 
2025-01-26 15:44:48.244034: Pseudo dice [np.float32(0.9538), np.float32(0.875)] 
2025-01-26 15:44:48.246792: Epoch time: 48.79 s 
2025-01-26 15:44:49.431567:  
2025-01-26 15:44:49.434354: Epoch 241 
2025-01-26 15:44:49.436897: Current learning rate: 0.0078 
2025-01-26 15:45:38.026257: train_loss -0.8042 
2025-01-26 15:45:38.034834: val_loss -0.7229 
2025-01-26 15:45:38.037816: Pseudo dice [np.float32(0.9469), np.float32(0.8598)] 
2025-01-26 15:45:38.042707: Epoch time: 48.6 s 
2025-01-26 15:45:39.225887:  
2025-01-26 15:45:39.230041: Epoch 242 
2025-01-26 15:45:39.232860: Current learning rate: 0.00779 
2025-01-26 15:46:28.091546: train_loss -0.8094 
2025-01-26 15:46:28.098408: val_loss -0.7336 
2025-01-26 15:46:28.101416: Pseudo dice [np.float32(0.9438), np.float32(0.8058)] 
2025-01-26 15:46:28.103762: Epoch time: 48.87 s 
2025-01-26 15:46:29.284611:  
2025-01-26 15:46:29.287553: Epoch 243 
2025-01-26 15:46:29.290394: Current learning rate: 0.00778 
2025-01-26 15:47:17.928024: train_loss -0.798 
2025-01-26 15:47:17.936535: val_loss -0.7302 
2025-01-26 15:47:17.939077: Pseudo dice [np.float32(0.9594), np.float32(0.8945)] 
2025-01-26 15:47:17.941609: Epoch time: 48.64 s 
2025-01-26 15:47:19.124845:  
2025-01-26 15:47:19.128893: Epoch 244 
2025-01-26 15:47:19.131645: Current learning rate: 0.00777 
2025-01-26 15:48:08.246354: train_loss -0.8124 
2025-01-26 15:48:08.254581: val_loss -0.7489 
2025-01-26 15:48:08.257253: Pseudo dice [np.float32(0.953), np.float32(0.8918)] 
2025-01-26 15:48:08.259907: Epoch time: 49.12 s 
2025-01-26 15:48:09.442616:  
2025-01-26 15:48:09.445797: Epoch 245 
2025-01-26 15:48:09.449319: Current learning rate: 0.00777 
2025-01-26 15:48:57.913172: train_loss -0.8068 
2025-01-26 15:48:57.922317: val_loss -0.7418 
2025-01-26 15:48:57.925487: Pseudo dice [np.float32(0.9567), np.float32(0.8832)] 
2025-01-26 15:48:57.928668: Epoch time: 48.47 s 
2025-01-26 15:48:59.108551:  
2025-01-26 15:48:59.111174: Epoch 246 
2025-01-26 15:48:59.113833: Current learning rate: 0.00776 
2025-01-26 15:49:47.465214: train_loss -0.7998 
2025-01-26 15:49:47.469859: val_loss -0.7927 
2025-01-26 15:49:47.472968: Pseudo dice [np.float32(0.9547), np.float32(0.8971)] 
2025-01-26 15:49:47.476243: Epoch time: 48.36 s 
2025-01-26 15:49:48.664623:  
2025-01-26 15:49:48.667550: Epoch 247 
2025-01-26 15:49:48.670276: Current learning rate: 0.00775 
2025-01-26 15:50:38.013201: train_loss -0.7957 
2025-01-26 15:50:38.020304: val_loss -0.7545 
2025-01-26 15:50:38.022972: Pseudo dice [np.float32(0.9467), np.float32(0.8798)] 
2025-01-26 15:50:38.025552: Epoch time: 49.35 s 
2025-01-26 15:50:39.208028:  
2025-01-26 15:50:39.211089: Epoch 248 
2025-01-26 15:50:39.214124: Current learning rate: 0.00774 
2025-01-26 15:51:28.194746: train_loss -0.7971 
2025-01-26 15:51:28.202004: val_loss -0.7383 
2025-01-26 15:51:28.205315: Pseudo dice [np.float32(0.9459), np.float32(0.8634)] 
2025-01-26 15:51:28.207953: Epoch time: 48.99 s 
2025-01-26 15:51:29.382614:  
2025-01-26 15:51:29.385446: Epoch 249 
2025-01-26 15:51:29.388552: Current learning rate: 0.00773 
2025-01-26 15:52:17.826094: train_loss -0.7957 
2025-01-26 15:52:17.833989: val_loss -0.7439 
2025-01-26 15:52:17.836989: Pseudo dice [np.float32(0.9345), np.float32(0.8609)] 
2025-01-26 15:52:17.839777: Epoch time: 48.44 s 
2025-01-26 15:52:19.645260:  
2025-01-26 15:52:19.649782: Epoch 250 
2025-01-26 15:52:19.652678: Current learning rate: 0.00772 
2025-01-26 15:53:07.987333: train_loss -0.7713 
2025-01-26 15:53:07.992310: val_loss -0.7732 
2025-01-26 15:53:07.995124: Pseudo dice [np.float32(0.9489), np.float32(0.8759)] 
2025-01-26 15:53:07.998062: Epoch time: 48.34 s 
2025-01-26 15:53:09.732439:  
2025-01-26 15:53:09.735213: Epoch 251 
2025-01-26 15:53:09.738144: Current learning rate: 0.00771 
2025-01-26 15:53:58.308156: train_loss -0.7943 
2025-01-26 15:53:58.315695: val_loss -0.7343 
2025-01-26 15:53:58.318509: Pseudo dice [np.float32(0.9453), np.float32(0.8633)] 
2025-01-26 15:53:58.321095: Epoch time: 48.58 s 
2025-01-26 15:53:59.501573:  
2025-01-26 15:53:59.504186: Epoch 252 
2025-01-26 15:53:59.506926: Current learning rate: 0.0077 
2025-01-26 15:54:48.643500: train_loss -0.7753 
2025-01-26 15:54:48.649900: val_loss -0.7486 
2025-01-26 15:54:48.653485: Pseudo dice [np.float32(0.9535), np.float32(0.8412)] 
2025-01-26 15:54:48.656460: Epoch time: 49.14 s 
2025-01-26 15:54:49.844883:  
2025-01-26 15:54:49.848254: Epoch 253 
2025-01-26 15:54:49.851278: Current learning rate: 0.00769 
2025-01-26 15:55:38.232033: train_loss -0.7724 
2025-01-26 15:55:38.238369: val_loss -0.7401 
2025-01-26 15:55:38.241388: Pseudo dice [np.float32(0.943), np.float32(0.8442)] 
2025-01-26 15:55:38.244370: Epoch time: 48.39 s 
2025-01-26 15:55:39.427263:  
2025-01-26 15:55:39.430322: Epoch 254 
2025-01-26 15:55:39.433457: Current learning rate: 0.00768 
2025-01-26 15:56:28.139914: train_loss -0.8081 
2025-01-26 15:56:28.145230: val_loss -0.7386 
2025-01-26 15:56:28.147996: Pseudo dice [np.float32(0.9469), np.float32(0.8469)] 
2025-01-26 15:56:28.150400: Epoch time: 48.71 s 
2025-01-26 15:56:29.336575:  
2025-01-26 15:56:29.339693: Epoch 255 
2025-01-26 15:56:29.342672: Current learning rate: 0.00767 
2025-01-26 15:57:17.831649: train_loss -0.7935 
2025-01-26 15:57:17.839173: val_loss -0.7583 
2025-01-26 15:57:17.842714: Pseudo dice [np.float32(0.9572), np.float32(0.8802)] 
2025-01-26 15:57:17.846884: Epoch time: 48.5 s 
2025-01-26 15:57:19.026300:  
2025-01-26 15:57:19.029407: Epoch 256 
2025-01-26 15:57:19.031880: Current learning rate: 0.00766 
2025-01-26 15:58:07.840366: train_loss -0.8087 
2025-01-26 15:58:07.843462: val_loss -0.7542 
2025-01-26 15:58:07.846212: Pseudo dice [np.float32(0.9579), np.float32(0.8939)] 
2025-01-26 15:58:07.848570: Epoch time: 48.82 s 
2025-01-26 15:58:09.034024:  
2025-01-26 15:58:09.036639: Epoch 257 
2025-01-26 15:58:09.039290: Current learning rate: 0.00765 
2025-01-26 15:58:57.649089: train_loss -0.8034 
2025-01-26 15:58:57.655760: val_loss -0.8253 
2025-01-26 15:58:57.658531: Pseudo dice [np.float32(0.9566), np.float32(0.8927)] 
2025-01-26 15:58:57.660880: Epoch time: 48.62 s 
2025-01-26 15:58:58.857585:  
2025-01-26 15:58:58.860823: Epoch 258 
2025-01-26 15:58:58.863366: Current learning rate: 0.00764 
2025-01-26 15:59:47.473879: train_loss -0.7948 
2025-01-26 15:59:47.477898: val_loss -0.7744 
2025-01-26 15:59:47.480815: Pseudo dice [np.float32(0.9584), np.float32(0.8916)] 
2025-01-26 15:59:47.483507: Epoch time: 48.62 s 
2025-01-26 15:59:48.676450:  
2025-01-26 15:59:48.679619: Epoch 259 
2025-01-26 15:59:48.683045: Current learning rate: 0.00764 
2025-01-26 16:00:37.430263: train_loss -0.813 
2025-01-26 16:00:37.436740: val_loss -0.7797 
2025-01-26 16:00:37.439474: Pseudo dice [np.float32(0.9574), np.float32(0.8821)] 
2025-01-26 16:00:37.442413: Epoch time: 48.75 s 
2025-01-26 16:00:38.627902:  
2025-01-26 16:00:38.631108: Epoch 260 
2025-01-26 16:00:38.634014: Current learning rate: 0.00763 
2025-01-26 16:01:27.348348: train_loss -0.7938 
2025-01-26 16:01:27.351967: val_loss -0.7778 
2025-01-26 16:01:27.355177: Pseudo dice [np.float32(0.9565), np.float32(0.851)] 
2025-01-26 16:01:27.357935: Epoch time: 48.72 s 
2025-01-26 16:01:28.541655:  
2025-01-26 16:01:28.544682: Epoch 261 
2025-01-26 16:01:28.547813: Current learning rate: 0.00762 
2025-01-26 16:02:16.848123: train_loss -0.8131 
2025-01-26 16:02:16.854910: val_loss -0.7882 
2025-01-26 16:02:16.857638: Pseudo dice [np.float32(0.958), np.float32(0.892)] 
2025-01-26 16:02:16.860076: Epoch time: 48.31 s 
2025-01-26 16:02:18.043672:  
2025-01-26 16:02:18.047027: Epoch 262 
2025-01-26 16:02:18.049848: Current learning rate: 0.00761 
2025-01-26 16:03:06.353230: train_loss -0.8123 
2025-01-26 16:03:06.357162: val_loss -0.7737 
2025-01-26 16:03:06.360311: Pseudo dice [np.float32(0.9595), np.float32(0.888)] 
2025-01-26 16:03:06.362906: Epoch time: 48.31 s 
2025-01-26 16:03:06.365024: Yayy! New best EMA pseudo Dice: 0.9139000177383423 
2025-01-26 16:03:08.126999:  
2025-01-26 16:03:08.130200: Epoch 263 
2025-01-26 16:03:08.133261: Current learning rate: 0.0076 
2025-01-26 16:03:56.587530: train_loss -0.7944 
2025-01-26 16:03:56.594536: val_loss -0.7726 
2025-01-26 16:03:56.597523: Pseudo dice [np.float32(0.9535), np.float32(0.8672)] 
2025-01-26 16:03:56.600563: Epoch time: 48.46 s 
2025-01-26 16:03:57.790519:  
2025-01-26 16:03:57.793303: Epoch 264 
2025-01-26 16:03:57.796109: Current learning rate: 0.00759 
2025-01-26 16:04:46.494318: train_loss -0.8104 
2025-01-26 16:04:46.498101: val_loss -0.7304 
2025-01-26 16:04:46.501119: Pseudo dice [np.float32(0.9526), np.float32(0.766)] 
2025-01-26 16:04:46.504260: Epoch time: 48.7 s 
2025-01-26 16:04:47.694417:  
2025-01-26 16:04:47.697171: Epoch 265 
2025-01-26 16:04:47.699521: Current learning rate: 0.00758 
2025-01-26 16:05:36.196207: train_loss -0.8071 
2025-01-26 16:05:36.202735: val_loss -0.789 
2025-01-26 16:05:36.205583: Pseudo dice [np.float32(0.954), np.float32(0.8873)] 
2025-01-26 16:05:36.208225: Epoch time: 48.5 s 
2025-01-26 16:05:37.400171:  
2025-01-26 16:05:37.402872: Epoch 266 
2025-01-26 16:05:37.405439: Current learning rate: 0.00757 
2025-01-26 16:06:26.714258: train_loss -0.8192 
2025-01-26 16:06:26.717920: val_loss -0.7632 
2025-01-26 16:06:26.720907: Pseudo dice [np.float32(0.9559), np.float32(0.8838)] 
2025-01-26 16:06:26.723633: Epoch time: 49.32 s 
2025-01-26 16:06:27.907844:  
2025-01-26 16:06:27.910901: Epoch 267 
2025-01-26 16:06:27.913815: Current learning rate: 0.00756 
2025-01-26 16:07:17.234479: train_loss -0.8116 
2025-01-26 16:07:17.240799: val_loss -0.7673 
2025-01-26 16:07:17.243433: Pseudo dice [np.float32(0.9584), np.float32(0.8737)] 
2025-01-26 16:07:17.245947: Epoch time: 49.33 s 
2025-01-26 16:07:18.438334:  
2025-01-26 16:07:18.441521: Epoch 268 
2025-01-26 16:07:18.444809: Current learning rate: 0.00755 
2025-01-26 16:08:06.936159: train_loss -0.8027 
2025-01-26 16:08:06.939489: val_loss -0.7696 
2025-01-26 16:08:06.942171: Pseudo dice [np.float32(0.9535), np.float32(0.8838)] 
2025-01-26 16:08:06.944620: Epoch time: 48.5 s 
2025-01-26 16:08:08.130361:  
2025-01-26 16:08:08.133032: Epoch 269 
2025-01-26 16:08:08.135782: Current learning rate: 0.00754 
2025-01-26 16:08:56.936431: train_loss -0.807 
2025-01-26 16:08:56.943016: val_loss -0.7391 
2025-01-26 16:08:56.946206: Pseudo dice [np.float32(0.9531), np.float32(0.8969)] 
2025-01-26 16:08:56.948612: Epoch time: 48.81 s 
2025-01-26 16:08:58.697275:  
2025-01-26 16:08:58.700645: Epoch 270 
2025-01-26 16:08:58.703234: Current learning rate: 0.00753 
2025-01-26 16:09:47.564009: train_loss -0.7985 
2025-01-26 16:09:47.567917: val_loss -0.7267 
2025-01-26 16:09:47.570865: Pseudo dice [np.float32(0.9437), np.float32(0.8746)] 
2025-01-26 16:09:47.573479: Epoch time: 48.87 s 
2025-01-26 16:09:48.764806:  
2025-01-26 16:09:48.767674: Epoch 271 
2025-01-26 16:09:48.770349: Current learning rate: 0.00752 
2025-01-26 16:10:37.045886: train_loss -0.7838 
2025-01-26 16:10:37.052921: val_loss -0.7414 
2025-01-26 16:10:37.055326: Pseudo dice [np.float32(0.9552), np.float32(0.814)] 
2025-01-26 16:10:37.058465: Epoch time: 48.28 s 
2025-01-26 16:10:38.253593:  
2025-01-26 16:10:38.256175: Epoch 272 
2025-01-26 16:10:38.259104: Current learning rate: 0.00751 
2025-01-26 16:11:26.867192: train_loss -0.8083 
2025-01-26 16:11:26.870822: val_loss -0.8193 
2025-01-26 16:11:26.873568: Pseudo dice [np.float32(0.9536), np.float32(0.8896)] 
2025-01-26 16:11:26.876440: Epoch time: 48.61 s 
2025-01-26 16:11:28.073317:  
2025-01-26 16:11:28.076341: Epoch 273 
2025-01-26 16:11:28.079208: Current learning rate: 0.00751 
2025-01-26 16:12:16.541757: train_loss -0.7973 
2025-01-26 16:12:16.548491: val_loss -0.7639 
2025-01-26 16:12:16.551253: Pseudo dice [np.float32(0.9527), np.float32(0.875)] 
2025-01-26 16:12:16.554071: Epoch time: 48.47 s 
2025-01-26 16:12:17.746216:  
2025-01-26 16:12:17.749545: Epoch 274 
2025-01-26 16:12:17.752466: Current learning rate: 0.0075 
2025-01-26 16:13:05.931580: train_loss -0.8144 
2025-01-26 16:13:05.934699: val_loss -0.7591 
2025-01-26 16:13:05.937284: Pseudo dice [np.float32(0.9537), np.float32(0.845)] 
2025-01-26 16:13:05.939632: Epoch time: 48.19 s 
2025-01-26 16:13:07.129854:  
2025-01-26 16:13:07.132498: Epoch 275 
2025-01-26 16:13:07.135218: Current learning rate: 0.00749 
2025-01-26 16:13:55.493662: train_loss -0.8088 
2025-01-26 16:13:55.499998: val_loss -0.7866 
2025-01-26 16:13:55.502386: Pseudo dice [np.float32(0.9546), np.float32(0.8826)] 
2025-01-26 16:13:55.505000: Epoch time: 48.36 s 
2025-01-26 16:13:56.693867:  
2025-01-26 16:13:56.696952: Epoch 276 
2025-01-26 16:13:56.700161: Current learning rate: 0.00748 
2025-01-26 16:14:45.446759: train_loss -0.7491 
2025-01-26 16:14:45.450439: val_loss -0.7162 
2025-01-26 16:14:45.453586: Pseudo dice [np.float32(0.9421), np.float32(0.8481)] 
2025-01-26 16:14:45.456019: Epoch time: 48.75 s 
2025-01-26 16:14:46.644959:  
2025-01-26 16:14:46.647928: Epoch 277 
2025-01-26 16:14:46.650588: Current learning rate: 0.00747 
2025-01-26 16:15:35.081573: train_loss -0.7694 
2025-01-26 16:15:35.088323: val_loss -0.7605 
2025-01-26 16:15:35.091132: Pseudo dice [np.float32(0.9519), np.float32(0.8921)] 
2025-01-26 16:15:35.094031: Epoch time: 48.44 s 
2025-01-26 16:15:36.281907:  
2025-01-26 16:15:36.285107: Epoch 278 
2025-01-26 16:15:36.288155: Current learning rate: 0.00746 
2025-01-26 16:16:24.966898: train_loss -0.808 
2025-01-26 16:16:24.971012: val_loss -0.7497 
2025-01-26 16:16:24.974679: Pseudo dice [np.float32(0.9493), np.float32(0.8789)] 
2025-01-26 16:16:24.977828: Epoch time: 48.69 s 
2025-01-26 16:16:26.167027:  
2025-01-26 16:16:26.169777: Epoch 279 
2025-01-26 16:16:26.172812: Current learning rate: 0.00745 
2025-01-26 16:17:14.879718: train_loss -0.8116 
2025-01-26 16:17:14.886479: val_loss -0.7641 
2025-01-26 16:17:14.889417: Pseudo dice [np.float32(0.9479), np.float32(0.8801)] 
2025-01-26 16:17:14.891989: Epoch time: 48.71 s 
2025-01-26 16:17:16.079259:  
2025-01-26 16:17:16.082461: Epoch 280 
2025-01-26 16:17:16.085446: Current learning rate: 0.00744 
2025-01-26 16:18:04.063181: train_loss -0.7974 
2025-01-26 16:18:04.066646: val_loss -0.8291 
2025-01-26 16:18:04.074143: Pseudo dice [np.float32(0.9557), np.float32(0.9106)] 
2025-01-26 16:18:04.077677: Epoch time: 47.98 s 
2025-01-26 16:18:05.260691:  
2025-01-26 16:18:05.263870: Epoch 281 
2025-01-26 16:18:05.266990: Current learning rate: 0.00743 
2025-01-26 16:18:53.891265: train_loss -0.8057 
2025-01-26 16:18:53.897459: val_loss -0.7377 
2025-01-26 16:18:53.899857: Pseudo dice [np.float32(0.9605), np.float32(0.8858)] 
2025-01-26 16:18:53.902363: Epoch time: 48.63 s 
2025-01-26 16:18:53.904874: Yayy! New best EMA pseudo Dice: 0.9143999814987183 
2025-01-26 16:18:55.657065:  
2025-01-26 16:18:55.660519: Epoch 282 
2025-01-26 16:18:55.663443: Current learning rate: 0.00742 
2025-01-26 16:19:44.332704: train_loss -0.7969 
2025-01-26 16:19:44.336261: val_loss -0.7255 
2025-01-26 16:19:44.338859: Pseudo dice [np.float32(0.9465), np.float32(0.8111)] 
2025-01-26 16:19:44.341697: Epoch time: 48.68 s 
2025-01-26 16:19:45.528280:  
2025-01-26 16:19:45.532020: Epoch 283 
2025-01-26 16:19:45.535753: Current learning rate: 0.00741 
2025-01-26 16:20:34.102839: train_loss -0.7907 
2025-01-26 16:20:34.109858: val_loss -0.762 
2025-01-26 16:20:34.113183: Pseudo dice [np.float32(0.9581), np.float32(0.8854)] 
2025-01-26 16:20:34.115837: Epoch time: 48.58 s 
2025-01-26 16:20:35.301558:  
2025-01-26 16:20:35.304783: Epoch 284 
2025-01-26 16:20:35.307711: Current learning rate: 0.0074 
2025-01-26 16:21:23.975233: train_loss -0.7664 
2025-01-26 16:21:23.977956: val_loss -0.7339 
2025-01-26 16:21:23.980761: Pseudo dice [np.float32(0.9504), np.float32(0.8521)] 
2025-01-26 16:21:23.983311: Epoch time: 48.67 s 
2025-01-26 16:21:25.168125:  
2025-01-26 16:21:25.170557: Epoch 285 
2025-01-26 16:21:25.172860: Current learning rate: 0.00739 
2025-01-26 16:22:13.645718: train_loss -0.805 
2025-01-26 16:22:13.654739: val_loss -0.7755 
2025-01-26 16:22:13.657760: Pseudo dice [np.float32(0.9547), np.float32(0.8939)] 
2025-01-26 16:22:13.660836: Epoch time: 48.48 s 
2025-01-26 16:22:14.848521:  
2025-01-26 16:22:14.851009: Epoch 286 
2025-01-26 16:22:14.853684: Current learning rate: 0.00738 
2025-01-26 16:23:03.319273: train_loss -0.7931 
2025-01-26 16:23:03.323805: val_loss -0.7687 
2025-01-26 16:23:03.326671: Pseudo dice [np.float32(0.9467), np.float32(0.8533)] 
2025-01-26 16:23:03.329475: Epoch time: 48.47 s 
2025-01-26 16:23:04.532790:  
2025-01-26 16:23:04.535635: Epoch 287 
2025-01-26 16:23:04.538775: Current learning rate: 0.00738 
2025-01-26 16:23:53.470630: train_loss -0.8108 
2025-01-26 16:23:53.477818: val_loss -0.7462 
2025-01-26 16:23:53.480948: Pseudo dice [np.float32(0.9493), np.float32(0.8754)] 
2025-01-26 16:23:53.483295: Epoch time: 48.94 s 
2025-01-26 16:23:55.254128:  
2025-01-26 16:23:55.256989: Epoch 288 
2025-01-26 16:23:55.259565: Current learning rate: 0.00737 
2025-01-26 16:24:44.462521: train_loss -0.8132 
2025-01-26 16:24:44.466049: val_loss -0.7776 
2025-01-26 16:24:44.468540: Pseudo dice [np.float32(0.9535), np.float32(0.9007)] 
2025-01-26 16:24:44.471267: Epoch time: 49.21 s 
2025-01-26 16:24:45.671788:  
2025-01-26 16:24:45.674789: Epoch 289 
2025-01-26 16:24:45.677426: Current learning rate: 0.00736 
2025-01-26 16:25:34.180741: train_loss -0.8096 
2025-01-26 16:25:34.188249: val_loss -0.7697 
2025-01-26 16:25:34.191021: Pseudo dice [np.float32(0.9541), np.float32(0.8657)] 
2025-01-26 16:25:34.193691: Epoch time: 48.51 s 
2025-01-26 16:25:35.396607:  
2025-01-26 16:25:35.399512: Epoch 290 
2025-01-26 16:25:35.402395: Current learning rate: 0.00735 
2025-01-26 16:26:24.242749: train_loss -0.8279 
2025-01-26 16:26:24.246429: val_loss -0.7304 
2025-01-26 16:26:24.248956: Pseudo dice [np.float32(0.953), np.float32(0.8554)] 
2025-01-26 16:26:24.251358: Epoch time: 48.85 s 
2025-01-26 16:26:25.457627:  
2025-01-26 16:26:25.460913: Epoch 291 
2025-01-26 16:26:25.464059: Current learning rate: 0.00734 
2025-01-26 16:27:13.938965: train_loss -0.8128 
2025-01-26 16:27:13.945569: val_loss -0.7608 
2025-01-26 16:27:13.948421: Pseudo dice [np.float32(0.9542), np.float32(0.8928)] 
2025-01-26 16:27:13.950624: Epoch time: 48.48 s 
2025-01-26 16:27:15.157152:  
2025-01-26 16:27:15.160774: Epoch 292 
2025-01-26 16:27:15.163730: Current learning rate: 0.00733 
2025-01-26 16:28:04.055282: train_loss -0.8219 
2025-01-26 16:28:04.058643: val_loss -0.8072 
2025-01-26 16:28:04.061270: Pseudo dice [np.float32(0.9501), np.float32(0.8982)] 
2025-01-26 16:28:04.064141: Epoch time: 48.9 s 
2025-01-26 16:28:05.267725:  
2025-01-26 16:28:05.270855: Epoch 293 
2025-01-26 16:28:05.273205: Current learning rate: 0.00732 
2025-01-26 16:28:53.438717: train_loss -0.8077 
2025-01-26 16:28:53.444747: val_loss -0.7472 
2025-01-26 16:28:53.447329: Pseudo dice [np.float32(0.9557), np.float32(0.8958)] 
2025-01-26 16:28:53.449612: Epoch time: 48.17 s 
2025-01-26 16:28:53.451891: Yayy! New best EMA pseudo Dice: 0.9150999784469604 
2025-01-26 16:28:55.226284:  
2025-01-26 16:28:55.229470: Epoch 294 
2025-01-26 16:28:55.232803: Current learning rate: 0.00731 
2025-01-26 16:29:43.653464: train_loss -0.8136 
2025-01-26 16:29:43.657213: val_loss -0.8142 
2025-01-26 16:29:43.660069: Pseudo dice [np.float32(0.96), np.float32(0.9122)] 
2025-01-26 16:29:43.662841: Epoch time: 48.43 s 
2025-01-26 16:29:43.665243: Yayy! New best EMA pseudo Dice: 0.9172000288963318 
2025-01-26 16:29:45.429665:  
2025-01-26 16:29:45.432655: Epoch 295 
2025-01-26 16:29:45.435364: Current learning rate: 0.0073 
2025-01-26 16:30:34.180271: train_loss -0.8264 
2025-01-26 16:30:34.186676: val_loss -0.7874 
2025-01-26 16:30:34.189196: Pseudo dice [np.float32(0.9571), np.float32(0.9026)] 
2025-01-26 16:30:34.191913: Epoch time: 48.75 s 
2025-01-26 16:30:34.194736: Yayy! New best EMA pseudo Dice: 0.9185000061988831 
2025-01-26 16:30:35.999920:  
2025-01-26 16:30:36.002412: Epoch 296 
2025-01-26 16:30:36.005097: Current learning rate: 0.00729 
2025-01-26 16:31:24.354297: train_loss -0.8089 
2025-01-26 16:31:24.358349: val_loss -0.7845 
2025-01-26 16:31:24.361576: Pseudo dice [np.float32(0.9583), np.float32(0.8937)] 
2025-01-26 16:31:24.364370: Epoch time: 48.36 s 
2025-01-26 16:31:24.367164: Yayy! New best EMA pseudo Dice: 0.9192000031471252 
2025-01-26 16:31:26.173102:  
2025-01-26 16:31:26.176367: Epoch 297 
2025-01-26 16:31:26.179466: Current learning rate: 0.00728 
2025-01-26 16:32:15.100698: train_loss -0.8044 
2025-01-26 16:32:15.107232: val_loss -0.7623 
2025-01-26 16:32:15.109760: Pseudo dice [np.float32(0.9546), np.float32(0.894)] 
2025-01-26 16:32:15.112517: Epoch time: 48.93 s 
2025-01-26 16:32:15.115304: Yayy! New best EMA pseudo Dice: 0.919700026512146 
2025-01-26 16:32:16.878150:  
2025-01-26 16:32:16.881030: Epoch 298 
2025-01-26 16:32:16.883852: Current learning rate: 0.00727 
2025-01-26 16:33:06.000147: train_loss -0.7979 
2025-01-26 16:33:06.004241: val_loss -0.7894 
2025-01-26 16:33:06.006872: Pseudo dice [np.float32(0.9489), np.float32(0.8534)] 
2025-01-26 16:33:06.009737: Epoch time: 49.12 s 
2025-01-26 16:33:07.283721:  
2025-01-26 16:33:07.287053: Epoch 299 
2025-01-26 16:33:07.289853: Current learning rate: 0.00726 
2025-01-26 16:33:55.853067: train_loss -0.8061 
2025-01-26 16:33:55.860860: val_loss -0.7698 
2025-01-26 16:33:55.863570: Pseudo dice [np.float32(0.9519), np.float32(0.8884)] 
2025-01-26 16:33:55.866419: Epoch time: 48.57 s 
2025-01-26 16:33:57.648410:  
2025-01-26 16:33:57.651465: Epoch 300 
2025-01-26 16:33:57.654466: Current learning rate: 0.00725 
2025-01-26 16:34:46.563501: train_loss -0.799 
2025-01-26 16:34:46.567475: val_loss -0.7976 
2025-01-26 16:34:46.570026: Pseudo dice [np.float32(0.9506), np.float32(0.8763)] 
2025-01-26 16:34:46.572577: Epoch time: 48.92 s 
2025-01-26 16:34:47.767667:  
2025-01-26 16:34:47.770745: Epoch 301 
2025-01-26 16:34:47.773786: Current learning rate: 0.00724 
2025-01-26 16:35:36.058011: train_loss -0.8083 
2025-01-26 16:35:36.065011: val_loss -0.7427 
2025-01-26 16:35:36.067791: Pseudo dice [np.float32(0.9595), np.float32(0.9028)] 
2025-01-26 16:35:36.070241: Epoch time: 48.29 s 
2025-01-26 16:35:37.266116:  
2025-01-26 16:35:37.269039: Epoch 302 
2025-01-26 16:35:37.272014: Current learning rate: 0.00724 
2025-01-26 16:36:25.875657: train_loss -0.8023 
2025-01-26 16:36:25.878762: val_loss -0.7494 
2025-01-26 16:36:25.881556: Pseudo dice [np.float32(0.9483), np.float32(0.8462)] 
2025-01-26 16:36:25.884087: Epoch time: 48.61 s 
2025-01-26 16:36:27.087729:  
2025-01-26 16:36:27.090651: Epoch 303 
2025-01-26 16:36:27.093688: Current learning rate: 0.00723 
2025-01-26 16:37:15.984904: train_loss -0.7913 
2025-01-26 16:37:15.991908: val_loss -0.8025 
2025-01-26 16:37:15.994674: Pseudo dice [np.float32(0.9548), np.float32(0.8909)] 
2025-01-26 16:37:15.997205: Epoch time: 48.9 s 
2025-01-26 16:37:17.197381:  
2025-01-26 16:37:17.200547: Epoch 304 
2025-01-26 16:37:17.203616: Current learning rate: 0.00722 
2025-01-26 16:38:05.491106: train_loss -0.8279 
2025-01-26 16:38:05.495143: val_loss -0.783 
2025-01-26 16:38:05.498273: Pseudo dice [np.float32(0.9624), np.float32(0.914)] 
2025-01-26 16:38:05.501264: Epoch time: 48.29 s 
2025-01-26 16:38:06.726284:  
2025-01-26 16:38:06.729572: Epoch 305 
2025-01-26 16:38:06.732763: Current learning rate: 0.00721 
2025-01-26 16:38:55.274164: train_loss -0.78 
2025-01-26 16:38:55.280871: val_loss -0.7205 
2025-01-26 16:38:55.283969: Pseudo dice [np.float32(0.948), np.float32(0.8455)] 
2025-01-26 16:38:55.286821: Epoch time: 48.55 s 
2025-01-26 16:38:57.097697:  
2025-01-26 16:38:57.100420: Epoch 306 
2025-01-26 16:38:57.103108: Current learning rate: 0.0072 
2025-01-26 16:39:45.777912: train_loss -0.7835 
2025-01-26 16:39:45.781545: val_loss -0.7871 
2025-01-26 16:39:45.784717: Pseudo dice [np.float32(0.9573), np.float32(0.9031)] 
2025-01-26 16:39:45.787461: Epoch time: 48.68 s 
2025-01-26 16:39:47.022090:  
2025-01-26 16:39:47.025585: Epoch 307 
2025-01-26 16:39:47.028409: Current learning rate: 0.00719 
2025-01-26 16:40:35.948046: train_loss -0.8139 
2025-01-26 16:40:35.955829: val_loss -0.7953 
2025-01-26 16:40:35.958816: Pseudo dice [np.float32(0.955), np.float32(0.8939)] 
2025-01-26 16:40:35.961646: Epoch time: 48.93 s 
2025-01-26 16:40:37.157238:  
2025-01-26 16:40:37.160969: Epoch 308 
2025-01-26 16:40:37.164080: Current learning rate: 0.00718 
2025-01-26 16:41:25.594872: train_loss -0.8054 
2025-01-26 16:41:25.598836: val_loss -0.7397 
2025-01-26 16:41:25.601721: Pseudo dice [np.float32(0.9393), np.float32(0.8758)] 
2025-01-26 16:41:25.604326: Epoch time: 48.44 s 
2025-01-26 16:41:26.806429:  
2025-01-26 16:41:26.809412: Epoch 309 
2025-01-26 16:41:26.812147: Current learning rate: 0.00717 
2025-01-26 16:42:15.371886: train_loss -0.7995 
2025-01-26 16:42:15.379687: val_loss -0.7955 
2025-01-26 16:42:15.382554: Pseudo dice [np.float32(0.955), np.float32(0.8721)] 
2025-01-26 16:42:15.385391: Epoch time: 48.57 s 
2025-01-26 16:42:16.618214:  
2025-01-26 16:42:16.620912: Epoch 310 
2025-01-26 16:42:16.623589: Current learning rate: 0.00716 
2025-01-26 16:43:05.405411: train_loss -0.7984 
2025-01-26 16:43:05.409925: val_loss -0.7391 
2025-01-26 16:43:05.413030: Pseudo dice [np.float32(0.9543), np.float32(0.8627)] 
2025-01-26 16:43:05.415700: Epoch time: 48.79 s 
2025-01-26 16:43:06.650171:  
2025-01-26 16:43:06.653329: Epoch 311 
2025-01-26 16:43:06.656463: Current learning rate: 0.00715 
2025-01-26 16:43:55.298968: train_loss -0.7957 
2025-01-26 16:43:55.306097: val_loss -0.8069 
2025-01-26 16:43:55.308701: Pseudo dice [np.float32(0.9506), np.float32(0.8972)] 
2025-01-26 16:43:55.311526: Epoch time: 48.65 s 
2025-01-26 16:43:56.509094:  
2025-01-26 16:43:56.512104: Epoch 312 
2025-01-26 16:43:56.514968: Current learning rate: 0.00714 
2025-01-26 16:44:44.280973: train_loss -0.8116 
2025-01-26 16:44:44.285059: val_loss -0.7693 
2025-01-26 16:44:44.288318: Pseudo dice [np.float32(0.9537), np.float32(0.8809)] 
2025-01-26 16:44:44.291071: Epoch time: 47.77 s 
2025-01-26 16:44:45.486745:  
2025-01-26 16:44:45.489874: Epoch 313 
2025-01-26 16:44:45.492903: Current learning rate: 0.00713 
2025-01-26 16:45:34.300118: train_loss -0.8053 
2025-01-26 16:45:34.307007: val_loss -0.8049 
2025-01-26 16:45:34.309900: Pseudo dice [np.float32(0.9508), np.float32(0.882)] 
2025-01-26 16:45:34.312632: Epoch time: 48.81 s 
2025-01-26 16:45:35.514798:  
2025-01-26 16:45:35.517778: Epoch 314 
2025-01-26 16:45:35.520543: Current learning rate: 0.00712 
2025-01-26 16:46:24.110603: train_loss -0.8018 
2025-01-26 16:46:24.114178: val_loss -0.7374 
2025-01-26 16:46:24.117275: Pseudo dice [np.float32(0.9485), np.float32(0.8876)] 
2025-01-26 16:46:24.119840: Epoch time: 48.6 s 
2025-01-26 16:46:25.359469:  
2025-01-26 16:46:25.362940: Epoch 315 
2025-01-26 16:46:25.365916: Current learning rate: 0.00711 
2025-01-26 16:47:14.071069: train_loss -0.7967 
2025-01-26 16:47:14.077766: val_loss -0.7579 
2025-01-26 16:47:14.080547: Pseudo dice [np.float32(0.9492), np.float32(0.8498)] 
2025-01-26 16:47:14.083447: Epoch time: 48.71 s 
2025-01-26 16:47:15.281210:  
2025-01-26 16:47:15.284254: Epoch 316 
2025-01-26 16:47:15.287327: Current learning rate: 0.0071 
2025-01-26 16:48:04.018841: train_loss -0.8143 
2025-01-26 16:48:04.022384: val_loss -0.7848 
2025-01-26 16:48:04.025576: Pseudo dice [np.float32(0.9553), np.float32(0.8876)] 
2025-01-26 16:48:04.028416: Epoch time: 48.74 s 
2025-01-26 16:48:05.222950:  
2025-01-26 16:48:05.226361: Epoch 317 
2025-01-26 16:48:05.229212: Current learning rate: 0.0071 
2025-01-26 16:48:54.036116: train_loss -0.8156 
2025-01-26 16:48:54.042172: val_loss -0.764 
2025-01-26 16:48:54.044739: Pseudo dice [np.float32(0.9594), np.float32(0.8997)] 
2025-01-26 16:48:54.047220: Epoch time: 48.81 s 
2025-01-26 16:48:55.242073:  
2025-01-26 16:48:55.245549: Epoch 318 
2025-01-26 16:48:55.248786: Current learning rate: 0.00709 
2025-01-26 16:49:44.074030: train_loss -0.7988 
2025-01-26 16:49:44.077747: val_loss -0.777 
2025-01-26 16:49:44.080801: Pseudo dice [np.float32(0.9548), np.float32(0.9005)] 
2025-01-26 16:49:44.083899: Epoch time: 48.83 s 
2025-01-26 16:49:45.326804:  
2025-01-26 16:49:45.330149: Epoch 319 
2025-01-26 16:49:45.333173: Current learning rate: 0.00708 
2025-01-26 16:50:33.867903: train_loss -0.8135 
2025-01-26 16:50:33.875579: val_loss -0.8165 
2025-01-26 16:50:33.878850: Pseudo dice [np.float32(0.9586), np.float32(0.9172)] 
2025-01-26 16:50:33.881852: Epoch time: 48.54 s 
2025-01-26 16:50:33.884579: Yayy! New best EMA pseudo Dice: 0.9204000234603882 
2025-01-26 16:50:35.645210:  
2025-01-26 16:50:35.648088: Epoch 320 
2025-01-26 16:50:35.651035: Current learning rate: 0.00707 
2025-01-26 16:51:23.885093: train_loss -0.8182 
2025-01-26 16:51:23.889115: val_loss -0.7549 
2025-01-26 16:51:23.892410: Pseudo dice [np.float32(0.9551), np.float32(0.8961)] 
2025-01-26 16:51:23.895127: Epoch time: 48.24 s 
2025-01-26 16:51:23.898055: Yayy! New best EMA pseudo Dice: 0.9210000038146973 
2025-01-26 16:51:25.683176:  
2025-01-26 16:51:25.685957: Epoch 321 
2025-01-26 16:51:25.688898: Current learning rate: 0.00706 
2025-01-26 16:52:14.118458: train_loss -0.8059 
2025-01-26 16:52:14.124965: val_loss -0.7267 
2025-01-26 16:52:14.127852: Pseudo dice [np.float32(0.9583), np.float32(0.871)] 
2025-01-26 16:52:14.130563: Epoch time: 48.44 s 
2025-01-26 16:52:15.335093:  
2025-01-26 16:52:15.337833: Epoch 322 
2025-01-26 16:52:15.340624: Current learning rate: 0.00705 
2025-01-26 16:53:03.632789: train_loss -0.8248 
2025-01-26 16:53:03.636647: val_loss -0.7458 
2025-01-26 16:53:03.639561: Pseudo dice [np.float32(0.9537), np.float32(0.8802)] 
2025-01-26 16:53:03.641722: Epoch time: 48.3 s 
2025-01-26 16:53:04.853422:  
2025-01-26 16:53:04.856681: Epoch 323 
2025-01-26 16:53:04.859581: Current learning rate: 0.00704 
2025-01-26 16:53:54.031271: train_loss -0.8127 
2025-01-26 16:53:54.037891: val_loss -0.7438 
2025-01-26 16:53:54.040743: Pseudo dice [np.float32(0.9464), np.float32(0.8777)] 
2025-01-26 16:53:54.043423: Epoch time: 49.18 s 
2025-01-26 16:53:55.931713:  
2025-01-26 16:53:55.934896: Epoch 324 
2025-01-26 16:53:55.937926: Current learning rate: 0.00703 
2025-01-26 16:54:44.354795: train_loss -0.7694 
2025-01-26 16:54:44.358441: val_loss -0.7532 
2025-01-26 16:54:44.360821: Pseudo dice [np.float32(0.9424), np.float32(0.8634)] 
2025-01-26 16:54:44.363393: Epoch time: 48.42 s 
2025-01-26 16:54:45.563232:  
2025-01-26 16:54:45.566347: Epoch 325 
2025-01-26 16:54:45.569061: Current learning rate: 0.00702 
2025-01-26 16:55:33.563407: train_loss -0.799 
2025-01-26 16:55:33.570041: val_loss -0.7817 
2025-01-26 16:55:33.572900: Pseudo dice [np.float32(0.9502), np.float32(0.8667)] 
2025-01-26 16:55:33.575405: Epoch time: 48.0 s 
2025-01-26 16:55:34.814458:  
2025-01-26 16:55:34.817696: Epoch 326 
2025-01-26 16:55:34.821022: Current learning rate: 0.00701 
2025-01-26 16:56:23.097594: train_loss -0.8265 
2025-01-26 16:56:23.101607: val_loss -0.7762 
2025-01-26 16:56:23.104634: Pseudo dice [np.float32(0.9602), np.float32(0.8744)] 
2025-01-26 16:56:23.107970: Epoch time: 48.28 s 
2025-01-26 16:56:24.311292:  
2025-01-26 16:56:24.314801: Epoch 327 
2025-01-26 16:56:24.317770: Current learning rate: 0.007 
2025-01-26 16:57:13.288502: train_loss -0.8177 
2025-01-26 16:57:13.295038: val_loss -0.8076 
2025-01-26 16:57:13.297851: Pseudo dice [np.float32(0.9625), np.float32(0.8929)] 
2025-01-26 16:57:13.300322: Epoch time: 48.98 s 
2025-01-26 16:57:14.534992:  
2025-01-26 16:57:14.538063: Epoch 328 
2025-01-26 16:57:14.540783: Current learning rate: 0.00699 
2025-01-26 16:58:03.102498: train_loss -0.8075 
2025-01-26 16:58:03.106164: val_loss -0.8134 
2025-01-26 16:58:03.109476: Pseudo dice [np.float32(0.9562), np.float32(0.8972)] 
2025-01-26 16:58:03.112534: Epoch time: 48.57 s 
2025-01-26 16:58:04.345615:  
2025-01-26 16:58:04.348820: Epoch 329 
2025-01-26 16:58:04.351903: Current learning rate: 0.00698 
2025-01-26 16:58:52.549788: train_loss -0.81 
2025-01-26 16:58:52.557109: val_loss -0.7351 
2025-01-26 16:58:52.560239: Pseudo dice [np.float32(0.9572), np.float32(0.8898)] 
2025-01-26 16:58:52.563105: Epoch time: 48.21 s 
2025-01-26 16:58:53.800718:  
2025-01-26 16:58:53.804176: Epoch 330 
2025-01-26 16:58:53.807564: Current learning rate: 0.00697 
2025-01-26 16:59:42.284670: train_loss -0.8 
2025-01-26 16:59:42.288352: val_loss -0.7649 
2025-01-26 16:59:42.291374: Pseudo dice [np.float32(0.9582), np.float32(0.8984)] 
2025-01-26 16:59:42.294413: Epoch time: 48.48 s 
2025-01-26 16:59:43.493400:  
2025-01-26 16:59:43.496522: Epoch 331 
2025-01-26 16:59:43.499324: Current learning rate: 0.00696 
2025-01-26 17:00:32.213570: train_loss -0.8221 
2025-01-26 17:00:32.220508: val_loss -0.7664 
2025-01-26 17:00:32.223283: Pseudo dice [np.float32(0.9569), np.float32(0.8926)] 
2025-01-26 17:00:32.225669: Epoch time: 48.72 s 
2025-01-26 17:00:33.475183:  
2025-01-26 17:00:33.478286: Epoch 332 
2025-01-26 17:00:33.481450: Current learning rate: 0.00696 
2025-01-26 17:01:22.010947: train_loss -0.8091 
2025-01-26 17:01:22.014466: val_loss -0.8054 
2025-01-26 17:01:22.017611: Pseudo dice [np.float32(0.9554), np.float32(0.8979)] 
2025-01-26 17:01:22.020366: Epoch time: 48.54 s 
2025-01-26 17:01:22.023110: Yayy! New best EMA pseudo Dice: 0.9211999773979187 
2025-01-26 17:01:23.792799:  
2025-01-26 17:01:23.797992: Epoch 333 
2025-01-26 17:01:23.801444: Current learning rate: 0.00695 
2025-01-26 17:02:12.671913: train_loss -0.8186 
2025-01-26 17:02:12.680316: val_loss -0.7705 
2025-01-26 17:02:12.682967: Pseudo dice [np.float32(0.9583), np.float32(0.9097)] 
2025-01-26 17:02:12.685545: Epoch time: 48.88 s 
2025-01-26 17:02:12.688076: Yayy! New best EMA pseudo Dice: 0.9225000143051147 
2025-01-26 17:02:14.486673:  
2025-01-26 17:02:14.489674: Epoch 334 
2025-01-26 17:02:14.492294: Current learning rate: 0.00694 
2025-01-26 17:03:02.792382: train_loss -0.81 
2025-01-26 17:03:02.796397: val_loss -0.7618 
2025-01-26 17:03:02.799315: Pseudo dice [np.float32(0.9572), np.float32(0.9018)] 
2025-01-26 17:03:02.801893: Epoch time: 48.31 s 
2025-01-26 17:03:02.804624: Yayy! New best EMA pseudo Dice: 0.9232000112533569 
2025-01-26 17:03:04.605136:  
2025-01-26 17:03:04.608218: Epoch 335 
2025-01-26 17:03:04.611462: Current learning rate: 0.00693 
2025-01-26 17:03:52.959614: train_loss -0.8015 
2025-01-26 17:03:52.966408: val_loss -0.8057 
2025-01-26 17:03:52.969111: Pseudo dice [np.float32(0.9597), np.float32(0.9036)] 
2025-01-26 17:03:52.971892: Epoch time: 48.36 s 
2025-01-26 17:03:52.974732: Yayy! New best EMA pseudo Dice: 0.9240000247955322 
2025-01-26 17:03:54.838948:  
2025-01-26 17:03:54.841942: Epoch 336 
2025-01-26 17:03:54.844705: Current learning rate: 0.00692 
2025-01-26 17:04:43.428920: train_loss -0.8218 
2025-01-26 17:04:43.432643: val_loss -0.7542 
2025-01-26 17:04:43.435727: Pseudo dice [np.float32(0.9558), np.float32(0.8828)] 
2025-01-26 17:04:43.438097: Epoch time: 48.59 s 
2025-01-26 17:04:44.648836:  
2025-01-26 17:04:44.651795: Epoch 337 
2025-01-26 17:04:44.655078: Current learning rate: 0.00691 
2025-01-26 17:05:33.488375: train_loss -0.8207 
2025-01-26 17:05:33.495651: val_loss -0.7537 
2025-01-26 17:05:33.498558: Pseudo dice [np.float32(0.9476), np.float32(0.8414)] 
2025-01-26 17:05:33.501146: Epoch time: 48.84 s 
2025-01-26 17:05:34.712610:  
2025-01-26 17:05:34.715565: Epoch 338 
2025-01-26 17:05:34.718464: Current learning rate: 0.0069 
2025-01-26 17:06:23.488128: train_loss -0.814 
2025-01-26 17:06:23.496023: val_loss -0.7872 
2025-01-26 17:06:23.499008: Pseudo dice [np.float32(0.9541), np.float32(0.8868)] 
2025-01-26 17:06:23.501949: Epoch time: 48.78 s 
2025-01-26 17:06:24.740344:  
2025-01-26 17:06:24.745243: Epoch 339 
2025-01-26 17:06:24.748035: Current learning rate: 0.00689 
2025-01-26 17:07:12.991370: train_loss -0.7936 
2025-01-26 17:07:12.998468: val_loss -0.7679 
2025-01-26 17:07:13.001374: Pseudo dice [np.float32(0.9596), np.float32(0.8639)] 
2025-01-26 17:07:13.003919: Epoch time: 48.25 s 
2025-01-26 17:07:14.243709:  
2025-01-26 17:07:14.247006: Epoch 340 
2025-01-26 17:07:14.249725: Current learning rate: 0.00688 
2025-01-26 17:08:02.907074: train_loss -0.8188 
2025-01-26 17:08:02.910586: val_loss -0.7705 
2025-01-26 17:08:02.913323: Pseudo dice [np.float32(0.9478), np.float32(0.8427)] 
2025-01-26 17:08:02.915905: Epoch time: 48.66 s 
2025-01-26 17:08:04.151477:  
2025-01-26 17:08:04.154609: Epoch 341 
2025-01-26 17:08:04.157204: Current learning rate: 0.00687 
2025-01-26 17:08:52.366425: train_loss -0.8219 
2025-01-26 17:08:52.373182: val_loss -0.757 
2025-01-26 17:08:52.375703: Pseudo dice [np.float32(0.951), np.float32(0.8803)] 
2025-01-26 17:08:52.378495: Epoch time: 48.22 s 
2025-01-26 17:08:54.225544:  
2025-01-26 17:08:54.229007: Epoch 342 
2025-01-26 17:08:54.232193: Current learning rate: 0.00686 
2025-01-26 17:09:43.597887: train_loss -0.8075 
2025-01-26 17:09:43.601673: val_loss -0.7466 
2025-01-26 17:09:43.604801: Pseudo dice [np.float32(0.9604), np.float32(0.8845)] 
2025-01-26 17:09:43.607569: Epoch time: 49.37 s 
2025-01-26 17:09:44.840123:  
2025-01-26 17:09:44.843704: Epoch 343 
2025-01-26 17:09:44.846848: Current learning rate: 0.00685 
2025-01-26 17:10:33.589649: train_loss -0.8153 
2025-01-26 17:10:33.595777: val_loss -0.7744 
2025-01-26 17:10:33.597973: Pseudo dice [np.float32(0.9555), np.float32(0.8892)] 
2025-01-26 17:10:33.600210: Epoch time: 48.75 s 
2025-01-26 17:10:34.829231:  
2025-01-26 17:10:34.832122: Epoch 344 
2025-01-26 17:10:34.834666: Current learning rate: 0.00684 
2025-01-26 17:11:23.297858: train_loss -0.7982 
2025-01-26 17:11:23.301471: val_loss -0.7477 
2025-01-26 17:11:23.304158: Pseudo dice [np.float32(0.9528), np.float32(0.8469)] 
2025-01-26 17:11:23.306449: Epoch time: 48.47 s 
2025-01-26 17:11:24.533133:  
2025-01-26 17:11:24.536013: Epoch 345 
2025-01-26 17:11:24.538813: Current learning rate: 0.00683 
2025-01-26 17:12:12.975083: train_loss -0.813 
2025-01-26 17:12:12.983008: val_loss -0.7733 
2025-01-26 17:12:12.986295: Pseudo dice [np.float32(0.9574), np.float32(0.9181)] 
2025-01-26 17:12:12.989631: Epoch time: 48.44 s 
2025-01-26 17:12:14.228572:  
2025-01-26 17:12:14.231511: Epoch 346 
2025-01-26 17:12:14.234568: Current learning rate: 0.00682 
2025-01-26 17:13:02.850056: train_loss -0.8124 
2025-01-26 17:13:02.854143: val_loss -0.7368 
2025-01-26 17:13:02.857475: Pseudo dice [np.float32(0.9571), np.float32(0.8931)] 
2025-01-26 17:13:02.860625: Epoch time: 48.62 s 
2025-01-26 17:13:04.089817:  
2025-01-26 17:13:04.092926: Epoch 347 
2025-01-26 17:13:04.095802: Current learning rate: 0.00681 
2025-01-26 17:13:52.347909: train_loss -0.8016 
2025-01-26 17:13:52.355096: val_loss -0.7719 
2025-01-26 17:13:52.357931: Pseudo dice [np.float32(0.9554), np.float32(0.8822)] 
2025-01-26 17:13:52.360535: Epoch time: 48.26 s 
2025-01-26 17:13:53.594793:  
2025-01-26 17:13:53.597833: Epoch 348 
2025-01-26 17:13:53.600415: Current learning rate: 0.0068 
2025-01-26 17:14:41.916257: train_loss -0.8064 
2025-01-26 17:14:41.920260: val_loss -0.783 
2025-01-26 17:14:41.922944: Pseudo dice [np.float32(0.9574), np.float32(0.8839)] 
2025-01-26 17:14:41.925632: Epoch time: 48.32 s 
2025-01-26 17:14:43.150216:  
2025-01-26 17:14:43.152924: Epoch 349 
2025-01-26 17:14:43.155687: Current learning rate: 0.0068 
2025-01-26 17:15:31.742876: train_loss -0.8199 
2025-01-26 17:15:31.749182: val_loss -0.7507 
2025-01-26 17:15:31.751876: Pseudo dice [np.float32(0.9511), np.float32(0.8917)] 
2025-01-26 17:15:31.754402: Epoch time: 48.59 s 
2025-01-26 17:15:33.538328:  
2025-01-26 17:15:33.541739: Epoch 350 
2025-01-26 17:15:33.544829: Current learning rate: 0.00679 
2025-01-26 17:16:22.205996: train_loss -0.7948 
2025-01-26 17:16:22.209476: val_loss -0.7634 
2025-01-26 17:16:22.212803: Pseudo dice [np.float32(0.9473), np.float32(0.8472)] 
2025-01-26 17:16:22.215466: Epoch time: 48.67 s 
2025-01-26 17:16:23.449427:  
2025-01-26 17:16:23.452628: Epoch 351 
2025-01-26 17:16:23.455630: Current learning rate: 0.00678 
2025-01-26 17:17:12.056926: train_loss -0.8012 
2025-01-26 17:17:12.064005: val_loss -0.7455 
2025-01-26 17:17:12.066568: Pseudo dice [np.float32(0.958), np.float32(0.8928)] 
2025-01-26 17:17:12.069250: Epoch time: 48.61 s 
2025-01-26 17:17:13.295228:  
2025-01-26 17:17:13.299451: Epoch 352 
2025-01-26 17:17:13.302292: Current learning rate: 0.00677 
2025-01-26 17:18:01.966858: train_loss -0.813 
2025-01-26 17:18:01.970371: val_loss -0.8086 
2025-01-26 17:18:01.973065: Pseudo dice [np.float32(0.9522), np.float32(0.8819)] 
2025-01-26 17:18:01.975769: Epoch time: 48.67 s 
2025-01-26 17:18:03.199776:  
2025-01-26 17:18:03.202840: Epoch 353 
2025-01-26 17:18:03.205432: Current learning rate: 0.00676 
2025-01-26 17:18:51.472343: train_loss -0.8164 
2025-01-26 17:18:51.480059: val_loss -0.7759 
2025-01-26 17:18:51.483176: Pseudo dice [np.float32(0.9579), np.float32(0.8994)] 
2025-01-26 17:18:51.486151: Epoch time: 48.27 s 
2025-01-26 17:18:52.719899:  
2025-01-26 17:18:52.722320: Epoch 354 
2025-01-26 17:18:52.725135: Current learning rate: 0.00675 
2025-01-26 17:19:41.204604: train_loss -0.8219 
2025-01-26 17:19:41.208387: val_loss -0.8092 
2025-01-26 17:19:41.211092: Pseudo dice [np.float32(0.9602), np.float32(0.9022)] 
2025-01-26 17:19:41.213870: Epoch time: 48.49 s 
2025-01-26 17:19:42.435672:  
2025-01-26 17:19:42.438690: Epoch 355 
2025-01-26 17:19:42.441285: Current learning rate: 0.00674 
2025-01-26 17:20:31.303839: train_loss -0.823 
2025-01-26 17:20:31.311496: val_loss -0.7555 
2025-01-26 17:20:31.314389: Pseudo dice [np.float32(0.9602), np.float32(0.909)] 
2025-01-26 17:20:31.317165: Epoch time: 48.87 s 
2025-01-26 17:20:32.552906:  
2025-01-26 17:20:32.555546: Epoch 356 
2025-01-26 17:20:32.557986: Current learning rate: 0.00673 
2025-01-26 17:21:20.864211: train_loss -0.821 
2025-01-26 17:21:20.867656: val_loss -0.7958 
2025-01-26 17:21:20.870860: Pseudo dice [np.float32(0.9545), np.float32(0.9145)] 
2025-01-26 17:21:20.873505: Epoch time: 48.31 s 
2025-01-26 17:21:22.102789:  
2025-01-26 17:21:22.106002: Epoch 357 
2025-01-26 17:21:22.108834: Current learning rate: 0.00672 
2025-01-26 17:22:10.819590: train_loss -0.8292 
2025-01-26 17:22:10.827359: val_loss -0.7338 
2025-01-26 17:22:10.830351: Pseudo dice [np.float32(0.9522), np.float32(0.8763)] 
2025-01-26 17:22:10.833328: Epoch time: 48.72 s 
2025-01-26 17:22:12.063490:  
2025-01-26 17:22:12.066183: Epoch 358 
2025-01-26 17:22:12.069032: Current learning rate: 0.00671 
2025-01-26 17:23:01.059017: train_loss -0.8269 
2025-01-26 17:23:01.062732: val_loss -0.7461 
2025-01-26 17:23:01.065899: Pseudo dice [np.float32(0.956), np.float32(0.8858)] 
2025-01-26 17:23:01.068407: Epoch time: 49.0 s 
2025-01-26 17:23:02.913917:  
2025-01-26 17:23:02.917383: Epoch 359 
2025-01-26 17:23:02.919998: Current learning rate: 0.0067 
2025-01-26 17:23:51.421604: train_loss -0.8247 
2025-01-26 17:23:51.428860: val_loss -0.7943 
2025-01-26 17:23:51.431949: Pseudo dice [np.float32(0.9526), np.float32(0.8656)] 
2025-01-26 17:23:51.434602: Epoch time: 48.51 s 
2025-01-26 17:23:52.678633:  
2025-01-26 17:23:52.683236: Epoch 360 
2025-01-26 17:23:52.687028: Current learning rate: 0.00669 
2025-01-26 17:24:41.311522: train_loss -0.8074 
2025-01-26 17:24:41.314906: val_loss -0.7659 
2025-01-26 17:24:41.317678: Pseudo dice [np.float32(0.9523), np.float32(0.8889)] 
2025-01-26 17:24:41.320443: Epoch time: 48.64 s 
2025-01-26 17:24:42.551910:  
2025-01-26 17:24:42.555105: Epoch 361 
2025-01-26 17:24:42.558205: Current learning rate: 0.00668 
2025-01-26 17:25:31.272355: train_loss -0.8085 
2025-01-26 17:25:31.280006: val_loss -0.7629 
2025-01-26 17:25:31.282558: Pseudo dice [np.float32(0.9529), np.float32(0.8728)] 
2025-01-26 17:25:31.285362: Epoch time: 48.72 s 
2025-01-26 17:25:32.518459:  
2025-01-26 17:25:32.521528: Epoch 362 
2025-01-26 17:25:32.524385: Current learning rate: 0.00667 
2025-01-26 17:26:21.043069: train_loss -0.8067 
2025-01-26 17:26:21.046288: val_loss -0.7818 
2025-01-26 17:26:21.049123: Pseudo dice [np.float32(0.9533), np.float32(0.8868)] 
2025-01-26 17:26:21.051895: Epoch time: 48.53 s 
2025-01-26 17:26:22.280066:  
2025-01-26 17:26:22.283260: Epoch 363 
2025-01-26 17:26:22.286041: Current learning rate: 0.00666 
2025-01-26 17:27:10.651080: train_loss -0.8336 
2025-01-26 17:27:10.658282: val_loss -0.7797 
2025-01-26 17:27:10.662702: Pseudo dice [np.float32(0.9587), np.float32(0.9128)] 
2025-01-26 17:27:10.665483: Epoch time: 48.37 s 
2025-01-26 17:27:11.881201:  
2025-01-26 17:27:11.884831: Epoch 364 
2025-01-26 17:27:11.887940: Current learning rate: 0.00665 
2025-01-26 17:28:00.125781: train_loss -0.8121 
2025-01-26 17:28:00.129896: val_loss -0.7335 
2025-01-26 17:28:00.132726: Pseudo dice [np.float32(0.9574), np.float32(0.8762)] 
2025-01-26 17:28:00.135463: Epoch time: 48.25 s 
2025-01-26 17:28:01.356142:  
2025-01-26 17:28:01.359276: Epoch 365 
2025-01-26 17:28:01.362288: Current learning rate: 0.00665 
2025-01-26 17:28:50.087911: train_loss -0.7942 
2025-01-26 17:28:50.095112: val_loss -0.7362 
2025-01-26 17:28:50.097818: Pseudo dice [np.float32(0.9417), np.float32(0.8215)] 
2025-01-26 17:28:50.100598: Epoch time: 48.73 s 
2025-01-26 17:28:51.328840:  
2025-01-26 17:28:51.332027: Epoch 366 
2025-01-26 17:28:51.334642: Current learning rate: 0.00664 
2025-01-26 17:29:39.852051: train_loss -0.8048 
2025-01-26 17:29:39.855177: val_loss -0.7874 
2025-01-26 17:29:39.857790: Pseudo dice [np.float32(0.9503), np.float32(0.8916)] 
2025-01-26 17:29:39.860343: Epoch time: 48.52 s 
2025-01-26 17:29:41.084548:  
2025-01-26 17:29:41.087261: Epoch 367 
2025-01-26 17:29:41.090234: Current learning rate: 0.00663 
2025-01-26 17:30:30.170604: train_loss -0.8052 
2025-01-26 17:30:30.177445: val_loss -0.6776 
2025-01-26 17:30:30.180321: Pseudo dice [np.float32(0.9503), np.float32(0.5645)] 
2025-01-26 17:30:30.183120: Epoch time: 49.09 s 
2025-01-26 17:30:31.404109:  
2025-01-26 17:30:31.407302: Epoch 368 
2025-01-26 17:30:31.410023: Current learning rate: 0.00662 
2025-01-26 17:31:20.200214: train_loss -0.8031 
2025-01-26 17:31:20.203661: val_loss -0.7739 
2025-01-26 17:31:20.206283: Pseudo dice [np.float32(0.9525), np.float32(0.8499)] 
2025-01-26 17:31:20.208771: Epoch time: 48.8 s 
2025-01-26 17:31:21.426857:  
2025-01-26 17:31:21.429500: Epoch 369 
2025-01-26 17:31:21.432291: Current learning rate: 0.00661 
2025-01-26 17:32:09.962378: train_loss -0.8155 
2025-01-26 17:32:09.968753: val_loss -0.7559 
2025-01-26 17:32:09.971258: Pseudo dice [np.float32(0.9589), np.float32(0.8609)] 
2025-01-26 17:32:09.973887: Epoch time: 48.54 s 
2025-01-26 17:32:11.197157:  
2025-01-26 17:32:11.199975: Epoch 370 
2025-01-26 17:32:11.202329: Current learning rate: 0.0066 
2025-01-26 17:32:59.815893: train_loss -0.8072 
2025-01-26 17:32:59.819805: val_loss -0.7918 
2025-01-26 17:32:59.822422: Pseudo dice [np.float32(0.9575), np.float32(0.8823)] 
2025-01-26 17:32:59.825118: Epoch time: 48.62 s 
2025-01-26 17:33:01.045514:  
2025-01-26 17:33:01.048373: Epoch 371 
2025-01-26 17:33:01.051033: Current learning rate: 0.00659 
2025-01-26 17:33:49.852695: train_loss -0.801 
2025-01-26 17:33:49.860728: val_loss -0.7753 
2025-01-26 17:33:49.863642: Pseudo dice [np.float32(0.9548), np.float32(0.8523)] 
2025-01-26 17:33:49.866593: Epoch time: 48.81 s 
2025-01-26 17:33:51.089796:  
2025-01-26 17:33:51.092610: Epoch 372 
2025-01-26 17:33:51.095340: Current learning rate: 0.00658 
2025-01-26 17:34:39.581170: train_loss -0.7842 
2025-01-26 17:34:39.584451: val_loss -0.7207 
2025-01-26 17:34:39.586906: Pseudo dice [np.float32(0.9538), np.float32(0.8615)] 
2025-01-26 17:34:39.589611: Epoch time: 48.49 s 
2025-01-26 17:34:40.812499:  
2025-01-26 17:34:40.815246: Epoch 373 
2025-01-26 17:34:40.818201: Current learning rate: 0.00657 
2025-01-26 17:35:29.672669: train_loss -0.8046 
2025-01-26 17:35:29.679346: val_loss -0.7343 
2025-01-26 17:35:29.682318: Pseudo dice [np.float32(0.9485), np.float32(0.8267)] 
2025-01-26 17:35:29.685079: Epoch time: 48.86 s 
2025-01-26 17:35:30.904388:  
2025-01-26 17:35:30.906953: Epoch 374 
2025-01-26 17:35:30.909896: Current learning rate: 0.00656 
2025-01-26 17:36:19.238591: train_loss -0.8004 
2025-01-26 17:36:19.241935: val_loss -0.7559 
2025-01-26 17:36:19.244852: Pseudo dice [np.float32(0.9539), np.float32(0.901)] 
2025-01-26 17:36:19.247530: Epoch time: 48.34 s 
2025-01-26 17:36:20.471683:  
2025-01-26 17:36:20.474281: Epoch 375 
2025-01-26 17:36:20.476877: Current learning rate: 0.00655 
2025-01-26 17:37:10.097390: train_loss -0.8122 
2025-01-26 17:37:10.103786: val_loss -0.7484 
2025-01-26 17:37:10.106469: Pseudo dice [np.float32(0.9563), np.float32(0.8706)] 
2025-01-26 17:37:10.108664: Epoch time: 49.63 s 
2025-01-26 17:37:11.334002:  
2025-01-26 17:37:11.337335: Epoch 376 
2025-01-26 17:37:11.340375: Current learning rate: 0.00654 
2025-01-26 17:37:59.962965: train_loss -0.8088 
2025-01-26 17:37:59.966363: val_loss -0.8036 
2025-01-26 17:37:59.969211: Pseudo dice [np.float32(0.9552), np.float32(0.9038)] 
2025-01-26 17:37:59.972401: Epoch time: 48.63 s 
2025-01-26 17:38:01.770695:  
2025-01-26 17:38:01.773571: Epoch 377 
2025-01-26 17:38:01.776233: Current learning rate: 0.00653 
2025-01-26 17:38:50.733782: train_loss -0.8237 
2025-01-26 17:38:50.740124: val_loss -0.7476 
2025-01-26 17:38:50.742688: Pseudo dice [np.float32(0.9623), np.float32(0.8896)] 
2025-01-26 17:38:50.745288: Epoch time: 48.96 s 
2025-01-26 17:38:51.963588:  
2025-01-26 17:38:51.966677: Epoch 378 
2025-01-26 17:38:51.969599: Current learning rate: 0.00652 
2025-01-26 17:39:40.859400: train_loss -0.8227 
2025-01-26 17:39:40.862639: val_loss -0.7423 
2025-01-26 17:39:40.864882: Pseudo dice [np.float32(0.9543), np.float32(0.8607)] 
2025-01-26 17:39:40.867418: Epoch time: 48.9 s 
2025-01-26 17:39:42.085166:  
2025-01-26 17:39:42.088406: Epoch 379 
2025-01-26 17:39:42.091742: Current learning rate: 0.00651 
2025-01-26 17:40:30.484531: train_loss -0.824 
2025-01-26 17:40:30.491087: val_loss -0.7598 
2025-01-26 17:40:30.493787: Pseudo dice [np.float32(0.9494), np.float32(0.8448)] 
2025-01-26 17:40:30.496365: Epoch time: 48.4 s 
2025-01-26 17:40:31.718627:  
2025-01-26 17:40:31.721962: Epoch 380 
2025-01-26 17:40:31.724873: Current learning rate: 0.0065 
2025-01-26 17:41:20.747533: train_loss -0.8154 
2025-01-26 17:41:20.751032: val_loss -0.753 
2025-01-26 17:41:20.753705: Pseudo dice [np.float32(0.9558), np.float32(0.8918)] 
2025-01-26 17:41:20.756320: Epoch time: 49.03 s 
2025-01-26 17:41:21.983934:  
2025-01-26 17:41:21.986902: Epoch 381 
2025-01-26 17:41:21.989718: Current learning rate: 0.00649 
2025-01-26 17:42:10.399992: train_loss -0.7985 
2025-01-26 17:42:10.406303: val_loss -0.7492 
2025-01-26 17:42:10.408858: Pseudo dice [np.float32(0.9492), np.float32(0.8208)] 
2025-01-26 17:42:10.411277: Epoch time: 48.42 s 
2025-01-26 17:42:11.657524:  
2025-01-26 17:42:11.660638: Epoch 382 
2025-01-26 17:42:11.663585: Current learning rate: 0.00648 
2025-01-26 17:43:00.291106: train_loss -0.8081 
2025-01-26 17:43:00.294395: val_loss -0.7536 
2025-01-26 17:43:00.297064: Pseudo dice [np.float32(0.9521), np.float32(0.8873)] 
2025-01-26 17:43:00.299340: Epoch time: 48.63 s 
2025-01-26 17:43:01.538254:  
2025-01-26 17:43:01.541496: Epoch 383 
2025-01-26 17:43:01.544201: Current learning rate: 0.00648 
2025-01-26 17:43:49.870397: train_loss -0.82 
2025-01-26 17:43:49.877481: val_loss -0.7952 
2025-01-26 17:43:49.880408: Pseudo dice [np.float32(0.9502), np.float32(0.8762)] 
2025-01-26 17:43:49.882832: Epoch time: 48.33 s 
2025-01-26 17:43:51.119275:  
2025-01-26 17:43:51.121976: Epoch 384 
2025-01-26 17:43:51.124537: Current learning rate: 0.00647 
2025-01-26 17:44:39.388170: train_loss -0.8148 
2025-01-26 17:44:39.392040: val_loss -0.7778 
2025-01-26 17:44:39.394724: Pseudo dice [np.float32(0.9545), np.float32(0.8696)] 
2025-01-26 17:44:39.397558: Epoch time: 48.27 s 
2025-01-26 17:44:40.634956:  
2025-01-26 17:44:40.637516: Epoch 385 
2025-01-26 17:44:40.640811: Current learning rate: 0.00646 
2025-01-26 17:45:29.390775: train_loss -0.8132 
2025-01-26 17:45:29.397362: val_loss -0.7428 
2025-01-26 17:45:29.399906: Pseudo dice [np.float32(0.9516), np.float32(0.8216)] 
2025-01-26 17:45:29.402378: Epoch time: 48.76 s 
2025-01-26 17:45:30.639018:  
2025-01-26 17:45:30.641522: Epoch 386 
2025-01-26 17:45:30.644310: Current learning rate: 0.00645 
2025-01-26 17:46:18.904757: train_loss -0.8026 
2025-01-26 17:46:18.912750: val_loss -0.7683 
2025-01-26 17:46:18.915244: Pseudo dice [np.float32(0.9518), np.float32(0.848)] 
2025-01-26 17:46:18.918589: Epoch time: 48.27 s 
2025-01-26 17:46:20.159549:  
2025-01-26 17:46:20.162580: Epoch 387 
2025-01-26 17:46:20.164953: Current learning rate: 0.00644 
2025-01-26 17:47:08.770153: train_loss -0.8199 
2025-01-26 17:47:08.779599: val_loss -0.7469 
2025-01-26 17:47:08.782264: Pseudo dice [np.float32(0.9463), np.float32(0.8415)] 
2025-01-26 17:47:08.784724: Epoch time: 48.61 s 
2025-01-26 17:47:10.015769:  
2025-01-26 17:47:10.018755: Epoch 388 
2025-01-26 17:47:10.021621: Current learning rate: 0.00643 
2025-01-26 17:47:58.430398: train_loss -0.7884 
2025-01-26 17:47:58.436628: val_loss -0.7565 
2025-01-26 17:47:58.439747: Pseudo dice [np.float32(0.9515), np.float32(0.8403)] 
2025-01-26 17:47:58.442426: Epoch time: 48.42 s 
2025-01-26 17:47:59.685471:  
2025-01-26 17:47:59.688555: Epoch 389 
2025-01-26 17:47:59.691347: Current learning rate: 0.00642 
2025-01-26 17:48:48.252362: train_loss -0.803 
2025-01-26 17:48:48.260669: val_loss -0.7904 
2025-01-26 17:48:48.263835: Pseudo dice [np.float32(0.9544), np.float32(0.8643)] 
2025-01-26 17:48:48.266511: Epoch time: 48.57 s 
2025-01-26 17:48:49.500872:  
2025-01-26 17:48:49.503851: Epoch 390 
2025-01-26 17:48:49.506739: Current learning rate: 0.00641 
2025-01-26 17:49:37.826408: train_loss -0.8199 
2025-01-26 17:49:37.829695: val_loss -0.8106 
2025-01-26 17:49:37.832659: Pseudo dice [np.float32(0.9593), np.float32(0.9039)] 
2025-01-26 17:49:37.835531: Epoch time: 48.33 s 
2025-01-26 17:49:39.070193:  
2025-01-26 17:49:39.072788: Epoch 391 
2025-01-26 17:49:39.075561: Current learning rate: 0.0064 
2025-01-26 17:50:27.638463: train_loss -0.8169 
2025-01-26 17:50:27.645520: val_loss -0.7871 
2025-01-26 17:50:27.648832: Pseudo dice [np.float32(0.9639), np.float32(0.8921)] 
2025-01-26 17:50:27.651825: Epoch time: 48.57 s 
2025-01-26 17:50:28.887654:  
2025-01-26 17:50:28.892109: Epoch 392 
2025-01-26 17:50:28.895024: Current learning rate: 0.00639 
2025-01-26 17:51:17.456351: train_loss -0.8168 
2025-01-26 17:51:17.459391: val_loss -0.7911 
2025-01-26 17:51:17.462032: Pseudo dice [np.float32(0.9593), np.float32(0.8932)] 
2025-01-26 17:51:17.464726: Epoch time: 48.57 s 
2025-01-26 17:51:18.695662:  
2025-01-26 17:51:18.698870: Epoch 393 
2025-01-26 17:51:18.701884: Current learning rate: 0.00638 
2025-01-26 17:52:07.344807: train_loss -0.8233 
2025-01-26 17:52:07.350798: val_loss -0.8217 
2025-01-26 17:52:07.353064: Pseudo dice [np.float32(0.9566), np.float32(0.9099)] 
2025-01-26 17:52:07.355452: Epoch time: 48.65 s 
2025-01-26 17:52:08.585387:  
2025-01-26 17:52:08.588317: Epoch 394 
2025-01-26 17:52:08.591241: Current learning rate: 0.00637 
2025-01-26 17:52:57.907565: train_loss -0.8096 
2025-01-26 17:52:57.911431: val_loss -0.7878 
2025-01-26 17:52:57.916407: Pseudo dice [np.float32(0.9531), np.float32(0.8841)] 
2025-01-26 17:52:57.919528: Epoch time: 49.32 s 
2025-01-26 17:52:59.861677:  
2025-01-26 17:52:59.865087: Epoch 395 
2025-01-26 17:52:59.868186: Current learning rate: 0.00636 
2025-01-26 17:53:48.598477: train_loss -0.7915 
2025-01-26 17:53:48.610831: val_loss -0.7864 
2025-01-26 17:53:48.614348: Pseudo dice [np.float32(0.952), np.float32(0.9012)] 
2025-01-26 17:53:48.618680: Epoch time: 48.74 s 
2025-01-26 17:53:49.872672:  
2025-01-26 17:53:49.882166: Epoch 396 
2025-01-26 17:53:49.885991: Current learning rate: 0.00635 
2025-01-26 17:54:38.229634: train_loss -0.7968 
2025-01-26 17:54:38.234912: val_loss -0.797 
2025-01-26 17:54:38.238220: Pseudo dice [np.float32(0.9537), np.float32(0.8965)] 
2025-01-26 17:54:38.241307: Epoch time: 48.36 s 
2025-01-26 17:54:39.490266:  
2025-01-26 17:54:39.494704: Epoch 397 
2025-01-26 17:54:39.497792: Current learning rate: 0.00634 
2025-01-26 17:55:27.913720: train_loss -0.8005 
2025-01-26 17:55:27.921952: val_loss -0.7551 
2025-01-26 17:55:27.924969: Pseudo dice [np.float32(0.958), np.float32(0.8928)] 
2025-01-26 17:55:27.927957: Epoch time: 48.42 s 
2025-01-26 17:55:29.171245:  
2025-01-26 17:55:29.174719: Epoch 398 
2025-01-26 17:55:29.177935: Current learning rate: 0.00633 
2025-01-26 17:56:18.118466: train_loss -0.8103 
2025-01-26 17:56:18.125337: val_loss -0.7457 
2025-01-26 17:56:18.128163: Pseudo dice [np.float32(0.962), np.float32(0.8962)] 
2025-01-26 17:56:18.131687: Epoch time: 48.95 s 
2025-01-26 17:56:19.385897:  
2025-01-26 17:56:19.388832: Epoch 399 
2025-01-26 17:56:19.391235: Current learning rate: 0.00632 
2025-01-26 17:57:08.395751: train_loss -0.8104 
2025-01-26 17:57:08.401933: val_loss -0.7595 
2025-01-26 17:57:08.404855: Pseudo dice [np.float32(0.9583), np.float32(0.8891)] 
2025-01-26 17:57:08.407527: Epoch time: 49.01 s 
2025-01-26 17:57:10.299316:  
2025-01-26 17:57:10.302485: Epoch 400 
2025-01-26 17:57:10.305405: Current learning rate: 0.00631 
2025-01-26 17:57:58.556963: train_loss -0.8262 
2025-01-26 17:57:58.560673: val_loss -0.7448 
2025-01-26 17:57:58.563361: Pseudo dice [np.float32(0.9594), np.float32(0.8911)] 
2025-01-26 17:57:58.566044: Epoch time: 48.26 s 
2025-01-26 17:57:59.798352:  
2025-01-26 17:57:59.801828: Epoch 401 
2025-01-26 17:57:59.804750: Current learning rate: 0.0063 
2025-01-26 17:58:48.018724: train_loss -0.812 
2025-01-26 17:58:48.026759: val_loss -0.7674 
2025-01-26 17:58:48.029362: Pseudo dice [np.float32(0.9539), np.float32(0.8659)] 
2025-01-26 17:58:48.031818: Epoch time: 48.22 s 
2025-01-26 17:58:49.266842:  
2025-01-26 17:58:49.270100: Epoch 402 
2025-01-26 17:58:49.273406: Current learning rate: 0.0063 
2025-01-26 17:59:37.686282: train_loss -0.8258 
2025-01-26 17:59:37.689894: val_loss -0.7908 
2025-01-26 17:59:37.692887: Pseudo dice [np.float32(0.9547), np.float32(0.9051)] 
2025-01-26 17:59:37.695287: Epoch time: 48.42 s 
2025-01-26 17:59:38.930653:  
2025-01-26 17:59:38.933640: Epoch 403 
2025-01-26 17:59:38.936695: Current learning rate: 0.00629 
2025-01-26 18:00:27.398617: train_loss -0.8141 
2025-01-26 18:00:27.405916: val_loss -0.8028 
2025-01-26 18:00:27.408663: Pseudo dice [np.float32(0.9516), np.float32(0.888)] 
2025-01-26 18:00:27.411256: Epoch time: 48.47 s 
2025-01-26 18:00:28.648485:  
2025-01-26 18:00:28.651659: Epoch 404 
2025-01-26 18:00:28.654673: Current learning rate: 0.00628 
2025-01-26 18:01:17.678364: train_loss -0.8205 
2025-01-26 18:01:17.682094: val_loss -0.7715 
2025-01-26 18:01:17.684882: Pseudo dice [np.float32(0.9608), np.float32(0.8849)] 
2025-01-26 18:01:17.687577: Epoch time: 49.03 s 
2025-01-26 18:01:18.925637:  
2025-01-26 18:01:18.928548: Epoch 405 
2025-01-26 18:01:18.931114: Current learning rate: 0.00627 
2025-01-26 18:02:07.254112: train_loss -0.8279 
2025-01-26 18:02:07.262499: val_loss -0.7586 
2025-01-26 18:02:07.265339: Pseudo dice [np.float32(0.9637), np.float32(0.8205)] 
2025-01-26 18:02:07.268050: Epoch time: 48.33 s 
2025-01-26 18:02:08.499746:  
2025-01-26 18:02:08.502568: Epoch 406 
2025-01-26 18:02:08.505628: Current learning rate: 0.00626 
2025-01-26 18:02:56.972041: train_loss -0.8253 
2025-01-26 18:02:56.975238: val_loss -0.7479 
2025-01-26 18:02:56.977697: Pseudo dice [np.float32(0.9541), np.float32(0.8919)] 
2025-01-26 18:02:56.980539: Epoch time: 48.47 s 
2025-01-26 18:02:58.215462:  
2025-01-26 18:02:58.218648: Epoch 407 
2025-01-26 18:02:58.221275: Current learning rate: 0.00625 
2025-01-26 18:03:46.533813: train_loss -0.8242 
2025-01-26 18:03:46.540519: val_loss -0.8006 
2025-01-26 18:03:46.542776: Pseudo dice [np.float32(0.9517), np.float32(0.8776)] 
2025-01-26 18:03:46.545315: Epoch time: 48.32 s 
2025-01-26 18:03:47.778467:  
2025-01-26 18:03:47.781097: Epoch 408 
2025-01-26 18:03:47.783831: Current learning rate: 0.00624 
2025-01-26 18:04:36.294540: train_loss -0.7983 
2025-01-26 18:04:36.297695: val_loss -0.7538 
2025-01-26 18:04:36.300788: Pseudo dice [np.float32(0.9455), np.float32(0.8565)] 
2025-01-26 18:04:36.303574: Epoch time: 48.52 s 
2025-01-26 18:04:37.537938:  
2025-01-26 18:04:37.540987: Epoch 409 
2025-01-26 18:04:37.543959: Current learning rate: 0.00623 
2025-01-26 18:05:25.723425: train_loss -0.8053 
2025-01-26 18:05:25.730286: val_loss -0.8062 
2025-01-26 18:05:25.733087: Pseudo dice [np.float32(0.9529), np.float32(0.8894)] 
2025-01-26 18:05:25.735545: Epoch time: 48.19 s 
2025-01-26 18:05:26.975274:  
2025-01-26 18:05:26.978491: Epoch 410 
2025-01-26 18:05:26.982092: Current learning rate: 0.00622 
2025-01-26 18:06:15.321131: train_loss -0.8231 
2025-01-26 18:06:15.324672: val_loss -0.7461 
2025-01-26 18:06:15.327678: Pseudo dice [np.float32(0.9525), np.float32(0.8757)] 
2025-01-26 18:06:15.330756: Epoch time: 48.35 s 
2025-01-26 18:06:16.513619:  
2025-01-26 18:06:16.516504: Epoch 411 
2025-01-26 18:06:16.519658: Current learning rate: 0.00621 
2025-01-26 18:07:04.926981: train_loss -0.812 
2025-01-26 18:07:04.933378: val_loss -0.7666 
2025-01-26 18:07:04.936069: Pseudo dice [np.float32(0.9523), np.float32(0.88)] 
2025-01-26 18:07:04.938957: Epoch time: 48.41 s 
2025-01-26 18:07:06.106473:  
2025-01-26 18:07:06.109417: Epoch 412 
2025-01-26 18:07:06.111916: Current learning rate: 0.0062 
2025-01-26 18:07:54.151386: train_loss -0.8153 
2025-01-26 18:07:54.154766: val_loss -0.7635 
2025-01-26 18:07:54.157329: Pseudo dice [np.float32(0.9524), np.float32(0.837)] 
2025-01-26 18:07:54.159893: Epoch time: 48.05 s 
2025-01-26 18:07:55.922182:  
2025-01-26 18:07:55.925090: Epoch 413 
2025-01-26 18:07:55.927822: Current learning rate: 0.00619 
2025-01-26 18:08:44.170978: train_loss -0.8041 
2025-01-26 18:08:44.177374: val_loss -0.7494 
2025-01-26 18:08:44.179788: Pseudo dice [np.float32(0.957), np.float32(0.8897)] 
2025-01-26 18:08:44.182584: Epoch time: 48.25 s 
2025-01-26 18:08:45.354681:  
2025-01-26 18:08:45.357573: Epoch 414 
2025-01-26 18:08:45.360829: Current learning rate: 0.00618 
2025-01-26 18:09:33.709430: train_loss -0.8232 
2025-01-26 18:09:33.713079: val_loss -0.7789 
2025-01-26 18:09:33.716027: Pseudo dice [np.float32(0.9607), np.float32(0.885)] 
2025-01-26 18:09:33.718575: Epoch time: 48.36 s 
2025-01-26 18:09:34.899665:  
2025-01-26 18:09:34.902976: Epoch 415 
2025-01-26 18:09:34.906024: Current learning rate: 0.00617 
2025-01-26 18:10:23.729449: train_loss -0.8085 
2025-01-26 18:10:23.735735: val_loss -0.771 
2025-01-26 18:10:23.738160: Pseudo dice [np.float32(0.954), np.float32(0.8852)] 
2025-01-26 18:10:23.740714: Epoch time: 48.83 s 
2025-01-26 18:10:24.914507:  
2025-01-26 18:10:24.916940: Epoch 416 
2025-01-26 18:10:24.919403: Current learning rate: 0.00616 
2025-01-26 18:11:13.669192: train_loss -0.8129 
2025-01-26 18:11:13.674227: val_loss -0.7725 
2025-01-26 18:11:13.677056: Pseudo dice [np.float32(0.9575), np.float32(0.8916)] 
2025-01-26 18:11:13.679583: Epoch time: 48.76 s 
2025-01-26 18:11:14.866021:  
2025-01-26 18:11:14.869092: Epoch 417 
2025-01-26 18:11:14.872107: Current learning rate: 0.00615 
2025-01-26 18:12:03.616558: train_loss -0.8229 
2025-01-26 18:12:03.623576: val_loss -0.7606 
2025-01-26 18:12:03.626297: Pseudo dice [np.float32(0.9579), np.float32(0.8744)] 
2025-01-26 18:12:03.629068: Epoch time: 48.75 s 
2025-01-26 18:12:04.817238:  
2025-01-26 18:12:04.819710: Epoch 418 
2025-01-26 18:12:04.822591: Current learning rate: 0.00614 
2025-01-26 18:12:53.668787: train_loss -0.8172 
2025-01-26 18:12:53.672041: val_loss -0.7569 
2025-01-26 18:12:53.674942: Pseudo dice [np.float32(0.96), np.float32(0.8098)] 
2025-01-26 18:12:53.677653: Epoch time: 48.85 s 
2025-01-26 18:12:54.859351:  
2025-01-26 18:12:54.862441: Epoch 419 
2025-01-26 18:12:54.865375: Current learning rate: 0.00613 
2025-01-26 18:13:43.253993: train_loss -0.7944 
2025-01-26 18:13:43.260412: val_loss -0.793 
2025-01-26 18:13:43.263340: Pseudo dice [np.float32(0.9614), np.float32(0.8975)] 
2025-01-26 18:13:43.266000: Epoch time: 48.4 s 
2025-01-26 18:13:44.441157:  
2025-01-26 18:13:44.444140: Epoch 420 
2025-01-26 18:13:44.447425: Current learning rate: 0.00612 
2025-01-26 18:14:33.739452: train_loss -0.8176 
2025-01-26 18:14:33.743326: val_loss -0.7631 
2025-01-26 18:14:33.746205: Pseudo dice [np.float32(0.9623), np.float32(0.915)] 
2025-01-26 18:14:33.748448: Epoch time: 49.3 s 
2025-01-26 18:14:34.935347:  
2025-01-26 18:14:34.938587: Epoch 421 
2025-01-26 18:14:34.941844: Current learning rate: 0.00612 
2025-01-26 18:15:23.442923: train_loss -0.8247 
2025-01-26 18:15:23.449716: val_loss -0.7923 
2025-01-26 18:15:23.452598: Pseudo dice [np.float32(0.9597), np.float32(0.9033)] 
2025-01-26 18:15:23.455417: Epoch time: 48.51 s 
2025-01-26 18:15:24.635693:  
2025-01-26 18:15:24.638759: Epoch 422 
2025-01-26 18:15:24.641658: Current learning rate: 0.00611 
2025-01-26 18:16:12.983120: train_loss -0.8174 
2025-01-26 18:16:12.986971: val_loss -0.7921 
2025-01-26 18:16:12.989957: Pseudo dice [np.float32(0.9586), np.float32(0.8951)] 
2025-01-26 18:16:12.993284: Epoch time: 48.35 s 
2025-01-26 18:16:14.162788:  
2025-01-26 18:16:14.165504: Epoch 423 
2025-01-26 18:16:14.168374: Current learning rate: 0.0061 
2025-01-26 18:17:02.878727: train_loss -0.8306 
2025-01-26 18:17:02.885393: val_loss -0.7441 
2025-01-26 18:17:02.888171: Pseudo dice [np.float32(0.96), np.float32(0.9108)] 
2025-01-26 18:17:02.890804: Epoch time: 48.72 s 
2025-01-26 18:17:04.080338:  
2025-01-26 18:17:04.083283: Epoch 424 
2025-01-26 18:17:04.086128: Current learning rate: 0.00609 
2025-01-26 18:17:52.568741: train_loss -0.8208 
2025-01-26 18:17:52.572330: val_loss -0.7452 
2025-01-26 18:17:52.575346: Pseudo dice [np.float32(0.9575), np.float32(0.8942)] 
2025-01-26 18:17:52.577868: Epoch time: 48.49 s 
2025-01-26 18:17:53.760445:  
2025-01-26 18:17:53.763517: Epoch 425 
2025-01-26 18:17:53.766331: Current learning rate: 0.00608 
2025-01-26 18:18:42.647331: train_loss -0.8253 
2025-01-26 18:18:42.654326: val_loss -0.7662 
2025-01-26 18:18:42.657455: Pseudo dice [np.float32(0.9608), np.float32(0.8961)] 
2025-01-26 18:18:42.660161: Epoch time: 48.89 s 
2025-01-26 18:18:43.852628:  
2025-01-26 18:18:43.855522: Epoch 426 
2025-01-26 18:18:43.858626: Current learning rate: 0.00607 
2025-01-26 18:19:32.023128: train_loss -0.8206 
2025-01-26 18:19:32.026759: val_loss -0.7786 
2025-01-26 18:19:32.029927: Pseudo dice [np.float32(0.9605), np.float32(0.9119)] 
2025-01-26 18:19:32.032990: Epoch time: 48.17 s 
2025-01-26 18:19:33.213533:  
2025-01-26 18:19:33.217105: Epoch 427 
2025-01-26 18:19:33.220149: Current learning rate: 0.00606 
2025-01-26 18:20:21.598589: train_loss -0.8391 
2025-01-26 18:20:21.604995: val_loss -0.7652 
2025-01-26 18:20:21.607934: Pseudo dice [np.float32(0.964), np.float32(0.9081)] 
2025-01-26 18:20:21.610828: Epoch time: 48.39 s 
2025-01-26 18:20:21.613526: Yayy! New best EMA pseudo Dice: 0.925000011920929 
2025-01-26 18:20:23.362015:  
2025-01-26 18:20:23.365354: Epoch 428 
2025-01-26 18:20:23.368083: Current learning rate: 0.00605 
2025-01-26 18:21:11.721729: train_loss -0.8239 
2025-01-26 18:21:11.727052: val_loss -0.7757 
2025-01-26 18:21:11.730485: Pseudo dice [np.float32(0.9534), np.float32(0.8909)] 
2025-01-26 18:21:11.733125: Epoch time: 48.36 s 
2025-01-26 18:21:12.901650:  
2025-01-26 18:21:12.904578: Epoch 429 
2025-01-26 18:21:12.907076: Current learning rate: 0.00604 
2025-01-26 18:22:01.694933: train_loss -0.8152 
2025-01-26 18:22:01.701467: val_loss -0.7451 
2025-01-26 18:22:01.703985: Pseudo dice [np.float32(0.9585), np.float32(0.8742)] 
2025-01-26 18:22:01.706647: Epoch time: 48.79 s 
2025-01-26 18:22:02.885544:  
2025-01-26 18:22:02.888139: Epoch 430 
2025-01-26 18:22:02.890897: Current learning rate: 0.00603 
2025-01-26 18:22:51.681216: train_loss -0.812 
2025-01-26 18:22:51.684895: val_loss -0.703 
2025-01-26 18:22:51.687892: Pseudo dice [np.float32(0.9391), np.float32(0.8205)] 
2025-01-26 18:22:51.690664: Epoch time: 48.8 s 
2025-01-26 18:22:52.871686:  
2025-01-26 18:22:52.874137: Epoch 431 
2025-01-26 18:22:52.877023: Current learning rate: 0.00602 
2025-01-26 18:23:41.602590: train_loss -0.8188 
2025-01-26 18:23:41.609833: val_loss -0.786 
2025-01-26 18:23:41.612610: Pseudo dice [np.float32(0.9588), np.float32(0.9011)] 
2025-01-26 18:23:41.615619: Epoch time: 48.73 s 
2025-01-26 18:23:43.357008:  
2025-01-26 18:23:43.359840: Epoch 432 
2025-01-26 18:23:43.362639: Current learning rate: 0.00601 
2025-01-26 18:24:31.849325: train_loss -0.8197 
2025-01-26 18:24:31.853308: val_loss -0.7449 
2025-01-26 18:24:31.856382: Pseudo dice [np.float32(0.9532), np.float32(0.8646)] 
2025-01-26 18:24:31.858879: Epoch time: 48.49 s 
2025-01-26 18:24:33.034397:  
2025-01-26 18:24:33.037340: Epoch 433 
2025-01-26 18:24:33.040065: Current learning rate: 0.006 
2025-01-26 18:25:21.525494: train_loss -0.7943 
2025-01-26 18:25:21.531776: val_loss -0.7509 
2025-01-26 18:25:21.534506: Pseudo dice [np.float32(0.9537), np.float32(0.8751)] 
2025-01-26 18:25:21.537132: Epoch time: 48.49 s 
2025-01-26 18:25:22.714717:  
2025-01-26 18:25:22.717508: Epoch 434 
2025-01-26 18:25:22.720385: Current learning rate: 0.00599 
2025-01-26 18:26:11.543636: train_loss -0.8051 
2025-01-26 18:26:11.547327: val_loss -0.7438 
2025-01-26 18:26:11.549877: Pseudo dice [np.float32(0.9474), np.float32(0.8722)] 
2025-01-26 18:26:11.552897: Epoch time: 48.83 s 
2025-01-26 18:26:12.729146:  
2025-01-26 18:26:12.732205: Epoch 435 
2025-01-26 18:26:12.735076: Current learning rate: 0.00598 
2025-01-26 18:27:01.569426: train_loss -0.8048 
2025-01-26 18:27:01.577365: val_loss -0.7015 
2025-01-26 18:27:01.580350: Pseudo dice [np.float32(0.943), np.float32(0.7673)] 
2025-01-26 18:27:01.583264: Epoch time: 48.84 s 
2025-01-26 18:27:02.788591:  
2025-01-26 18:27:02.792234: Epoch 436 
2025-01-26 18:27:02.795656: Current learning rate: 0.00597 
2025-01-26 18:27:51.333923: train_loss -0.7891 
2025-01-26 18:27:51.337687: val_loss -0.7537 
2025-01-26 18:27:51.340553: Pseudo dice [np.float32(0.9468), np.float32(0.8539)] 
2025-01-26 18:27:51.343827: Epoch time: 48.55 s 
2025-01-26 18:27:52.564303:  
2025-01-26 18:27:52.567824: Epoch 437 
2025-01-26 18:27:52.571465: Current learning rate: 0.00596 
2025-01-26 18:28:40.817956: train_loss -0.8088 
2025-01-26 18:28:40.824659: val_loss -0.797 
2025-01-26 18:28:40.827926: Pseudo dice [np.float32(0.9548), np.float32(0.8968)] 
2025-01-26 18:28:40.831368: Epoch time: 48.26 s 
2025-01-26 18:28:42.006930:  
2025-01-26 18:28:42.011061: Epoch 438 
2025-01-26 18:28:42.013926: Current learning rate: 0.00595 
2025-01-26 18:29:30.384136: train_loss -0.8138 
2025-01-26 18:29:30.387569: val_loss -0.7288 
2025-01-26 18:29:30.390450: Pseudo dice [np.float32(0.9521), np.float32(0.8698)] 
2025-01-26 18:29:30.393862: Epoch time: 48.38 s 
2025-01-26 18:29:31.557053:  
2025-01-26 18:29:31.560651: Epoch 439 
2025-01-26 18:29:31.563565: Current learning rate: 0.00594 
2025-01-26 18:30:20.193541: train_loss -0.7966 
2025-01-26 18:30:20.200741: val_loss -0.7693 
2025-01-26 18:30:20.203238: Pseudo dice [np.float32(0.9573), np.float32(0.8742)] 
2025-01-26 18:30:20.205615: Epoch time: 48.64 s 
2025-01-26 18:30:21.376235:  
2025-01-26 18:30:21.379216: Epoch 440 
2025-01-26 18:30:21.382309: Current learning rate: 0.00593 
2025-01-26 18:31:09.864433: train_loss -0.8277 
2025-01-26 18:31:09.868083: val_loss -0.7792 
2025-01-26 18:31:09.870605: Pseudo dice [np.float32(0.9565), np.float32(0.8965)] 
2025-01-26 18:31:09.873650: Epoch time: 48.49 s 
2025-01-26 18:31:11.043540:  
2025-01-26 18:31:11.046638: Epoch 441 
2025-01-26 18:31:11.049889: Current learning rate: 0.00592 
2025-01-26 18:31:59.554052: train_loss -0.7999 
2025-01-26 18:31:59.560839: val_loss -0.7756 
2025-01-26 18:31:59.563619: Pseudo dice [np.float32(0.9542), np.float32(0.8852)] 
2025-01-26 18:31:59.566112: Epoch time: 48.51 s 
2025-01-26 18:32:00.744143:  
2025-01-26 18:32:00.747449: Epoch 442 
2025-01-26 18:32:00.750495: Current learning rate: 0.00592 
2025-01-26 18:32:49.004051: train_loss -0.7985 
2025-01-26 18:32:49.008640: val_loss -0.77 
2025-01-26 18:32:49.011572: Pseudo dice [np.float32(0.9503), np.float32(0.8824)] 
2025-01-26 18:32:49.014523: Epoch time: 48.26 s 
2025-01-26 18:32:50.199800:  
2025-01-26 18:32:50.202846: Epoch 443 
2025-01-26 18:32:50.205945: Current learning rate: 0.00591 
2025-01-26 18:33:38.907795: train_loss -0.8074 
2025-01-26 18:33:38.914923: val_loss -0.778 
2025-01-26 18:33:38.918131: Pseudo dice [np.float32(0.9561), np.float32(0.8961)] 
2025-01-26 18:33:38.920939: Epoch time: 48.71 s 
2025-01-26 18:33:40.080174:  
2025-01-26 18:33:40.083065: Epoch 444 
2025-01-26 18:33:40.085859: Current learning rate: 0.0059 
2025-01-26 18:34:28.682879: train_loss -0.808 
2025-01-26 18:34:28.686595: val_loss -0.7511 
2025-01-26 18:34:28.689593: Pseudo dice [np.float32(0.9432), np.float32(0.8475)] 
2025-01-26 18:34:28.692492: Epoch time: 48.6 s 
2025-01-26 18:34:29.846302:  
2025-01-26 18:34:29.851457: Epoch 445 
2025-01-26 18:34:29.854141: Current learning rate: 0.00589 
2025-01-26 18:35:17.943181: train_loss -0.8294 
2025-01-26 18:35:17.949312: val_loss -0.8013 
2025-01-26 18:35:17.952335: Pseudo dice [np.float32(0.9586), np.float32(0.8931)] 
2025-01-26 18:35:17.955135: Epoch time: 48.1 s 
2025-01-26 18:35:19.115363:  
2025-01-26 18:35:19.118269: Epoch 446 
2025-01-26 18:35:19.121096: Current learning rate: 0.00588 
2025-01-26 18:36:07.658703: train_loss -0.8011 
2025-01-26 18:36:07.662656: val_loss -0.7795 
2025-01-26 18:36:07.665613: Pseudo dice [np.float32(0.9578), np.float32(0.888)] 
2025-01-26 18:36:07.668927: Epoch time: 48.54 s 
2025-01-26 18:36:08.852480:  
2025-01-26 18:36:08.855587: Epoch 447 
2025-01-26 18:36:08.859300: Current learning rate: 0.00587 
2025-01-26 18:36:57.112479: train_loss -0.8282 
2025-01-26 18:36:57.118768: val_loss -0.7824 
2025-01-26 18:36:57.121204: Pseudo dice [np.float32(0.9614), np.float32(0.8944)] 
2025-01-26 18:36:57.123554: Epoch time: 48.26 s 
2025-01-26 18:36:58.310408:  
2025-01-26 18:36:58.313710: Epoch 448 
2025-01-26 18:36:58.316670: Current learning rate: 0.00586 
2025-01-26 18:37:46.826793: train_loss -0.8181 
2025-01-26 18:37:46.830596: val_loss -0.785 
2025-01-26 18:37:46.833599: Pseudo dice [np.float32(0.9605), np.float32(0.9073)] 
2025-01-26 18:37:46.836355: Epoch time: 48.52 s 
2025-01-26 18:37:47.989247:  
2025-01-26 18:37:47.992222: Epoch 449 
2025-01-26 18:37:47.995261: Current learning rate: 0.00585 
2025-01-26 18:38:36.684788: train_loss -0.8192 
2025-01-26 18:38:36.690875: val_loss -0.7776 
2025-01-26 18:38:36.693669: Pseudo dice [np.float32(0.9537), np.float32(0.8701)] 
2025-01-26 18:38:36.696556: Epoch time: 48.7 s 
2025-01-26 18:38:38.422084:  
2025-01-26 18:38:38.424944: Epoch 450 
2025-01-26 18:38:38.427619: Current learning rate: 0.00584 
2025-01-26 18:39:27.500673: train_loss -0.8195 
2025-01-26 18:39:27.504037: val_loss -0.7844 
2025-01-26 18:39:27.506654: Pseudo dice [np.float32(0.9638), np.float32(0.9075)] 
2025-01-26 18:39:27.509776: Epoch time: 49.08 s 
2025-01-26 18:39:29.321876:  
2025-01-26 18:39:29.324496: Epoch 451 
2025-01-26 18:39:29.327296: Current learning rate: 0.00583 
2025-01-26 18:40:17.784372: train_loss -0.8286 
2025-01-26 18:40:17.792508: val_loss -0.8028 
2025-01-26 18:40:17.795426: Pseudo dice [np.float32(0.9628), np.float32(0.8815)] 
2025-01-26 18:40:17.797961: Epoch time: 48.46 s 
2025-01-26 18:40:18.953623:  
2025-01-26 18:40:18.956831: Epoch 452 
2025-01-26 18:40:18.959638: Current learning rate: 0.00582 
2025-01-26 18:41:07.857511: train_loss -0.8084 
2025-01-26 18:41:07.860966: val_loss -0.7842 
2025-01-26 18:41:07.863936: Pseudo dice [np.float32(0.9635), np.float32(0.8958)] 
2025-01-26 18:41:07.866889: Epoch time: 48.9 s 
2025-01-26 18:41:09.020955:  
2025-01-26 18:41:09.024060: Epoch 453 
2025-01-26 18:41:09.026883: Current learning rate: 0.00581 
2025-01-26 18:41:57.679171: train_loss -0.8154 
2025-01-26 18:41:57.685866: val_loss -0.8028 
2025-01-26 18:41:57.688618: Pseudo dice [np.float32(0.9589), np.float32(0.9078)] 
2025-01-26 18:41:57.691237: Epoch time: 48.66 s 
2025-01-26 18:41:58.845304:  
2025-01-26 18:41:58.848377: Epoch 454 
2025-01-26 18:41:58.851071: Current learning rate: 0.0058 
2025-01-26 18:42:47.960310: train_loss -0.8276 
2025-01-26 18:42:47.963874: val_loss -0.8221 
2025-01-26 18:42:47.966667: Pseudo dice [np.float32(0.9546), np.float32(0.8879)] 
2025-01-26 18:42:47.969478: Epoch time: 49.12 s 
2025-01-26 18:42:49.148961:  
2025-01-26 18:42:49.151903: Epoch 455 
2025-01-26 18:42:49.154787: Current learning rate: 0.00579 
2025-01-26 18:43:37.944945: train_loss -0.8501 
2025-01-26 18:43:37.952093: val_loss -0.7919 
2025-01-26 18:43:37.955046: Pseudo dice [np.float32(0.9577), np.float32(0.906)] 
2025-01-26 18:43:37.958057: Epoch time: 48.8 s 
2025-01-26 18:43:39.137664:  
2025-01-26 18:43:39.140593: Epoch 456 
2025-01-26 18:43:39.143009: Current learning rate: 0.00578 
2025-01-26 18:44:27.738577: train_loss -0.8313 
2025-01-26 18:44:27.742189: val_loss -0.7983 
2025-01-26 18:44:27.745068: Pseudo dice [np.float32(0.9648), np.float32(0.9109)] 
2025-01-26 18:44:27.747493: Epoch time: 48.6 s 
2025-01-26 18:44:28.918108:  
2025-01-26 18:44:28.921093: Epoch 457 
2025-01-26 18:44:28.923885: Current learning rate: 0.00577 
2025-01-26 18:45:17.451173: train_loss -0.8191 
2025-01-26 18:45:17.457562: val_loss -0.7465 
2025-01-26 18:45:17.460440: Pseudo dice [np.float32(0.9618), np.float32(0.9032)] 
2025-01-26 18:45:17.462831: Epoch time: 48.53 s 
2025-01-26 18:45:17.465413: Yayy! New best EMA pseudo Dice: 0.9253000020980835 
2025-01-26 18:45:19.208998:  
2025-01-26 18:45:19.211894: Epoch 458 
2025-01-26 18:45:19.214756: Current learning rate: 0.00576 
2025-01-26 18:46:07.469023: train_loss -0.827 
2025-01-26 18:46:07.472575: val_loss -0.7766 
2025-01-26 18:46:07.475880: Pseudo dice [np.float32(0.9535), np.float32(0.8966)] 
2025-01-26 18:46:07.478685: Epoch time: 48.26 s 
2025-01-26 18:46:08.649906:  
2025-01-26 18:46:08.652570: Epoch 459 
2025-01-26 18:46:08.655141: Current learning rate: 0.00575 
2025-01-26 18:46:56.805239: train_loss -0.8224 
2025-01-26 18:46:56.810820: val_loss -0.78 
2025-01-26 18:46:56.813615: Pseudo dice [np.float32(0.9593), np.float32(0.8836)] 
2025-01-26 18:46:56.816543: Epoch time: 48.16 s 
2025-01-26 18:46:57.978840:  
2025-01-26 18:46:57.981536: Epoch 460 
2025-01-26 18:46:57.984211: Current learning rate: 0.00574 
2025-01-26 18:47:46.581239: train_loss -0.8252 
2025-01-26 18:47:46.584464: val_loss -0.7647 
2025-01-26 18:47:46.587382: Pseudo dice [np.float32(0.9502), np.float32(0.8652)] 
2025-01-26 18:47:46.590192: Epoch time: 48.6 s 
2025-01-26 18:47:47.762512:  
2025-01-26 18:47:47.765199: Epoch 461 
2025-01-26 18:47:47.768197: Current learning rate: 0.00573 
2025-01-26 18:48:36.840951: train_loss -0.8145 
2025-01-26 18:48:36.847179: val_loss -0.7361 
2025-01-26 18:48:36.849903: Pseudo dice [np.float32(0.948), np.float32(0.848)] 
2025-01-26 18:48:36.852570: Epoch time: 49.08 s 
2025-01-26 18:48:38.026441:  
2025-01-26 18:48:38.029414: Epoch 462 
2025-01-26 18:48:38.032104: Current learning rate: 0.00572 
2025-01-26 18:49:27.104844: train_loss -0.8136 
2025-01-26 18:49:27.108174: val_loss -0.7551 
2025-01-26 18:49:27.111121: Pseudo dice [np.float32(0.9509), np.float32(0.883)] 
2025-01-26 18:49:27.113977: Epoch time: 49.08 s 
2025-01-26 18:49:28.282385:  
2025-01-26 18:49:28.285495: Epoch 463 
2025-01-26 18:49:28.288782: Current learning rate: 0.00571 
2025-01-26 18:50:16.897139: train_loss -0.8179 
2025-01-26 18:50:16.904377: val_loss -0.7986 
2025-01-26 18:50:16.907330: Pseudo dice [np.float32(0.9522), np.float32(0.9077)] 
2025-01-26 18:50:16.910357: Epoch time: 48.62 s 
2025-01-26 18:50:18.082048:  
2025-01-26 18:50:18.085136: Epoch 464 
2025-01-26 18:50:18.087896: Current learning rate: 0.0057 
2025-01-26 18:51:06.837689: train_loss -0.8269 
2025-01-26 18:51:06.841780: val_loss -0.7393 
2025-01-26 18:51:06.844912: Pseudo dice [np.float32(0.9505), np.float32(0.8805)] 
2025-01-26 18:51:06.847650: Epoch time: 48.76 s 
2025-01-26 18:51:08.026609:  
2025-01-26 18:51:08.029844: Epoch 465 
2025-01-26 18:51:08.033114: Current learning rate: 0.0057 
2025-01-26 18:51:56.592098: train_loss -0.8118 
2025-01-26 18:51:56.597925: val_loss -0.7135 
2025-01-26 18:51:56.600449: Pseudo dice [np.float32(0.9456), np.float32(0.8412)] 
2025-01-26 18:51:56.602630: Epoch time: 48.57 s 
2025-01-26 18:51:57.771686:  
2025-01-26 18:51:57.774574: Epoch 466 
2025-01-26 18:51:57.777421: Current learning rate: 0.00569 
2025-01-26 18:52:46.123514: train_loss -0.8203 
2025-01-26 18:52:46.127105: val_loss -0.8007 
2025-01-26 18:52:46.130605: Pseudo dice [np.float32(0.9543), np.float32(0.8881)] 
2025-01-26 18:52:46.133738: Epoch time: 48.35 s 
2025-01-26 18:52:47.301015:  
2025-01-26 18:52:47.303937: Epoch 467 
2025-01-26 18:52:47.306924: Current learning rate: 0.00568 
2025-01-26 18:53:35.932833: train_loss -0.8213 
2025-01-26 18:53:35.940410: val_loss -0.7772 
2025-01-26 18:53:35.943374: Pseudo dice [np.float32(0.9543), np.float32(0.888)] 
2025-01-26 18:53:35.946331: Epoch time: 48.63 s 
2025-01-26 18:53:37.123760:  
2025-01-26 18:53:37.127527: Epoch 468 
2025-01-26 18:53:37.130504: Current learning rate: 0.00567 
2025-01-26 18:54:25.428027: train_loss -0.8077 
2025-01-26 18:54:25.431492: val_loss -0.7588 
2025-01-26 18:54:25.434221: Pseudo dice [np.float32(0.956), np.float32(0.8404)] 
2025-01-26 18:54:25.437053: Epoch time: 48.31 s 
2025-01-26 18:54:26.600168:  
2025-01-26 18:54:26.603216: Epoch 469 
2025-01-26 18:54:26.606264: Current learning rate: 0.00566 
2025-01-26 18:55:15.197185: train_loss -0.8089 
2025-01-26 18:55:15.203648: val_loss -0.77 
2025-01-26 18:55:15.206150: Pseudo dice [np.float32(0.9604), np.float32(0.882)] 
2025-01-26 18:55:15.208950: Epoch time: 48.6 s 
2025-01-26 18:55:16.372293:  
2025-01-26 18:55:16.375124: Epoch 470 
2025-01-26 18:55:16.378105: Current learning rate: 0.00565 
2025-01-26 18:56:04.761230: train_loss -0.8178 
2025-01-26 18:56:04.765045: val_loss -0.7516 
2025-01-26 18:56:04.767817: Pseudo dice [np.float32(0.9549), np.float32(0.9024)] 
2025-01-26 18:56:04.770314: Epoch time: 48.39 s 
2025-01-26 18:56:06.537154:  
2025-01-26 18:56:06.539818: Epoch 471 
2025-01-26 18:56:06.542493: Current learning rate: 0.00564 
2025-01-26 18:56:54.848140: train_loss -0.8042 
2025-01-26 18:56:54.854535: val_loss -0.7902 
2025-01-26 18:56:54.857373: Pseudo dice [np.float32(0.9578), np.float32(0.9056)] 
2025-01-26 18:56:54.860055: Epoch time: 48.31 s 
2025-01-26 18:56:56.021482:  
2025-01-26 18:56:56.024719: Epoch 472 
2025-01-26 18:56:56.027725: Current learning rate: 0.00563 
2025-01-26 18:57:44.554590: train_loss -0.7944 
2025-01-26 18:57:44.558045: val_loss -0.731 
2025-01-26 18:57:44.560967: Pseudo dice [np.float32(0.9399), np.float32(0.7882)] 
2025-01-26 18:57:44.563709: Epoch time: 48.53 s 
2025-01-26 18:57:45.724694:  
2025-01-26 18:57:45.727493: Epoch 473 
2025-01-26 18:57:45.730206: Current learning rate: 0.00562 
2025-01-26 18:58:34.367012: train_loss -0.8146 
2025-01-26 18:58:34.372941: val_loss -0.7057 
2025-01-26 18:58:34.375535: Pseudo dice [np.float32(0.9502), np.float32(0.7696)] 
2025-01-26 18:58:34.377908: Epoch time: 48.64 s 
2025-01-26 18:58:35.553066:  
2025-01-26 18:58:35.555815: Epoch 474 
2025-01-26 18:58:35.558687: Current learning rate: 0.00561 
2025-01-26 18:59:24.131269: train_loss -0.8084 
2025-01-26 18:59:24.134529: val_loss -0.7556 
2025-01-26 18:59:24.137127: Pseudo dice [np.float32(0.9496), np.float32(0.8484)] 
2025-01-26 18:59:24.139732: Epoch time: 48.58 s 
2025-01-26 18:59:25.344221:  
2025-01-26 18:59:25.347120: Epoch 475 
2025-01-26 18:59:25.349879: Current learning rate: 0.0056 
2025-01-26 19:00:13.430063: train_loss -0.8082 
2025-01-26 19:00:13.437384: val_loss -0.7507 
2025-01-26 19:00:13.440272: Pseudo dice [np.float32(0.9551), np.float32(0.8928)] 
2025-01-26 19:00:13.443024: Epoch time: 48.09 s 
2025-01-26 19:00:14.616040:  
2025-01-26 19:00:14.619094: Epoch 476 
2025-01-26 19:00:14.621656: Current learning rate: 0.00559 
2025-01-26 19:01:02.845969: train_loss -0.8126 
2025-01-26 19:01:02.849460: val_loss -0.7921 
2025-01-26 19:01:02.852143: Pseudo dice [np.float32(0.9551), np.float32(0.9144)] 
2025-01-26 19:01:02.854917: Epoch time: 48.23 s 
2025-01-26 19:01:04.017633:  
2025-01-26 19:01:04.020534: Epoch 477 
2025-01-26 19:01:04.023353: Current learning rate: 0.00558 
2025-01-26 19:01:52.908859: train_loss -0.8096 
2025-01-26 19:01:52.915703: val_loss -0.7232 
2025-01-26 19:01:52.918848: Pseudo dice [np.float32(0.9407), np.float32(0.7913)] 
2025-01-26 19:01:52.921320: Epoch time: 48.89 s 
2025-01-26 19:01:54.108214:  
2025-01-26 19:01:54.111237: Epoch 478 
2025-01-26 19:01:54.113655: Current learning rate: 0.00557 
2025-01-26 19:02:42.683340: train_loss -0.8064 
2025-01-26 19:02:42.686817: val_loss -0.7579 
2025-01-26 19:02:42.689794: Pseudo dice [np.float32(0.9642), np.float32(0.8856)] 
2025-01-26 19:02:42.692626: Epoch time: 48.58 s 
2025-01-26 19:02:43.878345:  
2025-01-26 19:02:43.881299: Epoch 479 
2025-01-26 19:02:43.883972: Current learning rate: 0.00556 
2025-01-26 19:03:32.917674: train_loss -0.8025 
2025-01-26 19:03:32.924526: val_loss -0.7695 
2025-01-26 19:03:32.927094: Pseudo dice [np.float32(0.9481), np.float32(0.8486)] 
2025-01-26 19:03:32.929893: Epoch time: 49.04 s 
2025-01-26 19:03:34.112853:  
2025-01-26 19:03:34.115775: Epoch 480 
2025-01-26 19:03:34.118636: Current learning rate: 0.00555 
2025-01-26 19:04:22.540785: train_loss -0.8218 
2025-01-26 19:04:22.543910: val_loss -0.8108 
2025-01-26 19:04:22.546516: Pseudo dice [np.float32(0.9585), np.float32(0.8906)] 
2025-01-26 19:04:22.548970: Epoch time: 48.43 s 
2025-01-26 19:04:23.742927:  
2025-01-26 19:04:23.746054: Epoch 481 
2025-01-26 19:04:23.748620: Current learning rate: 0.00554 
2025-01-26 19:05:12.094107: train_loss -0.8094 
2025-01-26 19:05:12.100368: val_loss -0.7765 
2025-01-26 19:05:12.103125: Pseudo dice [np.float32(0.9582), np.float32(0.894)] 
2025-01-26 19:05:12.105780: Epoch time: 48.35 s 
2025-01-26 19:05:13.290654:  
2025-01-26 19:05:13.293331: Epoch 482 
2025-01-26 19:05:13.296066: Current learning rate: 0.00553 
2025-01-26 19:06:01.954641: train_loss -0.8184 
2025-01-26 19:06:01.957837: val_loss -0.7594 
2025-01-26 19:06:01.960742: Pseudo dice [np.float32(0.9507), np.float32(0.8747)] 
2025-01-26 19:06:01.963339: Epoch time: 48.66 s 
2025-01-26 19:06:03.151460:  
2025-01-26 19:06:03.155175: Epoch 483 
2025-01-26 19:06:03.157949: Current learning rate: 0.00552 
2025-01-26 19:06:51.520813: train_loss -0.8089 
2025-01-26 19:06:51.528026: val_loss -0.7765 
2025-01-26 19:06:51.530830: Pseudo dice [np.float32(0.9594), np.float32(0.891)] 
2025-01-26 19:06:51.533579: Epoch time: 48.37 s 
2025-01-26 19:06:52.716629:  
2025-01-26 19:06:52.719291: Epoch 484 
2025-01-26 19:06:52.721859: Current learning rate: 0.00551 
2025-01-26 19:07:41.404370: train_loss -0.8263 
2025-01-26 19:07:41.408187: val_loss -0.767 
2025-01-26 19:07:41.410918: Pseudo dice [np.float32(0.9609), np.float32(0.8917)] 
2025-01-26 19:07:41.413858: Epoch time: 48.69 s 
2025-01-26 19:07:42.598706:  
2025-01-26 19:07:42.601747: Epoch 485 
2025-01-26 19:07:42.604526: Current learning rate: 0.0055 
2025-01-26 19:08:31.263403: train_loss -0.817 
2025-01-26 19:08:31.270353: val_loss -0.7545 
2025-01-26 19:08:31.273114: Pseudo dice [np.float32(0.9543), np.float32(0.8828)] 
2025-01-26 19:08:31.277882: Epoch time: 48.67 s 
2025-01-26 19:08:32.472105:  
2025-01-26 19:08:32.474924: Epoch 486 
2025-01-26 19:08:32.477410: Current learning rate: 0.00549 
2025-01-26 19:09:21.158993: train_loss -0.8003 
2025-01-26 19:09:21.162499: val_loss -0.7474 
2025-01-26 19:09:21.165515: Pseudo dice [np.float32(0.9563), np.float32(0.8631)] 
2025-01-26 19:09:21.168089: Epoch time: 48.69 s 
2025-01-26 19:09:22.349563:  
2025-01-26 19:09:22.352702: Epoch 487 
2025-01-26 19:09:22.355707: Current learning rate: 0.00548 
2025-01-26 19:10:11.037541: train_loss -0.7984 
2025-01-26 19:10:11.044240: val_loss -0.7479 
2025-01-26 19:10:11.046771: Pseudo dice [np.float32(0.9523), np.float32(0.8617)] 
2025-01-26 19:10:11.049755: Epoch time: 48.69 s 
2025-01-26 19:10:12.236708:  
2025-01-26 19:10:12.239806: Epoch 488 
2025-01-26 19:10:12.242414: Current learning rate: 0.00547 
2025-01-26 19:11:00.611686: train_loss -0.8068 
2025-01-26 19:11:00.615326: val_loss -0.7848 
2025-01-26 19:11:00.618223: Pseudo dice [np.float32(0.958), np.float32(0.8929)] 
2025-01-26 19:11:00.621122: Epoch time: 48.38 s 
2025-01-26 19:11:01.807962:  
2025-01-26 19:11:01.810809: Epoch 489 
2025-01-26 19:11:01.813865: Current learning rate: 0.00546 
2025-01-26 19:11:50.372199: train_loss -0.8136 
2025-01-26 19:11:50.378183: val_loss -0.814 
2025-01-26 19:11:50.380844: Pseudo dice [np.float32(0.9586), np.float32(0.8889)] 
2025-01-26 19:11:50.383506: Epoch time: 48.57 s 
2025-01-26 19:11:51.568225:  
2025-01-26 19:11:51.571082: Epoch 490 
2025-01-26 19:11:51.574021: Current learning rate: 0.00546 
2025-01-26 19:12:40.237844: train_loss -0.8196 
2025-01-26 19:12:40.241459: val_loss -0.7843 
2025-01-26 19:12:40.244349: Pseudo dice [np.float32(0.9585), np.float32(0.9065)] 
2025-01-26 19:12:40.246774: Epoch time: 48.67 s 
2025-01-26 19:12:42.066807:  
2025-01-26 19:12:42.070208: Epoch 491 
2025-01-26 19:12:42.072964: Current learning rate: 0.00545 
2025-01-26 19:13:30.581640: train_loss -0.8174 
2025-01-26 19:13:30.589224: val_loss -0.7445 
2025-01-26 19:13:30.592448: Pseudo dice [np.float32(0.9551), np.float32(0.8864)] 
2025-01-26 19:13:30.595464: Epoch time: 48.52 s 
2025-01-26 19:13:31.777067:  
2025-01-26 19:13:31.781523: Epoch 492 
2025-01-26 19:13:31.784172: Current learning rate: 0.00544 
2025-01-26 19:14:20.489137: train_loss -0.8239 
2025-01-26 19:14:20.492728: val_loss -0.7853 
2025-01-26 19:14:20.495496: Pseudo dice [np.float32(0.9599), np.float32(0.8947)] 
2025-01-26 19:14:20.498244: Epoch time: 48.71 s 
2025-01-26 19:14:21.700225:  
2025-01-26 19:14:21.703742: Epoch 493 
2025-01-26 19:14:21.706429: Current learning rate: 0.00543 
2025-01-26 19:15:10.344460: train_loss -0.8232 
2025-01-26 19:15:10.351714: val_loss -0.7741 
2025-01-26 19:15:10.355121: Pseudo dice [np.float32(0.9602), np.float32(0.905)] 
2025-01-26 19:15:10.358189: Epoch time: 48.65 s 
2025-01-26 19:15:11.554004:  
2025-01-26 19:15:11.557778: Epoch 494 
2025-01-26 19:15:11.560515: Current learning rate: 0.00542 
2025-01-26 19:16:00.581540: train_loss -0.827 
2025-01-26 19:16:00.585204: val_loss -0.7752 
2025-01-26 19:16:00.589390: Pseudo dice [np.float32(0.955), np.float32(0.9171)] 
2025-01-26 19:16:00.592420: Epoch time: 49.03 s 
2025-01-26 19:16:01.779629:  
2025-01-26 19:16:01.782877: Epoch 495 
2025-01-26 19:16:01.785765: Current learning rate: 0.00541 
2025-01-26 19:16:50.064790: train_loss -0.8111 
2025-01-26 19:16:50.071404: val_loss -0.7826 
2025-01-26 19:16:50.074437: Pseudo dice [np.float32(0.9479), np.float32(0.8738)] 
2025-01-26 19:16:50.077287: Epoch time: 48.29 s 
2025-01-26 19:16:51.305472:  
2025-01-26 19:16:51.308980: Epoch 496 
2025-01-26 19:16:51.311769: Current learning rate: 0.0054 
2025-01-26 19:17:39.961232: train_loss -0.8067 
2025-01-26 19:17:39.964399: val_loss -0.7477 
2025-01-26 19:17:39.966821: Pseudo dice [np.float32(0.9575), np.float32(0.8815)] 
2025-01-26 19:17:39.969142: Epoch time: 48.66 s 
2025-01-26 19:17:41.206288:  
2025-01-26 19:17:41.211067: Epoch 497 
2025-01-26 19:17:41.214133: Current learning rate: 0.00539 
2025-01-26 19:18:30.075606: train_loss -0.8119 
2025-01-26 19:18:30.084573: val_loss -0.7603 
2025-01-26 19:18:30.087497: Pseudo dice [np.float32(0.9571), np.float32(0.8338)] 
2025-01-26 19:18:30.090173: Epoch time: 48.88 s 
2025-01-26 19:18:31.300978:  
2025-01-26 19:18:31.304228: Epoch 498 
2025-01-26 19:18:31.307178: Current learning rate: 0.00538 
2025-01-26 19:19:20.252407: train_loss -0.8242 
2025-01-26 19:19:20.256420: val_loss -0.7412 
2025-01-26 19:19:20.259591: Pseudo dice [np.float32(0.956), np.float32(0.8758)] 
2025-01-26 19:19:20.262404: Epoch time: 48.95 s 
2025-01-26 19:19:21.476680:  
2025-01-26 19:19:21.479589: Epoch 499 
2025-01-26 19:19:21.482330: Current learning rate: 0.00537 
2025-01-26 19:20:09.822045: train_loss -0.8265 
2025-01-26 19:20:09.828573: val_loss -0.8156 
2025-01-26 19:20:09.831424: Pseudo dice [np.float32(0.9587), np.float32(0.9209)] 
2025-01-26 19:20:09.834062: Epoch time: 48.35 s 
2025-01-26 19:20:11.664717:  
2025-01-26 19:20:11.667275: Epoch 500 
2025-01-26 19:20:11.670127: Current learning rate: 0.00536 
2025-01-26 19:21:00.074302: train_loss -0.822 
2025-01-26 19:21:00.077856: val_loss -0.7732 
2025-01-26 19:21:00.080777: Pseudo dice [np.float32(0.9533), np.float32(0.8776)] 
2025-01-26 19:21:00.083375: Epoch time: 48.41 s 
2025-01-26 19:21:01.280813:  
2025-01-26 19:21:01.284408: Epoch 501 
2025-01-26 19:21:01.287414: Current learning rate: 0.00535 
2025-01-26 19:21:49.442927: train_loss -0.7985 
2025-01-26 19:21:49.449383: val_loss -0.7769 
2025-01-26 19:21:49.452246: Pseudo dice [np.float32(0.9576), np.float32(0.8867)] 
2025-01-26 19:21:49.454715: Epoch time: 48.16 s 
2025-01-26 19:21:50.672708:  
2025-01-26 19:21:50.676149: Epoch 502 
2025-01-26 19:21:50.678984: Current learning rate: 0.00534 
2025-01-26 19:22:39.163578: train_loss -0.827 
2025-01-26 19:22:39.166979: val_loss -0.8092 
2025-01-26 19:22:39.169670: Pseudo dice [np.float32(0.9609), np.float32(0.9127)] 
2025-01-26 19:22:39.172295: Epoch time: 48.49 s 
2025-01-26 19:22:40.338432:  
2025-01-26 19:22:40.341675: Epoch 503 
2025-01-26 19:22:40.344845: Current learning rate: 0.00533 
2025-01-26 19:23:29.053792: train_loss -0.8063 
2025-01-26 19:23:29.063384: val_loss -0.7675 
2025-01-26 19:23:29.067279: Pseudo dice [np.float32(0.9548), np.float32(0.8842)] 
2025-01-26 19:23:29.072464: Epoch time: 48.72 s 
2025-01-26 19:23:30.281649:  
2025-01-26 19:23:30.284932: Epoch 504 
2025-01-26 19:23:30.288585: Current learning rate: 0.00532 
2025-01-26 19:24:18.547109: train_loss -0.8138 
2025-01-26 19:24:18.550604: val_loss -0.7968 
2025-01-26 19:24:18.553551: Pseudo dice [np.float32(0.953), np.float32(0.9007)] 
2025-01-26 19:24:18.556429: Epoch time: 48.27 s 
2025-01-26 19:24:19.762795:  
2025-01-26 19:24:19.765771: Epoch 505 
2025-01-26 19:24:19.768755: Current learning rate: 0.00531 
2025-01-26 19:25:08.679157: train_loss -0.806 
2025-01-26 19:25:08.686472: val_loss -0.7648 
2025-01-26 19:25:08.689476: Pseudo dice [np.float32(0.9615), np.float32(0.9038)] 
2025-01-26 19:25:08.692333: Epoch time: 48.92 s 
2025-01-26 19:25:09.869796:  
2025-01-26 19:25:09.872697: Epoch 506 
2025-01-26 19:25:09.875777: Current learning rate: 0.0053 
2025-01-26 19:25:58.711010: train_loss -0.8327 
2025-01-26 19:25:58.714586: val_loss -0.7738 
2025-01-26 19:25:58.717645: Pseudo dice [np.float32(0.9575), np.float32(0.9068)] 
2025-01-26 19:25:58.720487: Epoch time: 48.84 s 
2025-01-26 19:25:59.889350:  
2025-01-26 19:25:59.892508: Epoch 507 
2025-01-26 19:25:59.895277: Current learning rate: 0.00529 
2025-01-26 19:26:48.510704: train_loss -0.8205 
2025-01-26 19:26:48.517257: val_loss -0.7622 
2025-01-26 19:26:48.519888: Pseudo dice [np.float32(0.9523), np.float32(0.8639)] 
2025-01-26 19:26:48.523246: Epoch time: 48.62 s 
2025-01-26 19:26:49.699777:  
2025-01-26 19:26:49.702621: Epoch 508 
2025-01-26 19:26:49.705270: Current learning rate: 0.00528 
2025-01-26 19:27:38.583704: train_loss -0.8259 
2025-01-26 19:27:38.587276: val_loss -0.7533 
2025-01-26 19:27:38.590320: Pseudo dice [np.float32(0.9594), np.float32(0.8867)] 
2025-01-26 19:27:38.592969: Epoch time: 48.89 s 
2025-01-26 19:27:39.798989:  
2025-01-26 19:27:39.802100: Epoch 509 
2025-01-26 19:27:39.804508: Current learning rate: 0.00527 
2025-01-26 19:28:28.494464: train_loss -0.8331 
2025-01-26 19:28:28.501429: val_loss -0.8011 
2025-01-26 19:28:28.504133: Pseudo dice [np.float32(0.9594), np.float32(0.9001)] 
2025-01-26 19:28:28.506529: Epoch time: 48.7 s 
2025-01-26 19:28:30.291433:  
2025-01-26 19:28:30.294135: Epoch 510 
2025-01-26 19:28:30.296769: Current learning rate: 0.00526 
2025-01-26 19:29:18.881264: train_loss -0.8194 
2025-01-26 19:29:18.885174: val_loss -0.7714 
2025-01-26 19:29:18.887996: Pseudo dice [np.float32(0.9559), np.float32(0.9039)] 
2025-01-26 19:29:18.890423: Epoch time: 48.59 s 
2025-01-26 19:29:20.076949:  
2025-01-26 19:29:20.079615: Epoch 511 
2025-01-26 19:29:20.082058: Current learning rate: 0.00525 
2025-01-26 19:30:08.689346: train_loss -0.8059 
2025-01-26 19:30:08.695889: val_loss -0.8182 
2025-01-26 19:30:08.698561: Pseudo dice [np.float32(0.956), np.float32(0.9055)] 
2025-01-26 19:30:08.701218: Epoch time: 48.61 s 
2025-01-26 19:30:09.884126:  
2025-01-26 19:30:09.887503: Epoch 512 
2025-01-26 19:30:09.890229: Current learning rate: 0.00524 
2025-01-26 19:30:58.759342: train_loss -0.8137 
2025-01-26 19:30:58.762715: val_loss -0.7476 
2025-01-26 19:30:58.765593: Pseudo dice [np.float32(0.948), np.float32(0.87)] 
2025-01-26 19:30:58.768309: Epoch time: 48.88 s 
2025-01-26 19:30:59.955650:  
2025-01-26 19:30:59.958489: Epoch 513 
2025-01-26 19:30:59.961005: Current learning rate: 0.00523 
2025-01-26 19:31:48.702937: train_loss -0.8037 
2025-01-26 19:31:48.709489: val_loss -0.763 
2025-01-26 19:31:48.712357: Pseudo dice [np.float32(0.9399), np.float32(0.8773)] 
2025-01-26 19:31:48.714835: Epoch time: 48.75 s 
2025-01-26 19:31:49.903661:  
2025-01-26 19:31:49.906650: Epoch 514 
2025-01-26 19:31:49.909565: Current learning rate: 0.00522 
2025-01-26 19:32:38.816087: train_loss -0.8174 
2025-01-26 19:32:38.819713: val_loss -0.7698 
2025-01-26 19:32:38.822706: Pseudo dice [np.float32(0.957), np.float32(0.8878)] 
2025-01-26 19:32:38.825535: Epoch time: 48.91 s 
2025-01-26 19:32:40.017327:  
2025-01-26 19:32:40.020989: Epoch 515 
2025-01-26 19:32:40.024618: Current learning rate: 0.00521 
2025-01-26 19:33:28.527696: train_loss -0.8296 
2025-01-26 19:33:28.533664: val_loss -0.7879 
2025-01-26 19:33:28.536474: Pseudo dice [np.float32(0.9612), np.float32(0.8895)] 
2025-01-26 19:33:28.538966: Epoch time: 48.51 s 
2025-01-26 19:33:29.722514:  
2025-01-26 19:33:29.725649: Epoch 516 
2025-01-26 19:33:29.728673: Current learning rate: 0.0052 
2025-01-26 19:34:18.446146: train_loss -0.8105 
2025-01-26 19:34:18.449540: val_loss -0.773 
2025-01-26 19:34:18.452229: Pseudo dice [np.float32(0.9582), np.float32(0.8965)] 
2025-01-26 19:34:18.454651: Epoch time: 48.72 s 
2025-01-26 19:34:19.642509:  
2025-01-26 19:34:19.645493: Epoch 517 
2025-01-26 19:34:19.648261: Current learning rate: 0.00519 
2025-01-26 19:35:08.164562: train_loss -0.8324 
2025-01-26 19:35:08.171314: val_loss -0.7807 
2025-01-26 19:35:08.173882: Pseudo dice [np.float32(0.9565), np.float32(0.8843)] 
2025-01-26 19:35:08.176513: Epoch time: 48.52 s 
2025-01-26 19:35:09.364332:  
2025-01-26 19:35:09.367445: Epoch 518 
2025-01-26 19:35:09.370430: Current learning rate: 0.00518 
2025-01-26 19:35:57.928344: train_loss -0.81 
2025-01-26 19:35:57.931678: val_loss -0.7438 
2025-01-26 19:35:57.934084: Pseudo dice [np.float32(0.9554), np.float32(0.8422)] 
2025-01-26 19:35:57.936692: Epoch time: 48.56 s 
2025-01-26 19:35:59.130159:  
2025-01-26 19:35:59.133373: Epoch 519 
2025-01-26 19:35:59.135825: Current learning rate: 0.00518 
2025-01-26 19:36:47.570403: train_loss -0.8301 
2025-01-26 19:36:47.577277: val_loss -0.7987 
2025-01-26 19:36:47.580117: Pseudo dice [np.float32(0.9557), np.float32(0.8805)] 
2025-01-26 19:36:47.582632: Epoch time: 48.44 s 
2025-01-26 19:36:48.763608:  
2025-01-26 19:36:48.766873: Epoch 520 
2025-01-26 19:36:48.769975: Current learning rate: 0.00517 
2025-01-26 19:37:37.262835: train_loss -0.8101 
2025-01-26 19:37:37.266747: val_loss -0.7919 
2025-01-26 19:37:37.269870: Pseudo dice [np.float32(0.9572), np.float32(0.8901)] 
2025-01-26 19:37:37.272840: Epoch time: 48.5 s 
2025-01-26 19:37:38.466595:  
2025-01-26 19:37:38.469496: Epoch 521 
2025-01-26 19:37:38.472265: Current learning rate: 0.00516 
2025-01-26 19:38:27.566630: train_loss -0.8251 
2025-01-26 19:38:27.572482: val_loss -0.7897 
2025-01-26 19:38:27.575109: Pseudo dice [np.float32(0.9566), np.float32(0.8595)] 
2025-01-26 19:38:27.577729: Epoch time: 49.1 s 
2025-01-26 19:38:28.771547:  
2025-01-26 19:38:28.774345: Epoch 522 
2025-01-26 19:38:28.777033: Current learning rate: 0.00515 
2025-01-26 19:39:17.686492: train_loss -0.8138 
2025-01-26 19:39:17.689619: val_loss -0.7704 
2025-01-26 19:39:17.692491: Pseudo dice [np.float32(0.9523), np.float32(0.8689)] 
2025-01-26 19:39:17.695276: Epoch time: 48.92 s 
2025-01-26 19:39:18.881147:  
2025-01-26 19:39:18.884492: Epoch 523 
2025-01-26 19:39:18.887479: Current learning rate: 0.00514 
2025-01-26 19:40:07.284155: train_loss -0.8162 
2025-01-26 19:40:07.290714: val_loss -0.7367 
2025-01-26 19:40:07.293499: Pseudo dice [np.float32(0.9639), np.float32(0.8738)] 
2025-01-26 19:40:07.296098: Epoch time: 48.4 s 
2025-01-26 19:40:08.486257:  
2025-01-26 19:40:08.489278: Epoch 524 
2025-01-26 19:40:08.491901: Current learning rate: 0.00513 
2025-01-26 19:40:57.314193: train_loss -0.8139 
2025-01-26 19:40:57.317368: val_loss -0.7378 
2025-01-26 19:40:57.320030: Pseudo dice [np.float32(0.9594), np.float32(0.9029)] 
2025-01-26 19:40:57.322694: Epoch time: 48.83 s 
2025-01-26 19:40:58.515110:  
2025-01-26 19:40:58.517896: Epoch 525 
2025-01-26 19:40:58.520548: Current learning rate: 0.00512 
2025-01-26 19:41:47.253570: train_loss -0.8125 
2025-01-26 19:41:47.259826: val_loss -0.7926 
2025-01-26 19:41:47.262562: Pseudo dice [np.float32(0.9661), np.float32(0.8672)] 
2025-01-26 19:41:47.265238: Epoch time: 48.74 s 
2025-01-26 19:41:48.460056:  
2025-01-26 19:41:48.463184: Epoch 526 
2025-01-26 19:41:48.466569: Current learning rate: 0.00511 
2025-01-26 19:42:36.915712: train_loss -0.8443 
2025-01-26 19:42:36.919323: val_loss -0.8201 
2025-01-26 19:42:36.922183: Pseudo dice [np.float32(0.9643), np.float32(0.9225)] 
2025-01-26 19:42:36.925008: Epoch time: 48.46 s 
2025-01-26 19:42:38.123908:  
2025-01-26 19:42:38.126812: Epoch 527 
2025-01-26 19:42:38.129563: Current learning rate: 0.0051 
2025-01-26 19:43:26.467489: train_loss -0.8288 
2025-01-26 19:43:26.474182: val_loss -0.7721 
2025-01-26 19:43:26.476821: Pseudo dice [np.float32(0.9568), np.float32(0.8941)] 
2025-01-26 19:43:26.479543: Epoch time: 48.34 s 
2025-01-26 19:43:27.662240:  
2025-01-26 19:43:27.664870: Epoch 528 
2025-01-26 19:43:27.667464: Current learning rate: 0.00509 
2025-01-26 19:44:16.216722: train_loss -0.8254 
2025-01-26 19:44:16.220373: val_loss -0.7929 
2025-01-26 19:44:16.222702: Pseudo dice [np.float32(0.9631), np.float32(0.8898)] 
2025-01-26 19:44:16.225110: Epoch time: 48.56 s 
2025-01-26 19:44:18.007753:  
2025-01-26 19:44:18.010649: Epoch 529 
2025-01-26 19:44:18.013404: Current learning rate: 0.00508 
2025-01-26 19:45:06.466059: train_loss -0.8264 
2025-01-26 19:45:06.473634: val_loss -0.7755 
2025-01-26 19:45:06.476562: Pseudo dice [np.float32(0.9509), np.float32(0.8512)] 
2025-01-26 19:45:06.479455: Epoch time: 48.46 s 
2025-01-26 19:45:07.668409:  
2025-01-26 19:45:07.671258: Epoch 530 
2025-01-26 19:45:07.674053: Current learning rate: 0.00507 
2025-01-26 19:45:55.836896: train_loss -0.8268 
2025-01-26 19:45:55.839970: val_loss -0.7653 
2025-01-26 19:45:55.842310: Pseudo dice [np.float32(0.9618), np.float32(0.8568)] 
2025-01-26 19:45:55.845526: Epoch time: 48.17 s 
2025-01-26 19:45:57.032459:  
2025-01-26 19:45:57.035123: Epoch 531 
2025-01-26 19:45:57.037899: Current learning rate: 0.00506 
2025-01-26 19:46:45.885693: train_loss -0.8257 
2025-01-26 19:46:45.893088: val_loss -0.7918 
2025-01-26 19:46:45.895989: Pseudo dice [np.float32(0.9634), np.float32(0.858)] 
2025-01-26 19:46:45.898411: Epoch time: 48.85 s 
2025-01-26 19:46:47.089689:  
2025-01-26 19:46:47.092673: Epoch 532 
2025-01-26 19:46:47.095066: Current learning rate: 0.00505 
2025-01-26 19:47:35.680326: train_loss -0.8334 
2025-01-26 19:47:35.683687: val_loss -0.7743 
2025-01-26 19:47:35.686457: Pseudo dice [np.float32(0.9523), np.float32(0.8519)] 
2025-01-26 19:47:35.689292: Epoch time: 48.59 s 
2025-01-26 19:47:36.875593:  
2025-01-26 19:47:36.878263: Epoch 533 
2025-01-26 19:47:36.880966: Current learning rate: 0.00504 
2025-01-26 19:48:25.361840: train_loss -0.8141 
2025-01-26 19:48:25.370749: val_loss -0.8011 
2025-01-26 19:48:25.373756: Pseudo dice [np.float32(0.9518), np.float32(0.8941)] 
2025-01-26 19:48:25.376697: Epoch time: 48.49 s 
2025-01-26 19:48:26.568248:  
2025-01-26 19:48:26.571022: Epoch 534 
2025-01-26 19:48:26.573865: Current learning rate: 0.00503 
2025-01-26 19:49:15.050577: train_loss -0.8166 
2025-01-26 19:49:15.056477: val_loss -0.7715 
2025-01-26 19:49:15.059263: Pseudo dice [np.float32(0.9546), np.float32(0.8769)] 
2025-01-26 19:49:15.061950: Epoch time: 48.48 s 
2025-01-26 19:49:16.243399:  
2025-01-26 19:49:16.246198: Epoch 535 
2025-01-26 19:49:16.248914: Current learning rate: 0.00502 
2025-01-26 19:50:04.569030: train_loss -0.8261 
2025-01-26 19:50:04.575991: val_loss -0.7668 
2025-01-26 19:50:04.578678: Pseudo dice [np.float32(0.9491), np.float32(0.8855)] 
2025-01-26 19:50:04.581123: Epoch time: 48.33 s 
2025-01-26 19:50:05.765128:  
2025-01-26 19:50:05.767946: Epoch 536 
2025-01-26 19:50:05.770618: Current learning rate: 0.00501 
2025-01-26 19:50:54.426308: train_loss -0.8042 
2025-01-26 19:50:54.430339: val_loss -0.7438 
2025-01-26 19:50:54.433309: Pseudo dice [np.float32(0.9498), np.float32(0.851)] 
2025-01-26 19:50:54.435861: Epoch time: 48.66 s 
2025-01-26 19:50:55.624141:  
2025-01-26 19:50:55.627167: Epoch 537 
2025-01-26 19:50:55.629701: Current learning rate: 0.005 
2025-01-26 19:51:44.097459: train_loss -0.7943 
2025-01-26 19:51:44.103394: val_loss -0.7363 
2025-01-26 19:51:44.106057: Pseudo dice [np.float32(0.9454), np.float32(0.8164)] 
2025-01-26 19:51:44.108796: Epoch time: 48.47 s 
2025-01-26 19:51:45.296642:  
2025-01-26 19:51:45.299721: Epoch 538 
2025-01-26 19:51:45.302675: Current learning rate: 0.00499 
2025-01-26 19:52:34.034699: train_loss -0.8093 
2025-01-26 19:52:34.037987: val_loss -0.7722 
2025-01-26 19:52:34.040714: Pseudo dice [np.float32(0.953), np.float32(0.8279)] 
2025-01-26 19:52:34.043409: Epoch time: 48.74 s 
2025-01-26 19:52:35.230027:  
2025-01-26 19:52:35.233000: Epoch 539 
2025-01-26 19:52:35.235875: Current learning rate: 0.00498 
2025-01-26 19:53:23.373775: train_loss -0.82 
2025-01-26 19:53:23.380922: val_loss -0.75 
2025-01-26 19:53:23.383844: Pseudo dice [np.float32(0.9594), np.float32(0.8737)] 
2025-01-26 19:53:23.386344: Epoch time: 48.14 s 
2025-01-26 19:53:24.569505:  
2025-01-26 19:53:24.572133: Epoch 540 
2025-01-26 19:53:24.575103: Current learning rate: 0.00497 
2025-01-26 19:54:12.959585: train_loss -0.8218 
2025-01-26 19:54:12.963497: val_loss -0.7869 
2025-01-26 19:54:12.966033: Pseudo dice [np.float32(0.9535), np.float32(0.8309)] 
2025-01-26 19:54:12.968900: Epoch time: 48.39 s 
2025-01-26 19:54:14.158304:  
2025-01-26 19:54:14.160799: Epoch 541 
2025-01-26 19:54:14.163539: Current learning rate: 0.00496 
2025-01-26 19:55:02.485698: train_loss -0.823 
2025-01-26 19:55:02.493466: val_loss -0.759 
2025-01-26 19:55:02.496433: Pseudo dice [np.float32(0.9541), np.float32(0.8873)] 
2025-01-26 19:55:02.499237: Epoch time: 48.33 s 
2025-01-26 19:55:03.680785:  
2025-01-26 19:55:03.684403: Epoch 542 
2025-01-26 19:55:03.687204: Current learning rate: 0.00495 
2025-01-26 19:55:52.503659: train_loss -0.8224 
2025-01-26 19:55:52.507240: val_loss -0.7611 
2025-01-26 19:55:52.515309: Pseudo dice [np.float32(0.9585), np.float32(0.8933)] 
2025-01-26 19:55:52.519767: Epoch time: 48.82 s 
2025-01-26 19:55:53.706840:  
2025-01-26 19:55:53.709530: Epoch 543 
2025-01-26 19:55:53.712328: Current learning rate: 0.00494 
2025-01-26 19:56:42.466776: train_loss -0.8258 
2025-01-26 19:56:42.472902: val_loss -0.7833 
2025-01-26 19:56:42.475368: Pseudo dice [np.float32(0.959), np.float32(0.9037)] 
2025-01-26 19:56:42.477966: Epoch time: 48.76 s 
2025-01-26 19:56:43.660634:  
2025-01-26 19:56:43.663600: Epoch 544 
2025-01-26 19:56:43.666732: Current learning rate: 0.00493 
2025-01-26 19:57:32.600984: train_loss -0.8379 
2025-01-26 19:57:32.604884: val_loss -0.8108 
2025-01-26 19:57:32.608068: Pseudo dice [np.float32(0.9566), np.float32(0.8839)] 
2025-01-26 19:57:32.611527: Epoch time: 48.94 s 
2025-01-26 19:57:33.796113:  
2025-01-26 19:57:33.800499: Epoch 545 
2025-01-26 19:57:33.803110: Current learning rate: 0.00492 
2025-01-26 19:58:22.287632: train_loss -0.8228 
2025-01-26 19:58:22.294029: val_loss -0.7932 
2025-01-26 19:58:22.297007: Pseudo dice [np.float32(0.9582), np.float32(0.8737)] 
2025-01-26 19:58:22.299546: Epoch time: 48.49 s 
2025-01-26 19:58:23.476780:  
2025-01-26 19:58:23.480368: Epoch 546 
2025-01-26 19:58:23.483494: Current learning rate: 0.00491 
2025-01-26 19:59:12.068088: train_loss -0.8194 
2025-01-26 19:59:12.072899: val_loss -0.7997 
2025-01-26 19:59:12.076064: Pseudo dice [np.float32(0.9526), np.float32(0.9092)] 
2025-01-26 19:59:12.079546: Epoch time: 48.59 s 
2025-01-26 19:59:13.263448:  
2025-01-26 19:59:13.266603: Epoch 547 
2025-01-26 19:59:13.269903: Current learning rate: 0.0049 
2025-01-26 20:00:01.787119: train_loss -0.8251 
2025-01-26 20:00:01.793919: val_loss -0.7567 
2025-01-26 20:00:01.797238: Pseudo dice [np.float32(0.955), np.float32(0.8746)] 
2025-01-26 20:00:01.799724: Epoch time: 48.52 s 
2025-01-26 20:00:02.979085:  
2025-01-26 20:00:02.982808: Epoch 548 
2025-01-26 20:00:02.985650: Current learning rate: 0.00489 
2025-01-26 20:00:51.305887: train_loss -0.8171 
2025-01-26 20:00:51.313534: val_loss -0.7858 
2025-01-26 20:00:51.316578: Pseudo dice [np.float32(0.9585), np.float32(0.8966)] 
2025-01-26 20:00:51.319608: Epoch time: 48.33 s 
2025-01-26 20:00:53.082967:  
2025-01-26 20:00:53.086612: Epoch 549 
2025-01-26 20:00:53.089532: Current learning rate: 0.00488 
2025-01-26 20:01:41.835590: train_loss -0.8278 
2025-01-26 20:01:41.842024: val_loss -0.7999 
2025-01-26 20:01:41.845101: Pseudo dice [np.float32(0.9595), np.float32(0.9114)] 
2025-01-26 20:01:41.847963: Epoch time: 48.75 s 
2025-01-26 20:01:43.578742:  
2025-01-26 20:01:43.581977: Epoch 550 
2025-01-26 20:01:43.584882: Current learning rate: 0.00487 
2025-01-26 20:02:31.856605: train_loss -0.8223 
2025-01-26 20:02:31.860373: val_loss -0.7844 
2025-01-26 20:02:31.863346: Pseudo dice [np.float32(0.9509), np.float32(0.9141)] 
2025-01-26 20:02:31.866185: Epoch time: 48.28 s 
2025-01-26 20:02:33.039584:  
2025-01-26 20:02:33.042662: Epoch 551 
2025-01-26 20:02:33.045631: Current learning rate: 0.00486 
2025-01-26 20:03:21.521267: train_loss -0.8284 
2025-01-26 20:03:21.527827: val_loss -0.798 
2025-01-26 20:03:21.530666: Pseudo dice [np.float32(0.9587), np.float32(0.8966)] 
2025-01-26 20:03:21.533448: Epoch time: 48.48 s 
2025-01-26 20:03:22.714533:  
2025-01-26 20:03:22.717549: Epoch 552 
2025-01-26 20:03:22.720394: Current learning rate: 0.00485 
2025-01-26 20:04:11.084633: train_loss -0.8179 
2025-01-26 20:04:11.087837: val_loss -0.7681 
2025-01-26 20:04:11.090756: Pseudo dice [np.float32(0.9568), np.float32(0.8722)] 
2025-01-26 20:04:11.093381: Epoch time: 48.37 s 
2025-01-26 20:04:12.275656:  
2025-01-26 20:04:12.278413: Epoch 553 
2025-01-26 20:04:12.280816: Current learning rate: 0.00484 
2025-01-26 20:05:01.340843: train_loss -0.8306 
2025-01-26 20:05:01.347383: val_loss -0.7798 
2025-01-26 20:05:01.349983: Pseudo dice [np.float32(0.9615), np.float32(0.9067)] 
2025-01-26 20:05:01.352193: Epoch time: 49.07 s 
2025-01-26 20:05:02.562686:  
2025-01-26 20:05:02.565832: Epoch 554 
2025-01-26 20:05:02.568541: Current learning rate: 0.00484 
2025-01-26 20:05:51.185695: train_loss -0.8337 
2025-01-26 20:05:51.193297: val_loss -0.801 
2025-01-26 20:05:51.195893: Pseudo dice [np.float32(0.9609), np.float32(0.9053)] 
2025-01-26 20:05:51.198629: Epoch time: 48.62 s 
2025-01-26 20:05:52.439226:  
2025-01-26 20:05:52.442921: Epoch 555 
2025-01-26 20:05:52.446136: Current learning rate: 0.00483 
2025-01-26 20:06:40.833352: train_loss -0.8255 
2025-01-26 20:06:40.842202: val_loss -0.8205 
2025-01-26 20:06:40.845162: Pseudo dice [np.float32(0.9609), np.float32(0.9021)] 
2025-01-26 20:06:40.847988: Epoch time: 48.4 s 
2025-01-26 20:06:42.071313:  
2025-01-26 20:06:42.074463: Epoch 556 
2025-01-26 20:06:42.077718: Current learning rate: 0.00482 
2025-01-26 20:07:30.974845: train_loss -0.81 
2025-01-26 20:07:30.982300: val_loss -0.8004 
2025-01-26 20:07:30.984914: Pseudo dice [np.float32(0.9566), np.float32(0.9024)] 
2025-01-26 20:07:30.987461: Epoch time: 48.9 s 
2025-01-26 20:07:32.181991:  
2025-01-26 20:07:32.185431: Epoch 557 
2025-01-26 20:07:32.188391: Current learning rate: 0.00481 
2025-01-26 20:08:20.803393: train_loss -0.8365 
2025-01-26 20:08:20.811414: val_loss -0.7647 
2025-01-26 20:08:20.813979: Pseudo dice [np.float32(0.9542), np.float32(0.886)] 
2025-01-26 20:08:20.816668: Epoch time: 48.62 s 
2025-01-26 20:08:22.019138:  
2025-01-26 20:08:22.022186: Epoch 558 
2025-01-26 20:08:22.025076: Current learning rate: 0.0048 
2025-01-26 20:09:10.412835: train_loss -0.8143 
2025-01-26 20:09:10.420463: val_loss -0.8168 
2025-01-26 20:09:10.423582: Pseudo dice [np.float32(0.9588), np.float32(0.919)] 
2025-01-26 20:09:10.426293: Epoch time: 48.39 s 
2025-01-26 20:09:10.429162: Yayy! New best EMA pseudo Dice: 0.9254000186920166 
2025-01-26 20:09:12.208011:  
2025-01-26 20:09:12.211174: Epoch 559 
2025-01-26 20:09:12.213948: Current learning rate: 0.00479 
2025-01-26 20:10:00.869426: train_loss -0.8332 
2025-01-26 20:10:00.878319: val_loss -0.7797 
2025-01-26 20:10:00.885198: Pseudo dice [np.float32(0.9578), np.float32(0.9027)] 
2025-01-26 20:10:00.892378: Epoch time: 48.66 s 
2025-01-26 20:10:00.894859: Yayy! New best EMA pseudo Dice: 0.9258999824523926 
2025-01-26 20:10:02.741261:  
2025-01-26 20:10:02.744577: Epoch 560 
2025-01-26 20:10:02.748245: Current learning rate: 0.00478 
2025-01-26 20:10:51.549733: train_loss -0.8375 
2025-01-26 20:10:51.556227: val_loss -0.7768 
2025-01-26 20:10:51.558877: Pseudo dice [np.float32(0.9622), np.float32(0.9053)] 
2025-01-26 20:10:51.561168: Epoch time: 48.81 s 
2025-01-26 20:10:51.563746: Yayy! New best EMA pseudo Dice: 0.9266999959945679 
2025-01-26 20:10:53.311718:  
2025-01-26 20:10:53.314926: Epoch 561 
2025-01-26 20:10:53.317946: Current learning rate: 0.00477 
2025-01-26 20:11:41.698169: train_loss -0.842 
2025-01-26 20:11:41.705972: val_loss -0.7927 
2025-01-26 20:11:41.709418: Pseudo dice [np.float32(0.9584), np.float32(0.913)] 
2025-01-26 20:11:41.712857: Epoch time: 48.39 s 
2025-01-26 20:11:41.715556: Yayy! New best EMA pseudo Dice: 0.9276000261306763 
2025-01-26 20:11:43.462401:  
2025-01-26 20:11:43.465059: Epoch 562 
2025-01-26 20:11:43.467794: Current learning rate: 0.00476 
2025-01-26 20:12:32.417700: train_loss -0.823 
2025-01-26 20:12:32.422475: val_loss -0.7573 
2025-01-26 20:12:32.425108: Pseudo dice [np.float32(0.9578), np.float32(0.9004)] 
2025-01-26 20:12:32.427385: Epoch time: 48.96 s 
2025-01-26 20:12:32.430187: Yayy! New best EMA pseudo Dice: 0.9276999831199646 
2025-01-26 20:12:34.181177:  
2025-01-26 20:12:34.184331: Epoch 563 
2025-01-26 20:12:34.187013: Current learning rate: 0.00475 
2025-01-26 20:13:22.716575: train_loss -0.8257 
2025-01-26 20:13:22.724485: val_loss -0.8041 
2025-01-26 20:13:22.727080: Pseudo dice [np.float32(0.9641), np.float32(0.8895)] 
2025-01-26 20:13:22.729481: Epoch time: 48.54 s 
2025-01-26 20:13:23.910645:  
2025-01-26 20:13:23.913923: Epoch 564 
2025-01-26 20:13:23.916846: Current learning rate: 0.00474 
2025-01-26 20:14:12.446637: train_loss -0.8255 
2025-01-26 20:14:12.450407: val_loss -0.7691 
2025-01-26 20:14:12.453498: Pseudo dice [np.float32(0.9592), np.float32(0.9051)] 
2025-01-26 20:14:12.456364: Epoch time: 48.54 s 
2025-01-26 20:14:12.459347: Yayy! New best EMA pseudo Dice: 0.9280999898910522 
2025-01-26 20:14:14.231948:  
2025-01-26 20:14:14.235307: Epoch 565 
2025-01-26 20:14:14.238472: Current learning rate: 0.00473 
2025-01-26 20:15:02.630818: train_loss -0.8256 
2025-01-26 20:15:02.637177: val_loss -0.7802 
2025-01-26 20:15:02.640643: Pseudo dice [np.float32(0.9583), np.float32(0.919)] 
2025-01-26 20:15:02.643750: Epoch time: 48.4 s 
2025-01-26 20:15:02.646271: Yayy! New best EMA pseudo Dice: 0.929099977016449 
2025-01-26 20:15:04.512051:  
2025-01-26 20:15:04.514688: Epoch 566 
2025-01-26 20:15:04.517388: Current learning rate: 0.00472 
2025-01-26 20:15:53.306014: train_loss -0.8346 
2025-01-26 20:15:53.313449: val_loss -0.8054 
2025-01-26 20:15:53.316185: Pseudo dice [np.float32(0.9622), np.float32(0.8861)] 
2025-01-26 20:15:53.319356: Epoch time: 48.79 s 
2025-01-26 20:15:55.097312:  
2025-01-26 20:15:55.099845: Epoch 567 
2025-01-26 20:15:55.102726: Current learning rate: 0.00471 
2025-01-26 20:16:43.145729: train_loss -0.8414 
2025-01-26 20:16:43.152526: val_loss -0.7968 
2025-01-26 20:16:43.155202: Pseudo dice [np.float32(0.962), np.float32(0.908)] 
2025-01-26 20:16:43.157803: Epoch time: 48.05 s 
2025-01-26 20:16:43.160467: Yayy! New best EMA pseudo Dice: 0.9293000102043152 
2025-01-26 20:16:44.932548:  
2025-01-26 20:16:44.936079: Epoch 568 
2025-01-26 20:16:44.938895: Current learning rate: 0.0047 
2025-01-26 20:17:33.721276: train_loss -0.8291 
2025-01-26 20:17:33.726427: val_loss -0.7914 
2025-01-26 20:17:33.729154: Pseudo dice [np.float32(0.9595), np.float32(0.9194)] 
2025-01-26 20:17:33.732275: Epoch time: 48.79 s 
2025-01-26 20:17:33.735162: Yayy! New best EMA pseudo Dice: 0.9302999973297119 
2025-01-26 20:17:35.516473:  
2025-01-26 20:17:35.519147: Epoch 569 
2025-01-26 20:17:35.522388: Current learning rate: 0.00469 
2025-01-26 20:18:23.912026: train_loss -0.809 
2025-01-26 20:18:23.919415: val_loss -0.775 
2025-01-26 20:18:23.922095: Pseudo dice [np.float32(0.9615), np.float32(0.882)] 
2025-01-26 20:18:23.925051: Epoch time: 48.4 s 
2025-01-26 20:18:25.111796:  
2025-01-26 20:18:25.114644: Epoch 570 
2025-01-26 20:18:25.117520: Current learning rate: 0.00468 
2025-01-26 20:19:13.623222: train_loss -0.8228 
2025-01-26 20:19:13.626427: val_loss -0.7614 
2025-01-26 20:19:13.629087: Pseudo dice [np.float32(0.9568), np.float32(0.8626)] 
2025-01-26 20:19:13.631550: Epoch time: 48.51 s 
2025-01-26 20:19:14.829488:  
2025-01-26 20:19:14.832531: Epoch 571 
2025-01-26 20:19:14.835511: Current learning rate: 0.00467 
2025-01-26 20:20:03.256472: train_loss -0.8292 
2025-01-26 20:20:03.263134: val_loss -0.7739 
2025-01-26 20:20:03.266143: Pseudo dice [np.float32(0.9592), np.float32(0.9057)] 
2025-01-26 20:20:03.268901: Epoch time: 48.43 s 
2025-01-26 20:20:04.456264:  
2025-01-26 20:20:04.459580: Epoch 572 
2025-01-26 20:20:04.462480: Current learning rate: 0.00466 
2025-01-26 20:20:53.448156: train_loss -0.8334 
2025-01-26 20:20:53.453425: val_loss -0.7595 
2025-01-26 20:20:53.456461: Pseudo dice [np.float32(0.9517), np.float32(0.9015)] 
2025-01-26 20:20:53.459119: Epoch time: 48.99 s 
2025-01-26 20:20:54.659687:  
2025-01-26 20:20:54.662461: Epoch 573 
2025-01-26 20:20:54.665267: Current learning rate: 0.00465 
2025-01-26 20:21:42.995230: train_loss -0.8291 
2025-01-26 20:21:43.002802: val_loss -0.7769 
2025-01-26 20:21:43.005872: Pseudo dice [np.float32(0.9619), np.float32(0.9174)] 
2025-01-26 20:21:43.008757: Epoch time: 48.34 s 
2025-01-26 20:21:44.233849:  
2025-01-26 20:21:44.236910: Epoch 574 
2025-01-26 20:21:44.239696: Current learning rate: 0.00464 
2025-01-26 20:22:32.844247: train_loss -0.8111 
2025-01-26 20:22:32.847433: val_loss -0.7895 
2025-01-26 20:22:32.850195: Pseudo dice [np.float32(0.9488), np.float32(0.8698)] 
2025-01-26 20:22:32.853065: Epoch time: 48.61 s 
2025-01-26 20:22:34.044048:  
2025-01-26 20:22:34.046783: Epoch 575 
2025-01-26 20:22:34.049574: Current learning rate: 0.00463 
2025-01-26 20:23:22.563518: train_loss -0.8286 
2025-01-26 20:23:22.570089: val_loss -0.7771 
2025-01-26 20:23:22.572964: Pseudo dice [np.float32(0.9496), np.float32(0.9104)] 
2025-01-26 20:23:22.575700: Epoch time: 48.52 s 
2025-01-26 20:23:23.770238:  
2025-01-26 20:23:23.772824: Epoch 576 
2025-01-26 20:23:23.777366: Current learning rate: 0.00462 
2025-01-26 20:24:12.586962: train_loss -0.8307 
2025-01-26 20:24:12.590088: val_loss -0.8086 
2025-01-26 20:24:12.592641: Pseudo dice [np.float32(0.9614), np.float32(0.9133)] 
2025-01-26 20:24:12.595262: Epoch time: 48.82 s 
2025-01-26 20:24:13.786933:  
2025-01-26 20:24:13.789787: Epoch 577 
2025-01-26 20:24:13.792502: Current learning rate: 0.00461 
2025-01-26 20:25:02.390735: train_loss -0.8216 
2025-01-26 20:25:02.397155: val_loss -0.7927 
2025-01-26 20:25:02.400044: Pseudo dice [np.float32(0.957), np.float32(0.8816)] 
2025-01-26 20:25:02.402846: Epoch time: 48.6 s 
2025-01-26 20:25:03.603750:  
2025-01-26 20:25:03.606831: Epoch 578 
2025-01-26 20:25:03.609590: Current learning rate: 0.0046 
2025-01-26 20:25:52.696212: train_loss -0.833 
2025-01-26 20:25:52.700006: val_loss -0.7899 
2025-01-26 20:25:52.702521: Pseudo dice [np.float32(0.9593), np.float32(0.9159)] 
2025-01-26 20:25:52.705354: Epoch time: 49.09 s 
2025-01-26 20:25:53.927060:  
2025-01-26 20:25:53.930634: Epoch 579 
2025-01-26 20:25:53.933786: Current learning rate: 0.00459 
2025-01-26 20:26:42.384958: train_loss -0.8441 
2025-01-26 20:26:42.392191: val_loss -0.792 
2025-01-26 20:26:42.394883: Pseudo dice [np.float32(0.9643), np.float32(0.8982)] 
2025-01-26 20:26:42.397531: Epoch time: 48.46 s 
2025-01-26 20:26:43.595122:  
2025-01-26 20:26:43.598261: Epoch 580 
2025-01-26 20:26:43.601072: Current learning rate: 0.00458 
2025-01-26 20:27:32.111056: train_loss -0.8362 
2025-01-26 20:27:32.114731: val_loss -0.748 
2025-01-26 20:27:32.117472: Pseudo dice [np.float32(0.9528), np.float32(0.8859)] 
2025-01-26 20:27:32.119948: Epoch time: 48.52 s 
2025-01-26 20:27:33.316849:  
2025-01-26 20:27:33.320319: Epoch 581 
2025-01-26 20:27:33.322914: Current learning rate: 0.00457 
2025-01-26 20:28:21.912088: train_loss -0.8349 
2025-01-26 20:28:21.919024: val_loss -0.77 
2025-01-26 20:28:21.921897: Pseudo dice [np.float32(0.954), np.float32(0.8755)] 
2025-01-26 20:28:21.924381: Epoch time: 48.6 s 
2025-01-26 20:28:23.126590:  
2025-01-26 20:28:23.129706: Epoch 582 
2025-01-26 20:28:23.132396: Current learning rate: 0.00456 
2025-01-26 20:29:11.602854: train_loss -0.8164 
2025-01-26 20:29:11.606141: val_loss -0.8085 
2025-01-26 20:29:11.609165: Pseudo dice [np.float32(0.9574), np.float32(0.9142)] 
2025-01-26 20:29:11.611830: Epoch time: 48.48 s 
2025-01-26 20:29:12.805638:  
2025-01-26 20:29:12.808551: Epoch 583 
2025-01-26 20:29:12.811687: Current learning rate: 0.00455 
2025-01-26 20:30:01.088163: train_loss -0.8238 
2025-01-26 20:30:01.094908: val_loss -0.7865 
2025-01-26 20:30:01.097582: Pseudo dice [np.float32(0.9537), np.float32(0.8896)] 
2025-01-26 20:30:01.100461: Epoch time: 48.28 s 
2025-01-26 20:30:02.308207:  
2025-01-26 20:30:02.311466: Epoch 584 
2025-01-26 20:30:02.314580: Current learning rate: 0.00454 
2025-01-26 20:30:50.873226: train_loss -0.8335 
2025-01-26 20:30:50.876775: val_loss -0.7748 
2025-01-26 20:30:50.879628: Pseudo dice [np.float32(0.9592), np.float32(0.9068)] 
2025-01-26 20:30:50.882461: Epoch time: 48.57 s 
2025-01-26 20:30:52.635192:  
2025-01-26 20:30:52.638074: Epoch 585 
2025-01-26 20:30:52.640719: Current learning rate: 0.00453 
2025-01-26 20:31:41.335666: train_loss -0.845 
2025-01-26 20:31:41.342603: val_loss -0.782 
2025-01-26 20:31:41.345559: Pseudo dice [np.float32(0.9584), np.float32(0.8875)] 
2025-01-26 20:31:41.350050: Epoch time: 48.7 s 
2025-01-26 20:31:42.547322:  
2025-01-26 20:31:42.550208: Epoch 586 
2025-01-26 20:31:42.553099: Current learning rate: 0.00452 
2025-01-26 20:32:31.622724: train_loss -0.8405 
2025-01-26 20:32:31.626430: val_loss -0.7428 
2025-01-26 20:32:31.629174: Pseudo dice [np.float32(0.9637), np.float32(0.9078)] 
2025-01-26 20:32:31.631602: Epoch time: 49.08 s 
2025-01-26 20:32:32.831699:  
2025-01-26 20:32:32.834687: Epoch 587 
2025-01-26 20:32:32.837472: Current learning rate: 0.00451 
2025-01-26 20:33:21.314684: train_loss -0.8322 
2025-01-26 20:33:21.322083: val_loss -0.788 
2025-01-26 20:33:21.324874: Pseudo dice [np.float32(0.9612), np.float32(0.9082)] 
2025-01-26 20:33:21.328112: Epoch time: 48.48 s 
2025-01-26 20:33:22.524768:  
2025-01-26 20:33:22.527919: Epoch 588 
2025-01-26 20:33:22.530846: Current learning rate: 0.0045 
2025-01-26 20:34:11.172464: train_loss -0.8335 
2025-01-26 20:34:11.176418: val_loss -0.8096 
2025-01-26 20:34:11.179408: Pseudo dice [np.float32(0.9589), np.float32(0.8957)] 
2025-01-26 20:34:11.181939: Epoch time: 48.65 s 
2025-01-26 20:34:12.384312:  
2025-01-26 20:34:12.387250: Epoch 589 
2025-01-26 20:34:12.389963: Current learning rate: 0.00449 
2025-01-26 20:35:01.165978: train_loss -0.8164 
2025-01-26 20:35:01.173213: val_loss -0.8115 
2025-01-26 20:35:01.176479: Pseudo dice [np.float32(0.9564), np.float32(0.9059)] 
2025-01-26 20:35:01.179523: Epoch time: 48.78 s 
2025-01-26 20:35:02.378105:  
2025-01-26 20:35:02.381563: Epoch 590 
2025-01-26 20:35:02.384739: Current learning rate: 0.00448 
2025-01-26 20:35:51.345180: train_loss -0.8287 
2025-01-26 20:35:51.348703: val_loss -0.7416 
2025-01-26 20:35:51.351216: Pseudo dice [np.float32(0.9631), np.float32(0.8781)] 
2025-01-26 20:35:51.353473: Epoch time: 48.97 s 
2025-01-26 20:35:52.541623:  
2025-01-26 20:35:52.544936: Epoch 591 
2025-01-26 20:35:52.548446: Current learning rate: 0.00447 
2025-01-26 20:36:40.992119: train_loss -0.8243 
2025-01-26 20:36:40.999199: val_loss -0.7916 
2025-01-26 20:36:41.001866: Pseudo dice [np.float32(0.9588), np.float32(0.8255)] 
2025-01-26 20:36:41.004583: Epoch time: 48.45 s 
2025-01-26 20:36:42.203593:  
2025-01-26 20:36:42.206827: Epoch 592 
2025-01-26 20:36:42.209836: Current learning rate: 0.00446 
2025-01-26 20:37:30.330604: train_loss -0.8 
2025-01-26 20:37:30.334108: val_loss -0.7368 
2025-01-26 20:37:30.336628: Pseudo dice [np.float32(0.9517), np.float32(0.8918)] 
2025-01-26 20:37:30.339474: Epoch time: 48.13 s 
2025-01-26 20:37:31.538788:  
2025-01-26 20:37:31.541738: Epoch 593 
2025-01-26 20:37:31.544880: Current learning rate: 0.00445 
2025-01-26 20:38:19.896473: train_loss -0.8088 
2025-01-26 20:38:19.903026: val_loss -0.7485 
2025-01-26 20:38:19.905940: Pseudo dice [np.float32(0.9566), np.float32(0.88)] 
2025-01-26 20:38:19.908422: Epoch time: 48.36 s 
2025-01-26 20:38:21.102145:  
2025-01-26 20:38:21.105286: Epoch 594 
2025-01-26 20:38:21.108356: Current learning rate: 0.00444 
2025-01-26 20:39:09.579149: train_loss -0.8162 
2025-01-26 20:39:09.583500: val_loss -0.719 
2025-01-26 20:39:09.587173: Pseudo dice [np.float32(0.9577), np.float32(0.8793)] 
2025-01-26 20:39:09.589869: Epoch time: 48.48 s 
2025-01-26 20:39:10.780376:  
2025-01-26 20:39:10.783539: Epoch 595 
2025-01-26 20:39:10.786868: Current learning rate: 0.00443 
2025-01-26 20:39:58.953504: train_loss -0.8337 
2025-01-26 20:39:58.960296: val_loss -0.7736 
2025-01-26 20:39:58.963056: Pseudo dice [np.float32(0.951), np.float32(0.8341)] 
2025-01-26 20:39:58.965780: Epoch time: 48.17 s 
2025-01-26 20:40:00.165987:  
2025-01-26 20:40:00.169246: Epoch 596 
2025-01-26 20:40:00.172554: Current learning rate: 0.00442 
2025-01-26 20:40:48.945724: train_loss -0.834 
2025-01-26 20:40:48.949399: val_loss -0.7853 
2025-01-26 20:40:48.952352: Pseudo dice [np.float32(0.9589), np.float32(0.9103)] 
2025-01-26 20:40:48.955155: Epoch time: 48.78 s 
2025-01-26 20:40:50.155245:  
2025-01-26 20:40:50.158064: Epoch 597 
2025-01-26 20:40:50.160961: Current learning rate: 0.00441 
2025-01-26 20:41:38.616003: train_loss -0.8312 
2025-01-26 20:41:38.626297: val_loss -0.764 
2025-01-26 20:41:38.629120: Pseudo dice [np.float32(0.9595), np.float32(0.8995)] 
2025-01-26 20:41:38.631684: Epoch time: 48.46 s 
2025-01-26 20:41:39.865804:  
2025-01-26 20:41:39.868793: Epoch 598 
2025-01-26 20:41:39.871717: Current learning rate: 0.0044 
2025-01-26 20:42:28.485443: train_loss -0.8297 
2025-01-26 20:42:28.489061: val_loss -0.7814 
2025-01-26 20:42:28.491960: Pseudo dice [np.float32(0.9581), np.float32(0.901)] 
2025-01-26 20:42:28.494608: Epoch time: 48.62 s 
2025-01-26 20:42:29.681794:  
2025-01-26 20:42:29.685538: Epoch 599 
2025-01-26 20:42:29.688507: Current learning rate: 0.00439 
2025-01-26 20:43:18.698004: train_loss -0.8397 
2025-01-26 20:43:18.705145: val_loss -0.7578 
2025-01-26 20:43:18.707963: Pseudo dice [np.float32(0.9507), np.float32(0.8729)] 
2025-01-26 20:43:18.710585: Epoch time: 49.02 s 
2025-01-26 20:43:20.487875:  
2025-01-26 20:43:20.491208: Epoch 600 
2025-01-26 20:43:20.494416: Current learning rate: 0.00438 
2025-01-26 20:44:08.810477: train_loss -0.8287 
2025-01-26 20:44:08.813638: val_loss -0.7685 
2025-01-26 20:44:08.816358: Pseudo dice [np.float32(0.946), np.float32(0.8943)] 
2025-01-26 20:44:08.819124: Epoch time: 48.32 s 
2025-01-26 20:44:10.024641:  
2025-01-26 20:44:10.028111: Epoch 601 
2025-01-26 20:44:10.030962: Current learning rate: 0.00437 
2025-01-26 20:44:58.826943: train_loss -0.8232 
2025-01-26 20:44:58.834345: val_loss -0.7616 
2025-01-26 20:44:58.836975: Pseudo dice [np.float32(0.9601), np.float32(0.906)] 
2025-01-26 20:44:58.839253: Epoch time: 48.8 s 
2025-01-26 20:45:00.039011:  
2025-01-26 20:45:00.041799: Epoch 602 
2025-01-26 20:45:00.044514: Current learning rate: 0.00436 
2025-01-26 20:45:48.150339: train_loss -0.838 
2025-01-26 20:45:48.153876: val_loss -0.7704 
2025-01-26 20:45:48.157080: Pseudo dice [np.float32(0.9578), np.float32(0.9035)] 
2025-01-26 20:45:48.160042: Epoch time: 48.11 s 
2025-01-26 20:45:49.351425:  
2025-01-26 20:45:49.354454: Epoch 603 
2025-01-26 20:45:49.357485: Current learning rate: 0.00435 
2025-01-26 20:46:37.960898: train_loss -0.8246 
2025-01-26 20:46:37.967568: val_loss -0.7819 
2025-01-26 20:46:37.970171: Pseudo dice [np.float32(0.9584), np.float32(0.9068)] 
2025-01-26 20:46:37.972823: Epoch time: 48.61 s 
2025-01-26 20:46:39.725679:  
2025-01-26 20:46:39.728738: Epoch 604 
2025-01-26 20:46:39.731649: Current learning rate: 0.00434 
2025-01-26 20:47:28.418118: train_loss -0.8148 
2025-01-26 20:47:28.421769: val_loss -0.7724 
2025-01-26 20:47:28.424768: Pseudo dice [np.float32(0.9556), np.float32(0.8329)] 
2025-01-26 20:47:28.427527: Epoch time: 48.69 s 
2025-01-26 20:47:29.625489:  
2025-01-26 20:47:29.628430: Epoch 605 
2025-01-26 20:47:29.630940: Current learning rate: 0.00433 
2025-01-26 20:48:17.816499: train_loss -0.8446 
2025-01-26 20:48:17.823516: val_loss -0.7607 
2025-01-26 20:48:17.826438: Pseudo dice [np.float32(0.9477), np.float32(0.8922)] 
2025-01-26 20:48:17.828949: Epoch time: 48.19 s 
2025-01-26 20:48:19.024875:  
2025-01-26 20:48:19.028389: Epoch 606 
2025-01-26 20:48:19.031427: Current learning rate: 0.00432 
2025-01-26 20:49:07.651781: train_loss -0.8012 
2025-01-26 20:49:07.655978: val_loss -0.7588 
2025-01-26 20:49:07.658885: Pseudo dice [np.float32(0.9537), np.float32(0.896)] 
2025-01-26 20:49:07.661838: Epoch time: 48.63 s 
2025-01-26 20:49:08.859182:  
2025-01-26 20:49:08.862008: Epoch 607 
2025-01-26 20:49:08.864686: Current learning rate: 0.00431 
2025-01-26 20:49:58.312914: train_loss -0.8201 
2025-01-26 20:49:58.320228: val_loss -0.7786 
2025-01-26 20:49:58.323154: Pseudo dice [np.float32(0.9572), np.float32(0.8786)] 
2025-01-26 20:49:58.325788: Epoch time: 49.45 s 
2025-01-26 20:49:59.525668:  
2025-01-26 20:49:59.528770: Epoch 608 
2025-01-26 20:49:59.531392: Current learning rate: 0.0043 
2025-01-26 20:50:48.159294: train_loss -0.8191 
2025-01-26 20:50:48.162942: val_loss -0.7671 
2025-01-26 20:50:48.165935: Pseudo dice [np.float32(0.9514), np.float32(0.8817)] 
2025-01-26 20:50:48.168724: Epoch time: 48.63 s 
2025-01-26 20:50:49.361281:  
2025-01-26 20:50:49.364113: Epoch 609 
2025-01-26 20:50:49.366932: Current learning rate: 0.00429 
2025-01-26 20:51:38.098755: train_loss -0.8155 
2025-01-26 20:51:38.106399: val_loss -0.7883 
2025-01-26 20:51:38.109258: Pseudo dice [np.float32(0.9589), np.float32(0.8507)] 
2025-01-26 20:51:38.112075: Epoch time: 48.74 s 
2025-01-26 20:51:39.320488:  
2025-01-26 20:51:39.323895: Epoch 610 
2025-01-26 20:51:39.326718: Current learning rate: 0.00429 
2025-01-26 20:52:28.190998: train_loss -0.8163 
2025-01-26 20:52:28.194994: val_loss -0.7784 
2025-01-26 20:52:28.198075: Pseudo dice [np.float32(0.9567), np.float32(0.9033)] 
2025-01-26 20:52:28.200886: Epoch time: 48.87 s 
2025-01-26 20:52:29.403020:  
2025-01-26 20:52:29.406223: Epoch 611 
2025-01-26 20:52:29.409162: Current learning rate: 0.00428 
2025-01-26 20:53:17.816433: train_loss -0.8251 
2025-01-26 20:53:17.822707: val_loss -0.7806 
2025-01-26 20:53:17.825253: Pseudo dice [np.float32(0.9605), np.float32(0.9139)] 
2025-01-26 20:53:17.827861: Epoch time: 48.41 s 
2025-01-26 20:53:19.020929:  
2025-01-26 20:53:19.024311: Epoch 612 
2025-01-26 20:53:19.027447: Current learning rate: 0.00427 
2025-01-26 20:54:07.571262: train_loss -0.821 
2025-01-26 20:54:07.574847: val_loss -0.7789 
2025-01-26 20:54:07.577807: Pseudo dice [np.float32(0.9541), np.float32(0.8864)] 
2025-01-26 20:54:07.580264: Epoch time: 48.55 s 
2025-01-26 20:54:08.784194:  
2025-01-26 20:54:08.787611: Epoch 613 
2025-01-26 20:54:08.790931: Current learning rate: 0.00426 
2025-01-26 20:54:57.819011: train_loss -0.8185 
2025-01-26 20:54:57.826347: val_loss -0.8079 
2025-01-26 20:54:57.829582: Pseudo dice [np.float32(0.9615), np.float32(0.9004)] 
2025-01-26 20:54:57.832614: Epoch time: 49.04 s 
2025-01-26 20:54:59.039924:  
2025-01-26 20:54:59.043205: Epoch 614 
2025-01-26 20:54:59.045879: Current learning rate: 0.00425 
2025-01-26 20:55:47.201886: train_loss -0.8051 
2025-01-26 20:55:47.205254: val_loss -0.7584 
2025-01-26 20:55:47.208047: Pseudo dice [np.float32(0.9506), np.float32(0.8811)] 
2025-01-26 20:55:47.210552: Epoch time: 48.16 s 
2025-01-26 20:55:48.416212:  
2025-01-26 20:55:48.419227: Epoch 615 
2025-01-26 20:55:48.422403: Current learning rate: 0.00424 
2025-01-26 20:56:36.914463: train_loss -0.8073 
2025-01-26 20:56:36.921630: val_loss -0.7603 
2025-01-26 20:56:36.924415: Pseudo dice [np.float32(0.9604), np.float32(0.9074)] 
2025-01-26 20:56:36.926984: Epoch time: 48.5 s 
2025-01-26 20:56:38.129377:  
2025-01-26 20:56:38.132601: Epoch 616 
2025-01-26 20:56:38.135843: Current learning rate: 0.00423 
2025-01-26 20:57:26.709811: train_loss -0.817 
2025-01-26 20:57:26.713874: val_loss -0.8256 
2025-01-26 20:57:26.716767: Pseudo dice [np.float32(0.9612), np.float32(0.9011)] 
2025-01-26 20:57:26.720217: Epoch time: 48.58 s 
2025-01-26 20:57:27.931930:  
2025-01-26 20:57:27.935178: Epoch 617 
2025-01-26 20:57:27.938046: Current learning rate: 0.00422 
2025-01-26 20:58:16.751590: train_loss -0.8212 
2025-01-26 20:58:16.758714: val_loss -0.7551 
2025-01-26 20:58:16.761663: Pseudo dice [np.float32(0.9558), np.float32(0.8993)] 
2025-01-26 20:58:16.764052: Epoch time: 48.82 s 
2025-01-26 20:58:17.972494:  
2025-01-26 20:58:17.975751: Epoch 618 
2025-01-26 20:58:17.978635: Current learning rate: 0.00421 
2025-01-26 20:59:06.548251: train_loss -0.8398 
2025-01-26 20:59:06.552002: val_loss -0.7789 
2025-01-26 20:59:06.555253: Pseudo dice [np.float32(0.9577), np.float32(0.8865)] 
2025-01-26 20:59:06.557748: Epoch time: 48.58 s 
2025-01-26 20:59:07.759934:  
2025-01-26 20:59:07.763058: Epoch 619 
2025-01-26 20:59:07.766325: Current learning rate: 0.0042 
2025-01-26 20:59:56.373267: train_loss -0.8317 
2025-01-26 20:59:56.379574: val_loss -0.772 
2025-01-26 20:59:56.382246: Pseudo dice [np.float32(0.9531), np.float32(0.8959)] 
2025-01-26 20:59:56.384505: Epoch time: 48.61 s 
2025-01-26 20:59:57.595752:  
2025-01-26 20:59:57.598757: Epoch 620 
2025-01-26 20:59:57.601269: Current learning rate: 0.00419 
2025-01-26 21:00:46.220145: train_loss -0.8194 
2025-01-26 21:00:46.223295: val_loss -0.788 
2025-01-26 21:00:46.225791: Pseudo dice [np.float32(0.9531), np.float32(0.8325)] 
2025-01-26 21:00:46.228218: Epoch time: 48.63 s 
2025-01-26 21:00:47.437686:  
2025-01-26 21:00:47.440776: Epoch 621 
2025-01-26 21:00:47.443356: Current learning rate: 0.00418 
2025-01-26 21:01:35.968523: train_loss -0.818 
2025-01-26 21:01:35.975122: val_loss -0.7836 
2025-01-26 21:01:35.977630: Pseudo dice [np.float32(0.956), np.float32(0.8639)] 
2025-01-26 21:01:35.980114: Epoch time: 48.53 s 
2025-01-26 21:01:37.194327:  
2025-01-26 21:01:37.198994: Epoch 622 
2025-01-26 21:01:37.201978: Current learning rate: 0.00417 
2025-01-26 21:02:26.018673: train_loss -0.8201 
2025-01-26 21:02:26.022398: val_loss -0.7915 
2025-01-26 21:02:26.024973: Pseudo dice [np.float32(0.9516), np.float32(0.8898)] 
2025-01-26 21:02:26.028607: Epoch time: 48.83 s 
2025-01-26 21:02:27.831531:  
2025-01-26 21:02:27.834447: Epoch 623 
2025-01-26 21:02:27.837225: Current learning rate: 0.00416 
2025-01-26 21:03:16.519288: train_loss -0.8201 
2025-01-26 21:03:16.526045: val_loss -0.7811 
2025-01-26 21:03:16.528811: Pseudo dice [np.float32(0.9618), np.float32(0.8812)] 
2025-01-26 21:03:16.531225: Epoch time: 48.69 s 
2025-01-26 21:03:17.750240:  
2025-01-26 21:03:17.753320: Epoch 624 
2025-01-26 21:03:17.756157: Current learning rate: 0.00415 
2025-01-26 21:04:06.224424: train_loss -0.8226 
2025-01-26 21:04:06.227823: val_loss -0.7829 
2025-01-26 21:04:06.230725: Pseudo dice [np.float32(0.9547), np.float32(0.8872)] 
2025-01-26 21:04:06.233273: Epoch time: 48.48 s 
2025-01-26 21:04:07.441138:  
2025-01-26 21:04:07.444105: Epoch 625 
2025-01-26 21:04:07.446898: Current learning rate: 0.00414 
2025-01-26 21:04:55.581408: train_loss -0.8206 
2025-01-26 21:04:55.588313: val_loss -0.7655 
2025-01-26 21:04:55.591134: Pseudo dice [np.float32(0.9449), np.float32(0.784)] 
2025-01-26 21:04:55.593376: Epoch time: 48.14 s 
2025-01-26 21:04:56.804012:  
2025-01-26 21:04:56.807088: Epoch 626 
2025-01-26 21:04:56.809532: Current learning rate: 0.00413 
2025-01-26 21:05:45.529695: train_loss -0.8134 
2025-01-26 21:05:45.533233: val_loss -0.7603 
2025-01-26 21:05:45.536149: Pseudo dice [np.float32(0.9591), np.float32(0.8989)] 
2025-01-26 21:05:45.538645: Epoch time: 48.73 s 
2025-01-26 21:05:46.741140:  
2025-01-26 21:05:46.743871: Epoch 627 
2025-01-26 21:05:46.746423: Current learning rate: 0.00412 
2025-01-26 21:06:35.478932: train_loss -0.8199 
2025-01-26 21:06:35.485752: val_loss -0.7397 
2025-01-26 21:06:35.488205: Pseudo dice [np.float32(0.9573), np.float32(0.816)] 
2025-01-26 21:06:35.490976: Epoch time: 48.74 s 
2025-01-26 21:06:36.818712:  
2025-01-26 21:06:36.821968: Epoch 628 
2025-01-26 21:06:36.824944: Current learning rate: 0.00411 
2025-01-26 21:07:25.175069: train_loss -0.8403 
2025-01-26 21:07:25.178829: val_loss -0.8062 
2025-01-26 21:07:25.181645: Pseudo dice [np.float32(0.96), np.float32(0.8916)] 
2025-01-26 21:07:25.183961: Epoch time: 48.36 s 
2025-01-26 21:07:26.397497:  
2025-01-26 21:07:26.400767: Epoch 629 
2025-01-26 21:07:26.403545: Current learning rate: 0.0041 
2025-01-26 21:08:14.746278: train_loss -0.8348 
2025-01-26 21:08:14.753592: val_loss -0.7731 
2025-01-26 21:08:14.756486: Pseudo dice [np.float32(0.9587), np.float32(0.9139)] 
2025-01-26 21:08:14.758956: Epoch time: 48.35 s 
2025-01-26 21:08:15.972942:  
2025-01-26 21:08:15.975985: Epoch 630 
2025-01-26 21:08:15.978549: Current learning rate: 0.00409 
2025-01-26 21:09:04.425333: train_loss -0.8327 
2025-01-26 21:09:04.428891: val_loss -0.8002 
2025-01-26 21:09:04.432100: Pseudo dice [np.float32(0.9602), np.float32(0.899)] 
2025-01-26 21:09:04.435009: Epoch time: 48.45 s 
2025-01-26 21:09:05.650330:  
2025-01-26 21:09:05.653571: Epoch 631 
2025-01-26 21:09:05.656758: Current learning rate: 0.00408 
2025-01-26 21:09:54.120984: train_loss -0.835 
2025-01-26 21:09:54.129031: val_loss -0.8304 
2025-01-26 21:09:54.131598: Pseudo dice [np.float32(0.9602), np.float32(0.9034)] 
2025-01-26 21:09:54.134266: Epoch time: 48.47 s 
2025-01-26 21:09:55.344887:  
2025-01-26 21:09:55.350784: Epoch 632 
2025-01-26 21:09:55.353310: Current learning rate: 0.00407 
2025-01-26 21:10:43.784303: train_loss -0.8164 
2025-01-26 21:10:43.787967: val_loss -0.7858 
2025-01-26 21:10:43.790781: Pseudo dice [np.float32(0.9509), np.float32(0.8725)] 
2025-01-26 21:10:43.793780: Epoch time: 48.44 s 
2025-01-26 21:10:45.002526:  
2025-01-26 21:10:45.005602: Epoch 633 
2025-01-26 21:10:45.015070: Current learning rate: 0.00406 
2025-01-26 21:11:33.917217: train_loss -0.8237 
2025-01-26 21:11:33.924216: val_loss -0.7529 
2025-01-26 21:11:33.927021: Pseudo dice [np.float32(0.9517), np.float32(0.881)] 
2025-01-26 21:11:33.929877: Epoch time: 48.92 s 
2025-01-26 21:11:35.136889:  
2025-01-26 21:11:35.144297: Epoch 634 
2025-01-26 21:11:35.147274: Current learning rate: 0.00405 
2025-01-26 21:12:23.566977: train_loss -0.8296 
2025-01-26 21:12:23.570114: val_loss -0.7716 
2025-01-26 21:12:23.572603: Pseudo dice [np.float32(0.9556), np.float32(0.8937)] 
2025-01-26 21:12:23.575121: Epoch time: 48.43 s 
2025-01-26 21:12:24.787702:  
2025-01-26 21:12:24.790994: Epoch 635 
2025-01-26 21:12:24.801763: Current learning rate: 0.00404 
2025-01-26 21:13:13.616400: train_loss -0.818 
2025-01-26 21:13:13.622734: val_loss -0.7811 
2025-01-26 21:13:13.625266: Pseudo dice [np.float32(0.9549), np.float32(0.8716)] 
2025-01-26 21:13:13.627838: Epoch time: 48.83 s 
2025-01-26 21:13:14.834138:  
2025-01-26 21:13:14.840821: Epoch 636 
2025-01-26 21:13:14.843812: Current learning rate: 0.00403 
2025-01-26 21:14:03.442961: train_loss -0.8154 
2025-01-26 21:14:03.446797: val_loss -0.7901 
2025-01-26 21:14:03.449631: Pseudo dice [np.float32(0.9575), np.float32(0.9069)] 
2025-01-26 21:14:03.452342: Epoch time: 48.61 s 
2025-01-26 21:14:04.662724:  
2025-01-26 21:14:04.665781: Epoch 637 
2025-01-26 21:14:04.676118: Current learning rate: 0.00402 
2025-01-26 21:14:53.059577: train_loss -0.8432 
2025-01-26 21:14:53.066637: val_loss -0.7632 
2025-01-26 21:14:53.071692: Pseudo dice [np.float32(0.956), np.float32(0.8877)] 
2025-01-26 21:14:53.074419: Epoch time: 48.4 s 
2025-01-26 21:14:54.285354:  
2025-01-26 21:14:54.288951: Epoch 638 
2025-01-26 21:14:54.298632: Current learning rate: 0.00401 
2025-01-26 21:15:42.702462: train_loss -0.8286 
2025-01-26 21:15:42.705874: val_loss -0.779 
2025-01-26 21:15:42.708964: Pseudo dice [np.float32(0.9581), np.float32(0.8671)] 
2025-01-26 21:15:42.711495: Epoch time: 48.42 s 
2025-01-26 21:15:43.917207:  
2025-01-26 21:15:43.924705: Epoch 639 
2025-01-26 21:15:43.928044: Current learning rate: 0.004 
2025-01-26 21:16:32.739955: train_loss -0.827 
2025-01-26 21:16:32.747074: val_loss -0.7665 
2025-01-26 21:16:32.749907: Pseudo dice [np.float32(0.9521), np.float32(0.8404)] 
2025-01-26 21:16:32.752673: Epoch time: 48.82 s 
2025-01-26 21:16:33.967619:  
2025-01-26 21:16:33.970530: Epoch 640 
2025-01-26 21:16:33.979826: Current learning rate: 0.00399 
2025-01-26 21:17:22.363728: train_loss -0.8458 
2025-01-26 21:17:22.367399: val_loss -0.8018 
2025-01-26 21:17:22.370569: Pseudo dice [np.float32(0.957), np.float32(0.9143)] 
2025-01-26 21:17:22.373028: Epoch time: 48.4 s 
2025-01-26 21:17:24.140651:  
2025-01-26 21:17:24.147459: Epoch 641 
2025-01-26 21:17:24.150480: Current learning rate: 0.00398 
2025-01-26 21:18:12.356925: train_loss -0.8262 
2025-01-26 21:18:12.363338: val_loss -0.7741 
2025-01-26 21:18:12.366030: Pseudo dice [np.float32(0.9556), np.float32(0.9)] 
2025-01-26 21:18:12.368631: Epoch time: 48.22 s 
2025-01-26 21:18:13.571877:  
2025-01-26 21:18:13.575016: Epoch 642 
2025-01-26 21:18:13.583872: Current learning rate: 0.00397 
2025-01-26 21:19:02.084751: train_loss -0.8211 
2025-01-26 21:19:02.088517: val_loss -0.7733 
2025-01-26 21:19:02.091373: Pseudo dice [np.float32(0.953), np.float32(0.8987)] 
2025-01-26 21:19:02.094310: Epoch time: 48.51 s 
2025-01-26 21:19:03.295788:  
2025-01-26 21:19:03.298907: Epoch 643 
2025-01-26 21:19:03.307962: Current learning rate: 0.00396 
2025-01-26 21:19:51.965514: train_loss -0.8354 
2025-01-26 21:19:51.972246: val_loss -0.8009 
2025-01-26 21:19:51.975239: Pseudo dice [np.float32(0.9638), np.float32(0.9045)] 
2025-01-26 21:19:51.977801: Epoch time: 48.67 s 
2025-01-26 21:19:53.186354:  
2025-01-26 21:19:53.189563: Epoch 644 
2025-01-26 21:19:53.199620: Current learning rate: 0.00395 
2025-01-26 21:20:42.281906: train_loss -0.8257 
2025-01-26 21:20:42.285396: val_loss -0.7831 
2025-01-26 21:20:42.288371: Pseudo dice [np.float32(0.9619), np.float32(0.9089)] 
2025-01-26 21:20:42.291205: Epoch time: 49.1 s 
2025-01-26 21:20:43.505747:  
2025-01-26 21:20:43.513504: Epoch 645 
2025-01-26 21:20:43.516520: Current learning rate: 0.00394 
2025-01-26 21:21:32.022429: train_loss -0.8207 
2025-01-26 21:21:32.029768: val_loss -0.7734 
2025-01-26 21:21:32.032682: Pseudo dice [np.float32(0.9589), np.float32(0.8848)] 
2025-01-26 21:21:32.035378: Epoch time: 48.52 s 
2025-01-26 21:21:33.246135:  
2025-01-26 21:21:33.249346: Epoch 646 
2025-01-26 21:21:33.259291: Current learning rate: 0.00393 
2025-01-26 21:22:21.717476: train_loss -0.8266 
2025-01-26 21:22:21.720923: val_loss -0.7385 
2025-01-26 21:22:21.723614: Pseudo dice [np.float32(0.9536), np.float32(0.8817)] 
2025-01-26 21:22:21.726099: Epoch time: 48.47 s 
2025-01-26 21:22:22.935721:  
2025-01-26 21:22:22.938898: Epoch 647 
2025-01-26 21:22:22.948781: Current learning rate: 0.00392 
2025-01-26 21:23:11.616937: train_loss -0.8253 
2025-01-26 21:23:11.623137: val_loss -0.7576 
2025-01-26 21:23:11.626231: Pseudo dice [np.float32(0.9623), np.float32(0.9032)] 
2025-01-26 21:23:11.628470: Epoch time: 48.68 s 
2025-01-26 21:23:12.830227:  
2025-01-26 21:23:12.833660: Epoch 648 
2025-01-26 21:23:12.843214: Current learning rate: 0.00391 
2025-01-26 21:24:01.863569: train_loss -0.8193 
2025-01-26 21:24:01.867551: val_loss -0.7999 
2025-01-26 21:24:01.870954: Pseudo dice [np.float32(0.9544), np.float32(0.9013)] 
2025-01-26 21:24:01.873785: Epoch time: 49.03 s 
2025-01-26 21:24:03.091681:  
2025-01-26 21:24:03.098246: Epoch 649 
2025-01-26 21:24:03.100867: Current learning rate: 0.0039 
2025-01-26 21:24:51.562039: train_loss -0.8486 
2025-01-26 21:24:51.568084: val_loss -0.7613 
2025-01-26 21:24:51.570620: Pseudo dice [np.float32(0.9597), np.float32(0.8995)] 
2025-01-26 21:24:51.573261: Epoch time: 48.47 s 
2025-01-26 21:24:53.364822:  
2025-01-26 21:24:53.367798: Epoch 650 
2025-01-26 21:24:53.376915: Current learning rate: 0.00389 
2025-01-26 21:25:41.985642: train_loss -0.8334 
2025-01-26 21:25:41.988991: val_loss -0.7943 
2025-01-26 21:25:41.991786: Pseudo dice [np.float32(0.9607), np.float32(0.9091)] 
2025-01-26 21:25:41.994497: Epoch time: 48.62 s 
2025-01-26 21:25:43.213394:  
2025-01-26 21:25:43.216620: Epoch 651 
2025-01-26 21:25:43.225704: Current learning rate: 0.00388 
2025-01-26 21:26:31.808171: train_loss -0.8479 
2025-01-26 21:26:31.814102: val_loss -0.7739 
2025-01-26 21:26:31.816842: Pseudo dice [np.float32(0.9609), np.float32(0.8844)] 
2025-01-26 21:26:31.819489: Epoch time: 48.6 s 
2025-01-26 21:26:33.022413:  
2025-01-26 21:26:33.025548: Epoch 652 
2025-01-26 21:26:33.034171: Current learning rate: 0.00387 
2025-01-26 21:27:21.232357: train_loss -0.8344 
2025-01-26 21:27:21.235679: val_loss -0.7871 
2025-01-26 21:27:21.238088: Pseudo dice [np.float32(0.9609), np.float32(0.9064)] 
2025-01-26 21:27:21.240701: Epoch time: 48.21 s 
2025-01-26 21:27:22.446461:  
2025-01-26 21:27:22.449689: Epoch 653 
2025-01-26 21:27:22.458108: Current learning rate: 0.00386 
2025-01-26 21:28:11.106764: train_loss -0.8355 
2025-01-26 21:28:11.113830: val_loss -0.7732 
2025-01-26 21:28:11.118101: Pseudo dice [np.float32(0.9599), np.float32(0.8962)] 
2025-01-26 21:28:11.121272: Epoch time: 48.66 s 
2025-01-26 21:28:12.333685:  
2025-01-26 21:28:12.337404: Epoch 654 
2025-01-26 21:28:12.340351: Current learning rate: 0.00385 
2025-01-26 21:29:01.188064: train_loss -0.8423 
2025-01-26 21:29:01.192677: val_loss -0.7852 
2025-01-26 21:29:01.195994: Pseudo dice [np.float32(0.9625), np.float32(0.9057)] 
2025-01-26 21:29:01.199210: Epoch time: 48.86 s 
2025-01-26 21:29:02.450756:  
2025-01-26 21:29:02.454107: Epoch 655 
2025-01-26 21:29:02.461979: Current learning rate: 0.00384 
2025-01-26 21:29:51.102829: train_loss -0.8356 
2025-01-26 21:29:51.109619: val_loss -0.7703 
2025-01-26 21:29:51.112565: Pseudo dice [np.float32(0.9631), np.float32(0.8924)] 
2025-01-26 21:29:51.115047: Epoch time: 48.65 s 
2025-01-26 21:29:52.334417:  
2025-01-26 21:29:52.337625: Epoch 656 
2025-01-26 21:29:52.346209: Current learning rate: 0.00383 
2025-01-26 21:30:40.847929: train_loss -0.8389 
2025-01-26 21:30:40.851567: val_loss -0.784 
2025-01-26 21:30:40.854625: Pseudo dice [np.float32(0.9609), np.float32(0.8992)] 
2025-01-26 21:30:40.857560: Epoch time: 48.51 s 
2025-01-26 21:30:42.049883:  
2025-01-26 21:30:42.053133: Epoch 657 
2025-01-26 21:30:42.062286: Current learning rate: 0.00382 
2025-01-26 21:31:30.694331: train_loss -0.8346 
2025-01-26 21:31:30.701531: val_loss -0.7685 
2025-01-26 21:31:30.704395: Pseudo dice [np.float32(0.9606), np.float32(0.8911)] 
2025-01-26 21:31:30.707271: Epoch time: 48.65 s 
2025-01-26 21:31:31.920354:  
2025-01-26 21:31:31.923239: Epoch 658 
2025-01-26 21:31:31.931172: Current learning rate: 0.00381 
2025-01-26 21:32:20.439399: train_loss -0.8304 
2025-01-26 21:32:20.443793: val_loss -0.795 
2025-01-26 21:32:20.447465: Pseudo dice [np.float32(0.9596), np.float32(0.8992)] 
2025-01-26 21:32:20.450392: Epoch time: 48.52 s 
2025-01-26 21:32:21.648674:  
2025-01-26 21:32:21.654845: Epoch 659 
2025-01-26 21:32:21.657687: Current learning rate: 0.0038 
2025-01-26 21:33:10.467300: train_loss -0.8137 
2025-01-26 21:33:10.474879: val_loss -0.7556 
2025-01-26 21:33:10.477863: Pseudo dice [np.float32(0.9605), np.float32(0.8779)] 
2025-01-26 21:33:10.480987: Epoch time: 48.82 s 
2025-01-26 21:33:12.319623:  
2025-01-26 21:33:12.322779: Epoch 660 
2025-01-26 21:33:12.330708: Current learning rate: 0.00379 
2025-01-26 21:34:00.575676: train_loss -0.8264 
2025-01-26 21:34:00.579710: val_loss -0.7676 
2025-01-26 21:34:00.583043: Pseudo dice [np.float32(0.9543), np.float32(0.8588)] 
2025-01-26 21:34:00.586079: Epoch time: 48.26 s 
2025-01-26 21:34:01.780640:  
2025-01-26 21:34:01.783285: Epoch 661 
2025-01-26 21:34:01.791178: Current learning rate: 0.00378 
2025-01-26 21:34:50.291221: train_loss -0.8328 
2025-01-26 21:34:50.297305: val_loss -0.785 
2025-01-26 21:34:50.299911: Pseudo dice [np.float32(0.9595), np.float32(0.8831)] 
2025-01-26 21:34:50.302680: Epoch time: 48.51 s 
2025-01-26 21:34:51.505002:  
2025-01-26 21:34:51.508389: Epoch 662 
2025-01-26 21:34:51.517831: Current learning rate: 0.00377 
2025-01-26 21:35:40.105850: train_loss -0.849 
2025-01-26 21:35:40.109997: val_loss -0.7817 
2025-01-26 21:35:40.113130: Pseudo dice [np.float32(0.9639), np.float32(0.9033)] 
2025-01-26 21:35:40.116045: Epoch time: 48.6 s 
2025-01-26 21:35:41.314053:  
2025-01-26 21:35:41.317243: Epoch 663 
2025-01-26 21:35:41.325474: Current learning rate: 0.00376 
2025-01-26 21:36:29.543426: train_loss -0.834 
2025-01-26 21:36:29.550015: val_loss -0.7933 
2025-01-26 21:36:29.552751: Pseudo dice [np.float32(0.9605), np.float32(0.895)] 
2025-01-26 21:36:29.555601: Epoch time: 48.23 s 
2025-01-26 21:36:30.790637:  
2025-01-26 21:36:30.797194: Epoch 664 
2025-01-26 21:36:30.799826: Current learning rate: 0.00375 
2025-01-26 21:37:18.990001: train_loss -0.8382 
2025-01-26 21:37:18.993781: val_loss -0.8204 
2025-01-26 21:37:18.996706: Pseudo dice [np.float32(0.9627), np.float32(0.9092)] 
2025-01-26 21:37:18.999737: Epoch time: 48.2 s 
2025-01-26 21:37:20.235401:  
2025-01-26 21:37:20.238261: Epoch 665 
2025-01-26 21:37:20.246604: Current learning rate: 0.00374 
2025-01-26 21:38:08.740464: train_loss -0.832 
2025-01-26 21:38:08.746888: val_loss -0.7983 
2025-01-26 21:38:08.749315: Pseudo dice [np.float32(0.9571), np.float32(0.8901)] 
2025-01-26 21:38:08.752085: Epoch time: 48.51 s 
2025-01-26 21:38:09.951513:  
2025-01-26 21:38:09.954107: Epoch 666 
2025-01-26 21:38:09.961843: Current learning rate: 0.00373 
2025-01-26 21:38:58.304289: train_loss -0.8119 
2025-01-26 21:38:58.308048: val_loss -0.7523 
2025-01-26 21:38:58.311013: Pseudo dice [np.float32(0.9569), np.float32(0.8964)] 
2025-01-26 21:38:58.313843: Epoch time: 48.35 s 
2025-01-26 21:38:59.524393:  
2025-01-26 21:38:59.527255: Epoch 667 
2025-01-26 21:38:59.536119: Current learning rate: 0.00372 
2025-01-26 21:39:47.666810: train_loss -0.828 
2025-01-26 21:39:47.674561: val_loss -0.8185 
2025-01-26 21:39:47.677430: Pseudo dice [np.float32(0.9544), np.float32(0.9123)] 
2025-01-26 21:39:47.680009: Epoch time: 48.14 s 
2025-01-26 21:39:48.894440:  
2025-01-26 21:39:48.897455: Epoch 668 
2025-01-26 21:39:48.900216: Current learning rate: 0.00371 
2025-01-26 21:40:37.839528: train_loss -0.8347 
2025-01-26 21:40:37.842953: val_loss -0.7916 
2025-01-26 21:40:37.845846: Pseudo dice [np.float32(0.961), np.float32(0.9143)] 
2025-01-26 21:40:37.848755: Epoch time: 48.95 s 
2025-01-26 21:40:39.102715:  
2025-01-26 21:40:39.107754: Epoch 669 
2025-01-26 21:40:39.110839: Current learning rate: 0.0037 
2025-01-26 21:41:27.935637: train_loss -0.8259 
2025-01-26 21:41:27.942967: val_loss -0.7724 
2025-01-26 21:41:27.945805: Pseudo dice [np.float32(0.9562), np.float32(0.8828)] 
2025-01-26 21:41:27.948737: Epoch time: 48.83 s 
2025-01-26 21:41:29.164626:  
2025-01-26 21:41:29.167603: Epoch 670 
2025-01-26 21:41:29.175716: Current learning rate: 0.00369 
2025-01-26 21:42:17.590821: train_loss -0.8369 
2025-01-26 21:42:17.594583: val_loss -0.7511 
2025-01-26 21:42:17.597493: Pseudo dice [np.float32(0.9584), np.float32(0.897)] 
2025-01-26 21:42:17.600518: Epoch time: 48.43 s 
2025-01-26 21:42:18.808068:  
2025-01-26 21:42:18.810838: Epoch 671 
2025-01-26 21:42:18.819205: Current learning rate: 0.00368 
2025-01-26 21:43:07.431304: train_loss -0.8274 
2025-01-26 21:43:07.437755: val_loss -0.7635 
2025-01-26 21:43:07.440508: Pseudo dice [np.float32(0.9545), np.float32(0.8707)] 
2025-01-26 21:43:07.443000: Epoch time: 48.62 s 
2025-01-26 21:43:08.654378:  
2025-01-26 21:43:08.657530: Epoch 672 
2025-01-26 21:43:08.664749: Current learning rate: 0.00367 
2025-01-26 21:43:57.356776: train_loss -0.8377 
2025-01-26 21:43:57.360799: val_loss -0.8187 
2025-01-26 21:43:57.363975: Pseudo dice [np.float32(0.9598), np.float32(0.8923)] 
2025-01-26 21:43:57.367180: Epoch time: 48.7 s 
2025-01-26 21:43:58.588716:  
2025-01-26 21:43:58.595062: Epoch 673 
2025-01-26 21:43:58.598072: Current learning rate: 0.00366 
2025-01-26 21:44:46.968149: train_loss -0.8372 
2025-01-26 21:44:46.975026: val_loss -0.7765 
2025-01-26 21:44:46.978076: Pseudo dice [np.float32(0.9568), np.float32(0.8635)] 
2025-01-26 21:44:46.981088: Epoch time: 48.38 s 
2025-01-26 21:44:48.194855:  
2025-01-26 21:44:48.198160: Epoch 674 
2025-01-26 21:44:48.206694: Current learning rate: 0.00365 
2025-01-26 21:45:36.617998: train_loss -0.8249 
2025-01-26 21:45:36.621701: val_loss -0.7503 
2025-01-26 21:45:36.624563: Pseudo dice [np.float32(0.9574), np.float32(0.8696)] 
2025-01-26 21:45:36.627083: Epoch time: 48.42 s 
2025-01-26 21:45:37.879629:  
2025-01-26 21:45:37.882348: Epoch 675 
2025-01-26 21:45:37.891506: Current learning rate: 0.00364 
2025-01-26 21:46:26.619462: train_loss -0.8249 
2025-01-26 21:46:26.626527: val_loss -0.777 
2025-01-26 21:46:26.629587: Pseudo dice [np.float32(0.9566), np.float32(0.8842)] 
2025-01-26 21:46:26.632552: Epoch time: 48.74 s 
2025-01-26 21:46:27.852947:  
2025-01-26 21:46:27.856275: Epoch 676 
2025-01-26 21:46:27.864848: Current learning rate: 0.00363 
2025-01-26 21:47:16.362859: train_loss -0.8388 
2025-01-26 21:47:16.366345: val_loss -0.763 
2025-01-26 21:47:16.369351: Pseudo dice [np.float32(0.9597), np.float32(0.9027)] 
2025-01-26 21:47:16.372179: Epoch time: 48.51 s 
2025-01-26 21:47:17.600808:  
2025-01-26 21:47:17.605725: Epoch 677 
2025-01-26 21:47:17.608609: Current learning rate: 0.00362 
2025-01-26 21:48:06.059727: train_loss -0.8334 
2025-01-26 21:48:06.066520: val_loss -0.7868 
2025-01-26 21:48:06.069605: Pseudo dice [np.float32(0.9595), np.float32(0.879)] 
2025-01-26 21:48:06.077415: Epoch time: 48.46 s 
2025-01-26 21:48:07.914879:  
2025-01-26 21:48:07.918213: Epoch 678 
2025-01-26 21:48:07.926167: Current learning rate: 0.00361 
2025-01-26 21:48:56.461135: train_loss -0.8515 
2025-01-26 21:48:56.465459: val_loss -0.8018 
2025-01-26 21:48:56.468475: Pseudo dice [np.float32(0.9583), np.float32(0.9119)] 
2025-01-26 21:48:56.471204: Epoch time: 48.55 s 
2025-01-26 21:48:57.686115:  
2025-01-26 21:48:57.691795: Epoch 679 
2025-01-26 21:48:57.694545: Current learning rate: 0.0036 
2025-01-26 21:49:46.114678: train_loss -0.8296 
2025-01-26 21:49:46.121332: val_loss -0.7731 
2025-01-26 21:49:46.123564: Pseudo dice [np.float32(0.9636), np.float32(0.9072)] 
2025-01-26 21:49:46.126309: Epoch time: 48.43 s 
2025-01-26 21:49:47.340111:  
2025-01-26 21:49:47.344359: Epoch 680 
2025-01-26 21:49:47.351919: Current learning rate: 0.00359 
2025-01-26 21:50:36.413236: train_loss -0.8388 
2025-01-26 21:50:36.416952: val_loss -0.8118 
2025-01-26 21:50:36.419843: Pseudo dice [np.float32(0.9566), np.float32(0.8847)] 
2025-01-26 21:50:36.422587: Epoch time: 49.07 s 
2025-01-26 21:50:37.638659:  
2025-01-26 21:50:37.641742: Epoch 681 
2025-01-26 21:50:37.650426: Current learning rate: 0.00358 
2025-01-26 21:51:25.971096: train_loss -0.845 
2025-01-26 21:51:25.977895: val_loss -0.7868 
2025-01-26 21:51:25.980750: Pseudo dice [np.float32(0.9617), np.float32(0.8866)] 
2025-01-26 21:51:25.983389: Epoch time: 48.33 s 
2025-01-26 21:51:27.196126:  
2025-01-26 21:51:27.201523: Epoch 682 
2025-01-26 21:51:27.204789: Current learning rate: 0.00357 
2025-01-26 21:52:16.050992: train_loss -0.8408 
2025-01-26 21:52:16.054240: val_loss -0.7965 
2025-01-26 21:52:16.056862: Pseudo dice [np.float32(0.9603), np.float32(0.8993)] 
2025-01-26 21:52:16.059639: Epoch time: 48.86 s 
2025-01-26 21:52:17.293721:  
2025-01-26 21:52:17.296798: Epoch 683 
2025-01-26 21:52:17.305339: Current learning rate: 0.00356 
2025-01-26 21:53:05.978788: train_loss -0.8311 
2025-01-26 21:53:05.984926: val_loss -0.8187 
2025-01-26 21:53:05.987484: Pseudo dice [np.float32(0.9664), np.float32(0.9064)] 
2025-01-26 21:53:05.989856: Epoch time: 48.69 s 
2025-01-26 21:53:07.243352:  
2025-01-26 21:53:07.249099: Epoch 684 
2025-01-26 21:53:07.251689: Current learning rate: 0.00355 
2025-01-26 21:53:55.480608: train_loss -0.8248 
2025-01-26 21:53:55.486517: val_loss -0.8062 
2025-01-26 21:53:55.489359: Pseudo dice [np.float32(0.9578), np.float32(0.9078)] 
2025-01-26 21:53:55.492126: Epoch time: 48.24 s 
2025-01-26 21:53:56.750426:  
2025-01-26 21:53:56.753559: Epoch 685 
2025-01-26 21:53:56.762044: Current learning rate: 0.00354 
2025-01-26 21:54:45.328985: train_loss -0.8275 
2025-01-26 21:54:45.335704: val_loss -0.8014 
2025-01-26 21:54:45.338888: Pseudo dice [np.float32(0.9617), np.float32(0.9074)] 
2025-01-26 21:54:45.341640: Epoch time: 48.58 s 
2025-01-26 21:54:46.568925:  
2025-01-26 21:54:46.576081: Epoch 686 
2025-01-26 21:54:46.578956: Current learning rate: 0.00353 
2025-01-26 21:55:34.781136: train_loss -0.848 
2025-01-26 21:55:34.785078: val_loss -0.7598 
2025-01-26 21:55:34.788210: Pseudo dice [np.float32(0.9569), np.float32(0.8943)] 
2025-01-26 21:55:34.791195: Epoch time: 48.21 s 
2025-01-26 21:55:36.052147:  
2025-01-26 21:55:36.055040: Epoch 687 
2025-01-26 21:55:36.063683: Current learning rate: 0.00352 
2025-01-26 21:56:24.644088: train_loss -0.8521 
2025-01-26 21:56:24.651392: val_loss -0.8007 
2025-01-26 21:56:24.654363: Pseudo dice [np.float32(0.9593), np.float32(0.9125)] 
2025-01-26 21:56:24.657346: Epoch time: 48.59 s 
2025-01-26 21:56:25.914845:  
2025-01-26 21:56:25.917922: Epoch 688 
2025-01-26 21:56:25.925246: Current learning rate: 0.00351 
2025-01-26 21:57:14.872613: train_loss -0.8151 
2025-01-26 21:57:14.876647: val_loss -0.7786 
2025-01-26 21:57:14.879192: Pseudo dice [np.float32(0.9522), np.float32(0.8601)] 
2025-01-26 21:57:14.881969: Epoch time: 48.96 s 
2025-01-26 21:57:16.087837:  
2025-01-26 21:57:16.090883: Epoch 689 
2025-01-26 21:57:16.099540: Current learning rate: 0.0035 
2025-01-26 21:58:04.670132: train_loss -0.8313 
2025-01-26 21:58:04.678133: val_loss -0.7732 
2025-01-26 21:58:04.681425: Pseudo dice [np.float32(0.9595), np.float32(0.8963)] 
2025-01-26 21:58:04.684941: Epoch time: 48.58 s 
2025-01-26 21:58:05.945022:  
2025-01-26 21:58:05.947685: Epoch 690 
2025-01-26 21:58:05.956174: Current learning rate: 0.00349 
2025-01-26 21:58:54.256711: train_loss -0.8229 
2025-01-26 21:58:54.260337: val_loss -0.7886 
2025-01-26 21:58:54.263725: Pseudo dice [np.float32(0.9591), np.float32(0.9007)] 
2025-01-26 21:58:54.266970: Epoch time: 48.31 s 
2025-01-26 21:58:55.482693:  
2025-01-26 21:58:55.487348: Epoch 691 
2025-01-26 21:58:55.489990: Current learning rate: 0.00348 
2025-01-26 21:59:43.935116: train_loss -0.83 
2025-01-26 21:59:43.942018: val_loss -0.7673 
2025-01-26 21:59:43.944818: Pseudo dice [np.float32(0.9607), np.float32(0.8948)] 
2025-01-26 21:59:43.947555: Epoch time: 48.45 s 
2025-01-26 21:59:45.165899:  
2025-01-26 21:59:45.168657: Epoch 692 
2025-01-26 21:59:45.175131: Current learning rate: 0.00346 
2025-01-26 22:00:33.760841: train_loss -0.8374 
2025-01-26 22:00:33.764590: val_loss -0.829 
2025-01-26 22:00:33.767401: Pseudo dice [np.float32(0.9602), np.float32(0.9193)] 
2025-01-26 22:00:33.770131: Epoch time: 48.6 s 
2025-01-26 22:00:35.034774:  
2025-01-26 22:00:35.037897: Epoch 693 
2025-01-26 22:00:35.046013: Current learning rate: 0.00345 
2025-01-26 22:01:23.549332: train_loss -0.8286 
2025-01-26 22:01:23.555867: val_loss -0.7516 
2025-01-26 22:01:23.558608: Pseudo dice [np.float32(0.9608), np.float32(0.8952)] 
2025-01-26 22:01:23.561218: Epoch time: 48.52 s 
2025-01-26 22:01:24.778250:  
2025-01-26 22:01:24.784276: Epoch 694 
2025-01-26 22:01:24.787341: Current learning rate: 0.00344 
2025-01-26 22:02:13.175916: train_loss -0.8482 
2025-01-26 22:02:13.179241: val_loss -0.8087 
2025-01-26 22:02:13.181919: Pseudo dice [np.float32(0.9652), np.float32(0.8942)] 
2025-01-26 22:02:13.184812: Epoch time: 48.4 s 
2025-01-26 22:02:14.391494:  
2025-01-26 22:02:14.397531: Epoch 695 
2025-01-26 22:02:14.400532: Current learning rate: 0.00343 
2025-01-26 22:03:02.984976: train_loss -0.8151 
2025-01-26 22:03:02.991621: val_loss -0.7798 
2025-01-26 22:03:02.994527: Pseudo dice [np.float32(0.9551), np.float32(0.8886)] 
2025-01-26 22:03:02.997284: Epoch time: 48.59 s 
2025-01-26 22:03:04.207295:  
2025-01-26 22:03:04.210240: Epoch 696 
2025-01-26 22:03:04.219383: Current learning rate: 0.00342 
2025-01-26 22:03:52.810672: train_loss -0.8275 
2025-01-26 22:03:52.814399: val_loss -0.7638 
2025-01-26 22:03:52.817287: Pseudo dice [np.float32(0.9624), np.float32(0.8851)] 
2025-01-26 22:03:52.819983: Epoch time: 48.6 s 
2025-01-26 22:03:54.038858:  
2025-01-26 22:03:54.041785: Epoch 697 
2025-01-26 22:03:54.049593: Current learning rate: 0.00341 
2025-01-26 22:04:43.083984: train_loss -0.852 
2025-01-26 22:04:43.090501: val_loss -0.7958 
2025-01-26 22:04:43.093014: Pseudo dice [np.float32(0.9551), np.float32(0.8869)] 
2025-01-26 22:04:43.095826: Epoch time: 49.05 s 
2025-01-26 22:04:44.320710:  
2025-01-26 22:04:44.327167: Epoch 698 
2025-01-26 22:04:44.330007: Current learning rate: 0.0034 
2025-01-26 22:05:32.880868: train_loss -0.8362 
2025-01-26 22:05:32.884845: val_loss -0.7677 
2025-01-26 22:05:32.887861: Pseudo dice [np.float32(0.9592), np.float32(0.8926)] 
2025-01-26 22:05:32.890933: Epoch time: 48.56 s 
2025-01-26 22:05:34.145318:  
2025-01-26 22:05:34.148710: Epoch 699 
2025-01-26 22:05:34.157662: Current learning rate: 0.00339 
2025-01-26 22:06:22.954749: train_loss -0.8277 
2025-01-26 22:06:22.961743: val_loss -0.7741 
2025-01-26 22:06:22.964657: Pseudo dice [np.float32(0.9586), np.float32(0.8975)] 
2025-01-26 22:06:22.967433: Epoch time: 48.81 s 
2025-01-26 22:06:24.857575:  
2025-01-26 22:06:24.862310: Epoch 700 
2025-01-26 22:06:24.865014: Current learning rate: 0.00338 
2025-01-26 22:07:13.202471: train_loss -0.838 
2025-01-26 22:07:13.205409: val_loss -0.7534 
2025-01-26 22:07:13.208288: Pseudo dice [np.float32(0.9518), np.float32(0.8412)] 
2025-01-26 22:07:13.210946: Epoch time: 48.35 s 
2025-01-26 22:07:14.424424:  
2025-01-26 22:07:14.427639: Epoch 701 
2025-01-26 22:07:14.436823: Current learning rate: 0.00337 
2025-01-26 22:08:03.139573: train_loss -0.8171 
2025-01-26 22:08:03.145755: val_loss -0.8249 
2025-01-26 22:08:03.148572: Pseudo dice [np.float32(0.9556), np.float32(0.8881)] 
2025-01-26 22:08:03.151149: Epoch time: 48.72 s 
2025-01-26 22:08:04.365113:  
2025-01-26 22:08:04.368263: Epoch 702 
2025-01-26 22:08:04.377363: Current learning rate: 0.00336 
2025-01-26 22:08:52.889626: train_loss -0.8077 
2025-01-26 22:08:52.895648: val_loss -0.7924 
2025-01-26 22:08:52.898271: Pseudo dice [np.float32(0.9628), np.float32(0.8801)] 
2025-01-26 22:08:52.900682: Epoch time: 48.53 s 
2025-01-26 22:08:54.109395:  
2025-01-26 22:08:54.112231: Epoch 703 
2025-01-26 22:08:54.119524: Current learning rate: 0.00335 
2025-01-26 22:09:42.617008: train_loss -0.8262 
2025-01-26 22:09:42.623912: val_loss -0.7864 
2025-01-26 22:09:42.626734: Pseudo dice [np.float32(0.9616), np.float32(0.9041)] 
2025-01-26 22:09:42.629796: Epoch time: 48.51 s 
2025-01-26 22:09:43.883639:  
2025-01-26 22:09:43.889769: Epoch 704 
2025-01-26 22:09:43.892581: Current learning rate: 0.00334 
2025-01-26 22:10:32.417512: train_loss -0.8261 
2025-01-26 22:10:32.422592: val_loss -0.7821 
2025-01-26 22:10:32.425212: Pseudo dice [np.float32(0.964), np.float32(0.8996)] 
2025-01-26 22:10:32.427639: Epoch time: 48.53 s 
2025-01-26 22:10:33.652452:  
2025-01-26 22:10:33.656506: Epoch 705 
2025-01-26 22:10:33.659315: Current learning rate: 0.00333 
2025-01-26 22:11:21.804807: train_loss -0.8307 
2025-01-26 22:11:21.811574: val_loss -0.7641 
2025-01-26 22:11:21.815323: Pseudo dice [np.float32(0.9558), np.float32(0.8974)] 
2025-01-26 22:11:21.817935: Epoch time: 48.15 s 
2025-01-26 22:11:23.041815:  
2025-01-26 22:11:23.044574: Epoch 706 
2025-01-26 22:11:23.053293: Current learning rate: 0.00332 
2025-01-26 22:12:11.455066: train_loss -0.8091 
2025-01-26 22:12:11.458815: val_loss -0.7927 
2025-01-26 22:12:11.461545: Pseudo dice [np.float32(0.9656), np.float32(0.9074)] 
2025-01-26 22:12:11.464566: Epoch time: 48.41 s 
2025-01-26 22:12:12.676214:  
2025-01-26 22:12:12.679204: Epoch 707 
2025-01-26 22:12:12.687922: Current learning rate: 0.00331 
2025-01-26 22:13:01.215962: train_loss -0.8427 
2025-01-26 22:13:01.223964: val_loss -0.8036 
2025-01-26 22:13:01.226821: Pseudo dice [np.float32(0.9612), np.float32(0.9107)] 
2025-01-26 22:13:01.229765: Epoch time: 48.54 s 
2025-01-26 22:13:02.473898:  
2025-01-26 22:13:02.480304: Epoch 708 
2025-01-26 22:13:02.483447: Current learning rate: 0.0033 
2025-01-26 22:13:50.665666: train_loss -0.8274 
2025-01-26 22:13:50.671870: val_loss -0.8016 
2025-01-26 22:13:50.674806: Pseudo dice [np.float32(0.9646), np.float32(0.9106)] 
2025-01-26 22:13:50.677509: Epoch time: 48.19 s 
2025-01-26 22:13:51.910898:  
2025-01-26 22:13:51.918378: Epoch 709 
2025-01-26 22:13:51.921286: Current learning rate: 0.00329 
2025-01-26 22:14:40.782135: train_loss -0.8205 
2025-01-26 22:14:40.788916: val_loss -0.7961 
2025-01-26 22:14:40.791348: Pseudo dice [np.float32(0.9548), np.float32(0.9071)] 
2025-01-26 22:14:40.794195: Epoch time: 48.87 s 
2025-01-26 22:14:42.022974:  
2025-01-26 22:14:42.025879: Epoch 710 
2025-01-26 22:14:42.035574: Current learning rate: 0.00328 
2025-01-26 22:15:30.499053: train_loss -0.8382 
2025-01-26 22:15:30.504414: val_loss -0.8228 
2025-01-26 22:15:30.507304: Pseudo dice [np.float32(0.9591), np.float32(0.9128)] 
2025-01-26 22:15:30.510051: Epoch time: 48.48 s 
2025-01-26 22:15:31.765913:  
2025-01-26 22:15:31.768672: Epoch 711 
2025-01-26 22:15:31.777662: Current learning rate: 0.00327 
2025-01-26 22:16:20.420692: train_loss -0.8283 
2025-01-26 22:16:20.436466: val_loss -0.7917 
2025-01-26 22:16:20.442021: Pseudo dice [np.float32(0.9573), np.float32(0.9179)] 
2025-01-26 22:16:20.446096: Epoch time: 48.66 s 
2025-01-26 22:16:21.689656:  
2025-01-26 22:16:21.692499: Epoch 712 
2025-01-26 22:16:21.700127: Current learning rate: 0.00326 
2025-01-26 22:17:10.273046: train_loss -0.8224 
2025-01-26 22:17:10.276711: val_loss -0.7984 
2025-01-26 22:17:10.279521: Pseudo dice [np.float32(0.9571), np.float32(0.9038)] 
2025-01-26 22:17:10.282361: Epoch time: 48.58 s 
2025-01-26 22:17:11.539875:  
2025-01-26 22:17:11.545479: Epoch 713 
2025-01-26 22:17:11.548316: Current learning rate: 0.00325 
2025-01-26 22:17:59.804369: train_loss -0.8251 
2025-01-26 22:17:59.824321: val_loss -0.8161 
2025-01-26 22:17:59.827162: Pseudo dice [np.float32(0.9631), np.float32(0.8922)] 
2025-01-26 22:17:59.830095: Epoch time: 48.27 s 
2025-01-26 22:18:01.635047:  
2025-01-26 22:18:01.637960: Epoch 714 
2025-01-26 22:18:01.640613: Current learning rate: 0.00324 
2025-01-26 22:18:49.771802: train_loss -0.8546 
2025-01-26 22:18:49.776880: val_loss -0.7584 
2025-01-26 22:18:49.779210: Pseudo dice [np.float32(0.9641), np.float32(0.8828)] 
2025-01-26 22:18:49.781786: Epoch time: 48.14 s 
2025-01-26 22:18:51.045289:  
2025-01-26 22:18:51.048192: Epoch 715 
2025-01-26 22:18:51.055347: Current learning rate: 0.00323 
2025-01-26 22:19:39.758274: train_loss -0.8298 
2025-01-26 22:19:39.766151: val_loss -0.7953 
2025-01-26 22:19:39.769064: Pseudo dice [np.float32(0.9609), np.float32(0.899)] 
2025-01-26 22:19:39.771925: Epoch time: 48.71 s 
2025-01-26 22:19:40.991920:  
2025-01-26 22:19:40.995053: Epoch 716 
2025-01-26 22:19:41.004348: Current learning rate: 0.00322 
2025-01-26 22:20:29.218772: train_loss -0.8375 
2025-01-26 22:20:29.225416: val_loss -0.8213 
2025-01-26 22:20:29.228545: Pseudo dice [np.float32(0.9604), np.float32(0.9206)] 
2025-01-26 22:20:29.231289: Epoch time: 48.23 s 
2025-01-26 22:20:29.233800: Yayy! New best EMA pseudo Dice: 0.9304999709129333 
2025-01-26 22:20:31.060921:  
2025-01-26 22:20:31.067678: Epoch 717 
2025-01-26 22:20:31.070575: Current learning rate: 0.00321 
2025-01-26 22:21:19.618467: train_loss -0.8548 
2025-01-26 22:21:19.626043: val_loss -0.8118 
2025-01-26 22:21:19.629046: Pseudo dice [np.float32(0.9642), np.float32(0.9234)] 
2025-01-26 22:21:19.631697: Epoch time: 48.56 s 
2025-01-26 22:21:19.634294: Yayy! New best EMA pseudo Dice: 0.9318000078201294 
2025-01-26 22:21:21.432890:  
2025-01-26 22:21:21.435724: Epoch 718 
2025-01-26 22:21:21.438192: Current learning rate: 0.0032 
2025-01-26 22:22:09.911135: train_loss -0.8666 
2025-01-26 22:22:09.917261: val_loss -0.7833 
2025-01-26 22:22:09.920075: Pseudo dice [np.float32(0.9632), np.float32(0.8859)] 
2025-01-26 22:22:09.922490: Epoch time: 48.48 s 
2025-01-26 22:22:11.145490:  
2025-01-26 22:22:11.148754: Epoch 719 
2025-01-26 22:22:11.151389: Current learning rate: 0.00319 
2025-01-26 22:22:59.581929: train_loss -0.8462 
2025-01-26 22:22:59.589792: val_loss -0.7742 
2025-01-26 22:22:59.592404: Pseudo dice [np.float32(0.9624), np.float32(0.8808)] 
2025-01-26 22:22:59.596922: Epoch time: 48.44 s 
2025-01-26 22:23:00.821053:  
2025-01-26 22:23:00.824173: Epoch 720 
2025-01-26 22:23:00.832177: Current learning rate: 0.00318 
2025-01-26 22:23:49.314621: train_loss -0.8473 
2025-01-26 22:23:49.318671: val_loss -0.7846 
2025-01-26 22:23:49.321861: Pseudo dice [np.float32(0.9582), np.float32(0.9082)] 
2025-01-26 22:23:49.325258: Epoch time: 48.49 s 
2025-01-26 22:23:50.585799:  
2025-01-26 22:23:50.588425: Epoch 721 
2025-01-26 22:23:50.597197: Current learning rate: 0.00317 
2025-01-26 22:24:39.345689: train_loss -0.8453 
2025-01-26 22:24:39.354052: val_loss -0.7801 
2025-01-26 22:24:39.357385: Pseudo dice [np.float32(0.9592), np.float32(0.9065)] 
2025-01-26 22:24:39.360900: Epoch time: 48.76 s 
2025-01-26 22:24:40.582299:  
2025-01-26 22:24:40.585333: Epoch 722 
2025-01-26 22:24:40.593217: Current learning rate: 0.00316 
2025-01-26 22:25:29.321915: train_loss -0.8434 
2025-01-26 22:25:29.325303: val_loss -0.8042 
2025-01-26 22:25:29.328139: Pseudo dice [np.float32(0.9634), np.float32(0.912)] 
2025-01-26 22:25:29.331178: Epoch time: 48.74 s 
2025-01-26 22:25:30.594216:  
2025-01-26 22:25:30.601271: Epoch 723 
2025-01-26 22:25:30.604053: Current learning rate: 0.00315 
2025-01-26 22:26:19.497773: train_loss -0.8283 
2025-01-26 22:26:19.504988: val_loss -0.7726 
2025-01-26 22:26:19.508258: Pseudo dice [np.float32(0.9648), np.float32(0.8885)] 
2025-01-26 22:26:19.511064: Epoch time: 48.9 s 
2025-01-26 22:26:20.731479:  
2025-01-26 22:26:20.737782: Epoch 724 
2025-01-26 22:26:20.740341: Current learning rate: 0.00314 
2025-01-26 22:27:09.084992: train_loss -0.8363 
2025-01-26 22:27:09.088767: val_loss -0.7821 
2025-01-26 22:27:09.091590: Pseudo dice [np.float32(0.953), np.float32(0.8404)] 
2025-01-26 22:27:09.094390: Epoch time: 48.35 s 
2025-01-26 22:27:10.315360:  
2025-01-26 22:27:10.319037: Epoch 725 
2025-01-26 22:27:10.328303: Current learning rate: 0.00313 
2025-01-26 22:27:58.730223: train_loss -0.8432 
2025-01-26 22:27:58.738941: val_loss -0.7677 
2025-01-26 22:27:58.741883: Pseudo dice [np.float32(0.9611), np.float32(0.9089)] 
2025-01-26 22:27:58.744898: Epoch time: 48.42 s 
2025-01-26 22:27:59.969493:  
2025-01-26 22:27:59.972190: Epoch 726 
2025-01-26 22:27:59.979652: Current learning rate: 0.00312 
2025-01-26 22:28:48.655473: train_loss -0.8292 
2025-01-26 22:28:48.658531: val_loss -0.7676 
2025-01-26 22:28:48.661285: Pseudo dice [np.float32(0.9604), np.float32(0.9052)] 
2025-01-26 22:28:48.663815: Epoch time: 48.69 s 
2025-01-26 22:28:49.882366:  
2025-01-26 22:28:49.887790: Epoch 727 
2025-01-26 22:28:49.891013: Current learning rate: 0.00311 
2025-01-26 22:29:38.906961: train_loss -0.8394 
2025-01-26 22:29:38.916504: val_loss -0.7925 
2025-01-26 22:29:38.919211: Pseudo dice [np.float32(0.9589), np.float32(0.8995)] 
2025-01-26 22:29:38.921908: Epoch time: 49.03 s 
2025-01-26 22:29:40.150375:  
2025-01-26 22:29:40.153779: Epoch 728 
2025-01-26 22:29:40.161541: Current learning rate: 0.0031 
2025-01-26 22:30:29.227610: train_loss -0.8152 
2025-01-26 22:30:29.231415: val_loss -0.8036 
2025-01-26 22:30:29.235154: Pseudo dice [np.float32(0.9574), np.float32(0.8938)] 
2025-01-26 22:30:29.238317: Epoch time: 49.08 s 
2025-01-26 22:30:30.502063:  
2025-01-26 22:30:30.504726: Epoch 729 
2025-01-26 22:30:30.513220: Current learning rate: 0.00309 
2025-01-26 22:31:18.917272: train_loss -0.8255 
2025-01-26 22:31:18.924218: val_loss -0.7996 
2025-01-26 22:31:18.927297: Pseudo dice [np.float32(0.9607), np.float32(0.9017)] 
2025-01-26 22:31:18.930004: Epoch time: 48.42 s 
2025-01-26 22:31:20.160291:  
2025-01-26 22:31:20.167341: Epoch 730 
2025-01-26 22:31:20.170257: Current learning rate: 0.00308 
2025-01-26 22:32:08.546462: train_loss -0.833 
2025-01-26 22:32:08.550241: val_loss -0.7874 
2025-01-26 22:32:08.553489: Pseudo dice [np.float32(0.9588), np.float32(0.9071)] 
2025-01-26 22:32:08.556093: Epoch time: 48.39 s 
2025-01-26 22:32:09.783052:  
2025-01-26 22:32:09.786515: Epoch 731 
2025-01-26 22:32:09.796671: Current learning rate: 0.00307 
2025-01-26 22:32:58.438338: train_loss -0.8334 
2025-01-26 22:32:58.445225: val_loss -0.8092 
2025-01-26 22:32:58.448354: Pseudo dice [np.float32(0.9655), np.float32(0.8999)] 
2025-01-26 22:32:58.451626: Epoch time: 48.66 s 
2025-01-26 22:33:00.228961:  
2025-01-26 22:33:00.236319: Epoch 732 
2025-01-26 22:33:00.239092: Current learning rate: 0.00306 
2025-01-26 22:33:48.778629: train_loss -0.8426 
2025-01-26 22:33:48.782338: val_loss -0.7753 
2025-01-26 22:33:48.785513: Pseudo dice [np.float32(0.9602), np.float32(0.906)] 
2025-01-26 22:33:48.788914: Epoch time: 48.55 s 
2025-01-26 22:33:50.042200:  
2025-01-26 22:33:50.045493: Epoch 733 
2025-01-26 22:33:50.055468: Current learning rate: 0.00305 
2025-01-26 22:34:38.420420: train_loss -0.8214 
2025-01-26 22:34:38.426715: val_loss -0.7915 
2025-01-26 22:34:38.429083: Pseudo dice [np.float32(0.9625), np.float32(0.907)] 
2025-01-26 22:34:38.431759: Epoch time: 48.38 s 
2025-01-26 22:34:39.689330:  
2025-01-26 22:34:39.692153: Epoch 734 
2025-01-26 22:34:39.701102: Current learning rate: 0.00304 
2025-01-26 22:35:28.263458: train_loss -0.8374 
2025-01-26 22:35:28.266923: val_loss -0.7803 
2025-01-26 22:35:28.269661: Pseudo dice [np.float32(0.9573), np.float32(0.9211)] 
2025-01-26 22:35:28.272223: Epoch time: 48.58 s 
2025-01-26 22:35:29.529855:  
2025-01-26 22:35:29.534014: Epoch 735 
2025-01-26 22:35:29.541576: Current learning rate: 0.00303 
2025-01-26 22:36:18.676803: train_loss -0.8539 
2025-01-26 22:36:18.683269: val_loss -0.8136 
2025-01-26 22:36:18.685809: Pseudo dice [np.float32(0.9553), np.float32(0.9123)] 
2025-01-26 22:36:18.688122: Epoch time: 49.15 s 
2025-01-26 22:36:19.912605:  
2025-01-26 22:36:19.915613: Epoch 736 
2025-01-26 22:36:19.923429: Current learning rate: 0.00302 
2025-01-26 22:37:08.485541: train_loss -0.8212 
2025-01-26 22:37:08.489541: val_loss -0.793 
2025-01-26 22:37:08.492735: Pseudo dice [np.float32(0.9542), np.float32(0.9087)] 
2025-01-26 22:37:08.495683: Epoch time: 48.57 s 
2025-01-26 22:37:09.727423:  
2025-01-26 22:37:09.732629: Epoch 737 
2025-01-26 22:37:09.735592: Current learning rate: 0.00301 
2025-01-26 22:37:58.173190: train_loss -0.834 
2025-01-26 22:37:58.179988: val_loss -0.8055 
2025-01-26 22:37:58.182738: Pseudo dice [np.float32(0.9622), np.float32(0.9183)] 
2025-01-26 22:37:58.185176: Epoch time: 48.45 s 
2025-01-26 22:37:58.187597: Yayy! New best EMA pseudo Dice: 0.9323999881744385 
2025-01-26 22:37:59.990809:  
2025-01-26 22:37:59.997099: Epoch 738 
2025-01-26 22:38:00.000004: Current learning rate: 0.003 
2025-01-26 22:38:49.066018: train_loss -0.849 
2025-01-26 22:38:49.069999: val_loss -0.8016 
2025-01-26 22:38:49.073020: Pseudo dice [np.float32(0.9611), np.float32(0.9094)] 
2025-01-26 22:38:49.075806: Epoch time: 49.08 s 
2025-01-26 22:38:49.078264: Yayy! New best EMA pseudo Dice: 0.9326000213623047 
2025-01-26 22:38:51.026758:  
2025-01-26 22:38:51.032977: Epoch 739 
2025-01-26 22:38:51.035954: Current learning rate: 0.00299 
2025-01-26 22:39:39.401854: train_loss -0.8448 
2025-01-26 22:39:39.409265: val_loss -0.7573 
2025-01-26 22:39:39.412372: Pseudo dice [np.float32(0.9587), np.float32(0.8775)] 
2025-01-26 22:39:39.414777: Epoch time: 48.38 s 
2025-01-26 22:39:40.643804:  
2025-01-26 22:39:40.646829: Epoch 740 
2025-01-26 22:39:40.649468: Current learning rate: 0.00297 
2025-01-26 22:40:29.447688: train_loss -0.8237 
2025-01-26 22:40:29.451222: val_loss -0.795 
2025-01-26 22:40:29.454353: Pseudo dice [np.float32(0.9553), np.float32(0.9055)] 
2025-01-26 22:40:29.457084: Epoch time: 48.8 s 
2025-01-26 22:40:30.675308:  
2025-01-26 22:40:30.678238: Epoch 741 
2025-01-26 22:40:30.681161: Current learning rate: 0.00296 
2025-01-26 22:41:19.145837: train_loss -0.8403 
2025-01-26 22:41:19.151830: val_loss -0.7721 
2025-01-26 22:41:19.154520: Pseudo dice [np.float32(0.9601), np.float32(0.9024)] 
2025-01-26 22:41:19.157005: Epoch time: 48.47 s 
2025-01-26 22:41:20.366954:  
2025-01-26 22:41:20.370199: Epoch 742 
2025-01-26 22:41:20.379300: Current learning rate: 0.00295 
2025-01-26 22:42:08.888507: train_loss -0.8472 
2025-01-26 22:42:08.892145: val_loss -0.7838 
2025-01-26 22:42:08.894620: Pseudo dice [np.float32(0.9623), np.float32(0.9192)] 
2025-01-26 22:42:08.897402: Epoch time: 48.52 s 
2025-01-26 22:42:10.124286:  
2025-01-26 22:42:10.127635: Epoch 743 
2025-01-26 22:42:10.137206: Current learning rate: 0.00294 
2025-01-26 22:42:58.674669: train_loss -0.8213 
2025-01-26 22:42:58.682173: val_loss -0.7897 
2025-01-26 22:42:58.685101: Pseudo dice [np.float32(0.9574), np.float32(0.8928)] 
2025-01-26 22:42:58.687875: Epoch time: 48.55 s 
2025-01-26 22:42:59.917544:  
2025-01-26 22:42:59.920522: Epoch 744 
2025-01-26 22:42:59.928690: Current learning rate: 0.00293 
2025-01-26 22:43:48.268555: train_loss -0.8393 
2025-01-26 22:43:48.272050: val_loss -0.7488 
2025-01-26 22:43:48.274959: Pseudo dice [np.float32(0.9612), np.float32(0.8845)] 
2025-01-26 22:43:48.277837: Epoch time: 48.35 s 
2025-01-26 22:43:49.501021:  
2025-01-26 22:43:49.507262: Epoch 745 
2025-01-26 22:43:49.510072: Current learning rate: 0.00292 
2025-01-26 22:44:37.935696: train_loss -0.84 
2025-01-26 22:44:37.941883: val_loss -0.7797 
2025-01-26 22:44:37.944869: Pseudo dice [np.float32(0.9654), np.float32(0.9141)] 
2025-01-26 22:44:37.947598: Epoch time: 48.44 s 
2025-01-26 22:44:39.189791:  
2025-01-26 22:44:39.201825: Epoch 746 
2025-01-26 22:44:39.204887: Current learning rate: 0.00291 
2025-01-26 22:45:28.268811: train_loss -0.8301 
2025-01-26 22:45:28.272264: val_loss -0.8004 
2025-01-26 22:45:28.274960: Pseudo dice [np.float32(0.9541), np.float32(0.9109)] 
2025-01-26 22:45:28.277535: Epoch time: 49.08 s 
2025-01-26 22:45:29.534902:  
2025-01-26 22:45:29.537772: Epoch 747 
2025-01-26 22:45:29.545808: Current learning rate: 0.0029 
2025-01-26 22:46:18.230548: train_loss -0.8565 
2025-01-26 22:46:18.236655: val_loss -0.7411 
2025-01-26 22:46:18.239413: Pseudo dice [np.float32(0.9596), np.float32(0.6964)] 
2025-01-26 22:46:18.242267: Epoch time: 48.7 s 
2025-01-26 22:46:19.461751:  
2025-01-26 22:46:19.465016: Epoch 748 
2025-01-26 22:46:19.474211: Current learning rate: 0.00289 
2025-01-26 22:47:07.866710: train_loss -0.8463 
2025-01-26 22:47:07.870362: val_loss -0.7533 
2025-01-26 22:47:07.873313: Pseudo dice [np.float32(0.9618), np.float32(0.9012)] 
2025-01-26 22:47:07.875895: Epoch time: 48.41 s 
2025-01-26 22:47:09.088788:  
2025-01-26 22:47:09.091912: Epoch 749 
2025-01-26 22:47:09.100125: Current learning rate: 0.00288 
2025-01-26 22:47:57.328937: train_loss -0.8435 
2025-01-26 22:47:57.336315: val_loss -0.7836 
2025-01-26 22:47:57.339603: Pseudo dice [np.float32(0.962), np.float32(0.8468)] 
2025-01-26 22:47:57.342343: Epoch time: 48.24 s 
2025-01-26 22:47:59.964988:  
2025-01-26 22:47:59.968449: Epoch 750 
2025-01-26 22:47:59.971141: Current learning rate: 0.00287 
2025-01-26 22:48:48.606877: train_loss -0.8345 
2025-01-26 22:48:48.610454: val_loss -0.7603 
2025-01-26 22:48:48.613500: Pseudo dice [np.float32(0.9633), np.float32(0.8879)] 
2025-01-26 22:48:48.616260: Epoch time: 48.64 s 
2025-01-26 22:48:49.843160:  
2025-01-26 22:48:49.848545: Epoch 751 
2025-01-26 22:48:49.851491: Current learning rate: 0.00286 
2025-01-26 22:49:38.254702: train_loss -0.8479 
2025-01-26 22:49:38.262175: val_loss -0.7741 
2025-01-26 22:49:38.265131: Pseudo dice [np.float32(0.9605), np.float32(0.8984)] 
2025-01-26 22:49:38.267414: Epoch time: 48.41 s 
2025-01-26 22:49:39.490326:  
2025-01-26 22:49:39.493660: Epoch 752 
2025-01-26 22:49:39.503483: Current learning rate: 0.00285 
2025-01-26 22:50:28.406598: train_loss -0.84 
2025-01-26 22:50:28.410481: val_loss -0.795 
2025-01-26 22:50:28.413300: Pseudo dice [np.float32(0.964), np.float32(0.8968)] 
2025-01-26 22:50:28.415909: Epoch time: 48.92 s 
2025-01-26 22:50:29.643855:  
2025-01-26 22:50:29.647522: Epoch 753 
2025-01-26 22:50:29.656739: Current learning rate: 0.00284 
2025-01-26 22:51:18.700034: train_loss -0.8538 
2025-01-26 22:51:18.707828: val_loss -0.8071 
2025-01-26 22:51:18.710706: Pseudo dice [np.float32(0.9608), np.float32(0.909)] 
2025-01-26 22:51:18.713412: Epoch time: 49.06 s 
2025-01-26 22:51:19.934079:  
2025-01-26 22:51:19.937536: Epoch 754 
2025-01-26 22:51:19.945549: Current learning rate: 0.00283 
2025-01-26 22:52:09.403863: train_loss -0.8452 
2025-01-26 22:52:09.407606: val_loss -0.8096 
2025-01-26 22:52:09.410553: Pseudo dice [np.float32(0.9653), np.float32(0.9075)] 
2025-01-26 22:52:09.413519: Epoch time: 49.47 s 
2025-01-26 22:52:10.632423:  
2025-01-26 22:52:10.638062: Epoch 755 
2025-01-26 22:52:10.640952: Current learning rate: 0.00282 
2025-01-26 22:52:59.251058: train_loss -0.8428 
2025-01-26 22:52:59.257345: val_loss -0.7877 
2025-01-26 22:52:59.259972: Pseudo dice [np.float32(0.959), np.float32(0.9086)] 
2025-01-26 22:52:59.263025: Epoch time: 48.62 s 
2025-01-26 22:53:00.486135:  
2025-01-26 22:53:00.489510: Epoch 756 
2025-01-26 22:53:00.499249: Current learning rate: 0.00281 
2025-01-26 22:53:48.678610: train_loss -0.8281 
2025-01-26 22:53:48.682078: val_loss -0.7915 
2025-01-26 22:53:48.685144: Pseudo dice [np.float32(0.9634), np.float32(0.9047)] 
2025-01-26 22:53:48.687791: Epoch time: 48.19 s 
2025-01-26 22:53:49.901840:  
2025-01-26 22:53:49.905003: Epoch 757 
2025-01-26 22:53:49.913229: Current learning rate: 0.0028 
2025-01-26 22:54:38.462351: train_loss -0.8447 
2025-01-26 22:54:38.469112: val_loss -0.8208 
2025-01-26 22:54:38.471833: Pseudo dice [np.float32(0.9622), np.float32(0.9144)] 
2025-01-26 22:54:38.474155: Epoch time: 48.56 s 
2025-01-26 22:54:39.736184:  
2025-01-26 22:54:39.739552: Epoch 758 
2025-01-26 22:54:39.750581: Current learning rate: 0.00279 
2025-01-26 22:55:27.961708: train_loss -0.8591 
2025-01-26 22:55:27.965271: val_loss -0.785 
2025-01-26 22:55:27.968189: Pseudo dice [np.float32(0.9626), np.float32(0.9196)] 
2025-01-26 22:55:27.970576: Epoch time: 48.23 s 
2025-01-26 22:55:29.197223:  
2025-01-26 22:55:29.200369: Epoch 759 
2025-01-26 22:55:29.212927: Current learning rate: 0.00278 
2025-01-26 22:56:18.031519: train_loss -0.8392 
2025-01-26 22:56:18.037630: val_loss -0.8013 
2025-01-26 22:56:18.040408: Pseudo dice [np.float32(0.9631), np.float32(0.9011)] 
2025-01-26 22:56:18.043199: Epoch time: 48.84 s 
2025-01-26 22:56:19.285392:  
2025-01-26 22:56:19.288334: Epoch 760 
2025-01-26 22:56:19.291419: Current learning rate: 0.00277 
2025-01-26 22:57:07.760258: train_loss -0.8481 
2025-01-26 22:57:07.763407: val_loss -0.8059 
2025-01-26 22:57:07.766127: Pseudo dice [np.float32(0.9629), np.float32(0.9072)] 
2025-01-26 22:57:07.769147: Epoch time: 48.48 s 
2025-01-26 22:57:08.997758:  
2025-01-26 22:57:09.000908: Epoch 761 
2025-01-26 22:57:09.009589: Current learning rate: 0.00276 
2025-01-26 22:57:57.503697: train_loss -0.8557 
2025-01-26 22:57:57.510391: val_loss -0.8018 
2025-01-26 22:57:57.513033: Pseudo dice [np.float32(0.9618), np.float32(0.9137)] 
2025-01-26 22:57:57.515598: Epoch time: 48.51 s 
2025-01-26 22:57:58.758790:  
2025-01-26 22:57:58.761695: Epoch 762 
2025-01-26 22:57:58.769447: Current learning rate: 0.00275 
2025-01-26 22:58:46.947259: train_loss -0.8431 
2025-01-26 22:58:46.950904: val_loss -0.8094 
2025-01-26 22:58:46.953732: Pseudo dice [np.float32(0.9634), np.float32(0.9115)] 
2025-01-26 22:58:46.956749: Epoch time: 48.19 s 
2025-01-26 22:58:48.232153:  
2025-01-26 22:58:48.235090: Epoch 763 
2025-01-26 22:58:48.243580: Current learning rate: 0.00274 
2025-01-26 22:59:36.876247: train_loss -0.8419 
2025-01-26 22:59:36.884453: val_loss -0.7834 
2025-01-26 22:59:36.887639: Pseudo dice [np.float32(0.954), np.float32(0.9181)] 
2025-01-26 22:59:36.891016: Epoch time: 48.65 s 
2025-01-26 22:59:38.167688:  
2025-01-26 22:59:38.173807: Epoch 764 
2025-01-26 22:59:38.176636: Current learning rate: 0.00273 
2025-01-26 23:00:27.056232: train_loss -0.8345 
2025-01-26 23:00:27.060287: val_loss -0.7798 
2025-01-26 23:00:27.063390: Pseudo dice [np.float32(0.9598), np.float32(0.908)] 
2025-01-26 23:00:27.066776: Epoch time: 48.89 s 
2025-01-26 23:00:28.354381:  
2025-01-26 23:00:28.357634: Epoch 765 
2025-01-26 23:00:28.365519: Current learning rate: 0.00272 
2025-01-26 23:01:16.960814: train_loss -0.8354 
2025-01-26 23:01:16.969466: val_loss -0.7928 
2025-01-26 23:01:16.972367: Pseudo dice [np.float32(0.9617), np.float32(0.9055)] 
2025-01-26 23:01:16.975267: Epoch time: 48.61 s 
2025-01-26 23:01:18.257379:  
2025-01-26 23:01:18.260560: Epoch 766 
2025-01-26 23:01:18.269131: Current learning rate: 0.00271 
2025-01-26 23:02:06.741789: train_loss -0.838 
2025-01-26 23:02:06.747202: val_loss -0.7901 
2025-01-26 23:02:06.750145: Pseudo dice [np.float32(0.9612), np.float32(0.9179)] 
2025-01-26 23:02:06.752934: Epoch time: 48.49 s 
2025-01-26 23:02:06.755700: Yayy! New best EMA pseudo Dice: 0.9330000281333923 
2025-01-26 23:02:08.572074:  
2025-01-26 23:02:08.574958: Epoch 767 
2025-01-26 23:02:08.583716: Current learning rate: 0.0027 
2025-01-26 23:02:57.317476: train_loss -0.8501 
2025-01-26 23:02:57.323981: val_loss -0.7778 
2025-01-26 23:02:57.326835: Pseudo dice [np.float32(0.9634), np.float32(0.8916)] 
2025-01-26 23:02:57.329234: Epoch time: 48.75 s 
2025-01-26 23:02:59.122983:  
2025-01-26 23:02:59.129414: Epoch 768 
2025-01-26 23:02:59.132357: Current learning rate: 0.00268 
2025-01-26 23:03:47.410845: train_loss -0.8338 
2025-01-26 23:03:47.414535: val_loss -0.7877 
2025-01-26 23:03:47.417786: Pseudo dice [np.float32(0.9592), np.float32(0.9039)] 
2025-01-26 23:03:47.420866: Epoch time: 48.29 s 
2025-01-26 23:03:48.705933:  
2025-01-26 23:03:48.711425: Epoch 769 
2025-01-26 23:03:48.713986: Current learning rate: 0.00267 
2025-01-26 23:04:37.091361: train_loss -0.829 
2025-01-26 23:04:37.098490: val_loss -0.8296 
2025-01-26 23:04:37.101472: Pseudo dice [np.float32(0.9643), np.float32(0.9134)] 
2025-01-26 23:04:37.104329: Epoch time: 48.39 s 
2025-01-26 23:04:37.106943: Yayy! New best EMA pseudo Dice: 0.9330000281333923 
2025-01-26 23:04:38.973724:  
2025-01-26 23:04:38.980962: Epoch 770 
2025-01-26 23:04:38.984134: Current learning rate: 0.00266 
2025-01-26 23:05:27.279310: train_loss -0.8338 
2025-01-26 23:05:27.282694: val_loss -0.7552 
2025-01-26 23:05:27.285448: Pseudo dice [np.float32(0.9624), np.float32(0.8993)] 
2025-01-26 23:05:27.287889: Epoch time: 48.31 s 
2025-01-26 23:05:28.539268:  
2025-01-26 23:05:28.541939: Epoch 771 
2025-01-26 23:05:28.549970: Current learning rate: 0.00265 
2025-01-26 23:06:17.209992: train_loss -0.8374 
2025-01-26 23:06:17.216100: val_loss -0.7676 
2025-01-26 23:06:17.218581: Pseudo dice [np.float32(0.9596), np.float32(0.9119)] 
2025-01-26 23:06:17.221054: Epoch time: 48.67 s 
2025-01-26 23:06:17.223422: Yayy! New best EMA pseudo Dice: 0.9330999851226807 
2025-01-26 23:06:19.073378:  
2025-01-26 23:06:19.080205: Epoch 772 
2025-01-26 23:06:19.082899: Current learning rate: 0.00264 
2025-01-26 23:07:07.455874: train_loss -0.8335 
2025-01-26 23:07:07.459154: val_loss -0.742 
2025-01-26 23:07:07.461778: Pseudo dice [np.float32(0.9642), np.float32(0.8976)] 
2025-01-26 23:07:07.464386: Epoch time: 48.38 s 
2025-01-26 23:07:08.702979:  
2025-01-26 23:07:08.709432: Epoch 773 
2025-01-26 23:07:08.712140: Current learning rate: 0.00263 
2025-01-26 23:07:57.198022: train_loss -0.8255 
2025-01-26 23:07:57.204228: val_loss -0.7884 
2025-01-26 23:07:57.207388: Pseudo dice [np.float32(0.9654), np.float32(0.9124)] 
2025-01-26 23:07:57.210135: Epoch time: 48.5 s 
2025-01-26 23:07:57.212331: Yayy! New best EMA pseudo Dice: 0.9334999918937683 
2025-01-26 23:07:59.052718:  
2025-01-26 23:07:59.059162: Epoch 774 
2025-01-26 23:07:59.062001: Current learning rate: 0.00262 
2025-01-26 23:08:47.410105: train_loss -0.8385 
2025-01-26 23:08:47.413732: val_loss -0.7733 
2025-01-26 23:08:47.416588: Pseudo dice [np.float32(0.9636), np.float32(0.8776)] 
2025-01-26 23:08:47.419678: Epoch time: 48.36 s 
2025-01-26 23:08:48.657207:  
2025-01-26 23:08:48.660732: Epoch 775 
2025-01-26 23:08:48.669538: Current learning rate: 0.00261 
2025-01-26 23:09:37.226079: train_loss -0.8521 
2025-01-26 23:09:37.232943: val_loss -0.8293 
2025-01-26 23:09:37.235863: Pseudo dice [np.float32(0.9624), np.float32(0.912)] 
2025-01-26 23:09:37.238935: Epoch time: 48.57 s 
2025-01-26 23:09:38.517840:  
2025-01-26 23:09:38.520649: Epoch 776 
2025-01-26 23:09:38.529502: Current learning rate: 0.0026 
2025-01-26 23:10:26.894622: train_loss -0.8352 
2025-01-26 23:10:26.898222: val_loss -0.8013 
2025-01-26 23:10:26.900794: Pseudo dice [np.float32(0.9576), np.float32(0.9035)] 
2025-01-26 23:10:26.903377: Epoch time: 48.38 s 
2025-01-26 23:10:28.182218:  
2025-01-26 23:10:28.185284: Epoch 777 
2025-01-26 23:10:28.193209: Current learning rate: 0.00259 
2025-01-26 23:11:16.784044: train_loss -0.8506 
2025-01-26 23:11:16.790956: val_loss -0.754 
2025-01-26 23:11:16.793666: Pseudo dice [np.float32(0.9533), np.float32(0.8834)] 
2025-01-26 23:11:16.796661: Epoch time: 48.6 s 
2025-01-26 23:11:18.081672:  
2025-01-26 23:11:18.087548: Epoch 778 
2025-01-26 23:11:18.090290: Current learning rate: 0.00258 
2025-01-26 23:12:06.867286: train_loss -0.8493 
2025-01-26 23:12:06.871274: val_loss -0.7807 
2025-01-26 23:12:06.874259: Pseudo dice [np.float32(0.9647), np.float32(0.9224)] 
2025-01-26 23:12:06.877398: Epoch time: 48.79 s 
2025-01-26 23:12:08.110451:  
2025-01-26 23:12:08.113270: Epoch 779 
2025-01-26 23:12:08.122316: Current learning rate: 0.00257 
2025-01-26 23:12:56.377990: train_loss -0.8592 
2025-01-26 23:12:56.385060: val_loss -0.7832 
2025-01-26 23:12:56.387736: Pseudo dice [np.float32(0.9608), np.float32(0.9171)] 
2025-01-26 23:12:56.390878: Epoch time: 48.27 s 
2025-01-26 23:12:57.624253:  
2025-01-26 23:12:57.627661: Epoch 780 
2025-01-26 23:12:57.636704: Current learning rate: 0.00256 
2025-01-26 23:13:45.839492: train_loss -0.8414 
2025-01-26 23:13:45.843007: val_loss -0.7832 
2025-01-26 23:13:45.845603: Pseudo dice [np.float32(0.9661), np.float32(0.902)] 
2025-01-26 23:13:45.848131: Epoch time: 48.22 s 
2025-01-26 23:13:47.083175:  
2025-01-26 23:13:47.086072: Epoch 781 
2025-01-26 23:13:47.095850: Current learning rate: 0.00255 
2025-01-26 23:14:35.581014: train_loss -0.8371 
2025-01-26 23:14:35.588002: val_loss -0.7604 
2025-01-26 23:14:35.590791: Pseudo dice [np.float32(0.9599), np.float32(0.9113)] 
2025-01-26 23:14:35.593750: Epoch time: 48.5 s 
2025-01-26 23:14:36.865200:  
2025-01-26 23:14:36.867642: Epoch 782 
2025-01-26 23:14:36.876482: Current learning rate: 0.00254 
2025-01-26 23:15:25.487867: train_loss -0.8464 
2025-01-26 23:15:25.491662: val_loss -0.7528 
2025-01-26 23:15:25.494707: Pseudo dice [np.float32(0.9643), np.float32(0.904)] 
2025-01-26 23:15:25.497571: Epoch time: 48.62 s 
2025-01-26 23:15:26.732645:  
2025-01-26 23:15:26.738343: Epoch 783 
2025-01-26 23:15:26.740777: Current learning rate: 0.00253 
2025-01-26 23:16:14.768086: train_loss -0.8529 
2025-01-26 23:16:14.774077: val_loss -0.8277 
2025-01-26 23:16:14.776667: Pseudo dice [np.float32(0.9603), np.float32(0.9124)] 
2025-01-26 23:16:14.779121: Epoch time: 48.04 s 
2025-01-26 23:16:14.781588: Yayy! New best EMA pseudo Dice: 0.9337000250816345 
2025-01-26 23:16:16.652144:  
2025-01-26 23:16:16.655274: Epoch 784 
2025-01-26 23:16:16.663337: Current learning rate: 0.00252 
2025-01-26 23:17:05.104829: train_loss -0.8373 
2025-01-26 23:17:05.108379: val_loss -0.7753 
2025-01-26 23:17:05.111103: Pseudo dice [np.float32(0.9613), np.float32(0.8807)] 
2025-01-26 23:17:05.114038: Epoch time: 48.45 s 
2025-01-26 23:17:06.356408:  
2025-01-26 23:17:06.359462: Epoch 785 
2025-01-26 23:17:06.368268: Current learning rate: 0.00251 
2025-01-26 23:17:54.796390: train_loss -0.8326 
2025-01-26 23:17:54.802609: val_loss -0.8014 
2025-01-26 23:17:54.804909: Pseudo dice [np.float32(0.9653), np.float32(0.9001)] 
2025-01-26 23:17:54.807318: Epoch time: 48.44 s 
2025-01-26 23:17:56.636707:  
2025-01-26 23:17:56.639736: Epoch 786 
2025-01-26 23:17:56.648538: Current learning rate: 0.0025 
2025-01-26 23:18:45.345291: train_loss -0.8391 
2025-01-26 23:18:45.348678: val_loss -0.7991 
2025-01-26 23:18:45.351064: Pseudo dice [np.float32(0.9601), np.float32(0.8709)] 
2025-01-26 23:18:45.353539: Epoch time: 48.71 s 
2025-01-26 23:18:46.601612:  
2025-01-26 23:18:46.607547: Epoch 787 
2025-01-26 23:18:46.610178: Current learning rate: 0.00249 
2025-01-26 23:19:35.003048: train_loss -0.8057 
2025-01-26 23:19:35.009537: val_loss -0.7744 
2025-01-26 23:19:35.012378: Pseudo dice [np.float32(0.9666), np.float32(0.9139)] 
2025-01-26 23:19:35.015257: Epoch time: 48.4 s 
2025-01-26 23:19:36.288238:  
2025-01-26 23:19:36.294680: Epoch 788 
2025-01-26 23:19:36.297229: Current learning rate: 0.00248 
2025-01-26 23:20:24.690473: train_loss -0.8389 
2025-01-26 23:20:24.695398: val_loss -0.755 
2025-01-26 23:20:24.698154: Pseudo dice [np.float32(0.9595), np.float32(0.89)] 
2025-01-26 23:20:24.700711: Epoch time: 48.4 s 
2025-01-26 23:20:25.949046:  
2025-01-26 23:20:25.952104: Epoch 789 
2025-01-26 23:20:25.960809: Current learning rate: 0.00247 
2025-01-26 23:21:14.422808: train_loss -0.8437 
2025-01-26 23:21:14.429360: val_loss -0.7779 
2025-01-26 23:21:14.432019: Pseudo dice [np.float32(0.9594), np.float32(0.9129)] 
2025-01-26 23:21:14.434683: Epoch time: 48.47 s 
2025-01-26 23:21:15.716694:  
2025-01-26 23:21:15.719739: Epoch 790 
2025-01-26 23:21:15.728182: Current learning rate: 0.00245 
2025-01-26 23:22:04.539045: train_loss -0.849 
2025-01-26 23:22:04.542540: val_loss -0.7777 
2025-01-26 23:22:04.545102: Pseudo dice [np.float32(0.9576), np.float32(0.9054)] 
2025-01-26 23:22:04.548165: Epoch time: 48.82 s 
2025-01-26 23:22:05.829604:  
2025-01-26 23:22:05.832371: Epoch 791 
2025-01-26 23:22:05.841082: Current learning rate: 0.00244 
2025-01-26 23:22:54.174689: train_loss -0.8468 
2025-01-26 23:22:54.183110: val_loss -0.7785 
2025-01-26 23:22:54.185886: Pseudo dice [np.float32(0.9596), np.float32(0.899)] 
2025-01-26 23:22:54.188642: Epoch time: 48.35 s 
2025-01-26 23:22:55.420404:  
2025-01-26 23:22:55.426945: Epoch 792 
2025-01-26 23:22:55.429413: Current learning rate: 0.00243 
2025-01-26 23:23:43.699188: train_loss -0.8464 
2025-01-26 23:23:43.702475: val_loss -0.7747 
2025-01-26 23:23:43.705222: Pseudo dice [np.float32(0.9597), np.float32(0.908)] 
2025-01-26 23:23:43.707791: Epoch time: 48.28 s 
2025-01-26 23:23:44.945491:  
2025-01-26 23:23:44.949411: Epoch 793 
2025-01-26 23:23:44.957628: Current learning rate: 0.00242 
2025-01-26 23:24:33.803951: train_loss -0.8349 
2025-01-26 23:24:33.810861: val_loss -0.7825 
2025-01-26 23:24:33.813760: Pseudo dice [np.float32(0.9596), np.float32(0.9121)] 
2025-01-26 23:24:33.816357: Epoch time: 48.86 s 
2025-01-26 23:24:35.099665:  
2025-01-26 23:24:35.106260: Epoch 794 
2025-01-26 23:24:35.109032: Current learning rate: 0.00241 
2025-01-26 23:25:23.551925: train_loss -0.8334 
2025-01-26 23:25:23.555402: val_loss -0.7568 
2025-01-26 23:25:23.558220: Pseudo dice [np.float32(0.9571), np.float32(0.8562)] 
2025-01-26 23:25:23.560790: Epoch time: 48.45 s 
2025-01-26 23:25:24.842156:  
2025-01-26 23:25:24.845269: Epoch 795 
2025-01-26 23:25:24.853532: Current learning rate: 0.0024 
2025-01-26 23:26:13.236141: train_loss -0.8206 
2025-01-26 23:26:13.242623: val_loss -0.7973 
2025-01-26 23:26:13.245676: Pseudo dice [np.float32(0.9504), np.float32(0.8793)] 
2025-01-26 23:26:13.248353: Epoch time: 48.39 s 
2025-01-26 23:26:14.489480:  
2025-01-26 23:26:14.497021: Epoch 796 
2025-01-26 23:26:14.500499: Current learning rate: 0.00239 
2025-01-26 23:27:03.261662: train_loss -0.8322 
2025-01-26 23:27:03.265500: val_loss -0.8027 
2025-01-26 23:27:03.268559: Pseudo dice [np.float32(0.96), np.float32(0.8673)] 
2025-01-26 23:27:03.271278: Epoch time: 48.77 s 
2025-01-26 23:27:04.504580:  
2025-01-26 23:27:04.507524: Epoch 797 
2025-01-26 23:27:04.516146: Current learning rate: 0.00238 
2025-01-26 23:27:53.032319: train_loss -0.8457 
2025-01-26 23:27:53.038694: val_loss -0.7792 
2025-01-26 23:27:53.041477: Pseudo dice [np.float32(0.9644), np.float32(0.9029)] 
2025-01-26 23:27:53.044464: Epoch time: 48.53 s 
2025-01-26 23:27:54.289653:  
2025-01-26 23:27:54.293311: Epoch 798 
2025-01-26 23:27:54.301941: Current learning rate: 0.00237 
2025-01-26 23:28:43.148086: train_loss -0.8222 
2025-01-26 23:28:43.151692: val_loss -0.7843 
2025-01-26 23:28:43.154849: Pseudo dice [np.float32(0.9603), np.float32(0.8926)] 
2025-01-26 23:28:43.157862: Epoch time: 48.86 s 
2025-01-26 23:28:44.397916:  
2025-01-26 23:28:44.402058: Epoch 799 
2025-01-26 23:28:44.411729: Current learning rate: 0.00236 
2025-01-26 23:29:32.957605: train_loss -0.8194 
2025-01-26 23:29:32.964360: val_loss -0.7857 
2025-01-26 23:29:32.967346: Pseudo dice [np.float32(0.9567), np.float32(0.9153)] 
2025-01-26 23:29:32.970275: Epoch time: 48.56 s 
2025-01-26 23:29:34.853559:  
2025-01-26 23:29:34.860381: Epoch 800 
2025-01-26 23:29:34.863091: Current learning rate: 0.00235 
2025-01-26 23:30:23.510411: train_loss -0.831 
2025-01-26 23:30:23.514102: val_loss -0.7708 
2025-01-26 23:30:23.516969: Pseudo dice [np.float32(0.9608), np.float32(0.8969)] 
2025-01-26 23:30:23.519722: Epoch time: 48.66 s 
2025-01-26 23:30:24.776074:  
2025-01-26 23:30:24.783256: Epoch 801 
2025-01-26 23:30:24.786464: Current learning rate: 0.00234 
2025-01-26 23:31:13.029653: train_loss -0.8484 
2025-01-26 23:31:13.036137: val_loss -0.7981 
2025-01-26 23:31:13.038774: Pseudo dice [np.float32(0.96), np.float32(0.9166)] 
2025-01-26 23:31:13.041707: Epoch time: 48.25 s 
2025-01-26 23:31:14.309188:  
2025-01-26 23:31:14.311873: Epoch 802 
2025-01-26 23:31:14.320696: Current learning rate: 0.00233 
2025-01-26 23:32:03.027005: train_loss -0.854 
2025-01-26 23:32:03.030465: val_loss -0.8072 
2025-01-26 23:32:03.033483: Pseudo dice [np.float32(0.9659), np.float32(0.9106)] 
2025-01-26 23:32:03.035874: Epoch time: 48.72 s 
2025-01-26 23:32:05.085801:  
2025-01-26 23:32:05.088380: Epoch 803 
2025-01-26 23:32:05.097430: Current learning rate: 0.00232 
2025-01-26 23:32:54.129808: train_loss -0.841 
2025-01-26 23:32:54.135918: val_loss -0.8085 
2025-01-26 23:32:54.138618: Pseudo dice [np.float32(0.9619), np.float32(0.9235)] 
2025-01-26 23:32:54.141265: Epoch time: 49.05 s 
2025-01-26 23:32:55.402864:  
2025-01-26 23:32:55.405771: Epoch 804 
2025-01-26 23:32:55.414119: Current learning rate: 0.00231 
2025-01-26 23:33:44.187300: train_loss -0.845 
2025-01-26 23:33:44.190555: val_loss -0.7532 
2025-01-26 23:33:44.193147: Pseudo dice [np.float32(0.9624), np.float32(0.8936)] 
2025-01-26 23:33:44.195525: Epoch time: 48.79 s 
2025-01-26 23:33:45.479286:  
2025-01-26 23:33:45.482066: Epoch 805 
2025-01-26 23:33:45.490500: Current learning rate: 0.0023 
2025-01-26 23:34:33.879131: train_loss -0.839 
2025-01-26 23:34:33.885394: val_loss -0.758 
2025-01-26 23:34:33.888215: Pseudo dice [np.float32(0.9636), np.float32(0.9048)] 
2025-01-26 23:34:33.890473: Epoch time: 48.4 s 
2025-01-26 23:34:35.148843:  
2025-01-26 23:34:35.154515: Epoch 806 
2025-01-26 23:34:35.157550: Current learning rate: 0.00229 
2025-01-26 23:35:23.885646: train_loss -0.855 
2025-01-26 23:35:23.888737: val_loss -0.7981 
2025-01-26 23:35:23.891419: Pseudo dice [np.float32(0.965), np.float32(0.9155)] 
2025-01-26 23:35:23.893912: Epoch time: 48.74 s 
2025-01-26 23:35:25.148773:  
2025-01-26 23:35:25.151263: Epoch 807 
2025-01-26 23:35:25.159994: Current learning rate: 0.00228 
2025-01-26 23:36:13.990702: train_loss -0.8458 
2025-01-26 23:36:13.996605: val_loss -0.7893 
2025-01-26 23:36:13.998770: Pseudo dice [np.float32(0.9575), np.float32(0.9089)] 
2025-01-26 23:36:14.001569: Epoch time: 48.84 s 
2025-01-26 23:36:15.253145:  
2025-01-26 23:36:15.255709: Epoch 808 
2025-01-26 23:36:15.264295: Current learning rate: 0.00226 
2025-01-26 23:37:03.583802: train_loss -0.8393 
2025-01-26 23:37:03.587718: val_loss -0.8096 
2025-01-26 23:37:03.590755: Pseudo dice [np.float32(0.9603), np.float32(0.9185)] 
2025-01-26 23:37:03.593627: Epoch time: 48.33 s 
2025-01-26 23:37:04.857145:  
2025-01-26 23:37:04.860210: Epoch 809 
2025-01-26 23:37:04.869526: Current learning rate: 0.00225 
2025-01-26 23:37:53.563165: train_loss -0.8352 
2025-01-26 23:37:53.568840: val_loss -0.7954 
2025-01-26 23:37:53.571812: Pseudo dice [np.float32(0.966), np.float32(0.9211)] 
2025-01-26 23:37:53.574747: Epoch time: 48.71 s 
2025-01-26 23:37:53.577495: Yayy! New best EMA pseudo Dice: 0.9340999722480774 
2025-01-26 23:37:55.403577:  
2025-01-26 23:37:55.409823: Epoch 810 
2025-01-26 23:37:55.412848: Current learning rate: 0.00224 
2025-01-26 23:38:44.492748: train_loss -0.8479 
2025-01-26 23:38:44.496357: val_loss -0.8276 
2025-01-26 23:38:44.499068: Pseudo dice [np.float32(0.964), np.float32(0.9105)] 
2025-01-26 23:38:44.501703: Epoch time: 49.09 s 
2025-01-26 23:38:44.504102: Yayy! New best EMA pseudo Dice: 0.9344000220298767 
2025-01-26 23:38:46.366453:  
2025-01-26 23:38:46.372799: Epoch 811 
2025-01-26 23:38:46.375493: Current learning rate: 0.00223 
2025-01-26 23:39:35.293910: train_loss -0.8463 
2025-01-26 23:39:35.300503: val_loss -0.7672 
2025-01-26 23:39:35.302884: Pseudo dice [np.float32(0.9606), np.float32(0.9167)] 
2025-01-26 23:39:35.305263: Epoch time: 48.93 s 
2025-01-26 23:39:35.307876: Yayy! New best EMA pseudo Dice: 0.9348000288009644 
2025-01-26 23:39:37.129009:  
2025-01-26 23:39:37.135802: Epoch 812 
2025-01-26 23:39:37.138320: Current learning rate: 0.00222 
2025-01-26 23:40:25.379218: train_loss -0.8578 
2025-01-26 23:40:25.383379: val_loss -0.8021 
2025-01-26 23:40:25.386624: Pseudo dice [np.float32(0.9624), np.float32(0.9133)] 
2025-01-26 23:40:25.389822: Epoch time: 48.25 s 
2025-01-26 23:40:25.392549: Yayy! New best EMA pseudo Dice: 0.9351000189781189 
2025-01-26 23:40:27.289660:  
2025-01-26 23:40:27.294885: Epoch 813 
2025-01-26 23:40:27.297643: Current learning rate: 0.00221 
2025-01-26 23:41:15.833741: train_loss -0.8309 
2025-01-26 23:41:15.840294: val_loss -0.789 
2025-01-26 23:41:15.843071: Pseudo dice [np.float32(0.9641), np.float32(0.9055)] 
2025-01-26 23:41:15.845795: Epoch time: 48.55 s 
