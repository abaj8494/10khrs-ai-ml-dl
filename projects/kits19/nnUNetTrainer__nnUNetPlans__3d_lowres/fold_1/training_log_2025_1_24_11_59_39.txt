
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-01-24 11:59:39.253006: do_dummy_2d_data_aug: False 
2025-01-24 11:59:39.288312: Using splits from existing split file: /srv/scratch/z5362216/kits19/nnUNet_db/nnUNet_preprocessed/Dataset001_Kits19/splits_final.json 
2025-01-24 11:59:39.317677: The split file contains 5 splits. 
2025-01-24 11:59:39.320731: Desired fold for training: 1 
2025-01-24 11:59:39.323489: This split has 80 training and 20 validation cases. 
2025-01-24 11:59:45.750397: Using torch.compile... 

This is the configuration used by this training:
Configuration name: 3d_lowres
 {'data_identifier': 'nnUNetPlans_3d_lowres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [128, 128, 128], 'median_image_size_in_voxels': [200, 205, 205], 'spacing': [1.9849520718478983, 1.9849270710444444, 1.9849270710444444], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False, 'next_stage': '3d_cascade_fullres'} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset001_Kits19', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [3.0, 0.7939453125, 0.7939453125], 'original_median_shape_after_transp': [104, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [2, 0, 1], 'transpose_backward': [1, 2, 0], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 2553.0, 'mean': 104.46720886230469, 'median': 104.0, 'min': -277.0, 'percentile_00_5': -73.0, 'percentile_99_5': 292.0, 'std': 74.68063354492188}}} 
 
2025-01-24 11:59:49.841099: unpacking dataset... 
2025-01-24 12:00:04.580593: unpacking done... 
2025-01-24 12:00:04.687757: 
printing the network instead:
 
2025-01-24 12:00:04.690994: OptimizedModule(
  (_orig_mod): PlainConvUNet(
    (encoder): PlainConvEncoder(
      (stages): Sequential(
        (0): Sequential(
          (0): StackedConvBlocks(
            (convs): Sequential(
              (0): ConvDropoutNormReLU(
                (conv): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (1): ConvDropoutNormReLU(
                (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
            )
          )
        )
        (1): Sequential(
          (0): StackedConvBlocks(
            (convs): Sequential(
              (0): ConvDropoutNormReLU(
                (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (1): ConvDropoutNormReLU(
                (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
            )
          )
        )
        (2): Sequential(
          (0): StackedConvBlocks(
            (convs): Sequential(
              (0): ConvDropoutNormReLU(
                (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (1): ConvDropoutNormReLU(
                (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
            )
          )
        )
        (3): Sequential(
          (0): StackedConvBlocks(
            (convs): Sequential(
              (0): ConvDropoutNormReLU(
                (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (1): ConvDropoutNormReLU(
                (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
            )
          )
        )
        (4): Sequential(
          (0): StackedConvBlocks(
            (convs): Sequential(
              (0): ConvDropoutNormReLU(
                (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (1): ConvDropoutNormReLU(
                (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
            )
          )
        )
        (5): Sequential(
          (0): StackedConvBlocks(
            (convs): Sequential(
              (0): ConvDropoutNormReLU(
                (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (1): ConvDropoutNormReLU(
                (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
            )
          )
        )
      )
    )
    (decoder): UNetDecoder(
      (encoder): PlainConvEncoder(
        (stages): Sequential(
          (0): Sequential(
            (0): StackedConvBlocks(
              (convs): Sequential(
                (0): ConvDropoutNormReLU(
                  (conv): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                  (all_modules): Sequential(
                    (0): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                    (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                    (2): LeakyReLU(negative_slope=0.01, inplace=True)
                  )
                )
                (1): ConvDropoutNormReLU(
                  (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                  (all_modules): Sequential(
                    (0): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                    (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                    (2): LeakyReLU(negative_slope=0.01, inplace=True)
                  )
                )
              )
            )
          )
          (1): Sequential(
            (0): StackedConvBlocks(
              (convs): Sequential(
                (0): ConvDropoutNormReLU(
                  (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                  (all_modules): Sequential(
                    (0): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                    (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                    (2): LeakyReLU(negative_slope=0.01, inplace=True)
                  )
                )
                (1): ConvDropoutNormReLU(
                  (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                  (all_modules): Sequential(
                    (0): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                    (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                    (2): LeakyReLU(negative_slope=0.01, inplace=True)
                  )
                )
              )
            )
          )
          (2): Sequential(
            (0): StackedConvBlocks(
              (convs): Sequential(
                (0): ConvDropoutNormReLU(
                  (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                  (all_modules): Sequential(
                    (0): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                    (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                    (2): LeakyReLU(negative_slope=0.01, inplace=True)
                  )
                )
                (1): ConvDropoutNormReLU(
                  (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                  (all_modules): Sequential(
                    (0): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                    (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                    (2): LeakyReLU(negative_slope=0.01, inplace=True)
                  )
                )
              )
            )
          )
          (3): Sequential(
            (0): StackedConvBlocks(
              (convs): Sequential(
                (0): ConvDropoutNormReLU(
                  (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                  (all_modules): Sequential(
                    (0): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                    (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                    (2): LeakyReLU(negative_slope=0.01, inplace=True)
                  )
                )
                (1): ConvDropoutNormReLU(
                  (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                  (all_modules): Sequential(
                    (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                    (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                    (2): LeakyReLU(negative_slope=0.01, inplace=True)
                  )
                )
              )
            )
          )
          (4): Sequential(
            (0): StackedConvBlocks(
              (convs): Sequential(
                (0): ConvDropoutNormReLU(
                  (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                  (all_modules): Sequential(
                    (0): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                    (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                    (2): LeakyReLU(negative_slope=0.01, inplace=True)
                  )
                )
                (1): ConvDropoutNormReLU(
                  (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                  (all_modules): Sequential(
                    (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                    (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                    (2): LeakyReLU(negative_slope=0.01, inplace=True)
                  )
                )
              )
            )
          )
          (5): Sequential(
            (0): StackedConvBlocks(
              (convs): Sequential(
                (0): ConvDropoutNormReLU(
                  (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                  (all_modules): Sequential(
                    (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                    (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                    (2): LeakyReLU(negative_slope=0.01, inplace=True)
                  )
                )
                (1): ConvDropoutNormReLU(
                  (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                  (all_modules): Sequential(
                    (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                    (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                    (2): LeakyReLU(negative_slope=0.01, inplace=True)
                  )
                )
              )
            )
          )
        )
      )
      (stages): ModuleList(
        (0): StackedConvBlocks(
          (convs): Sequential(
            (0): ConvDropoutNormReLU(
              (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
              (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (1): ConvDropoutNormReLU(
              (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
              (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
          )
        )
        (1): StackedConvBlocks(
          (convs): Sequential(
            (0): ConvDropoutNormReLU(
              (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
              (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (1): ConvDropoutNormReLU(
              (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
              (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
          )
        )
        (2): StackedConvBlocks(
          (convs): Sequential(
            (0): ConvDropoutNormReLU(
              (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (1): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
          )
        )
        (3): StackedConvBlocks(
          (convs): Sequential(
            (0): ConvDropoutNormReLU(
              (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (1): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
          )
        )
        (4): StackedConvBlocks(
          (convs): Sequential(
            (0): ConvDropoutNormReLU(
              (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (1): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
          )
        )
      )
      (transpconvs): ModuleList(
        (0): ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2))
        (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2))
        (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2))
        (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2))
        (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2))
      )
      (seg_layers): ModuleList(
        (0): Conv3d(320, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1))
        (1): Conv3d(256, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1))
        (2): Conv3d(128, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1))
        (3): Conv3d(64, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1))
        (4): Conv3d(32, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1))
      )
    )
  )
) 
2025-01-24 12:00:04.699555: 
 
2025-01-24 12:00:04.701879: Unable to plot network architecture: nnUNet_compile is enabled! 
2025-01-24 12:00:04.930708:  
2025-01-24 12:00:04.933555: Epoch 0 
2025-01-24 12:00:04.936379: Current learning rate: 0.01 
2025-01-24 12:02:25.547672: train_loss 0.0638 
2025-01-24 12:02:25.596398: val_loss -0.054 
2025-01-24 12:02:25.599163: Pseudo dice [np.float32(0.0), np.float32(0.0)] 
2025-01-24 12:02:25.601715: Epoch time: 140.62 s 
2025-01-24 12:02:25.604073: Yayy! New best EMA pseudo Dice: 0.0 
2025-01-24 12:02:28.102748:  
2025-01-24 12:02:28.105356: Epoch 1 
2025-01-24 12:02:28.107918: Current learning rate: 0.00999 
2025-01-24 12:03:17.110948: train_loss -0.2537 
2025-01-24 12:03:17.117731: val_loss -0.2897 
2025-01-24 12:03:17.120554: Pseudo dice [np.float32(0.7792), np.float32(0.0)] 
2025-01-24 12:03:17.123005: Epoch time: 49.01 s 
2025-01-24 12:03:17.125295: Yayy! New best EMA pseudo Dice: 0.039000000804662704 
2025-01-24 12:03:18.890839:  
2025-01-24 12:03:18.893454: Epoch 2 
2025-01-24 12:03:18.895891: Current learning rate: 0.00998 
2025-01-24 12:04:07.619620: train_loss -0.3661 
2025-01-24 12:04:07.629868: val_loss -0.3649 
2025-01-24 12:04:07.632517: Pseudo dice [np.float32(0.8033), np.float32(0.2851)] 
2025-01-24 12:04:07.635035: Epoch time: 48.73 s 
2025-01-24 12:04:07.637588: Yayy! New best EMA pseudo Dice: 0.08950000256299973 
2025-01-24 12:04:09.449172:  
2025-01-24 12:04:09.451721: Epoch 3 
2025-01-24 12:04:09.454444: Current learning rate: 0.00997 
2025-01-24 12:04:57.923413: train_loss -0.4077 
2025-01-24 12:04:57.930734: val_loss -0.3761 
2025-01-24 12:04:57.933245: Pseudo dice [np.float32(0.8083), np.float32(0.314)] 
2025-01-24 12:04:57.936079: Epoch time: 48.48 s 
2025-01-24 12:04:57.938914: Yayy! New best EMA pseudo Dice: 0.13670000433921814 
2025-01-24 12:04:59.742059:  
2025-01-24 12:04:59.744987: Epoch 4 
2025-01-24 12:04:59.747745: Current learning rate: 0.00996 
2025-01-24 12:05:48.109348: train_loss -0.4374 
2025-01-24 12:05:48.116098: val_loss -0.4338 
2025-01-24 12:05:48.118606: Pseudo dice [np.float32(0.8389), np.float32(0.4575)] 
2025-01-24 12:05:48.121155: Epoch time: 48.37 s 
2025-01-24 12:05:48.123458: Yayy! New best EMA pseudo Dice: 0.18780000507831573 
2025-01-24 12:05:49.933763:  
2025-01-24 12:05:49.937207: Epoch 5 
2025-01-24 12:05:49.939924: Current learning rate: 0.00995 
2025-01-24 12:06:38.173159: train_loss -0.481 
2025-01-24 12:06:38.180054: val_loss -0.424 
2025-01-24 12:06:38.182777: Pseudo dice [np.float32(0.7811), np.float32(0.5328)] 
2025-01-24 12:06:38.185410: Epoch time: 48.24 s 
2025-01-24 12:06:38.188039: Yayy! New best EMA pseudo Dice: 0.23469999432563782 
2025-01-24 12:06:39.914889:  
2025-01-24 12:06:39.918982: Epoch 6 
2025-01-24 12:06:39.921706: Current learning rate: 0.00995 
2025-01-24 12:07:28.361301: train_loss -0.5009 
2025-01-24 12:07:28.366379: val_loss -0.3523 
2025-01-24 12:07:28.368963: Pseudo dice [np.float32(0.8039), np.float32(0.4019)] 
2025-01-24 12:07:28.371789: Epoch time: 48.45 s 
2025-01-24 12:07:28.374159: Yayy! New best EMA pseudo Dice: 0.27149999141693115 
2025-01-24 12:07:30.208016:  
2025-01-24 12:07:30.211107: Epoch 7 
2025-01-24 12:07:30.214076: Current learning rate: 0.00994 
2025-01-24 12:08:19.165188: train_loss -0.5002 
2025-01-24 12:08:19.171982: val_loss -0.4343 
2025-01-24 12:08:19.174421: Pseudo dice [np.float32(0.8339), np.float32(0.4911)] 
2025-01-24 12:08:19.176881: Epoch time: 48.96 s 
2025-01-24 12:08:19.179264: Yayy! New best EMA pseudo Dice: 0.31060001254081726 
2025-01-24 12:08:20.930947:  
2025-01-24 12:08:20.933857: Epoch 8 
2025-01-24 12:08:20.936755: Current learning rate: 0.00993 
2025-01-24 12:09:09.420097: train_loss -0.5361 
2025-01-24 12:09:09.426354: val_loss -0.4853 
2025-01-24 12:09:09.429026: Pseudo dice [np.float32(0.8527), np.float32(0.5631)] 
2025-01-24 12:09:09.431707: Epoch time: 48.49 s 
2025-01-24 12:09:09.434554: Yayy! New best EMA pseudo Dice: 0.35040000081062317 
2025-01-24 12:09:11.241682:  
2025-01-24 12:09:11.244405: Epoch 9 
2025-01-24 12:09:11.247161: Current learning rate: 0.00992 
2025-01-24 12:09:59.591346: train_loss -0.5367 
2025-01-24 12:09:59.599624: val_loss -0.4814 
2025-01-24 12:09:59.602669: Pseudo dice [np.float32(0.8532), np.float32(0.5484)] 
2025-01-24 12:09:59.605502: Epoch time: 48.35 s 
2025-01-24 12:09:59.608345: Yayy! New best EMA pseudo Dice: 0.3853999972343445 
2025-01-24 12:10:01.387946:  
2025-01-24 12:10:01.390724: Epoch 10 
2025-01-24 12:10:01.393505: Current learning rate: 0.00991 
2025-01-24 12:10:50.256768: train_loss -0.5673 
2025-01-24 12:10:50.264052: val_loss -0.5004 
2025-01-24 12:10:50.266794: Pseudo dice [np.float32(0.8357), np.float32(0.7095)] 
2025-01-24 12:10:50.269359: Epoch time: 48.87 s 
2025-01-24 12:10:50.272131: Yayy! New best EMA pseudo Dice: 0.42410001158714294 
2025-01-24 12:10:51.992111:  
2025-01-24 12:10:51.994932: Epoch 11 
2025-01-24 12:10:51.997721: Current learning rate: 0.0099 
2025-01-24 12:11:40.684870: train_loss -0.5654 
2025-01-24 12:11:40.692157: val_loss -0.545 
2025-01-24 12:11:40.694846: Pseudo dice [np.float32(0.8689), np.float32(0.606)] 
2025-01-24 12:11:40.697497: Epoch time: 48.69 s 
2025-01-24 12:11:40.700039: Yayy! New best EMA pseudo Dice: 0.4555000066757202 
2025-01-24 12:11:42.454020:  
2025-01-24 12:11:42.456719: Epoch 12 
2025-01-24 12:11:42.459466: Current learning rate: 0.00989 
2025-01-24 12:12:31.198876: train_loss -0.6015 
2025-01-24 12:12:31.205935: val_loss -0.5462 
2025-01-24 12:12:31.208685: Pseudo dice [np.float32(0.8713), np.float32(0.6934)] 
2025-01-24 12:12:31.211345: Epoch time: 48.75 s 
2025-01-24 12:12:31.214356: Yayy! New best EMA pseudo Dice: 0.48820000886917114 
2025-01-24 12:12:32.978643:  
2025-01-24 12:12:32.981507: Epoch 13 
2025-01-24 12:12:32.984079: Current learning rate: 0.00988 
2025-01-24 12:13:21.515104: train_loss -0.6152 
2025-01-24 12:13:21.523462: val_loss -0.4993 
2025-01-24 12:13:21.526205: Pseudo dice [np.float32(0.8832), np.float32(0.5224)] 
2025-01-24 12:13:21.528947: Epoch time: 48.54 s 
2025-01-24 12:13:21.531384: Yayy! New best EMA pseudo Dice: 0.5095999836921692 
2025-01-24 12:13:23.305976:  
2025-01-24 12:13:23.311119: Epoch 14 
2025-01-24 12:13:23.314117: Current learning rate: 0.00987 
2025-01-24 12:14:12.428342: train_loss -0.6206 
2025-01-24 12:14:12.434207: val_loss -0.5715 
2025-01-24 12:14:12.436689: Pseudo dice [np.float32(0.9085), np.float32(0.5133)] 
2025-01-24 12:14:12.438962: Epoch time: 49.12 s 
2025-01-24 12:14:12.441468: Yayy! New best EMA pseudo Dice: 0.529699981212616 
2025-01-24 12:14:14.242971:  
2025-01-24 12:14:14.245732: Epoch 15 
2025-01-24 12:14:14.248550: Current learning rate: 0.00986 
2025-01-24 12:15:03.342343: train_loss -0.6337 
2025-01-24 12:15:03.350035: val_loss -0.5749 
2025-01-24 12:15:03.353132: Pseudo dice [np.float32(0.8665), np.float32(0.7199)] 
2025-01-24 12:15:03.356552: Epoch time: 49.1 s 
2025-01-24 12:15:03.359736: Yayy! New best EMA pseudo Dice: 0.5561000108718872 
2025-01-24 12:15:05.158297:  
2025-01-24 12:15:05.161480: Epoch 16 
2025-01-24 12:15:05.165002: Current learning rate: 0.00986 
2025-01-24 12:15:54.104543: train_loss -0.603 
2025-01-24 12:15:54.110959: val_loss -0.5299 
2025-01-24 12:15:54.113601: Pseudo dice [np.float32(0.8432), np.float32(0.6761)] 
2025-01-24 12:15:54.116261: Epoch time: 48.95 s 
2025-01-24 12:15:54.118648: Yayy! New best EMA pseudo Dice: 0.5763999819755554 
2025-01-24 12:15:55.944128:  
2025-01-24 12:15:55.946841: Epoch 17 
2025-01-24 12:15:55.949358: Current learning rate: 0.00985 
2025-01-24 12:16:44.717843: train_loss -0.5917 
2025-01-24 12:16:44.724868: val_loss -0.5592 
2025-01-24 12:16:44.727531: Pseudo dice [np.float32(0.8835), np.float32(0.7546)] 
2025-01-24 12:16:44.729776: Epoch time: 48.77 s 
2025-01-24 12:16:44.732186: Yayy! New best EMA pseudo Dice: 0.6007000207901001 
2025-01-24 12:16:47.440985:  
2025-01-24 12:16:47.444501: Epoch 18 
2025-01-24 12:16:47.447441: Current learning rate: 0.00984 
2025-01-24 12:17:35.949147: train_loss -0.6205 
2025-01-24 12:17:35.955530: val_loss -0.5538 
2025-01-24 12:17:35.958034: Pseudo dice [np.float32(0.8865), np.float32(0.7167)] 
2025-01-24 12:17:35.960667: Epoch time: 48.51 s 
2025-01-24 12:17:35.963229: Yayy! New best EMA pseudo Dice: 0.6208000183105469 
2025-01-24 12:17:37.795438:  
2025-01-24 12:17:37.797915: Epoch 19 
2025-01-24 12:17:37.800371: Current learning rate: 0.00983 
2025-01-24 12:18:26.706891: train_loss -0.6352 
2025-01-24 12:18:26.715121: val_loss -0.5789 
2025-01-24 12:18:26.717810: Pseudo dice [np.float32(0.857), np.float32(0.7392)] 
2025-01-24 12:18:26.720432: Epoch time: 48.91 s 
2025-01-24 12:18:26.722894: Yayy! New best EMA pseudo Dice: 0.6384999752044678 
2025-01-24 12:18:28.529612:  
2025-01-24 12:18:28.532559: Epoch 20 
2025-01-24 12:18:28.536523: Current learning rate: 0.00982 
2025-01-24 12:19:17.344367: train_loss -0.6277 
2025-01-24 12:19:17.351213: val_loss -0.5793 
2025-01-24 12:19:17.353742: Pseudo dice [np.float32(0.888), np.float32(0.7476)] 
2025-01-24 12:19:17.356449: Epoch time: 48.82 s 
2025-01-24 12:19:17.359176: Yayy! New best EMA pseudo Dice: 0.6564000248908997 
2025-01-24 12:19:19.201515:  
2025-01-24 12:19:19.204853: Epoch 21 
2025-01-24 12:19:19.207836: Current learning rate: 0.00981 
2025-01-24 12:20:07.862416: train_loss -0.6588 
2025-01-24 12:20:07.870878: val_loss -0.5808 
2025-01-24 12:20:07.873701: Pseudo dice [np.float32(0.868), np.float32(0.7891)] 
2025-01-24 12:20:07.876821: Epoch time: 48.66 s 
2025-01-24 12:20:07.879499: Yayy! New best EMA pseudo Dice: 0.6736999750137329 
2025-01-24 12:20:09.635559:  
2025-01-24 12:20:09.638993: Epoch 22 
2025-01-24 12:20:09.641731: Current learning rate: 0.0098 
2025-01-24 12:20:57.875943: train_loss -0.6644 
2025-01-24 12:20:57.882417: val_loss -0.5933 
2025-01-24 12:20:57.885060: Pseudo dice [np.float32(0.8965), np.float32(0.6876)] 
2025-01-24 12:20:57.887812: Epoch time: 48.24 s 
2025-01-24 12:20:57.890224: Yayy! New best EMA pseudo Dice: 0.6855000257492065 
2025-01-24 12:20:59.633737:  
2025-01-24 12:20:59.636494: Epoch 23 
2025-01-24 12:20:59.639208: Current learning rate: 0.00979 
2025-01-24 12:21:48.069472: train_loss -0.6757 
2025-01-24 12:21:48.077514: val_loss -0.6135 
2025-01-24 12:21:48.080853: Pseudo dice [np.float32(0.902), np.float32(0.7865)] 
2025-01-24 12:21:48.083639: Epoch time: 48.44 s 
2025-01-24 12:21:48.086479: Yayy! New best EMA pseudo Dice: 0.7013999819755554 
2025-01-24 12:21:49.842730:  
2025-01-24 12:21:49.846163: Epoch 24 
2025-01-24 12:21:49.848864: Current learning rate: 0.00978 
2025-01-24 12:22:38.508140: train_loss -0.689 
2025-01-24 12:22:38.514333: val_loss -0.6279 
2025-01-24 12:22:38.517661: Pseudo dice [np.float32(0.8989), np.float32(0.8264)] 
2025-01-24 12:22:38.520490: Epoch time: 48.67 s 
2025-01-24 12:22:38.523789: Yayy! New best EMA pseudo Dice: 0.7174999713897705 
2025-01-24 12:22:40.340587:  
2025-01-24 12:22:40.344201: Epoch 25 
2025-01-24 12:22:40.347136: Current learning rate: 0.00977 
2025-01-24 12:23:29.181612: train_loss -0.693 
2025-01-24 12:23:29.189132: val_loss -0.598 
2025-01-24 12:23:29.192085: Pseudo dice [np.float32(0.8826), np.float32(0.7836)] 
2025-01-24 12:23:29.194788: Epoch time: 48.84 s 
2025-01-24 12:23:29.197520: Yayy! New best EMA pseudo Dice: 0.7290999889373779 
2025-01-24 12:23:30.963382:  
2025-01-24 12:23:30.966860: Epoch 26 
2025-01-24 12:23:30.969947: Current learning rate: 0.00977 
2025-01-24 12:24:20.139205: train_loss -0.6901 
2025-01-24 12:24:20.145729: val_loss -0.6641 
2025-01-24 12:24:20.148852: Pseudo dice [np.float32(0.9092), np.float32(0.7625)] 
2025-01-24 12:24:20.151354: Epoch time: 49.18 s 
2025-01-24 12:24:20.154011: Yayy! New best EMA pseudo Dice: 0.7397000193595886 
2025-01-24 12:24:21.941661:  
2025-01-24 12:24:21.944549: Epoch 27 
2025-01-24 12:24:21.947563: Current learning rate: 0.00976 
2025-01-24 12:25:11.008510: train_loss -0.6898 
2025-01-24 12:25:11.014040: val_loss -0.6272 
2025-01-24 12:25:11.017281: Pseudo dice [np.float32(0.8883), np.float32(0.7551)] 
2025-01-24 12:25:11.020122: Epoch time: 49.07 s 
2025-01-24 12:25:11.022889: Yayy! New best EMA pseudo Dice: 0.7479000091552734 
2025-01-24 12:25:12.832868:  
2025-01-24 12:25:12.836026: Epoch 28 
2025-01-24 12:25:12.838825: Current learning rate: 0.00975 
2025-01-24 12:26:01.474199: train_loss -0.6958 
2025-01-24 12:26:01.479697: val_loss -0.6271 
2025-01-24 12:26:01.482380: Pseudo dice [np.float32(0.9021), np.float32(0.6888)] 
2025-01-24 12:26:01.484889: Epoch time: 48.64 s 
2025-01-24 12:26:01.487505: Yayy! New best EMA pseudo Dice: 0.7526999711990356 
2025-01-24 12:26:03.309620:  
2025-01-24 12:26:03.312798: Epoch 29 
2025-01-24 12:26:03.315681: Current learning rate: 0.00974 
2025-01-24 12:26:52.454780: train_loss -0.6946 
2025-01-24 12:26:52.460526: val_loss -0.598 
2025-01-24 12:26:52.463142: Pseudo dice [np.float32(0.8667), np.float32(0.7492)] 
2025-01-24 12:26:52.465945: Epoch time: 49.15 s 
2025-01-24 12:26:52.468550: Yayy! New best EMA pseudo Dice: 0.7581999897956848 
2025-01-24 12:26:54.244134:  
2025-01-24 12:26:54.247274: Epoch 30 
2025-01-24 12:26:54.249943: Current learning rate: 0.00973 
2025-01-24 12:27:43.168051: train_loss -0.6984 
2025-01-24 12:27:43.175248: val_loss -0.6109 
2025-01-24 12:27:43.178260: Pseudo dice [np.float32(0.8956), np.float32(0.6781)] 
2025-01-24 12:27:43.180993: Epoch time: 48.93 s 
2025-01-24 12:27:43.183525: Yayy! New best EMA pseudo Dice: 0.7610999941825867 
2025-01-24 12:27:45.000180:  
2025-01-24 12:27:45.003112: Epoch 31 
2025-01-24 12:27:45.006052: Current learning rate: 0.00972 
2025-01-24 12:28:34.209515: train_loss -0.7002 
2025-01-24 12:28:34.215449: val_loss -0.5975 
2025-01-24 12:28:34.218678: Pseudo dice [np.float32(0.8915), np.float32(0.7531)] 
2025-01-24 12:28:34.221778: Epoch time: 49.21 s 
2025-01-24 12:28:34.224611: Yayy! New best EMA pseudo Dice: 0.7671999931335449 
2025-01-24 12:28:36.031861:  
2025-01-24 12:28:36.035603: Epoch 32 
2025-01-24 12:28:36.038650: Current learning rate: 0.00971 
2025-01-24 12:29:24.714034: train_loss -0.6994 
2025-01-24 12:29:24.720378: val_loss -0.6616 
2025-01-24 12:29:24.723204: Pseudo dice [np.float32(0.894), np.float32(0.725)] 
2025-01-24 12:29:24.725849: Epoch time: 48.68 s 
2025-01-24 12:29:24.728537: Yayy! New best EMA pseudo Dice: 0.771399974822998 
2025-01-24 12:29:26.568928:  
2025-01-24 12:29:26.572100: Epoch 33 
2025-01-24 12:29:26.575039: Current learning rate: 0.0097 
2025-01-24 12:30:15.176937: train_loss -0.7061 
2025-01-24 12:30:15.184718: val_loss -0.6996 
2025-01-24 12:30:15.187878: Pseudo dice [np.float32(0.8937), np.float32(0.8161)] 
2025-01-24 12:30:15.191059: Epoch time: 48.61 s 
2025-01-24 12:30:15.193847: Yayy! New best EMA pseudo Dice: 0.7797999978065491 
2025-01-24 12:30:16.990813:  
2025-01-24 12:30:16.993732: Epoch 34 
2025-01-24 12:30:16.996568: Current learning rate: 0.00969 
2025-01-24 12:31:05.642292: train_loss -0.7257 
2025-01-24 12:31:05.647587: val_loss -0.6575 
2025-01-24 12:31:05.650404: Pseudo dice [np.float32(0.9163), np.float32(0.8061)] 
2025-01-24 12:31:05.652899: Epoch time: 48.65 s 
2025-01-24 12:31:05.655300: Yayy! New best EMA pseudo Dice: 0.7878999710083008 
2025-01-24 12:31:07.481249:  
2025-01-24 12:31:07.484172: Epoch 35 
2025-01-24 12:31:07.487079: Current learning rate: 0.00968 
2025-01-24 12:31:56.032418: train_loss -0.6956 
2025-01-24 12:31:56.037326: val_loss -0.5079 
2025-01-24 12:31:56.040068: Pseudo dice [np.float32(0.9039), np.float32(0.4519)] 
2025-01-24 12:31:56.042675: Epoch time: 48.55 s 
2025-01-24 12:31:57.985925:  
2025-01-24 12:31:57.989046: Epoch 36 
2025-01-24 12:31:57.991891: Current learning rate: 0.00968 
2025-01-24 12:32:46.241668: train_loss -0.7005 
2025-01-24 12:32:46.247201: val_loss -0.6708 
2025-01-24 12:32:46.249782: Pseudo dice [np.float32(0.8965), np.float32(0.818)] 
2025-01-24 12:32:46.252267: Epoch time: 48.26 s 
2025-01-24 12:32:47.493031:  
2025-01-24 12:32:47.496105: Epoch 37 
2025-01-24 12:32:47.498701: Current learning rate: 0.00967 
2025-01-24 12:33:36.176273: train_loss -0.7264 
2025-01-24 12:33:36.181609: val_loss -0.6879 
2025-01-24 12:33:36.184309: Pseudo dice [np.float32(0.9336), np.float32(0.8393)] 
2025-01-24 12:33:36.186867: Epoch time: 48.68 s 
2025-01-24 12:33:36.189319: Yayy! New best EMA pseudo Dice: 0.7950999736785889 
2025-01-24 12:33:38.023094:  
2025-01-24 12:33:38.026075: Epoch 38 
2025-01-24 12:33:38.028633: Current learning rate: 0.00966 
2025-01-24 12:34:26.585636: train_loss -0.7341 
2025-01-24 12:34:26.591512: val_loss -0.6877 
2025-01-24 12:34:26.594554: Pseudo dice [np.float32(0.9013), np.float32(0.872)] 
2025-01-24 12:34:26.597522: Epoch time: 48.56 s 
2025-01-24 12:34:26.600069: Yayy! New best EMA pseudo Dice: 0.8043000102043152 
2025-01-24 12:34:28.490667:  
2025-01-24 12:34:28.493707: Epoch 39 
2025-01-24 12:34:28.496665: Current learning rate: 0.00965 
2025-01-24 12:35:17.684604: train_loss -0.7143 
2025-01-24 12:35:17.689587: val_loss -0.6604 
2025-01-24 12:35:17.691881: Pseudo dice [np.float32(0.9175), np.float32(0.8431)] 
2025-01-24 12:35:17.694208: Epoch time: 49.2 s 
2025-01-24 12:35:17.696645: Yayy! New best EMA pseudo Dice: 0.8119000196456909 
2025-01-24 12:35:19.568226:  
2025-01-24 12:35:19.571621: Epoch 40 
2025-01-24 12:35:19.574730: Current learning rate: 0.00964 
2025-01-24 12:36:08.561530: train_loss -0.7276 
2025-01-24 12:36:08.567140: val_loss -0.6482 
2025-01-24 12:36:08.569778: Pseudo dice [np.float32(0.8847), np.float32(0.805)] 
2025-01-24 12:36:08.572191: Epoch time: 49.0 s 
2025-01-24 12:36:08.574571: Yayy! New best EMA pseudo Dice: 0.8151999711990356 
2025-01-24 12:36:10.405234:  
2025-01-24 12:36:10.408059: Epoch 41 
2025-01-24 12:36:10.410586: Current learning rate: 0.00963 
2025-01-24 12:36:59.134535: train_loss -0.7409 
2025-01-24 12:36:59.140066: val_loss -0.6408 
2025-01-24 12:36:59.142849: Pseudo dice [np.float32(0.8869), np.float32(0.8076)] 
2025-01-24 12:36:59.145327: Epoch time: 48.73 s 
2025-01-24 12:36:59.147782: Yayy! New best EMA pseudo Dice: 0.8184000253677368 
2025-01-24 12:37:00.923286:  
2025-01-24 12:37:00.926415: Epoch 42 
2025-01-24 12:37:00.929396: Current learning rate: 0.00962 
2025-01-24 12:37:49.733533: train_loss -0.717 
2025-01-24 12:37:49.737967: val_loss -0.6564 
2025-01-24 12:37:49.740745: Pseudo dice [np.float32(0.9022), np.float32(0.8525)] 
2025-01-24 12:37:49.743062: Epoch time: 48.81 s 
2025-01-24 12:37:49.745299: Yayy! New best EMA pseudo Dice: 0.8242999911308289 
2025-01-24 12:37:51.557879:  
2025-01-24 12:37:51.560895: Epoch 43 
2025-01-24 12:37:51.563721: Current learning rate: 0.00961 
2025-01-24 12:38:40.367171: train_loss -0.7329 
2025-01-24 12:38:40.374204: val_loss -0.6545 
2025-01-24 12:38:40.377135: Pseudo dice [np.float32(0.9247), np.float32(0.7967)] 
2025-01-24 12:38:40.379736: Epoch time: 48.81 s 
2025-01-24 12:38:40.382330: Yayy! New best EMA pseudo Dice: 0.8278999924659729 
2025-01-24 12:38:42.204264:  
2025-01-24 12:38:42.207323: Epoch 44 
2025-01-24 12:38:42.210343: Current learning rate: 0.0096 
2025-01-24 12:39:31.105597: train_loss -0.7227 
2025-01-24 12:39:31.111081: val_loss -0.6157 
2025-01-24 12:39:31.113684: Pseudo dice [np.float32(0.8945), np.float32(0.772)] 
2025-01-24 12:39:31.116215: Epoch time: 48.9 s 
2025-01-24 12:39:31.118446: Yayy! New best EMA pseudo Dice: 0.8284000158309937 
2025-01-24 12:39:32.895689:  
2025-01-24 12:39:32.898697: Epoch 45 
2025-01-24 12:39:32.901604: Current learning rate: 0.00959 
2025-01-24 12:40:21.107876: train_loss -0.7231 
2025-01-24 12:40:21.114623: val_loss -0.6574 
2025-01-24 12:40:21.117416: Pseudo dice [np.float32(0.9182), np.float32(0.8237)] 
2025-01-24 12:40:21.119867: Epoch time: 48.21 s 
2025-01-24 12:40:21.122194: Yayy! New best EMA pseudo Dice: 0.8327000141143799 
2025-01-24 12:40:22.842511:  
2025-01-24 12:40:22.845384: Epoch 46 
2025-01-24 12:40:22.848267: Current learning rate: 0.00959 
2025-01-24 12:41:11.104011: train_loss -0.7187 
2025-01-24 12:41:11.108743: val_loss -0.6568 
2025-01-24 12:41:11.111332: Pseudo dice [np.float32(0.9159), np.float32(0.8241)] 
2025-01-24 12:41:11.114719: Epoch time: 48.26 s 
2025-01-24 12:41:11.117242: Yayy! New best EMA pseudo Dice: 0.8363999724388123 
2025-01-24 12:41:12.849592:  
2025-01-24 12:41:12.852511: Epoch 47 
2025-01-24 12:41:12.857514: Current learning rate: 0.00958 
2025-01-24 12:42:01.746698: train_loss -0.7387 
2025-01-24 12:42:01.752534: val_loss -0.6446 
2025-01-24 12:42:01.755686: Pseudo dice [np.float32(0.9142), np.float32(0.8864)] 
2025-01-24 12:42:01.758468: Epoch time: 48.9 s 
2025-01-24 12:42:01.761138: Yayy! New best EMA pseudo Dice: 0.8428000211715698 
2025-01-24 12:42:03.585581:  
2025-01-24 12:42:03.588195: Epoch 48 
2025-01-24 12:42:03.590732: Current learning rate: 0.00957 
2025-01-24 12:42:52.358030: train_loss -0.7212 
2025-01-24 12:42:52.363703: val_loss -0.7 
2025-01-24 12:42:52.366650: Pseudo dice [np.float32(0.9203), np.float32(0.8461)] 
2025-01-24 12:42:52.369665: Epoch time: 48.77 s 
2025-01-24 12:42:52.372269: Yayy! New best EMA pseudo Dice: 0.8468999862670898 
2025-01-24 12:42:54.156278:  
2025-01-24 12:42:54.159733: Epoch 49 
2025-01-24 12:42:54.162963: Current learning rate: 0.00956 
2025-01-24 12:43:42.969342: train_loss -0.7327 
2025-01-24 12:43:42.974689: val_loss -0.6905 
2025-01-24 12:43:42.977463: Pseudo dice [np.float32(0.9308), np.float32(0.8533)] 
2025-01-24 12:43:42.980070: Epoch time: 48.81 s 
2025-01-24 12:43:43.510243: Yayy! New best EMA pseudo Dice: 0.8514000177383423 
2025-01-24 12:43:45.268872:  
2025-01-24 12:43:45.272425: Epoch 50 
2025-01-24 12:43:45.275047: Current learning rate: 0.00955 
2025-01-24 12:44:33.789303: train_loss -0.7371 
2025-01-24 12:44:33.795056: val_loss -0.6655 
2025-01-24 12:44:33.797983: Pseudo dice [np.float32(0.9199), np.float32(0.8043)] 
2025-01-24 12:44:33.800662: Epoch time: 48.52 s 
2025-01-24 12:44:33.803483: Yayy! New best EMA pseudo Dice: 0.852400004863739 
2025-01-24 12:44:35.621279:  
2025-01-24 12:44:35.624894: Epoch 51 
2025-01-24 12:44:35.628281: Current learning rate: 0.00954 
2025-01-24 12:45:23.893297: train_loss -0.7538 
2025-01-24 12:45:23.900789: val_loss -0.689 
2025-01-24 12:45:23.903852: Pseudo dice [np.float32(0.9337), np.float32(0.8059)] 
2025-01-24 12:45:23.906788: Epoch time: 48.27 s 
2025-01-24 12:45:23.909560: Yayy! New best EMA pseudo Dice: 0.854200005531311 
2025-01-24 12:45:25.740330:  
2025-01-24 12:45:25.743293: Epoch 52 
2025-01-24 12:45:25.746105: Current learning rate: 0.00953 
2025-01-24 12:46:14.141731: train_loss -0.7524 
2025-01-24 12:46:14.147811: val_loss -0.6665 
2025-01-24 12:46:14.150772: Pseudo dice [np.float32(0.8861), np.float32(0.753)] 
2025-01-24 12:46:14.153864: Epoch time: 48.4 s 
2025-01-24 12:46:15.334346:  
2025-01-24 12:46:15.337758: Epoch 53 
2025-01-24 12:46:15.340575: Current learning rate: 0.00952 
2025-01-24 12:47:03.465709: train_loss -0.7213 
2025-01-24 12:47:03.473779: val_loss -0.7149 
2025-01-24 12:47:03.476972: Pseudo dice [np.float32(0.9119), np.float32(0.8336)] 
2025-01-24 12:47:03.480083: Epoch time: 48.13 s 
2025-01-24 12:47:05.479956:  
2025-01-24 12:47:05.483513: Epoch 54 
2025-01-24 12:47:05.486927: Current learning rate: 0.00951 
2025-01-24 12:47:55.148179: train_loss -0.7214 
2025-01-24 12:47:55.155364: val_loss -0.6172 
2025-01-24 12:47:55.158774: Pseudo dice [np.float32(0.9157), np.float32(0.7259)] 
2025-01-24 12:47:55.161643: Epoch time: 49.67 s 
2025-01-24 12:47:56.345869:  
2025-01-24 12:47:56.348948: Epoch 55 
2025-01-24 12:47:56.351763: Current learning rate: 0.0095 
2025-01-24 12:48:45.536370: train_loss -0.7348 
2025-01-24 12:48:45.541650: val_loss -0.6538 
2025-01-24 12:48:45.544816: Pseudo dice [np.float32(0.9053), np.float32(0.8386)] 
2025-01-24 12:48:45.547644: Epoch time: 49.19 s 
2025-01-24 12:48:46.736926:  
2025-01-24 12:48:46.740118: Epoch 56 
2025-01-24 12:48:46.742957: Current learning rate: 0.00949 
2025-01-24 12:49:35.762713: train_loss -0.7548 
2025-01-24 12:49:35.770601: val_loss -0.7084 
2025-01-24 12:49:35.773682: Pseudo dice [np.float32(0.9337), np.float32(0.8739)] 
2025-01-24 12:49:35.776382: Epoch time: 49.03 s 
2025-01-24 12:49:35.778814: Yayy! New best EMA pseudo Dice: 0.8571000099182129 
2025-01-24 12:49:37.524370:  
2025-01-24 12:49:37.527345: Epoch 57 
2025-01-24 12:49:37.530054: Current learning rate: 0.00949 
2025-01-24 12:50:25.925625: train_loss -0.7517 
2025-01-24 12:50:25.930470: val_loss -0.6617 
2025-01-24 12:50:25.933002: Pseudo dice [np.float32(0.9161), np.float32(0.8561)] 
2025-01-24 12:50:25.935534: Epoch time: 48.4 s 
2025-01-24 12:50:25.938135: Yayy! New best EMA pseudo Dice: 0.8600000143051147 
2025-01-24 12:50:27.669052:  
2025-01-24 12:50:27.672051: Epoch 58 
2025-01-24 12:50:27.674801: Current learning rate: 0.00948 
2025-01-24 12:51:16.826206: train_loss -0.7457 
2025-01-24 12:51:16.831509: val_loss -0.6843 
2025-01-24 12:51:16.834489: Pseudo dice [np.float32(0.9204), np.float32(0.8549)] 
2025-01-24 12:51:16.837320: Epoch time: 49.16 s 
2025-01-24 12:51:16.839896: Yayy! New best EMA pseudo Dice: 0.8628000020980835 
2025-01-24 12:51:18.611753:  
2025-01-24 12:51:18.615061: Epoch 59 
2025-01-24 12:51:18.618129: Current learning rate: 0.00947 
2025-01-24 12:52:07.451856: train_loss -0.7436 
2025-01-24 12:52:07.457341: val_loss -0.689 
2025-01-24 12:52:07.460429: Pseudo dice [np.float32(0.9286), np.float32(0.8661)] 
2025-01-24 12:52:07.463176: Epoch time: 48.84 s 
2025-01-24 12:52:07.466013: Yayy! New best EMA pseudo Dice: 0.8661999702453613 
2025-01-24 12:52:09.351579:  
2025-01-24 12:52:09.354453: Epoch 60 
2025-01-24 12:52:09.357484: Current learning rate: 0.00946 
2025-01-24 12:52:58.105907: train_loss -0.7424 
2025-01-24 12:52:58.111505: val_loss -0.7312 
2025-01-24 12:52:58.114564: Pseudo dice [np.float32(0.9324), np.float32(0.8828)] 
2025-01-24 12:52:58.117357: Epoch time: 48.76 s 
2025-01-24 12:52:58.119912: Yayy! New best EMA pseudo Dice: 0.8704000115394592 
2025-01-24 12:52:59.919055:  
2025-01-24 12:52:59.922116: Epoch 61 
2025-01-24 12:52:59.925105: Current learning rate: 0.00945 
2025-01-24 12:53:48.266555: train_loss -0.7622 
2025-01-24 12:53:48.272359: val_loss -0.7036 
2025-01-24 12:53:48.275033: Pseudo dice [np.float32(0.9274), np.float32(0.8799)] 
2025-01-24 12:53:48.277697: Epoch time: 48.35 s 
2025-01-24 12:53:48.280277: Yayy! New best EMA pseudo Dice: 0.8737000226974487 
2025-01-24 12:53:50.111094:  
2025-01-24 12:53:50.114561: Epoch 62 
2025-01-24 12:53:50.117585: Current learning rate: 0.00944 
2025-01-24 12:54:38.829744: train_loss -0.7482 
2025-01-24 12:54:38.835326: val_loss -0.726 
2025-01-24 12:54:38.838446: Pseudo dice [np.float32(0.9309), np.float32(0.8907)] 
2025-01-24 12:54:38.841439: Epoch time: 48.72 s 
2025-01-24 12:54:38.844258: Yayy! New best EMA pseudo Dice: 0.8773999810218811 
2025-01-24 12:54:40.662719:  
2025-01-24 12:54:40.666175: Epoch 63 
2025-01-24 12:54:40.669170: Current learning rate: 0.00943 
2025-01-24 12:55:29.607245: train_loss -0.7691 
2025-01-24 12:55:29.613091: val_loss -0.7053 
2025-01-24 12:55:29.616696: Pseudo dice [np.float32(0.9349), np.float32(0.8757)] 
2025-01-24 12:55:29.619753: Epoch time: 48.95 s 
2025-01-24 12:55:29.622814: Yayy! New best EMA pseudo Dice: 0.8802000284194946 
2025-01-24 12:55:31.424473:  
2025-01-24 12:55:31.427825: Epoch 64 
2025-01-24 12:55:31.430833: Current learning rate: 0.00942 
2025-01-24 12:56:20.746103: train_loss -0.766 
2025-01-24 12:56:20.751698: val_loss -0.6966 
2025-01-24 12:56:20.754671: Pseudo dice [np.float32(0.9382), np.float32(0.8017)] 
2025-01-24 12:56:20.757875: Epoch time: 49.32 s 
2025-01-24 12:56:21.994267:  
2025-01-24 12:56:21.997556: Epoch 65 
2025-01-24 12:56:22.000855: Current learning rate: 0.00941 
2025-01-24 12:57:10.483063: train_loss -0.7574 
2025-01-24 12:57:10.489187: val_loss -0.6588 
2025-01-24 12:57:10.492183: Pseudo dice [np.float32(0.9129), np.float32(0.8467)] 
2025-01-24 12:57:10.495012: Epoch time: 48.49 s 
2025-01-24 12:57:11.696589:  
2025-01-24 12:57:11.699526: Epoch 66 
2025-01-24 12:57:11.702163: Current learning rate: 0.0094 
2025-01-24 12:58:00.693190: train_loss -0.7819 
2025-01-24 12:58:00.701151: val_loss -0.688 
2025-01-24 12:58:00.703991: Pseudo dice [np.float32(0.9372), np.float32(0.8491)] 
2025-01-24 12:58:00.706555: Epoch time: 49.0 s 
2025-01-24 12:58:00.709146: Yayy! New best EMA pseudo Dice: 0.8805999755859375 
2025-01-24 12:58:02.496583:  
2025-01-24 12:58:02.499831: Epoch 67 
2025-01-24 12:58:02.502692: Current learning rate: 0.00939 
2025-01-24 12:58:51.432859: train_loss -0.7387 
2025-01-24 12:58:51.438059: val_loss -0.7296 
2025-01-24 12:58:51.440851: Pseudo dice [np.float32(0.9445), np.float32(0.8766)] 
2025-01-24 12:58:51.443843: Epoch time: 48.94 s 
2025-01-24 12:58:51.446310: Yayy! New best EMA pseudo Dice: 0.8835999965667725 
2025-01-24 12:58:53.326845:  
2025-01-24 12:58:53.329848: Epoch 68 
2025-01-24 12:58:53.332705: Current learning rate: 0.00939 
2025-01-24 12:59:42.500130: train_loss -0.7676 
2025-01-24 12:59:42.505331: val_loss -0.6531 
2025-01-24 12:59:42.508151: Pseudo dice [np.float32(0.9268), np.float32(0.7652)] 
2025-01-24 12:59:42.510822: Epoch time: 49.17 s 
2025-01-24 12:59:43.724982:  
2025-01-24 12:59:43.728797: Epoch 69 
2025-01-24 12:59:43.731759: Current learning rate: 0.00938 
2025-01-24 13:00:32.667674: train_loss -0.7595 
2025-01-24 13:00:32.672410: val_loss -0.6952 
2025-01-24 13:00:32.674688: Pseudo dice [np.float32(0.9181), np.float32(0.8766)] 
2025-01-24 13:00:32.677328: Epoch time: 48.94 s 
2025-01-24 13:00:33.878897:  
2025-01-24 13:00:33.882066: Epoch 70 
2025-01-24 13:00:33.884948: Current learning rate: 0.00937 
2025-01-24 13:01:22.693251: train_loss -0.7481 
2025-01-24 13:01:22.699733: val_loss -0.6789 
2025-01-24 13:01:22.702703: Pseudo dice [np.float32(0.9174), np.float32(0.8676)] 
2025-01-24 13:01:22.705495: Epoch time: 48.82 s 
2025-01-24 13:01:23.931253:  
2025-01-24 13:01:23.933960: Epoch 71 
2025-01-24 13:01:23.936567: Current learning rate: 0.00936 
2025-01-24 13:02:12.847584: train_loss -0.7594 
2025-01-24 13:02:12.854405: val_loss -0.6711 
2025-01-24 13:02:12.857545: Pseudo dice [np.float32(0.9159), np.float32(0.8106)] 
2025-01-24 13:02:12.859953: Epoch time: 48.92 s 
2025-01-24 13:02:14.724247:  
2025-01-24 13:02:14.727641: Epoch 72 
2025-01-24 13:02:14.731042: Current learning rate: 0.00935 
2025-01-24 13:03:03.661823: train_loss -0.7377 
2025-01-24 13:03:03.668300: val_loss -0.6795 
2025-01-24 13:03:03.671069: Pseudo dice [np.float32(0.9247), np.float32(0.8414)] 
2025-01-24 13:03:03.674274: Epoch time: 48.94 s 
2025-01-24 13:03:04.891746:  
2025-01-24 13:03:04.894431: Epoch 73 
2025-01-24 13:03:04.897416: Current learning rate: 0.00934 
2025-01-24 13:03:53.569997: train_loss -0.7439 
2025-01-24 13:03:53.576597: val_loss -0.6963 
2025-01-24 13:03:53.579218: Pseudo dice [np.float32(0.9195), np.float32(0.7916)] 
2025-01-24 13:03:53.581578: Epoch time: 48.68 s 
2025-01-24 13:03:54.790480:  
2025-01-24 13:03:54.793312: Epoch 74 
2025-01-24 13:03:54.795787: Current learning rate: 0.00933 
2025-01-24 13:04:43.617855: train_loss -0.7591 
2025-01-24 13:04:43.625106: val_loss -0.6817 
2025-01-24 13:04:43.627804: Pseudo dice [np.float32(0.9059), np.float32(0.8224)] 
2025-01-24 13:04:43.630422: Epoch time: 48.83 s 
2025-01-24 13:04:44.846911:  
2025-01-24 13:04:44.850008: Epoch 75 
2025-01-24 13:04:44.853010: Current learning rate: 0.00932 
2025-01-24 13:05:33.496433: train_loss -0.7714 
2025-01-24 13:05:33.501106: val_loss -0.6957 
2025-01-24 13:05:33.504312: Pseudo dice [np.float32(0.9076), np.float32(0.8323)] 
2025-01-24 13:05:33.507127: Epoch time: 48.65 s 
2025-01-24 13:05:34.735327:  
2025-01-24 13:05:34.738523: Epoch 76 
2025-01-24 13:05:34.741572: Current learning rate: 0.00931 
2025-01-24 13:06:23.619485: train_loss -0.7734 
2025-01-24 13:06:23.625102: val_loss -0.6691 
2025-01-24 13:06:23.627909: Pseudo dice [np.float32(0.9371), np.float32(0.7756)] 
2025-01-24 13:06:23.631238: Epoch time: 48.89 s 
2025-01-24 13:06:24.863118:  
2025-01-24 13:06:24.866129: Epoch 77 
2025-01-24 13:06:24.869211: Current learning rate: 0.0093 
2025-01-24 13:07:13.272444: train_loss -0.7719 
2025-01-24 13:07:13.277452: val_loss -0.607 
2025-01-24 13:07:13.280264: Pseudo dice [np.float32(0.861), np.float32(0.7707)] 
2025-01-24 13:07:13.283312: Epoch time: 48.41 s 
2025-01-24 13:07:14.526884:  
2025-01-24 13:07:14.529733: Epoch 78 
2025-01-24 13:07:14.532359: Current learning rate: 0.0093 
2025-01-24 13:08:03.199712: train_loss -0.7617 
2025-01-24 13:08:03.206677: val_loss -0.7291 
2025-01-24 13:08:03.209552: Pseudo dice [np.float32(0.9283), np.float32(0.9078)] 
2025-01-24 13:08:03.212284: Epoch time: 48.67 s 
2025-01-24 13:08:04.443173:  
2025-01-24 13:08:04.446362: Epoch 79 
2025-01-24 13:08:04.449003: Current learning rate: 0.00929 
2025-01-24 13:08:52.718473: train_loss -0.7604 
2025-01-24 13:08:52.725378: val_loss -0.7329 
2025-01-24 13:08:52.728136: Pseudo dice [np.float32(0.9207), np.float32(0.8867)] 
2025-01-24 13:08:52.731230: Epoch time: 48.28 s 
2025-01-24 13:08:54.008867:  
2025-01-24 13:08:54.011933: Epoch 80 
2025-01-24 13:08:54.014826: Current learning rate: 0.00928 
2025-01-24 13:09:42.369265: train_loss -0.7809 
2025-01-24 13:09:42.373861: val_loss -0.6956 
2025-01-24 13:09:42.376427: Pseudo dice [np.float32(0.9358), np.float32(0.8732)] 
2025-01-24 13:09:42.378893: Epoch time: 48.36 s 
2025-01-24 13:09:43.604217:  
2025-01-24 13:09:43.607803: Epoch 81 
2025-01-24 13:09:43.610455: Current learning rate: 0.00927 
2025-01-24 13:10:32.341008: train_loss -0.7666 
2025-01-24 13:10:32.347064: val_loss -0.6898 
2025-01-24 13:10:32.350059: Pseudo dice [np.float32(0.9203), np.float32(0.8699)] 
2025-01-24 13:10:32.353139: Epoch time: 48.74 s 
2025-01-24 13:10:33.589396:  
2025-01-24 13:10:33.592465: Epoch 82 
2025-01-24 13:10:33.595548: Current learning rate: 0.00926 
2025-01-24 13:11:22.380744: train_loss -0.7621 
2025-01-24 13:11:22.385814: val_loss -0.7241 
2025-01-24 13:11:22.388344: Pseudo dice [np.float32(0.9284), np.float32(0.9025)] 
2025-01-24 13:11:22.390630: Epoch time: 48.79 s 
2025-01-24 13:11:22.393003: Yayy! New best EMA pseudo Dice: 0.8842999935150146 
2025-01-24 13:11:24.192102:  
2025-01-24 13:11:24.196167: Epoch 83 
2025-01-24 13:11:24.199332: Current learning rate: 0.00925 
2025-01-24 13:12:13.195475: train_loss -0.7725 
2025-01-24 13:12:13.201358: val_loss -0.659 
2025-01-24 13:12:13.204246: Pseudo dice [np.float32(0.9197), np.float32(0.8738)] 
2025-01-24 13:12:13.207081: Epoch time: 49.0 s 
2025-01-24 13:12:13.210089: Yayy! New best EMA pseudo Dice: 0.8855000138282776 
2025-01-24 13:12:14.980285:  
2025-01-24 13:12:14.983307: Epoch 84 
2025-01-24 13:12:14.986337: Current learning rate: 0.00924 
2025-01-24 13:13:03.461704: train_loss -0.7588 
2025-01-24 13:13:03.467525: val_loss -0.6995 
2025-01-24 13:13:03.470509: Pseudo dice [np.float32(0.9146), np.float32(0.8083)] 
2025-01-24 13:13:03.473375: Epoch time: 48.48 s 
2025-01-24 13:13:04.634942:  
2025-01-24 13:13:04.637637: Epoch 85 
2025-01-24 13:13:04.640668: Current learning rate: 0.00923 
2025-01-24 13:13:53.719089: train_loss -0.7505 
2025-01-24 13:13:53.725146: val_loss -0.6614 
2025-01-24 13:13:53.728185: Pseudo dice [np.float32(0.928), np.float32(0.882)] 
2025-01-24 13:13:53.731250: Epoch time: 49.09 s 
2025-01-24 13:13:54.904883:  
2025-01-24 13:13:54.907877: Epoch 86 
2025-01-24 13:13:54.911302: Current learning rate: 0.00922 
2025-01-24 13:14:43.194733: train_loss -0.7727 
2025-01-24 13:14:43.199669: val_loss -0.7019 
2025-01-24 13:14:43.203765: Pseudo dice [np.float32(0.941), np.float32(0.8418)] 
2025-01-24 13:14:43.206518: Epoch time: 48.29 s 
2025-01-24 13:14:43.208995: Yayy! New best EMA pseudo Dice: 0.8859000205993652 
2025-01-24 13:14:44.938454:  
2025-01-24 13:14:44.941900: Epoch 87 
2025-01-24 13:14:44.944967: Current learning rate: 0.00921 
2025-01-24 13:15:33.477833: train_loss -0.7702 
2025-01-24 13:15:33.483035: val_loss -0.6944 
2025-01-24 13:15:33.485739: Pseudo dice [np.float32(0.9393), np.float32(0.8894)] 
2025-01-24 13:15:33.488634: Epoch time: 48.54 s 
2025-01-24 13:15:33.491375: Yayy! New best EMA pseudo Dice: 0.8888000249862671 
2025-01-24 13:15:35.376008:  
2025-01-24 13:15:35.379036: Epoch 88 
2025-01-24 13:15:35.382265: Current learning rate: 0.0092 
2025-01-24 13:16:24.417687: train_loss -0.7738 
2025-01-24 13:16:24.423530: val_loss -0.7465 
2025-01-24 13:16:24.426676: Pseudo dice [np.float32(0.9361), np.float32(0.8973)] 
2025-01-24 13:16:24.429713: Epoch time: 49.04 s 
2025-01-24 13:16:24.432173: Yayy! New best EMA pseudo Dice: 0.8916000127792358 
2025-01-24 13:16:26.205964:  
2025-01-24 13:16:26.208808: Epoch 89 
2025-01-24 13:16:26.211526: Current learning rate: 0.0092 
2025-01-24 13:17:14.995754: train_loss -0.7688 
2025-01-24 13:17:15.001774: val_loss -0.7156 
2025-01-24 13:17:15.004882: Pseudo dice [np.float32(0.9392), np.float32(0.8033)] 
2025-01-24 13:17:15.007354: Epoch time: 48.79 s 
2025-01-24 13:17:16.804404:  
2025-01-24 13:17:16.807677: Epoch 90 
2025-01-24 13:17:16.810344: Current learning rate: 0.00919 
2025-01-24 13:18:05.980861: train_loss -0.7881 
2025-01-24 13:18:05.986217: val_loss -0.7376 
2025-01-24 13:18:05.989003: Pseudo dice [np.float32(0.9212), np.float32(0.8816)] 
2025-01-24 13:18:05.991579: Epoch time: 49.18 s 
2025-01-24 13:18:07.198984:  
2025-01-24 13:18:07.202275: Epoch 91 
2025-01-24 13:18:07.205506: Current learning rate: 0.00918 
2025-01-24 13:18:56.167724: train_loss -0.7785 
2025-01-24 13:18:56.173822: val_loss -0.7248 
2025-01-24 13:18:56.176877: Pseudo dice [np.float32(0.9318), np.float32(0.8788)] 
2025-01-24 13:18:56.180153: Epoch time: 48.97 s 
2025-01-24 13:18:56.183730: Yayy! New best EMA pseudo Dice: 0.8921999931335449 
2025-01-24 13:18:57.927621:  
2025-01-24 13:18:57.931134: Epoch 92 
2025-01-24 13:18:57.934203: Current learning rate: 0.00917 
2025-01-24 13:19:46.127512: train_loss -0.7927 
2025-01-24 13:19:46.133251: val_loss -0.7375 
2025-01-24 13:19:46.136321: Pseudo dice [np.float32(0.9389), np.float32(0.859)] 
2025-01-24 13:19:46.139338: Epoch time: 48.2 s 
2025-01-24 13:19:46.141775: Yayy! New best EMA pseudo Dice: 0.8928999900817871 
2025-01-24 13:19:47.948292:  
2025-01-24 13:19:47.951677: Epoch 93 
2025-01-24 13:19:47.954592: Current learning rate: 0.00916 
2025-01-24 13:20:36.550627: train_loss -0.7768 
2025-01-24 13:20:36.556416: val_loss -0.7441 
2025-01-24 13:20:36.559508: Pseudo dice [np.float32(0.9348), np.float32(0.8153)] 
2025-01-24 13:20:36.562106: Epoch time: 48.6 s 
2025-01-24 13:20:37.786874:  
2025-01-24 13:20:37.790193: Epoch 94 
2025-01-24 13:20:37.793699: Current learning rate: 0.00915 
2025-01-24 13:21:26.853755: train_loss -0.7672 
2025-01-24 13:21:26.858951: val_loss -0.7303 
2025-01-24 13:21:26.861653: Pseudo dice [np.float32(0.9331), np.float32(0.8054)] 
2025-01-24 13:21:26.864204: Epoch time: 49.07 s 
2025-01-24 13:21:28.023396:  
2025-01-24 13:21:28.027043: Epoch 95 
2025-01-24 13:21:28.030096: Current learning rate: 0.00914 
2025-01-24 13:22:16.571598: train_loss -0.7599 
2025-01-24 13:22:16.578410: val_loss -0.6772 
2025-01-24 13:22:16.581454: Pseudo dice [np.float32(0.9283), np.float32(0.8363)] 
2025-01-24 13:22:16.584353: Epoch time: 48.55 s 
2025-01-24 13:22:17.738522:  
2025-01-24 13:22:17.741716: Epoch 96 
2025-01-24 13:22:17.744821: Current learning rate: 0.00913 
2025-01-24 13:23:07.319821: train_loss -0.786 
2025-01-24 13:23:07.326243: val_loss -0.7124 
2025-01-24 13:23:07.329382: Pseudo dice [np.float32(0.9355), np.float32(0.8582)] 
2025-01-24 13:23:07.332658: Epoch time: 49.58 s 
2025-01-24 13:23:08.513233:  
2025-01-24 13:23:08.516523: Epoch 97 
2025-01-24 13:23:08.519387: Current learning rate: 0.00912 
2025-01-24 13:23:57.676582: train_loss -0.7862 
2025-01-24 13:23:57.683021: val_loss -0.6964 
2025-01-24 13:23:57.686529: Pseudo dice [np.float32(0.9339), np.float32(0.9065)] 
2025-01-24 13:23:57.690150: Epoch time: 49.16 s 
2025-01-24 13:23:58.874967:  
2025-01-24 13:23:58.878175: Epoch 98 
2025-01-24 13:23:58.881281: Current learning rate: 0.00911 
2025-01-24 13:24:47.659223: train_loss -0.784 
2025-01-24 13:24:47.664961: val_loss -0.6431 
2025-01-24 13:24:47.668193: Pseudo dice [np.float32(0.92), np.float32(0.8734)] 
2025-01-24 13:24:47.670998: Epoch time: 48.79 s 
2025-01-24 13:24:48.844167:  
2025-01-24 13:24:48.847356: Epoch 99 
2025-01-24 13:24:48.850163: Current learning rate: 0.0091 
2025-01-24 13:25:37.820143: train_loss -0.7603 
2025-01-24 13:25:37.835521: val_loss -0.6744 
2025-01-24 13:25:37.838548: Pseudo dice [np.float32(0.9253), np.float32(0.8218)] 
2025-01-24 13:25:37.841328: Epoch time: 48.98 s 
2025-01-24 13:25:39.560392:  
2025-01-24 13:25:39.563985: Epoch 100 
2025-01-24 13:25:39.567033: Current learning rate: 0.0091 
2025-01-24 13:26:28.317873: train_loss -0.7609 
2025-01-24 13:26:28.324187: val_loss -0.7111 
2025-01-24 13:26:28.326953: Pseudo dice [np.float32(0.9342), np.float32(0.8943)] 
2025-01-24 13:26:28.329815: Epoch time: 48.76 s 
2025-01-24 13:26:28.332269: Yayy! New best EMA pseudo Dice: 0.8931000232696533 
2025-01-24 13:26:30.125143:  
2025-01-24 13:26:30.128112: Epoch 101 
2025-01-24 13:26:30.130805: Current learning rate: 0.00909 
2025-01-24 13:27:19.102173: train_loss -0.7735 
2025-01-24 13:27:19.107588: val_loss -0.7288 
2025-01-24 13:27:19.110299: Pseudo dice [np.float32(0.936), np.float32(0.8457)] 
2025-01-24 13:27:19.112809: Epoch time: 48.98 s 
2025-01-24 13:27:20.339961:  
2025-01-24 13:27:20.343178: Epoch 102 
2025-01-24 13:27:20.346848: Current learning rate: 0.00908 
2025-01-24 13:28:09.054676: train_loss -0.771 
2025-01-24 13:28:09.059723: val_loss -0.7111 
2025-01-24 13:28:09.062675: Pseudo dice [np.float32(0.9267), np.float32(0.8708)] 
2025-01-24 13:28:09.065413: Epoch time: 48.72 s 
2025-01-24 13:28:09.067831: Yayy! New best EMA pseudo Dice: 0.8934999704360962 
2025-01-24 13:28:10.826985:  
2025-01-24 13:28:10.830040: Epoch 103 
2025-01-24 13:28:10.833043: Current learning rate: 0.00907 
2025-01-24 13:28:59.147084: train_loss -0.7814 
2025-01-24 13:28:59.152863: val_loss -0.6835 
2025-01-24 13:28:59.155642: Pseudo dice [np.float32(0.9441), np.float32(0.7777)] 
2025-01-24 13:28:59.158744: Epoch time: 48.32 s 
2025-01-24 13:29:00.344191:  
2025-01-24 13:29:00.347173: Epoch 104 
2025-01-24 13:29:00.350173: Current learning rate: 0.00906 
2025-01-24 13:29:49.157345: train_loss -0.7817 
2025-01-24 13:29:49.163131: val_loss -0.7084 
2025-01-24 13:29:49.166700: Pseudo dice [np.float32(0.9417), np.float32(0.8671)] 
2025-01-24 13:29:49.169610: Epoch time: 48.81 s 
2025-01-24 13:29:50.342022:  
2025-01-24 13:29:50.345248: Epoch 105 
2025-01-24 13:29:50.348197: Current learning rate: 0.00905 
2025-01-24 13:30:38.853558: train_loss -0.7993 
2025-01-24 13:30:38.859223: val_loss -0.7445 
2025-01-24 13:30:38.862185: Pseudo dice [np.float32(0.9468), np.float32(0.9071)] 
2025-01-24 13:30:38.865067: Epoch time: 48.51 s 
2025-01-24 13:30:38.868168: Yayy! New best EMA pseudo Dice: 0.8952000141143799 
2025-01-24 13:30:40.657979:  
2025-01-24 13:30:40.660910: Epoch 106 
2025-01-24 13:30:40.663785: Current learning rate: 0.00904 
2025-01-24 13:31:29.296961: train_loss -0.7881 
2025-01-24 13:31:29.302200: val_loss -0.7338 
2025-01-24 13:31:29.305393: Pseudo dice [np.float32(0.9303), np.float32(0.8904)] 
2025-01-24 13:31:29.308393: Epoch time: 48.64 s 
2025-01-24 13:31:29.311074: Yayy! New best EMA pseudo Dice: 0.8967000246047974 
2025-01-24 13:31:31.102339:  
2025-01-24 13:31:31.105755: Epoch 107 
2025-01-24 13:31:31.108674: Current learning rate: 0.00903 
2025-01-24 13:32:19.878185: train_loss -0.78 
2025-01-24 13:32:19.883281: val_loss -0.7003 
2025-01-24 13:32:19.886122: Pseudo dice [np.float32(0.9296), np.float32(0.9064)] 
2025-01-24 13:32:19.888598: Epoch time: 48.78 s 
2025-01-24 13:32:19.891037: Yayy! New best EMA pseudo Dice: 0.8988000154495239 
2025-01-24 13:32:21.632801:  
2025-01-24 13:32:21.636113: Epoch 108 
2025-01-24 13:32:21.639157: Current learning rate: 0.00902 
2025-01-24 13:33:10.433479: train_loss -0.7691 
2025-01-24 13:33:10.440179: val_loss -0.7566 
2025-01-24 13:33:10.443305: Pseudo dice [np.float32(0.9485), np.float32(0.923)] 
2025-01-24 13:33:10.446112: Epoch time: 48.8 s 
2025-01-24 13:33:10.449172: Yayy! New best EMA pseudo Dice: 0.9024999737739563 
2025-01-24 13:33:12.842649:  
2025-01-24 13:33:12.845862: Epoch 109 
2025-01-24 13:33:12.848729: Current learning rate: 0.00901 
2025-01-24 13:34:01.430489: train_loss -0.7778 
2025-01-24 13:34:01.435974: val_loss -0.7068 
2025-01-24 13:34:01.438870: Pseudo dice [np.float32(0.9231), np.float32(0.8877)] 
2025-01-24 13:34:01.441696: Epoch time: 48.59 s 
2025-01-24 13:34:01.444183: Yayy! New best EMA pseudo Dice: 0.9028000235557556 
2025-01-24 13:34:03.261063:  
2025-01-24 13:34:03.264937: Epoch 110 
2025-01-24 13:34:03.267863: Current learning rate: 0.009 
2025-01-24 13:34:52.560419: train_loss -0.7683 
2025-01-24 13:34:52.566088: val_loss -0.6756 
2025-01-24 13:34:52.569090: Pseudo dice [np.float32(0.9207), np.float32(0.8312)] 
2025-01-24 13:34:52.571904: Epoch time: 49.3 s 
2025-01-24 13:34:53.748789:  
2025-01-24 13:34:53.751904: Epoch 111 
2025-01-24 13:34:53.754758: Current learning rate: 0.009 
2025-01-24 13:35:42.180612: train_loss -0.7826 
2025-01-24 13:35:42.185925: val_loss -0.6565 
2025-01-24 13:35:42.188752: Pseudo dice [np.float32(0.9092), np.float32(0.8247)] 
2025-01-24 13:35:42.191829: Epoch time: 48.43 s 
2025-01-24 13:35:43.411556:  
2025-01-24 13:35:43.414522: Epoch 112 
2025-01-24 13:35:43.417191: Current learning rate: 0.00899 
2025-01-24 13:36:32.112955: train_loss -0.7709 
2025-01-24 13:36:32.119042: val_loss -0.7168 
2025-01-24 13:36:32.121967: Pseudo dice [np.float32(0.9404), np.float32(0.8462)] 
2025-01-24 13:36:32.124856: Epoch time: 48.7 s 
2025-01-24 13:36:33.305942:  
2025-01-24 13:36:33.309587: Epoch 113 
2025-01-24 13:36:33.312423: Current learning rate: 0.00898 
2025-01-24 13:37:21.891245: train_loss -0.7746 
2025-01-24 13:37:21.896594: val_loss -0.7259 
2025-01-24 13:37:21.899318: Pseudo dice [np.float32(0.9314), np.float32(0.7565)] 
2025-01-24 13:37:21.902175: Epoch time: 48.59 s 
2025-01-24 13:37:23.092406:  
2025-01-24 13:37:23.095673: Epoch 114 
2025-01-24 13:37:23.100207: Current learning rate: 0.00897 
2025-01-24 13:38:11.800730: train_loss -0.7847 
2025-01-24 13:38:11.806316: val_loss -0.7468 
2025-01-24 13:38:11.808558: Pseudo dice [np.float32(0.9425), np.float32(0.8955)] 
2025-01-24 13:38:11.810914: Epoch time: 48.71 s 
2025-01-24 13:38:12.986204:  
2025-01-24 13:38:12.989540: Epoch 115 
2025-01-24 13:38:12.992728: Current learning rate: 0.00896 
2025-01-24 13:39:01.608945: train_loss -0.7788 
2025-01-24 13:39:01.616375: val_loss -0.7392 
2025-01-24 13:39:01.619895: Pseudo dice [np.float32(0.9213), np.float32(0.846)] 
2025-01-24 13:39:01.623059: Epoch time: 48.62 s 
2025-01-24 13:39:02.823235:  
2025-01-24 13:39:02.826645: Epoch 116 
2025-01-24 13:39:02.829486: Current learning rate: 0.00895 
2025-01-24 13:39:51.575302: train_loss -0.7793 
2025-01-24 13:39:51.582327: val_loss -0.7187 
2025-01-24 13:39:51.584917: Pseudo dice [np.float32(0.9271), np.float32(0.8789)] 
2025-01-24 13:39:51.587776: Epoch time: 48.75 s 
2025-01-24 13:39:52.783529:  
2025-01-24 13:39:52.786658: Epoch 117 
2025-01-24 13:39:52.789682: Current learning rate: 0.00894 
2025-01-24 13:40:41.649644: train_loss -0.789 
2025-01-24 13:40:41.655387: val_loss -0.6277 
2025-01-24 13:40:41.658502: Pseudo dice [np.float32(0.9174), np.float32(0.7905)] 
2025-01-24 13:40:41.661109: Epoch time: 48.87 s 
2025-01-24 13:40:42.892678:  
2025-01-24 13:40:42.896385: Epoch 118 
2025-01-24 13:40:42.899400: Current learning rate: 0.00893 
2025-01-24 13:41:31.841537: train_loss -0.7858 
2025-01-24 13:41:31.847043: val_loss -0.6737 
2025-01-24 13:41:31.849947: Pseudo dice [np.float32(0.9046), np.float32(0.7925)] 
2025-01-24 13:41:31.852973: Epoch time: 48.95 s 
2025-01-24 13:41:33.063243:  
2025-01-24 13:41:33.066370: Epoch 119 
2025-01-24 13:41:33.069173: Current learning rate: 0.00892 
2025-01-24 13:42:22.018621: train_loss -0.7621 
2025-01-24 13:42:22.026124: val_loss -0.6505 
2025-01-24 13:42:22.028931: Pseudo dice [np.float32(0.9344), np.float32(0.7885)] 
2025-01-24 13:42:22.032058: Epoch time: 48.96 s 
2025-01-24 13:42:23.226161:  
2025-01-24 13:42:23.229325: Epoch 120 
2025-01-24 13:42:23.232147: Current learning rate: 0.00891 
2025-01-24 13:43:11.652960: train_loss -0.7676 
2025-01-24 13:43:11.658540: val_loss -0.5933 
2025-01-24 13:43:11.661519: Pseudo dice [np.float32(0.9078), np.float32(0.5293)] 
2025-01-24 13:43:11.664086: Epoch time: 48.43 s 
2025-01-24 13:43:12.888309:  
2025-01-24 13:43:12.891333: Epoch 121 
2025-01-24 13:43:12.894272: Current learning rate: 0.0089 
2025-01-24 13:44:01.327471: train_loss -0.7707 
2025-01-24 13:44:01.332731: val_loss -0.7255 
2025-01-24 13:44:01.335596: Pseudo dice [np.float32(0.9295), np.float32(0.9002)] 
2025-01-24 13:44:01.338545: Epoch time: 48.44 s 
2025-01-24 13:44:02.565470:  
2025-01-24 13:44:02.568947: Epoch 122 
2025-01-24 13:44:02.572021: Current learning rate: 0.00889 
2025-01-24 13:44:51.038723: train_loss -0.7849 
2025-01-24 13:44:51.044306: val_loss -0.6781 
2025-01-24 13:44:51.047249: Pseudo dice [np.float32(0.9356), np.float32(0.863)] 
2025-01-24 13:44:51.050087: Epoch time: 48.47 s 
2025-01-24 13:44:52.233166:  
2025-01-24 13:44:52.236275: Epoch 123 
2025-01-24 13:44:52.238746: Current learning rate: 0.00889 
2025-01-24 13:45:41.108706: train_loss -0.7693 
2025-01-24 13:45:41.113920: val_loss -0.7625 
2025-01-24 13:45:41.116767: Pseudo dice [np.float32(0.9432), np.float32(0.8645)] 
2025-01-24 13:45:41.119115: Epoch time: 48.88 s 
2025-01-24 13:45:42.311611:  
2025-01-24 13:45:42.314796: Epoch 124 
2025-01-24 13:45:42.318069: Current learning rate: 0.00888 
2025-01-24 13:46:30.954977: train_loss -0.7605 
2025-01-24 13:46:30.960373: val_loss -0.6922 
2025-01-24 13:46:30.963313: Pseudo dice [np.float32(0.924), np.float32(0.8911)] 
2025-01-24 13:46:30.965980: Epoch time: 48.64 s 
2025-01-24 13:46:32.161644:  
2025-01-24 13:46:32.165141: Epoch 125 
2025-01-24 13:46:32.168510: Current learning rate: 0.00887 
2025-01-24 13:47:21.053945: train_loss -0.7799 
2025-01-24 13:47:21.059842: val_loss -0.656 
2025-01-24 13:47:21.062835: Pseudo dice [np.float32(0.9386), np.float32(0.8786)] 
2025-01-24 13:47:21.065804: Epoch time: 48.89 s 
2025-01-24 13:47:22.261064:  
2025-01-24 13:47:22.264138: Epoch 126 
2025-01-24 13:47:22.266592: Current learning rate: 0.00886 
2025-01-24 13:48:11.128209: train_loss -0.7749 
2025-01-24 13:48:11.132854: val_loss -0.7581 
2025-01-24 13:48:11.135426: Pseudo dice [np.float32(0.9332), np.float32(0.8937)] 
2025-01-24 13:48:11.138044: Epoch time: 48.87 s 
2025-01-24 13:48:12.331489:  
2025-01-24 13:48:12.334649: Epoch 127 
2025-01-24 13:48:12.337655: Current learning rate: 0.00885 
2025-01-24 13:49:01.198076: train_loss -0.7905 
2025-01-24 13:49:01.203931: val_loss -0.6693 
2025-01-24 13:49:01.206683: Pseudo dice [np.float32(0.9279), np.float32(0.7108)] 
2025-01-24 13:49:01.209240: Epoch time: 48.87 s 
2025-01-24 13:49:03.060323:  
2025-01-24 13:49:03.063538: Epoch 128 
2025-01-24 13:49:03.066498: Current learning rate: 0.00884 
2025-01-24 13:49:52.391806: train_loss -0.748 
2025-01-24 13:49:52.397813: val_loss -0.7521 
2025-01-24 13:49:52.400676: Pseudo dice [np.float32(0.9456), np.float32(0.9268)] 
2025-01-24 13:49:52.403588: Epoch time: 49.33 s 
2025-01-24 13:49:53.602786:  
2025-01-24 13:49:53.606640: Epoch 129 
2025-01-24 13:49:53.609413: Current learning rate: 0.00883 
2025-01-24 13:50:42.307787: train_loss -0.7806 
2025-01-24 13:50:42.313665: val_loss -0.6977 
2025-01-24 13:50:42.316698: Pseudo dice [np.float32(0.9307), np.float32(0.8654)] 
2025-01-24 13:50:42.319772: Epoch time: 48.71 s 
2025-01-24 13:50:43.570353:  
2025-01-24 13:50:43.573588: Epoch 130 
2025-01-24 13:50:43.576265: Current learning rate: 0.00882 
2025-01-24 13:51:32.261794: train_loss -0.7743 
2025-01-24 13:51:32.267690: val_loss -0.6859 
2025-01-24 13:51:32.270648: Pseudo dice [np.float32(0.9222), np.float32(0.8232)] 
2025-01-24 13:51:32.273291: Epoch time: 48.69 s 
2025-01-24 13:51:33.532755:  
2025-01-24 13:51:33.536127: Epoch 131 
2025-01-24 13:51:33.539062: Current learning rate: 0.00881 
2025-01-24 13:52:22.285960: train_loss -0.7828 
2025-01-24 13:52:22.291205: val_loss -0.7373 
2025-01-24 13:52:22.294323: Pseudo dice [np.float32(0.9436), np.float32(0.8927)] 
2025-01-24 13:52:22.297104: Epoch time: 48.76 s 
2025-01-24 13:52:23.539386:  
2025-01-24 13:52:23.542367: Epoch 132 
2025-01-24 13:52:23.545724: Current learning rate: 0.0088 
2025-01-24 13:53:11.995046: train_loss -0.7938 
2025-01-24 13:53:12.001381: val_loss -0.7488 
2025-01-24 13:53:12.003667: Pseudo dice [np.float32(0.9268), np.float32(0.8567)] 
2025-01-24 13:53:12.006128: Epoch time: 48.46 s 
2025-01-24 13:53:13.237047:  
2025-01-24 13:53:13.240009: Epoch 133 
2025-01-24 13:53:13.243042: Current learning rate: 0.00879 
2025-01-24 13:54:02.101253: train_loss -0.7802 
2025-01-24 13:54:02.106649: val_loss -0.7604 
2025-01-24 13:54:02.109484: Pseudo dice [np.float32(0.9451), np.float32(0.8994)] 
2025-01-24 13:54:02.112159: Epoch time: 48.87 s 
2025-01-24 13:54:03.318003:  
2025-01-24 13:54:03.321314: Epoch 134 
2025-01-24 13:54:03.324270: Current learning rate: 0.00879 
2025-01-24 13:54:52.104229: train_loss -0.7997 
2025-01-24 13:54:52.109856: val_loss -0.7363 
2025-01-24 13:54:52.112814: Pseudo dice [np.float32(0.9408), np.float32(0.8796)] 
2025-01-24 13:54:52.115549: Epoch time: 48.79 s 
2025-01-24 13:54:53.348933:  
2025-01-24 13:54:53.352388: Epoch 135 
2025-01-24 13:54:53.355330: Current learning rate: 0.00878 
2025-01-24 13:55:41.940527: train_loss -0.8027 
2025-01-24 13:55:41.945968: val_loss -0.707 
2025-01-24 13:55:41.948653: Pseudo dice [np.float32(0.9235), np.float32(0.9077)] 
2025-01-24 13:55:41.951461: Epoch time: 48.59 s 
2025-01-24 13:55:43.171538:  
2025-01-24 13:55:43.175100: Epoch 136 
2025-01-24 13:55:43.178048: Current learning rate: 0.00877 
2025-01-24 13:56:32.123948: train_loss -0.795 
2025-01-24 13:56:32.129320: val_loss -0.6467 
2025-01-24 13:56:32.132050: Pseudo dice [np.float32(0.9361), np.float32(0.6836)] 
2025-01-24 13:56:32.134713: Epoch time: 48.95 s 
2025-01-24 13:56:33.355424:  
2025-01-24 13:56:33.358506: Epoch 137 
2025-01-24 13:56:33.361423: Current learning rate: 0.00876 
2025-01-24 13:57:22.746408: train_loss -0.781 
2025-01-24 13:57:22.753038: val_loss -0.6709 
2025-01-24 13:57:22.755911: Pseudo dice [np.float32(0.93), np.float32(0.7985)] 
2025-01-24 13:57:22.758790: Epoch time: 49.39 s 
2025-01-24 13:57:24.018090:  
2025-01-24 13:57:24.021103: Epoch 138 
2025-01-24 13:57:24.024001: Current learning rate: 0.00875 
2025-01-24 13:58:12.872069: train_loss -0.786 
2025-01-24 13:58:12.877491: val_loss -0.6434 
2025-01-24 13:58:12.880378: Pseudo dice [np.float32(0.908), np.float32(0.6616)] 
2025-01-24 13:58:12.883168: Epoch time: 48.86 s 
2025-01-24 13:58:14.102619:  
2025-01-24 13:58:14.105607: Epoch 139 
2025-01-24 13:58:14.108327: Current learning rate: 0.00874 
2025-01-24 13:59:02.890387: train_loss -0.7828 
2025-01-24 13:59:02.895964: val_loss -0.7648 
2025-01-24 13:59:02.898777: Pseudo dice [np.float32(0.9448), np.float32(0.9015)] 
2025-01-24 13:59:02.901483: Epoch time: 48.79 s 
2025-01-24 13:59:04.161796:  
2025-01-24 13:59:04.165445: Epoch 140 
2025-01-24 13:59:04.168778: Current learning rate: 0.00873 
2025-01-24 13:59:52.896125: train_loss -0.7743 
2025-01-24 13:59:52.901255: val_loss -0.7075 
2025-01-24 13:59:52.903887: Pseudo dice [np.float32(0.9505), np.float32(0.9031)] 
2025-01-24 13:59:52.906673: Epoch time: 48.74 s 
2025-01-24 13:59:54.117322:  
2025-01-24 13:59:54.120741: Epoch 141 
2025-01-24 13:59:54.123936: Current learning rate: 0.00872 
2025-01-24 14:00:42.689575: train_loss -0.7771 
2025-01-24 14:00:42.694917: val_loss -0.7145 
2025-01-24 14:00:42.698236: Pseudo dice [np.float32(0.934), np.float32(0.8192)] 
2025-01-24 14:00:42.701044: Epoch time: 48.57 s 
2025-01-24 14:00:43.960248:  
2025-01-24 14:00:43.963233: Epoch 142 
2025-01-24 14:00:43.965833: Current learning rate: 0.00871 
2025-01-24 14:01:32.598353: train_loss -0.7721 
2025-01-24 14:01:32.604870: val_loss -0.6307 
2025-01-24 14:01:32.607593: Pseudo dice [np.float32(0.9006), np.float32(0.6756)] 
2025-01-24 14:01:32.610505: Epoch time: 48.64 s 
2025-01-24 14:01:33.819729:  
2025-01-24 14:01:33.823224: Epoch 143 
2025-01-24 14:01:33.826320: Current learning rate: 0.0087 
2025-01-24 14:02:22.509355: train_loss -0.744 
2025-01-24 14:02:22.515484: val_loss -0.6851 
2025-01-24 14:02:22.518260: Pseudo dice [np.float32(0.9106), np.float32(0.8288)] 
2025-01-24 14:02:22.521021: Epoch time: 48.69 s 
2025-01-24 14:02:23.759540:  
2025-01-24 14:02:23.762571: Epoch 144 
2025-01-24 14:02:23.765404: Current learning rate: 0.00869 
2025-01-24 14:03:12.427379: train_loss -0.789 
2025-01-24 14:03:12.433588: val_loss -0.6839 
2025-01-24 14:03:12.436362: Pseudo dice [np.float32(0.9424), np.float32(0.8208)] 
2025-01-24 14:03:12.439300: Epoch time: 48.67 s 
2025-01-24 14:03:13.663718:  
2025-01-24 14:03:13.666246: Epoch 145 
2025-01-24 14:03:13.668986: Current learning rate: 0.00868 
2025-01-24 14:04:02.409941: train_loss -0.7738 
2025-01-24 14:04:02.416129: val_loss -0.6884 
2025-01-24 14:04:02.419441: Pseudo dice [np.float32(0.9398), np.float32(0.7475)] 
2025-01-24 14:04:02.422532: Epoch time: 48.75 s 
2025-01-24 14:04:04.329001:  
2025-01-24 14:04:04.332394: Epoch 146 
2025-01-24 14:04:04.335148: Current learning rate: 0.00868 
2025-01-24 14:04:52.802072: train_loss -0.7762 
2025-01-24 14:04:52.807008: val_loss -0.6728 
2025-01-24 14:04:52.809198: Pseudo dice [np.float32(0.9333), np.float32(0.8483)] 
2025-01-24 14:04:52.811550: Epoch time: 48.47 s 
2025-01-24 14:04:54.031123:  
2025-01-24 14:04:54.034142: Epoch 147 
2025-01-24 14:04:54.037339: Current learning rate: 0.00867 
2025-01-24 14:05:42.776913: train_loss -0.8022 
2025-01-24 14:05:42.782256: val_loss -0.7066 
2025-01-24 14:05:42.785254: Pseudo dice [np.float32(0.922), np.float32(0.8579)] 
2025-01-24 14:05:42.788193: Epoch time: 48.75 s 
2025-01-24 14:05:44.012957:  
2025-01-24 14:05:44.015486: Epoch 148 
2025-01-24 14:05:44.018549: Current learning rate: 0.00866 
2025-01-24 14:06:33.046509: train_loss -0.7825 
2025-01-24 14:06:33.051794: val_loss -0.7087 
2025-01-24 14:06:33.054658: Pseudo dice [np.float32(0.934), np.float32(0.7605)] 
2025-01-24 14:06:33.057182: Epoch time: 49.04 s 
2025-01-24 14:06:34.278605:  
2025-01-24 14:06:34.282025: Epoch 149 
2025-01-24 14:06:34.285187: Current learning rate: 0.00865 
2025-01-24 14:07:22.461337: train_loss -0.7996 
2025-01-24 14:07:22.466894: val_loss -0.7298 
2025-01-24 14:07:22.469539: Pseudo dice [np.float32(0.9395), np.float32(0.9151)] 
2025-01-24 14:07:22.472334: Epoch time: 48.18 s 
2025-01-24 14:07:24.323221:  
2025-01-24 14:07:24.326051: Epoch 150 
2025-01-24 14:07:24.329005: Current learning rate: 0.00864 
2025-01-24 14:08:12.881843: train_loss -0.7955 
2025-01-24 14:08:12.887759: val_loss -0.7065 
2025-01-24 14:08:12.890720: Pseudo dice [np.float32(0.939), np.float32(0.8529)] 
2025-01-24 14:08:12.893841: Epoch time: 48.56 s 
2025-01-24 14:08:14.144327:  
2025-01-24 14:08:14.147237: Epoch 151 
2025-01-24 14:08:14.150422: Current learning rate: 0.00863 
2025-01-24 14:09:02.391151: train_loss -0.8106 
2025-01-24 14:09:02.396688: val_loss -0.7412 
2025-01-24 14:09:02.399792: Pseudo dice [np.float32(0.9408), np.float32(0.8858)] 
2025-01-24 14:09:02.402570: Epoch time: 48.25 s 
2025-01-24 14:09:03.620043:  
2025-01-24 14:09:03.623082: Epoch 152 
2025-01-24 14:09:03.625937: Current learning rate: 0.00862 
2025-01-24 14:09:52.187585: train_loss -0.7822 
2025-01-24 14:09:52.193314: val_loss -0.6833 
2025-01-24 14:09:52.196629: Pseudo dice [np.float32(0.9494), np.float32(0.7537)] 
2025-01-24 14:09:52.199302: Epoch time: 48.57 s 
2025-01-24 14:09:53.426310:  
2025-01-24 14:09:53.429433: Epoch 153 
2025-01-24 14:09:53.432351: Current learning rate: 0.00861 
2025-01-24 14:10:42.338034: train_loss -0.7875 
2025-01-24 14:10:42.343247: val_loss -0.7259 
2025-01-24 14:10:42.346161: Pseudo dice [np.float32(0.9446), np.float32(0.8897)] 
2025-01-24 14:10:42.348767: Epoch time: 48.91 s 
2025-01-24 14:10:43.584903:  
2025-01-24 14:10:43.588109: Epoch 154 
2025-01-24 14:10:43.590855: Current learning rate: 0.0086 
2025-01-24 14:11:32.345374: train_loss -0.7668 
2025-01-24 14:11:32.350763: val_loss -0.7453 
2025-01-24 14:11:32.354047: Pseudo dice [np.float32(0.9379), np.float32(0.876)] 
2025-01-24 14:11:32.356868: Epoch time: 48.76 s 
2025-01-24 14:11:33.593865:  
2025-01-24 14:11:33.596689: Epoch 155 
2025-01-24 14:11:33.599811: Current learning rate: 0.00859 
2025-01-24 14:12:22.420261: train_loss -0.7578 
2025-01-24 14:12:22.425745: val_loss -0.6989 
2025-01-24 14:12:22.428571: Pseudo dice [np.float32(0.8995), np.float32(0.8724)] 
2025-01-24 14:12:22.431527: Epoch time: 48.83 s 
2025-01-24 14:12:23.667202:  
2025-01-24 14:12:23.670319: Epoch 156 
2025-01-24 14:12:23.673305: Current learning rate: 0.00858 
2025-01-24 14:13:12.675545: train_loss -0.764 
2025-01-24 14:13:12.681223: val_loss -0.7098 
2025-01-24 14:13:12.684052: Pseudo dice [np.float32(0.9286), np.float32(0.8012)] 
2025-01-24 14:13:12.687094: Epoch time: 49.01 s 
2025-01-24 14:13:13.910227:  
2025-01-24 14:13:13.913287: Epoch 157 
2025-01-24 14:13:13.916162: Current learning rate: 0.00858 
2025-01-24 14:14:02.632351: train_loss -0.7769 
2025-01-24 14:14:02.637740: val_loss -0.7215 
2025-01-24 14:14:02.640718: Pseudo dice [np.float32(0.9498), np.float32(0.9068)] 
2025-01-24 14:14:02.643463: Epoch time: 48.72 s 
2025-01-24 14:14:03.873452:  
2025-01-24 14:14:03.876165: Epoch 158 
2025-01-24 14:14:03.879093: Current learning rate: 0.00857 
2025-01-24 14:14:53.114458: train_loss -0.791 
2025-01-24 14:14:53.122368: val_loss -0.7287 
2025-01-24 14:14:53.125467: Pseudo dice [np.float32(0.9415), np.float32(0.8444)] 
2025-01-24 14:14:53.128125: Epoch time: 49.24 s 
2025-01-24 14:14:54.412115:  
2025-01-24 14:14:54.415487: Epoch 159 
2025-01-24 14:14:54.418614: Current learning rate: 0.00856 
2025-01-24 14:15:42.969783: train_loss -0.7813 
2025-01-24 14:15:42.975152: val_loss -0.7545 
2025-01-24 14:15:42.978210: Pseudo dice [np.float32(0.9377), np.float32(0.8871)] 
2025-01-24 14:15:42.981183: Epoch time: 48.56 s 
2025-01-24 14:15:44.262089:  
2025-01-24 14:15:44.265544: Epoch 160 
2025-01-24 14:15:44.268556: Current learning rate: 0.00855 
2025-01-24 14:16:32.601811: train_loss -0.7947 
2025-01-24 14:16:32.606294: val_loss -0.7439 
2025-01-24 14:16:32.608708: Pseudo dice [np.float32(0.9441), np.float32(0.9119)] 
2025-01-24 14:16:32.611354: Epoch time: 48.34 s 
2025-01-24 14:16:33.887429:  
2025-01-24 14:16:33.890232: Epoch 161 
2025-01-24 14:16:33.893296: Current learning rate: 0.00854 
2025-01-24 14:17:23.346008: train_loss -0.8014 
2025-01-24 14:17:23.351559: val_loss -0.722 
2025-01-24 14:17:23.354403: Pseudo dice [np.float32(0.9467), np.float32(0.9076)] 
2025-01-24 14:17:23.357023: Epoch time: 49.46 s 
2025-01-24 14:17:24.667962:  
2025-01-24 14:17:24.671514: Epoch 162 
2025-01-24 14:17:24.674875: Current learning rate: 0.00853 
2025-01-24 14:18:13.668746: train_loss -0.7786 
2025-01-24 14:18:13.674197: val_loss -0.6959 
2025-01-24 14:18:13.676971: Pseudo dice [np.float32(0.9304), np.float32(0.8856)] 
2025-01-24 14:18:13.679589: Epoch time: 49.0 s 
2025-01-24 14:18:15.717633:  
2025-01-24 14:18:15.720715: Epoch 163 
2025-01-24 14:18:15.723381: Current learning rate: 0.00852 
2025-01-24 14:19:04.697182: train_loss -0.7995 
2025-01-24 14:19:04.702984: val_loss -0.7256 
2025-01-24 14:19:04.706164: Pseudo dice [np.float32(0.9308), np.float32(0.8656)] 
2025-01-24 14:19:04.708947: Epoch time: 48.98 s 
2025-01-24 14:19:06.013843:  
2025-01-24 14:19:06.017612: Epoch 164 
2025-01-24 14:19:06.021002: Current learning rate: 0.00851 
2025-01-24 14:19:54.589502: train_loss -0.7632 
2025-01-24 14:19:54.594932: val_loss -0.7441 
2025-01-24 14:19:54.597670: Pseudo dice [np.float32(0.9401), np.float32(0.9126)] 
2025-01-24 14:19:54.600492: Epoch time: 48.58 s 
2025-01-24 14:19:55.817582:  
2025-01-24 14:19:55.820573: Epoch 165 
2025-01-24 14:19:55.823376: Current learning rate: 0.0085 
2025-01-24 14:20:44.465752: train_loss -0.7974 
2025-01-24 14:20:44.470311: val_loss -0.7642 
2025-01-24 14:20:44.472839: Pseudo dice [np.float32(0.9403), np.float32(0.843)] 
2025-01-24 14:20:44.475189: Epoch time: 48.65 s 
2025-01-24 14:20:45.686680:  
2025-01-24 14:20:45.690097: Epoch 166 
2025-01-24 14:20:45.692723: Current learning rate: 0.00849 
2025-01-24 14:21:34.202600: train_loss -0.7844 
2025-01-24 14:21:34.207366: val_loss -0.6853 
2025-01-24 14:21:34.209838: Pseudo dice [np.float32(0.9358), np.float32(0.905)] 
2025-01-24 14:21:34.212425: Epoch time: 48.52 s 
2025-01-24 14:21:35.454569:  
2025-01-24 14:21:35.457357: Epoch 167 
2025-01-24 14:21:35.460221: Current learning rate: 0.00848 
2025-01-24 14:22:24.353085: train_loss -0.7795 
2025-01-24 14:22:24.357995: val_loss -0.6903 
2025-01-24 14:22:24.361014: Pseudo dice [np.float32(0.886), np.float32(0.7551)] 
2025-01-24 14:22:24.363539: Epoch time: 48.9 s 
2025-01-24 14:22:25.621799:  
2025-01-24 14:22:25.625344: Epoch 168 
2025-01-24 14:22:25.628001: Current learning rate: 0.00847 
2025-01-24 14:23:14.275809: train_loss -0.7875 
2025-01-24 14:23:14.280875: val_loss -0.7446 
2025-01-24 14:23:14.283745: Pseudo dice [np.float32(0.951), np.float32(0.917)] 
2025-01-24 14:23:14.286213: Epoch time: 48.66 s 
2025-01-24 14:23:15.514096:  
2025-01-24 14:23:15.516876: Epoch 169 
2025-01-24 14:23:15.519536: Current learning rate: 0.00847 
2025-01-24 14:24:04.640189: train_loss -0.8113 
2025-01-24 14:24:04.646690: val_loss -0.7224 
2025-01-24 14:24:04.650102: Pseudo dice [np.float32(0.931), np.float32(0.898)] 
2025-01-24 14:24:04.653180: Epoch time: 49.13 s 
2025-01-24 14:24:05.924104:  
2025-01-24 14:24:05.927088: Epoch 170 
2025-01-24 14:24:05.929939: Current learning rate: 0.00846 
2025-01-24 14:24:54.664696: train_loss -0.8041 
2025-01-24 14:24:54.669692: val_loss -0.6676 
2025-01-24 14:24:54.672506: Pseudo dice [np.float32(0.9256), np.float32(0.8777)] 
2025-01-24 14:24:54.675061: Epoch time: 48.74 s 
2025-01-24 14:24:55.906683:  
2025-01-24 14:24:55.910066: Epoch 171 
2025-01-24 14:24:55.912803: Current learning rate: 0.00845 
2025-01-24 14:25:44.482304: train_loss -0.7894 
2025-01-24 14:25:44.487657: val_loss -0.676 
2025-01-24 14:25:44.490382: Pseudo dice [np.float32(0.9303), np.float32(0.8174)] 
2025-01-24 14:25:44.492780: Epoch time: 48.58 s 
2025-01-24 14:25:45.727308:  
2025-01-24 14:25:45.730486: Epoch 172 
2025-01-24 14:25:45.733372: Current learning rate: 0.00844 
2025-01-24 14:26:34.621561: train_loss -0.7883 
2025-01-24 14:26:34.626497: val_loss -0.6325 
2025-01-24 14:26:34.628971: Pseudo dice [np.float32(0.943), np.float32(0.7229)] 
2025-01-24 14:26:34.631473: Epoch time: 48.9 s 
2025-01-24 14:26:35.867034:  
2025-01-24 14:26:35.869942: Epoch 173 
2025-01-24 14:26:35.872987: Current learning rate: 0.00843 
2025-01-24 14:27:25.154680: train_loss -0.7793 
2025-01-24 14:27:25.160222: val_loss -0.6752 
2025-01-24 14:27:25.163188: Pseudo dice [np.float32(0.9215), np.float32(0.7767)] 
2025-01-24 14:27:25.165956: Epoch time: 49.29 s 
2025-01-24 14:27:26.398597:  
2025-01-24 14:27:26.401856: Epoch 174 
2025-01-24 14:27:26.404619: Current learning rate: 0.00842 
2025-01-24 14:28:15.224247: train_loss -0.7307 
2025-01-24 14:28:15.228744: val_loss -0.6815 
2025-01-24 14:28:15.231159: Pseudo dice [np.float32(0.9286), np.float32(0.8887)] 
2025-01-24 14:28:15.233417: Epoch time: 48.83 s 
2025-01-24 14:28:16.494627:  
2025-01-24 14:28:16.497191: Epoch 175 
2025-01-24 14:28:16.499699: Current learning rate: 0.00841 
2025-01-24 14:29:05.602678: train_loss -0.7564 
2025-01-24 14:29:05.608582: val_loss -0.7485 
2025-01-24 14:29:05.611571: Pseudo dice [np.float32(0.9365), np.float32(0.9008)] 
2025-01-24 14:29:05.614907: Epoch time: 49.11 s 
2025-01-24 14:29:06.840289:  
2025-01-24 14:29:06.843200: Epoch 176 
2025-01-24 14:29:06.846252: Current learning rate: 0.0084 
2025-01-24 14:29:55.679216: train_loss -0.7785 
2025-01-24 14:29:55.684286: val_loss -0.6827 
2025-01-24 14:29:55.687055: Pseudo dice [np.float32(0.9175), np.float32(0.8528)] 
2025-01-24 14:29:55.689741: Epoch time: 48.84 s 
2025-01-24 14:29:56.911900:  
2025-01-24 14:29:56.914890: Epoch 177 
2025-01-24 14:29:56.917519: Current learning rate: 0.00839 
2025-01-24 14:30:45.713539: train_loss -0.7945 
2025-01-24 14:30:45.718573: val_loss -0.7421 
2025-01-24 14:30:45.721207: Pseudo dice [np.float32(0.9427), np.float32(0.8226)] 
2025-01-24 14:30:45.723815: Epoch time: 48.8 s 
2025-01-24 14:30:46.952120:  
2025-01-24 14:30:46.955401: Epoch 178 
2025-01-24 14:30:46.958424: Current learning rate: 0.00838 
2025-01-24 14:31:36.032160: train_loss -0.77 
2025-01-24 14:31:36.037775: val_loss -0.6927 
2025-01-24 14:31:36.040597: Pseudo dice [np.float32(0.9254), np.float32(0.8369)] 
2025-01-24 14:31:36.043376: Epoch time: 49.08 s 
2025-01-24 14:31:37.312196:  
2025-01-24 14:31:37.315237: Epoch 179 
2025-01-24 14:31:37.318500: Current learning rate: 0.00837 
2025-01-24 14:32:26.281334: train_loss -0.7926 
2025-01-24 14:32:26.286619: val_loss -0.6633 
2025-01-24 14:32:26.289612: Pseudo dice [np.float32(0.9275), np.float32(0.8476)] 
2025-01-24 14:32:26.292404: Epoch time: 48.97 s 
2025-01-24 14:32:27.552524:  
2025-01-24 14:32:27.555800: Epoch 180 
2025-01-24 14:32:27.558899: Current learning rate: 0.00836 
2025-01-24 14:33:16.574652: train_loss -0.7786 
2025-01-24 14:33:16.580552: val_loss -0.7337 
2025-01-24 14:33:16.584060: Pseudo dice [np.float32(0.9496), np.float32(0.9055)] 
2025-01-24 14:33:16.586921: Epoch time: 49.02 s 
2025-01-24 14:33:18.531988:  
2025-01-24 14:33:18.535617: Epoch 181 
2025-01-24 14:33:18.538214: Current learning rate: 0.00836 
2025-01-24 14:34:07.420245: train_loss -0.8001 
2025-01-24 14:34:07.426160: val_loss -0.7305 
2025-01-24 14:34:07.428879: Pseudo dice [np.float32(0.9351), np.float32(0.8498)] 
2025-01-24 14:34:07.431261: Epoch time: 48.89 s 
2025-01-24 14:34:08.690361:  
2025-01-24 14:34:08.693345: Epoch 182 
2025-01-24 14:34:08.696222: Current learning rate: 0.00835 
2025-01-24 14:34:57.775963: train_loss -0.7936 
2025-01-24 14:34:57.780707: val_loss -0.6942 
2025-01-24 14:34:57.783570: Pseudo dice [np.float32(0.9416), np.float32(0.8994)] 
2025-01-24 14:34:57.786319: Epoch time: 49.09 s 
2025-01-24 14:34:59.002950:  
2025-01-24 14:34:59.005447: Epoch 183 
2025-01-24 14:34:59.007882: Current learning rate: 0.00834 
2025-01-24 14:35:47.893009: train_loss -0.8008 
2025-01-24 14:35:47.898258: val_loss -0.7513 
2025-01-24 14:35:47.901069: Pseudo dice [np.float32(0.9363), np.float32(0.8793)] 
2025-01-24 14:35:47.904026: Epoch time: 48.89 s 
2025-01-24 14:35:49.127952:  
2025-01-24 14:35:49.131416: Epoch 184 
2025-01-24 14:35:49.134338: Current learning rate: 0.00833 
2025-01-24 14:36:37.788483: train_loss -0.7945 
2025-01-24 14:36:37.794136: val_loss -0.6895 
2025-01-24 14:36:37.797092: Pseudo dice [np.float32(0.94), np.float32(0.779)] 
2025-01-24 14:36:37.799813: Epoch time: 48.66 s 
2025-01-24 14:36:39.090466:  
2025-01-24 14:36:39.093886: Epoch 185 
2025-01-24 14:36:39.096969: Current learning rate: 0.00832 
2025-01-24 14:37:28.057778: train_loss -0.7851 
2025-01-24 14:37:28.063179: val_loss -0.7694 
2025-01-24 14:37:28.066528: Pseudo dice [np.float32(0.9342), np.float32(0.9053)] 
2025-01-24 14:37:28.069667: Epoch time: 48.97 s 
2025-01-24 14:37:29.301869:  
2025-01-24 14:37:29.304748: Epoch 186 
2025-01-24 14:37:29.307690: Current learning rate: 0.00831 
2025-01-24 14:38:18.068886: train_loss -0.7946 
2025-01-24 14:38:18.074908: val_loss -0.746 
2025-01-24 14:38:18.077991: Pseudo dice [np.float32(0.9488), np.float32(0.9287)] 
2025-01-24 14:38:18.080905: Epoch time: 48.77 s 
2025-01-24 14:38:19.311670:  
2025-01-24 14:38:19.315558: Epoch 187 
2025-01-24 14:38:19.318973: Current learning rate: 0.0083 
2025-01-24 14:39:08.587022: train_loss -0.7835 
2025-01-24 14:39:08.592687: val_loss -0.727 
2025-01-24 14:39:08.595651: Pseudo dice [np.float32(0.9184), np.float32(0.8936)] 
2025-01-24 14:39:08.598415: Epoch time: 49.28 s 
2025-01-24 14:39:09.826252:  
2025-01-24 14:39:09.828925: Epoch 188 
2025-01-24 14:39:09.831483: Current learning rate: 0.00829 
2025-01-24 14:39:58.912812: train_loss -0.8035 
2025-01-24 14:39:58.918916: val_loss -0.6955 
2025-01-24 14:39:58.922707: Pseudo dice [np.float32(0.9493), np.float32(0.6717)] 
2025-01-24 14:39:58.926119: Epoch time: 49.09 s 
2025-01-24 14:40:00.152363:  
2025-01-24 14:40:00.155205: Epoch 189 
2025-01-24 14:40:00.158139: Current learning rate: 0.00828 
2025-01-24 14:40:48.983145: train_loss -0.8007 
2025-01-24 14:40:48.988225: val_loss -0.7377 
2025-01-24 14:40:48.991084: Pseudo dice [np.float32(0.9479), np.float32(0.8873)] 
2025-01-24 14:40:48.993908: Epoch time: 48.83 s 
2025-01-24 14:40:50.224393:  
2025-01-24 14:40:50.227917: Epoch 190 
2025-01-24 14:40:50.230779: Current learning rate: 0.00827 
2025-01-24 14:41:39.022685: train_loss -0.7892 
2025-01-24 14:41:39.028035: val_loss -0.7086 
2025-01-24 14:41:39.031053: Pseudo dice [np.float32(0.9404), np.float32(0.8959)] 
2025-01-24 14:41:39.033507: Epoch time: 48.8 s 
2025-01-24 14:41:40.291406:  
2025-01-24 14:41:40.294746: Epoch 191 
2025-01-24 14:41:40.298035: Current learning rate: 0.00826 
2025-01-24 14:42:29.458821: train_loss -0.8143 
2025-01-24 14:42:29.466034: val_loss -0.7344 
2025-01-24 14:42:29.469127: Pseudo dice [np.float32(0.9478), np.float32(0.8783)] 
2025-01-24 14:42:29.471898: Epoch time: 49.17 s 
2025-01-24 14:42:30.759646:  
2025-01-24 14:42:30.764205: Epoch 192 
2025-01-24 14:42:30.767322: Current learning rate: 0.00825 
2025-01-24 14:43:19.744409: train_loss -0.7937 
2025-01-24 14:43:19.750082: val_loss -0.7409 
2025-01-24 14:43:19.752997: Pseudo dice [np.float32(0.9445), np.float32(0.8777)] 
2025-01-24 14:43:19.755600: Epoch time: 48.99 s 
2025-01-24 14:43:20.995727:  
2025-01-24 14:43:20.998560: Epoch 193 
2025-01-24 14:43:21.001345: Current learning rate: 0.00824 
2025-01-24 14:44:09.674329: train_loss -0.7886 
2025-01-24 14:44:09.679642: val_loss -0.7168 
2025-01-24 14:44:09.682736: Pseudo dice [np.float32(0.9367), np.float32(0.8886)] 
2025-01-24 14:44:09.685489: Epoch time: 48.68 s 
2025-01-24 14:44:10.965345:  
2025-01-24 14:44:10.968228: Epoch 194 
2025-01-24 14:44:10.971168: Current learning rate: 0.00824 
2025-01-24 14:44:59.717038: train_loss -0.7759 
2025-01-24 14:44:59.722495: val_loss -0.7077 
2025-01-24 14:44:59.725401: Pseudo dice [np.float32(0.9157), np.float32(0.835)] 
2025-01-24 14:44:59.727987: Epoch time: 48.75 s 
2025-01-24 14:45:01.012687:  
2025-01-24 14:45:01.015871: Epoch 195 
2025-01-24 14:45:01.018682: Current learning rate: 0.00823 
2025-01-24 14:45:49.586603: train_loss -0.7616 
2025-01-24 14:45:49.593784: val_loss -0.7755 
2025-01-24 14:45:49.596690: Pseudo dice [np.float32(0.9337), np.float32(0.9225)] 
2025-01-24 14:45:49.599312: Epoch time: 48.57 s 
2025-01-24 14:45:50.837746:  
2025-01-24 14:45:50.840666: Epoch 196 
2025-01-24 14:45:50.843817: Current learning rate: 0.00822 
2025-01-24 14:46:39.988656: train_loss -0.7966 
2025-01-24 14:46:39.993992: val_loss -0.7308 
2025-01-24 14:46:39.996924: Pseudo dice [np.float32(0.9433), np.float32(0.9058)] 
2025-01-24 14:46:39.999656: Epoch time: 49.15 s 
2025-01-24 14:46:40.002308: Yayy! New best EMA pseudo Dice: 0.9036999940872192 
2025-01-24 14:46:41.776489:  
2025-01-24 14:46:41.779537: Epoch 197 
2025-01-24 14:46:41.782561: Current learning rate: 0.00821 
2025-01-24 14:47:30.661927: train_loss -0.8209 
2025-01-24 14:47:30.667948: val_loss -0.697 
2025-01-24 14:47:30.670853: Pseudo dice [np.float32(0.9314), np.float32(0.8566)] 
2025-01-24 14:47:30.673421: Epoch time: 48.89 s 
2025-01-24 14:47:31.959985:  
2025-01-24 14:47:31.964272: Epoch 198 
2025-01-24 14:47:31.967242: Current learning rate: 0.0082 
2025-01-24 14:48:20.925149: train_loss -0.7769 
2025-01-24 14:48:20.932728: val_loss -0.7222 
2025-01-24 14:48:20.935637: Pseudo dice [np.float32(0.9308), np.float32(0.8789)] 
2025-01-24 14:48:20.938663: Epoch time: 48.97 s 
2025-01-24 14:48:22.824732:  
2025-01-24 14:48:22.828538: Epoch 199 
2025-01-24 14:48:22.831964: Current learning rate: 0.00819 
2025-01-24 14:49:11.550281: train_loss -0.7933 
2025-01-24 14:49:11.555663: val_loss -0.7836 
2025-01-24 14:49:11.558881: Pseudo dice [np.float32(0.9441), np.float32(0.9287)] 
2025-01-24 14:49:11.561791: Epoch time: 48.73 s 
2025-01-24 14:49:12.156319: Yayy! New best EMA pseudo Dice: 0.9063000082969666 
2025-01-24 14:49:14.018080:  
2025-01-24 14:49:14.021761: Epoch 200 
2025-01-24 14:49:14.024753: Current learning rate: 0.00818 
2025-01-24 14:50:02.635684: train_loss -0.7889 
2025-01-24 14:50:02.642597: val_loss -0.7425 
2025-01-24 14:50:02.645330: Pseudo dice [np.float32(0.9275), np.float32(0.8846)] 
2025-01-24 14:50:02.648209: Epoch time: 48.62 s 
2025-01-24 14:50:03.928121:  
2025-01-24 14:50:03.931787: Epoch 201 
2025-01-24 14:50:03.934709: Current learning rate: 0.00817 
2025-01-24 14:50:52.491303: train_loss -0.8018 
2025-01-24 14:50:52.496691: val_loss -0.7387 
2025-01-24 14:50:52.499413: Pseudo dice [np.float32(0.9456), np.float32(0.9149)] 
2025-01-24 14:50:52.502272: Epoch time: 48.56 s 
2025-01-24 14:50:52.504697: Yayy! New best EMA pseudo Dice: 0.9085999727249146 
2025-01-24 14:50:54.418738:  
2025-01-24 14:50:54.422729: Epoch 202 
2025-01-24 14:50:54.426026: Current learning rate: 0.00816 
2025-01-24 14:51:43.115304: train_loss -0.807 
2025-01-24 14:51:43.121975: val_loss -0.7065 
2025-01-24 14:51:43.124469: Pseudo dice [np.float32(0.9495), np.float32(0.8941)] 
2025-01-24 14:51:43.127140: Epoch time: 48.7 s 
2025-01-24 14:51:43.129916: Yayy! New best EMA pseudo Dice: 0.9100000262260437 
2025-01-24 14:51:44.954555:  
2025-01-24 14:51:44.957629: Epoch 203 
2025-01-24 14:51:44.960546: Current learning rate: 0.00815 
2025-01-24 14:52:33.357140: train_loss -0.8162 
2025-01-24 14:52:33.362495: val_loss -0.7554 
2025-01-24 14:52:33.365472: Pseudo dice [np.float32(0.9492), np.float32(0.8919)] 
2025-01-24 14:52:33.368190: Epoch time: 48.4 s 
2025-01-24 14:52:33.370638: Yayy! New best EMA pseudo Dice: 0.9110000133514404 
2025-01-24 14:52:35.187987:  
2025-01-24 14:52:35.191229: Epoch 204 
2025-01-24 14:52:35.194059: Current learning rate: 0.00814 
2025-01-24 14:53:23.751171: train_loss -0.798 
2025-01-24 14:53:23.756603: val_loss -0.7241 
2025-01-24 14:53:23.759560: Pseudo dice [np.float32(0.9387), np.float32(0.8948)] 
2025-01-24 14:53:23.762451: Epoch time: 48.56 s 
2025-01-24 14:53:23.765144: Yayy! New best EMA pseudo Dice: 0.9115999937057495 
2025-01-24 14:53:25.615323:  
2025-01-24 14:53:25.619216: Epoch 205 
2025-01-24 14:53:25.622540: Current learning rate: 0.00813 
2025-01-24 14:54:14.554597: train_loss -0.7723 
2025-01-24 14:54:14.559552: val_loss -0.7266 
2025-01-24 14:54:14.562338: Pseudo dice [np.float32(0.947), np.float32(0.9135)] 
2025-01-24 14:54:14.564855: Epoch time: 48.94 s 
2025-01-24 14:54:14.567218: Yayy! New best EMA pseudo Dice: 0.9135000109672546 
2025-01-24 14:54:16.333063:  
2025-01-24 14:54:16.336316: Epoch 206 
2025-01-24 14:54:16.339150: Current learning rate: 0.00813 
2025-01-24 14:55:04.971894: train_loss -0.8025 
2025-01-24 14:55:04.977477: val_loss -0.709 
2025-01-24 14:55:04.980542: Pseudo dice [np.float32(0.9393), np.float32(0.8966)] 
2025-01-24 14:55:04.983725: Epoch time: 48.64 s 
2025-01-24 14:55:04.986521: Yayy! New best EMA pseudo Dice: 0.9139000177383423 
2025-01-24 14:55:06.784427:  
2025-01-24 14:55:06.787862: Epoch 207 
2025-01-24 14:55:06.790686: Current learning rate: 0.00812 
2025-01-24 14:55:55.083299: train_loss -0.8049 
2025-01-24 14:55:55.088214: val_loss -0.7165 
2025-01-24 14:55:55.090928: Pseudo dice [np.float32(0.9354), np.float32(0.8911)] 
2025-01-24 14:55:55.093405: Epoch time: 48.3 s 
2025-01-24 14:55:56.261605:  
2025-01-24 14:55:56.264762: Epoch 208 
2025-01-24 14:55:56.267767: Current learning rate: 0.00811 
2025-01-24 14:56:44.808483: train_loss -0.8053 
2025-01-24 14:56:44.813620: val_loss -0.7275 
2025-01-24 14:56:44.816324: Pseudo dice [np.float32(0.9281), np.float32(0.8692)] 
2025-01-24 14:56:44.819010: Epoch time: 48.55 s 
2025-01-24 14:56:46.011307:  
2025-01-24 14:56:46.014293: Epoch 209 
2025-01-24 14:56:46.017795: Current learning rate: 0.0081 
2025-01-24 14:57:34.490016: train_loss -0.7812 
2025-01-24 14:57:34.496524: val_loss -0.7052 
2025-01-24 14:57:34.499154: Pseudo dice [np.float32(0.9489), np.float32(0.9098)] 
2025-01-24 14:57:34.501933: Epoch time: 48.48 s 
2025-01-24 14:57:34.504737: Yayy! New best EMA pseudo Dice: 0.9139999747276306 
2025-01-24 14:57:36.312268:  
2025-01-24 14:57:36.315299: Epoch 210 
2025-01-24 14:57:36.318039: Current learning rate: 0.00809 
2025-01-24 14:58:24.998461: train_loss -0.8135 
2025-01-24 14:58:25.004224: val_loss -0.7395 
2025-01-24 14:58:25.007417: Pseudo dice [np.float32(0.9435), np.float32(0.9176)] 
2025-01-24 14:58:25.010327: Epoch time: 48.69 s 
2025-01-24 14:58:25.013053: Yayy! New best EMA pseudo Dice: 0.9157000184059143 
2025-01-24 14:58:26.759357:  
2025-01-24 14:58:26.762903: Epoch 211 
2025-01-24 14:58:26.765625: Current learning rate: 0.00808 
2025-01-24 14:59:15.329220: train_loss -0.796 
2025-01-24 14:59:15.334397: val_loss -0.7194 
2025-01-24 14:59:15.337196: Pseudo dice [np.float32(0.9358), np.float32(0.883)] 
2025-01-24 14:59:15.339879: Epoch time: 48.57 s 
2025-01-24 14:59:16.511551:  
2025-01-24 14:59:16.514379: Epoch 212 
2025-01-24 14:59:16.517072: Current learning rate: 0.00807 
2025-01-24 15:00:04.949601: train_loss -0.8084 
2025-01-24 15:00:04.954594: val_loss -0.7638 
2025-01-24 15:00:04.957027: Pseudo dice [np.float32(0.9247), np.float32(0.8984)] 
2025-01-24 15:00:04.959868: Epoch time: 48.44 s 
2025-01-24 15:00:06.132125:  
2025-01-24 15:00:06.135171: Epoch 213 
2025-01-24 15:00:06.138051: Current learning rate: 0.00806 
2025-01-24 15:00:55.390749: train_loss -0.8074 
2025-01-24 15:00:55.395710: val_loss -0.7694 
2025-01-24 15:00:55.398406: Pseudo dice [np.float32(0.9247), np.float32(0.9067)] 
2025-01-24 15:00:55.401015: Epoch time: 49.26 s 
2025-01-24 15:00:56.602185:  
2025-01-24 15:00:56.606209: Epoch 214 
2025-01-24 15:00:56.609281: Current learning rate: 0.00805 
2025-01-24 15:01:45.320490: train_loss -0.8059 
2025-01-24 15:01:45.325246: val_loss -0.7421 
2025-01-24 15:01:45.328050: Pseudo dice [np.float32(0.9354), np.float32(0.8751)] 
2025-01-24 15:01:45.330878: Epoch time: 48.72 s 
2025-01-24 15:01:46.531242:  
2025-01-24 15:01:46.534271: Epoch 215 
2025-01-24 15:01:46.537092: Current learning rate: 0.00804 
2025-01-24 15:02:35.791735: train_loss -0.7925 
2025-01-24 15:02:35.798767: val_loss -0.7072 
2025-01-24 15:02:35.801624: Pseudo dice [np.float32(0.9241), np.float32(0.8546)] 
2025-01-24 15:02:35.804078: Epoch time: 49.26 s 
2025-01-24 15:02:37.019214:  
2025-01-24 15:02:37.022344: Epoch 216 
2025-01-24 15:02:37.025553: Current learning rate: 0.00803 
2025-01-24 15:03:25.829822: train_loss -0.8061 
2025-01-24 15:03:25.837123: val_loss -0.7456 
2025-01-24 15:03:25.839678: Pseudo dice [np.float32(0.9429), np.float32(0.8883)] 
2025-01-24 15:03:25.842633: Epoch time: 48.81 s 
2025-01-24 15:03:27.791302:  
2025-01-24 15:03:27.794740: Epoch 217 
2025-01-24 15:03:27.797159: Current learning rate: 0.00802 
2025-01-24 15:04:16.229499: train_loss -0.8011 
2025-01-24 15:04:16.236114: val_loss -0.7612 
2025-01-24 15:04:16.238891: Pseudo dice [np.float32(0.9428), np.float32(0.8657)] 
2025-01-24 15:04:16.241457: Epoch time: 48.44 s 
2025-01-24 15:04:17.469417:  
2025-01-24 15:04:17.472856: Epoch 218 
2025-01-24 15:04:17.476129: Current learning rate: 0.00801 
2025-01-24 15:05:06.137304: train_loss -0.8047 
2025-01-24 15:05:06.142954: val_loss -0.6756 
2025-01-24 15:05:06.145835: Pseudo dice [np.float32(0.9417), np.float32(0.7769)] 
2025-01-24 15:05:06.148413: Epoch time: 48.67 s 
2025-01-24 15:05:07.359412:  
2025-01-24 15:05:07.362407: Epoch 219 
2025-01-24 15:05:07.365059: Current learning rate: 0.00801 
2025-01-24 15:05:55.937182: train_loss -0.7721 
2025-01-24 15:05:55.942926: val_loss -0.675 
2025-01-24 15:05:55.945963: Pseudo dice [np.float32(0.9307), np.float32(0.7235)] 
2025-01-24 15:05:55.948644: Epoch time: 48.58 s 
2025-01-24 15:05:57.153625:  
2025-01-24 15:05:57.156902: Epoch 220 
2025-01-24 15:05:57.159726: Current learning rate: 0.008 
2025-01-24 15:06:45.510238: train_loss -0.7636 
2025-01-24 15:06:45.517089: val_loss -0.6841 
2025-01-24 15:06:45.520082: Pseudo dice [np.float32(0.9222), np.float32(0.8749)] 
2025-01-24 15:06:45.523039: Epoch time: 48.36 s 
2025-01-24 15:06:46.716970:  
2025-01-24 15:06:46.720642: Epoch 221 
2025-01-24 15:06:46.724000: Current learning rate: 0.00799 
2025-01-24 15:07:35.759258: train_loss -0.7643 
2025-01-24 15:07:35.763746: val_loss -0.6454 
2025-01-24 15:07:35.766224: Pseudo dice [np.float32(0.9202), np.float32(0.84)] 
2025-01-24 15:07:35.768980: Epoch time: 49.04 s 
2025-01-24 15:07:36.980185:  
2025-01-24 15:07:36.983010: Epoch 222 
2025-01-24 15:07:36.986014: Current learning rate: 0.00798 
2025-01-24 15:08:25.606832: train_loss -0.7527 
2025-01-24 15:08:25.612713: val_loss -0.6635 
2025-01-24 15:08:25.615825: Pseudo dice [np.float32(0.9274), np.float32(0.7896)] 
2025-01-24 15:08:25.618647: Epoch time: 48.63 s 
2025-01-24 15:08:26.846776:  
2025-01-24 15:08:26.849645: Epoch 223 
2025-01-24 15:08:26.852307: Current learning rate: 0.00797 
2025-01-24 15:09:15.552977: train_loss -0.777 
2025-01-24 15:09:15.558964: val_loss -0.6093 
2025-01-24 15:09:15.561854: Pseudo dice [np.float32(0.9197), np.float32(0.7116)] 
2025-01-24 15:09:15.564582: Epoch time: 48.71 s 
2025-01-24 15:09:16.786891:  
2025-01-24 15:09:16.789887: Epoch 224 
2025-01-24 15:09:16.792550: Current learning rate: 0.00796 
2025-01-24 15:10:05.525297: train_loss -0.7912 
2025-01-24 15:10:05.530608: val_loss -0.713 
2025-01-24 15:10:05.533737: Pseudo dice [np.float32(0.9401), np.float32(0.8513)] 
2025-01-24 15:10:05.536299: Epoch time: 48.74 s 
2025-01-24 15:10:06.752610:  
2025-01-24 15:10:06.755771: Epoch 225 
2025-01-24 15:10:06.758706: Current learning rate: 0.00795 
2025-01-24 15:10:55.145494: train_loss -0.789 
2025-01-24 15:10:55.152208: val_loss -0.7033 
2025-01-24 15:10:55.155105: Pseudo dice [np.float32(0.9356), np.float32(0.8624)] 
2025-01-24 15:10:55.157584: Epoch time: 48.39 s 
2025-01-24 15:10:56.348745:  
2025-01-24 15:10:56.352102: Epoch 226 
2025-01-24 15:10:56.355023: Current learning rate: 0.00794 
2025-01-24 15:11:44.496660: train_loss -0.813 
2025-01-24 15:11:44.501823: val_loss -0.6808 
2025-01-24 15:11:44.504791: Pseudo dice [np.float32(0.9298), np.float32(0.8023)] 
2025-01-24 15:11:44.507280: Epoch time: 48.15 s 
2025-01-24 15:11:45.700784:  
2025-01-24 15:11:45.703594: Epoch 227 
2025-01-24 15:11:45.706533: Current learning rate: 0.00793 
2025-01-24 15:12:33.891621: train_loss -0.7899 
2025-01-24 15:12:33.896783: val_loss -0.7087 
2025-01-24 15:12:33.899338: Pseudo dice [np.float32(0.9376), np.float32(0.8716)] 
2025-01-24 15:12:33.901654: Epoch time: 48.19 s 
2025-01-24 15:12:35.087138:  
2025-01-24 15:12:35.090100: Epoch 228 
2025-01-24 15:12:35.092860: Current learning rate: 0.00792 
2025-01-24 15:13:24.325700: train_loss -0.7952 
2025-01-24 15:13:24.330348: val_loss -0.7285 
2025-01-24 15:13:24.332862: Pseudo dice [np.float32(0.9383), np.float32(0.8719)] 
2025-01-24 15:13:24.335182: Epoch time: 49.24 s 
2025-01-24 15:13:25.527818:  
2025-01-24 15:13:25.530849: Epoch 229 
2025-01-24 15:13:25.533539: Current learning rate: 0.00791 
2025-01-24 15:14:13.871589: train_loss -0.7977 
2025-01-24 15:14:13.877092: val_loss -0.7622 
2025-01-24 15:14:13.879945: Pseudo dice [np.float32(0.954), np.float32(0.9348)] 
2025-01-24 15:14:13.882708: Epoch time: 48.34 s 
2025-01-24 15:14:15.082201:  
2025-01-24 15:14:15.085636: Epoch 230 
2025-01-24 15:14:15.088608: Current learning rate: 0.0079 
2025-01-24 15:15:03.539912: train_loss -0.8043 
2025-01-24 15:15:03.545180: val_loss -0.7625 
2025-01-24 15:15:03.547811: Pseudo dice [np.float32(0.9452), np.float32(0.9191)] 
2025-01-24 15:15:03.550485: Epoch time: 48.46 s 
2025-01-24 15:15:04.746594:  
2025-01-24 15:15:04.749521: Epoch 231 
2025-01-24 15:15:04.752467: Current learning rate: 0.00789 
2025-01-24 15:15:53.479192: train_loss -0.8165 
2025-01-24 15:15:53.484167: val_loss -0.7207 
2025-01-24 15:15:53.486830: Pseudo dice [np.float32(0.947), np.float32(0.8181)] 
2025-01-24 15:15:53.489365: Epoch time: 48.73 s 
2025-01-24 15:15:54.681618:  
2025-01-24 15:15:54.684642: Epoch 232 
2025-01-24 15:15:54.687191: Current learning rate: 0.00789 
2025-01-24 15:16:43.510891: train_loss -0.8006 
2025-01-24 15:16:43.516145: val_loss -0.6986 
2025-01-24 15:16:43.518995: Pseudo dice [np.float32(0.9332), np.float32(0.8967)] 
2025-01-24 15:16:43.521465: Epoch time: 48.83 s 
2025-01-24 15:16:44.712576:  
2025-01-24 15:16:44.715477: Epoch 233 
2025-01-24 15:16:44.718281: Current learning rate: 0.00788 
2025-01-24 15:17:33.320223: train_loss -0.7979 
2025-01-24 15:17:33.324782: val_loss -0.7117 
2025-01-24 15:17:33.327567: Pseudo dice [np.float32(0.9536), np.float32(0.8804)] 
2025-01-24 15:17:33.330082: Epoch time: 48.61 s 
2025-01-24 15:17:34.521544:  
2025-01-24 15:17:34.524124: Epoch 234 
2025-01-24 15:17:34.526489: Current learning rate: 0.00787 
2025-01-24 15:18:22.996992: train_loss -0.802 
2025-01-24 15:18:23.002369: val_loss -0.7393 
2025-01-24 15:18:23.005316: Pseudo dice [np.float32(0.9486), np.float32(0.8997)] 
2025-01-24 15:18:23.008121: Epoch time: 48.48 s 
2025-01-24 15:18:24.209748:  
2025-01-24 15:18:24.212727: Epoch 235 
2025-01-24 15:18:24.215704: Current learning rate: 0.00786 
2025-01-24 15:19:12.646146: train_loss -0.7953 
2025-01-24 15:19:12.651440: val_loss -0.7067 
2025-01-24 15:19:12.654327: Pseudo dice [np.float32(0.9388), np.float32(0.8964)] 
2025-01-24 15:19:12.657142: Epoch time: 48.44 s 
2025-01-24 15:19:14.458186:  
2025-01-24 15:19:14.461290: Epoch 236 
2025-01-24 15:19:14.463972: Current learning rate: 0.00785 
2025-01-24 15:20:03.273707: train_loss -0.7814 
2025-01-24 15:20:03.279288: val_loss -0.7475 
2025-01-24 15:20:03.282291: Pseudo dice [np.float32(0.9443), np.float32(0.8978)] 
2025-01-24 15:20:03.285338: Epoch time: 48.82 s 
2025-01-24 15:20:04.474311:  
2025-01-24 15:20:04.477300: Epoch 237 
2025-01-24 15:20:04.479805: Current learning rate: 0.00784 
2025-01-24 15:20:53.327712: train_loss -0.8092 
2025-01-24 15:20:53.334271: val_loss -0.7532 
2025-01-24 15:20:53.336572: Pseudo dice [np.float32(0.9343), np.float32(0.8879)] 
2025-01-24 15:20:53.338835: Epoch time: 48.85 s 
2025-01-24 15:20:54.543078:  
2025-01-24 15:20:54.545748: Epoch 238 
2025-01-24 15:20:54.548442: Current learning rate: 0.00783 
2025-01-24 15:21:43.396822: train_loss -0.7948 
2025-01-24 15:21:43.402356: val_loss -0.7163 
2025-01-24 15:21:43.405239: Pseudo dice [np.float32(0.9529), np.float32(0.8671)] 
2025-01-24 15:21:43.408021: Epoch time: 48.86 s 
2025-01-24 15:21:44.605978:  
2025-01-24 15:21:44.609220: Epoch 239 
2025-01-24 15:21:44.612129: Current learning rate: 0.00782 
2025-01-24 15:22:33.404692: train_loss -0.7996 
2025-01-24 15:22:33.409693: val_loss -0.7298 
2025-01-24 15:22:33.412256: Pseudo dice [np.float32(0.9052), np.float32(0.8842)] 
2025-01-24 15:22:33.414975: Epoch time: 48.8 s 
2025-01-24 15:22:34.615064:  
2025-01-24 15:22:34.618983: Epoch 240 
2025-01-24 15:22:34.621942: Current learning rate: 0.00781 
2025-01-24 15:23:23.017587: train_loss -0.8131 
2025-01-24 15:23:23.023190: val_loss -0.6924 
2025-01-24 15:23:23.026020: Pseudo dice [np.float32(0.9444), np.float32(0.8678)] 
2025-01-24 15:23:23.029098: Epoch time: 48.4 s 
2025-01-24 15:23:24.221259:  
2025-01-24 15:23:24.224892: Epoch 241 
2025-01-24 15:23:24.227819: Current learning rate: 0.0078 
2025-01-24 15:24:13.268923: train_loss -0.806 
2025-01-24 15:24:13.273938: val_loss -0.7311 
2025-01-24 15:24:13.276712: Pseudo dice [np.float32(0.9365), np.float32(0.9181)] 
2025-01-24 15:24:13.279285: Epoch time: 49.05 s 
2025-01-24 15:24:14.492866:  
2025-01-24 15:24:14.495979: Epoch 242 
2025-01-24 15:24:14.498970: Current learning rate: 0.00779 
2025-01-24 15:25:03.216702: train_loss -0.7999 
2025-01-24 15:25:03.221686: val_loss -0.7258 
2025-01-24 15:25:03.224238: Pseudo dice [np.float32(0.9289), np.float32(0.8536)] 
2025-01-24 15:25:03.226676: Epoch time: 48.72 s 
2025-01-24 15:25:04.449986:  
2025-01-24 15:25:04.453254: Epoch 243 
2025-01-24 15:25:04.456063: Current learning rate: 0.00778 
2025-01-24 15:25:53.808816: train_loss -0.7767 
2025-01-24 15:25:53.813746: val_loss -0.6422 
2025-01-24 15:25:53.816619: Pseudo dice [np.float32(0.9185), np.float32(0.8161)] 
2025-01-24 15:25:53.819151: Epoch time: 49.36 s 
2025-01-24 15:25:55.023833:  
2025-01-24 15:25:55.026727: Epoch 244 
2025-01-24 15:25:55.029687: Current learning rate: 0.00777 
2025-01-24 15:26:43.916697: train_loss -0.7865 
2025-01-24 15:26:43.921874: val_loss -0.7533 
2025-01-24 15:26:43.924757: Pseudo dice [np.float32(0.947), np.float32(0.9026)] 
2025-01-24 15:26:43.927638: Epoch time: 48.89 s 
2025-01-24 15:26:45.144452:  
2025-01-24 15:26:45.147911: Epoch 245 
2025-01-24 15:26:45.151083: Current learning rate: 0.00777 
2025-01-24 15:27:33.993344: train_loss -0.7799 
2025-01-24 15:27:33.998531: val_loss -0.657 
2025-01-24 15:27:34.001139: Pseudo dice [np.float32(0.9358), np.float32(0.8188)] 
2025-01-24 15:27:34.003746: Epoch time: 48.85 s 
2025-01-24 15:27:35.210888:  
2025-01-24 15:27:35.214201: Epoch 246 
2025-01-24 15:27:35.216587: Current learning rate: 0.00776 
2025-01-24 15:28:23.887786: train_loss -0.7847 
2025-01-24 15:28:23.894800: val_loss -0.6857 
2025-01-24 15:28:23.898074: Pseudo dice [np.float32(0.9414), np.float32(0.8106)] 
2025-01-24 15:28:23.900791: Epoch time: 48.68 s 
2025-01-24 15:28:25.115884:  
2025-01-24 15:28:25.119100: Epoch 247 
2025-01-24 15:28:25.122061: Current learning rate: 0.00775 
2025-01-24 15:29:13.866076: train_loss -0.7658 
2025-01-24 15:29:13.871315: val_loss -0.6905 
2025-01-24 15:29:13.873879: Pseudo dice [np.float32(0.9291), np.float32(0.8848)] 
2025-01-24 15:29:13.876359: Epoch time: 48.75 s 
2025-01-24 15:29:15.084022:  
2025-01-24 15:29:15.086958: Epoch 248 
2025-01-24 15:29:15.089720: Current learning rate: 0.00774 
2025-01-24 15:30:04.068293: train_loss -0.7919 
2025-01-24 15:30:04.073586: val_loss -0.6789 
2025-01-24 15:30:04.076393: Pseudo dice [np.float32(0.9423), np.float32(0.6852)] 
2025-01-24 15:30:04.079298: Epoch time: 48.99 s 
2025-01-24 15:30:05.283036:  
2025-01-24 15:30:05.286191: Epoch 249 
2025-01-24 15:30:05.289183: Current learning rate: 0.00773 
2025-01-24 15:30:54.168069: train_loss -0.7918 
2025-01-24 15:30:54.173450: val_loss -0.7238 
2025-01-24 15:30:54.176340: Pseudo dice [np.float32(0.9138), np.float32(0.8173)] 
2025-01-24 15:30:54.178943: Epoch time: 48.89 s 
2025-01-24 15:30:55.930160:  
2025-01-24 15:30:55.933220: Epoch 250 
2025-01-24 15:30:55.936046: Current learning rate: 0.00772 
2025-01-24 15:31:44.611949: train_loss -0.8007 
2025-01-24 15:31:44.617769: val_loss -0.7021 
2025-01-24 15:31:44.620530: Pseudo dice [np.float32(0.9339), np.float32(0.8315)] 
2025-01-24 15:31:44.623232: Epoch time: 48.68 s 
2025-01-24 15:31:45.842242:  
2025-01-24 15:31:45.845870: Epoch 251 
2025-01-24 15:31:45.848812: Current learning rate: 0.00771 
2025-01-24 15:32:34.606527: train_loss -0.7887 
2025-01-24 15:32:34.611604: val_loss -0.7569 
2025-01-24 15:32:34.614221: Pseudo dice [np.float32(0.9436), np.float32(0.8656)] 
2025-01-24 15:32:34.616751: Epoch time: 48.77 s 
2025-01-24 15:32:35.820783:  
2025-01-24 15:32:35.824500: Epoch 252 
2025-01-24 15:32:35.827349: Current learning rate: 0.0077 
2025-01-24 15:33:24.710641: train_loss -0.7753 
2025-01-24 15:33:24.715995: val_loss -0.6155 
2025-01-24 15:33:24.718813: Pseudo dice [np.float32(0.934), np.float32(0.7525)] 
2025-01-24 15:33:24.721774: Epoch time: 48.89 s 
2025-01-24 15:33:25.937943:  
2025-01-24 15:33:25.941206: Epoch 253 
2025-01-24 15:33:25.944047: Current learning rate: 0.00769 
2025-01-24 15:34:15.050481: train_loss -0.7877 
2025-01-24 15:34:15.055358: val_loss -0.6398 
2025-01-24 15:34:15.058239: Pseudo dice [np.float32(0.9244), np.float32(0.7263)] 
2025-01-24 15:34:15.060765: Epoch time: 49.11 s 
2025-01-24 15:34:16.264972:  
2025-01-24 15:34:16.268154: Epoch 254 
2025-01-24 15:34:16.271209: Current learning rate: 0.00768 
2025-01-24 15:35:05.013006: train_loss -0.7921 
2025-01-24 15:35:05.018091: val_loss -0.7808 
2025-01-24 15:35:05.020750: Pseudo dice [np.float32(0.9515), np.float32(0.9397)] 
2025-01-24 15:35:05.023504: Epoch time: 48.75 s 
2025-01-24 15:35:06.230448:  
2025-01-24 15:35:06.233640: Epoch 255 
2025-01-24 15:35:06.236506: Current learning rate: 0.00767 
2025-01-24 15:35:54.783637: train_loss -0.8007 
2025-01-24 15:35:54.789078: val_loss -0.7207 
2025-01-24 15:35:54.792186: Pseudo dice [np.float32(0.9391), np.float32(0.883)] 
2025-01-24 15:35:54.794886: Epoch time: 48.55 s 
2025-01-24 15:35:56.606070:  
2025-01-24 15:35:56.609390: Epoch 256 
2025-01-24 15:35:56.612309: Current learning rate: 0.00766 
2025-01-24 15:36:45.495730: train_loss -0.795 
2025-01-24 15:36:45.501389: val_loss -0.7093 
2025-01-24 15:36:45.504178: Pseudo dice [np.float32(0.9393), np.float32(0.8076)] 
2025-01-24 15:36:45.507159: Epoch time: 48.89 s 
2025-01-24 15:36:46.723175:  
2025-01-24 15:36:46.726340: Epoch 257 
2025-01-24 15:36:46.728903: Current learning rate: 0.00765 
2025-01-24 15:37:35.112097: train_loss -0.7995 
2025-01-24 15:37:35.119183: val_loss -0.7346 
2025-01-24 15:37:35.121829: Pseudo dice [np.float32(0.9522), np.float32(0.8213)] 
2025-01-24 15:37:35.124243: Epoch time: 48.39 s 
2025-01-24 15:37:36.341673:  
2025-01-24 15:37:36.345509: Epoch 258 
2025-01-24 15:37:36.348100: Current learning rate: 0.00764 
2025-01-24 15:38:24.689247: train_loss -0.7907 
2025-01-24 15:38:24.693879: val_loss -0.7138 
2025-01-24 15:38:24.696813: Pseudo dice [np.float32(0.9434), np.float32(0.8562)] 
2025-01-24 15:38:24.699207: Epoch time: 48.35 s 
2025-01-24 15:38:25.908847:  
2025-01-24 15:38:25.911879: Epoch 259 
2025-01-24 15:38:25.914906: Current learning rate: 0.00764 
2025-01-24 15:39:14.527812: train_loss -0.7925 
2025-01-24 15:39:14.533414: val_loss -0.7028 
2025-01-24 15:39:14.536319: Pseudo dice [np.float32(0.9463), np.float32(0.9064)] 
2025-01-24 15:39:14.539093: Epoch time: 48.62 s 
2025-01-24 15:39:15.760728:  
2025-01-24 15:39:15.764124: Epoch 260 
2025-01-24 15:39:15.767061: Current learning rate: 0.00763 
2025-01-24 15:40:04.321866: train_loss -0.8045 
2025-01-24 15:40:04.326855: val_loss -0.7128 
2025-01-24 15:40:04.329528: Pseudo dice [np.float32(0.9188), np.float32(0.8641)] 
2025-01-24 15:40:04.332228: Epoch time: 48.56 s 
2025-01-24 15:40:05.542287:  
2025-01-24 15:40:05.545395: Epoch 261 
2025-01-24 15:40:05.548059: Current learning rate: 0.00762 
2025-01-24 15:40:53.687063: train_loss -0.7868 
2025-01-24 15:40:53.693777: val_loss -0.7471 
2025-01-24 15:40:53.697058: Pseudo dice [np.float32(0.9443), np.float32(0.9042)] 
2025-01-24 15:40:53.699990: Epoch time: 48.15 s 
2025-01-24 15:40:54.927993:  
2025-01-24 15:40:54.931198: Epoch 262 
2025-01-24 15:40:54.934022: Current learning rate: 0.00761 
2025-01-24 15:41:43.446660: train_loss -0.8031 
2025-01-24 15:41:43.452289: val_loss -0.7032 
2025-01-24 15:41:43.454999: Pseudo dice [np.float32(0.9329), np.float32(0.8831)] 
2025-01-24 15:41:43.457942: Epoch time: 48.52 s 
2025-01-24 15:41:44.668506:  
2025-01-24 15:41:44.672262: Epoch 263 
2025-01-24 15:41:44.675290: Current learning rate: 0.0076 
2025-01-24 15:42:33.496525: train_loss -0.7875 
2025-01-24 15:42:33.502325: val_loss -0.7008 
2025-01-24 15:42:33.505432: Pseudo dice [np.float32(0.9495), np.float32(0.905)] 
2025-01-24 15:42:33.508258: Epoch time: 48.83 s 
2025-01-24 15:42:34.692340:  
2025-01-24 15:42:34.695466: Epoch 264 
2025-01-24 15:42:34.698422: Current learning rate: 0.00759 
2025-01-24 15:43:23.640844: train_loss -0.8161 
2025-01-24 15:43:23.648571: val_loss -0.7152 
2025-01-24 15:43:23.653163: Pseudo dice [np.float32(0.9478), np.float32(0.907)] 
2025-01-24 15:43:23.656630: Epoch time: 48.95 s 
2025-01-24 15:43:24.839991:  
2025-01-24 15:43:24.843712: Epoch 265 
2025-01-24 15:43:24.846577: Current learning rate: 0.00758 
2025-01-24 15:44:13.685749: train_loss -0.8068 
2025-01-24 15:44:13.691352: val_loss -0.7078 
2025-01-24 15:44:13.694372: Pseudo dice [np.float32(0.9534), np.float32(0.8909)] 
2025-01-24 15:44:13.697140: Epoch time: 48.85 s 
2025-01-24 15:44:14.912892:  
2025-01-24 15:44:14.915608: Epoch 266 
2025-01-24 15:44:14.918637: Current learning rate: 0.00757 
2025-01-24 15:45:03.670347: train_loss -0.7969 
2025-01-24 15:45:03.675338: val_loss -0.7182 
2025-01-24 15:45:03.678240: Pseudo dice [np.float32(0.9348), np.float32(0.8502)] 
2025-01-24 15:45:03.680945: Epoch time: 48.76 s 
2025-01-24 15:45:04.863730:  
2025-01-24 15:45:04.866956: Epoch 267 
2025-01-24 15:45:04.869921: Current learning rate: 0.00756 
2025-01-24 15:45:53.589100: train_loss -0.8041 
2025-01-24 15:45:53.594358: val_loss -0.7317 
2025-01-24 15:45:53.596967: Pseudo dice [np.float32(0.9505), np.float32(0.8378)] 
2025-01-24 15:45:53.599617: Epoch time: 48.73 s 
2025-01-24 15:45:54.778462:  
2025-01-24 15:45:54.781396: Epoch 268 
2025-01-24 15:45:54.784147: Current learning rate: 0.00755 
2025-01-24 15:46:43.547724: train_loss -0.792 
2025-01-24 15:46:43.553233: val_loss -0.7465 
2025-01-24 15:46:43.556095: Pseudo dice [np.float32(0.9361), np.float32(0.9156)] 
2025-01-24 15:46:43.558604: Epoch time: 48.77 s 
2025-01-24 15:46:44.743843:  
2025-01-24 15:46:44.747083: Epoch 269 
2025-01-24 15:46:44.750263: Current learning rate: 0.00754 
2025-01-24 15:47:33.395710: train_loss -0.7962 
2025-01-24 15:47:33.401265: val_loss -0.7234 
2025-01-24 15:47:33.403977: Pseudo dice [np.float32(0.941), np.float32(0.9172)] 
2025-01-24 15:47:33.406597: Epoch time: 48.65 s 
2025-01-24 15:47:34.581567:  
2025-01-24 15:47:34.585157: Epoch 270 
2025-01-24 15:47:34.587738: Current learning rate: 0.00753 
2025-01-24 15:48:23.100147: train_loss -0.8042 
2025-01-24 15:48:23.106641: val_loss -0.758 
2025-01-24 15:48:23.110077: Pseudo dice [np.float32(0.9259), np.float32(0.8921)] 
2025-01-24 15:48:23.112570: Epoch time: 48.52 s 
2025-01-24 15:48:24.323865:  
2025-01-24 15:48:24.327090: Epoch 271 
2025-01-24 15:48:24.330380: Current learning rate: 0.00752 
2025-01-24 15:49:12.648798: train_loss -0.7987 
2025-01-24 15:49:12.654707: val_loss -0.7644 
2025-01-24 15:49:12.657571: Pseudo dice [np.float32(0.9488), np.float32(0.8993)] 
2025-01-24 15:49:12.660687: Epoch time: 48.33 s 
2025-01-24 15:49:13.846462:  
2025-01-24 15:49:13.849584: Epoch 272 
2025-01-24 15:49:13.852651: Current learning rate: 0.00751 
2025-01-24 15:50:03.082127: train_loss -0.7961 
2025-01-24 15:50:03.087663: val_loss -0.7553 
2025-01-24 15:50:03.090421: Pseudo dice [np.float32(0.9512), np.float32(0.8547)] 
2025-01-24 15:50:03.093348: Epoch time: 49.24 s 
2025-01-24 15:50:04.272629:  
2025-01-24 15:50:04.276034: Epoch 273 
2025-01-24 15:50:04.279261: Current learning rate: 0.00751 
2025-01-24 15:50:52.590573: train_loss -0.7883 
2025-01-24 15:50:52.596637: val_loss -0.7203 
2025-01-24 15:50:52.599573: Pseudo dice [np.float32(0.9391), np.float32(0.8977)] 
2025-01-24 15:50:52.602397: Epoch time: 48.32 s 
2025-01-24 15:50:53.781518:  
2025-01-24 15:50:53.784739: Epoch 274 
2025-01-24 15:50:53.787658: Current learning rate: 0.0075 
2025-01-24 15:51:42.043682: train_loss -0.8074 
2025-01-24 15:51:42.052658: val_loss -0.724 
2025-01-24 15:51:42.055559: Pseudo dice [np.float32(0.9443), np.float32(0.8527)] 
2025-01-24 15:51:42.058400: Epoch time: 48.26 s 
2025-01-24 15:51:43.907826:  
2025-01-24 15:51:43.911252: Epoch 275 
2025-01-24 15:51:43.913849: Current learning rate: 0.00749 
2025-01-24 15:52:33.278319: train_loss -0.782 
2025-01-24 15:52:33.284395: val_loss -0.758 
2025-01-24 15:52:33.287430: Pseudo dice [np.float32(0.9363), np.float32(0.891)] 
2025-01-24 15:52:33.290449: Epoch time: 49.37 s 
2025-01-24 15:52:34.471527:  
2025-01-24 15:52:34.474957: Epoch 276 
2025-01-24 15:52:34.477799: Current learning rate: 0.00748 
2025-01-24 15:53:23.131835: train_loss -0.8037 
2025-01-24 15:53:23.137665: val_loss -0.7608 
2025-01-24 15:53:23.140626: Pseudo dice [np.float32(0.94), np.float32(0.9048)] 
2025-01-24 15:53:23.143629: Epoch time: 48.66 s 
2025-01-24 15:53:24.347564:  
2025-01-24 15:53:24.350788: Epoch 277 
2025-01-24 15:53:24.353824: Current learning rate: 0.00747 
2025-01-24 15:54:13.232990: train_loss -0.8104 
2025-01-24 15:54:13.238965: val_loss -0.7031 
2025-01-24 15:54:13.242041: Pseudo dice [np.float32(0.9221), np.float32(0.8536)] 
2025-01-24 15:54:13.245092: Epoch time: 48.89 s 
2025-01-24 15:54:14.450491:  
2025-01-24 15:54:14.453885: Epoch 278 
2025-01-24 15:54:14.457234: Current learning rate: 0.00746 
2025-01-24 15:55:02.786005: train_loss -0.8122 
2025-01-24 15:55:02.791459: val_loss -0.6691 
2025-01-24 15:55:02.794383: Pseudo dice [np.float32(0.9085), np.float32(0.8217)] 
2025-01-24 15:55:02.797403: Epoch time: 48.34 s 
2025-01-24 15:55:03.977989:  
2025-01-24 15:55:03.981487: Epoch 279 
2025-01-24 15:55:03.984514: Current learning rate: 0.00745 
2025-01-24 15:55:52.860655: train_loss -0.7972 
2025-01-24 15:55:52.865292: val_loss -0.6645 
2025-01-24 15:55:52.868051: Pseudo dice [np.float32(0.9235), np.float32(0.8074)] 
2025-01-24 15:55:52.870704: Epoch time: 48.88 s 
2025-01-24 15:55:54.079077:  
2025-01-24 15:55:54.082047: Epoch 280 
2025-01-24 15:55:54.085066: Current learning rate: 0.00744 
2025-01-24 15:56:42.897053: train_loss -0.7938 
2025-01-24 15:56:42.902712: val_loss -0.7682 
2025-01-24 15:56:42.905506: Pseudo dice [np.float32(0.9368), np.float32(0.868)] 
2025-01-24 15:56:42.908366: Epoch time: 48.82 s 
2025-01-24 15:56:44.090139:  
2025-01-24 15:56:44.093192: Epoch 281 
2025-01-24 15:56:44.097402: Current learning rate: 0.00743 
2025-01-24 15:57:32.857337: train_loss -0.796 
2025-01-24 15:57:32.862863: val_loss -0.7272 
2025-01-24 15:57:32.865956: Pseudo dice [np.float32(0.9375), np.float32(0.8577)] 
2025-01-24 15:57:32.868544: Epoch time: 48.77 s 
2025-01-24 15:57:34.047858:  
2025-01-24 15:57:34.050765: Epoch 282 
2025-01-24 15:57:34.053329: Current learning rate: 0.00742 
2025-01-24 15:58:22.402895: train_loss -0.8344 
2025-01-24 15:58:22.408340: val_loss -0.7219 
2025-01-24 15:58:22.411054: Pseudo dice [np.float32(0.9325), np.float32(0.882)] 
2025-01-24 15:58:22.413823: Epoch time: 48.36 s 
2025-01-24 15:58:23.586686:  
2025-01-24 15:58:23.590087: Epoch 283 
2025-01-24 15:58:23.593009: Current learning rate: 0.00741 
2025-01-24 15:59:12.295164: train_loss -0.7882 
2025-01-24 15:59:12.300624: val_loss -0.6551 
2025-01-24 15:59:12.303609: Pseudo dice [np.float32(0.9035), np.float32(0.8003)] 
2025-01-24 15:59:12.306200: Epoch time: 48.71 s 
2025-01-24 15:59:13.517609:  
2025-01-24 15:59:13.520956: Epoch 284 
2025-01-24 15:59:13.524333: Current learning rate: 0.0074 
2025-01-24 16:00:02.203419: train_loss -0.81 
2025-01-24 16:00:02.207931: val_loss -0.7015 
2025-01-24 16:00:02.210718: Pseudo dice [np.float32(0.9417), np.float32(0.8487)] 
2025-01-24 16:00:02.213212: Epoch time: 48.69 s 
2025-01-24 16:00:03.390762:  
2025-01-24 16:00:03.395033: Epoch 285 
2025-01-24 16:00:03.398192: Current learning rate: 0.00739 
2025-01-24 16:00:52.443584: train_loss -0.8067 
2025-01-24 16:00:52.449835: val_loss -0.7315 
2025-01-24 16:00:52.453161: Pseudo dice [np.float32(0.9389), np.float32(0.7998)] 
2025-01-24 16:00:52.456236: Epoch time: 49.06 s 
2025-01-24 16:00:53.639763:  
2025-01-24 16:00:53.643638: Epoch 286 
2025-01-24 16:00:53.646925: Current learning rate: 0.00738 
2025-01-24 16:01:42.881126: train_loss -0.8152 
2025-01-24 16:01:42.886852: val_loss -0.7517 
2025-01-24 16:01:42.889968: Pseudo dice [np.float32(0.948), np.float32(0.8912)] 
2025-01-24 16:01:42.892972: Epoch time: 49.24 s 
2025-01-24 16:01:44.087396:  
2025-01-24 16:01:44.090244: Epoch 287 
2025-01-24 16:01:44.093044: Current learning rate: 0.00738 
2025-01-24 16:02:32.697764: train_loss -0.7986 
2025-01-24 16:02:32.702721: val_loss -0.7122 
2025-01-24 16:02:32.705397: Pseudo dice [np.float32(0.9354), np.float32(0.8057)] 
2025-01-24 16:02:32.707981: Epoch time: 48.61 s 
2025-01-24 16:02:33.906799:  
2025-01-24 16:02:33.909784: Epoch 288 
2025-01-24 16:02:33.912504: Current learning rate: 0.00737 
2025-01-24 16:03:22.674191: train_loss -0.8135 
2025-01-24 16:03:22.680073: val_loss -0.7704 
2025-01-24 16:03:22.682988: Pseudo dice [np.float32(0.9426), np.float32(0.9168)] 
2025-01-24 16:03:22.685762: Epoch time: 48.77 s 
2025-01-24 16:03:23.873840:  
2025-01-24 16:03:23.876879: Epoch 289 
2025-01-24 16:03:23.879508: Current learning rate: 0.00736 
2025-01-24 16:04:12.507097: train_loss -0.7959 
2025-01-24 16:04:12.512844: val_loss -0.6884 
2025-01-24 16:04:12.515824: Pseudo dice [np.float32(0.9387), np.float32(0.9021)] 
2025-01-24 16:04:12.518701: Epoch time: 48.63 s 
2025-01-24 16:04:13.750741:  
2025-01-24 16:04:13.753561: Epoch 290 
2025-01-24 16:04:13.755996: Current learning rate: 0.00735 
2025-01-24 16:05:02.206368: train_loss -0.8034 
2025-01-24 16:05:02.211013: val_loss -0.6895 
2025-01-24 16:05:02.213529: Pseudo dice [np.float32(0.9386), np.float32(0.8452)] 
2025-01-24 16:05:02.216170: Epoch time: 48.46 s 
2025-01-24 16:05:03.409591:  
2025-01-24 16:05:03.412482: Epoch 291 
2025-01-24 16:05:03.415342: Current learning rate: 0.00734 
2025-01-24 16:05:52.165673: train_loss -0.8012 
2025-01-24 16:05:52.170661: val_loss -0.7479 
2025-01-24 16:05:52.173560: Pseudo dice [np.float32(0.9299), np.float32(0.9003)] 
2025-01-24 16:05:52.176308: Epoch time: 48.76 s 
2025-01-24 16:05:53.392751:  
2025-01-24 16:05:53.396220: Epoch 292 
2025-01-24 16:05:53.399253: Current learning rate: 0.00733 
2025-01-24 16:06:42.195162: train_loss -0.8139 
2025-01-24 16:06:42.199937: val_loss -0.7627 
2025-01-24 16:06:42.202588: Pseudo dice [np.float32(0.9371), np.float32(0.9082)] 
2025-01-24 16:06:42.204937: Epoch time: 48.8 s 
2025-01-24 16:06:44.037979:  
2025-01-24 16:06:44.041857: Epoch 293 
2025-01-24 16:06:44.044483: Current learning rate: 0.00732 
2025-01-24 16:07:32.469450: train_loss -0.8056 
2025-01-24 16:07:32.475003: val_loss -0.7356 
2025-01-24 16:07:32.478533: Pseudo dice [np.float32(0.9219), np.float32(0.8363)] 
2025-01-24 16:07:32.481615: Epoch time: 48.43 s 
2025-01-24 16:07:33.721734:  
2025-01-24 16:07:33.724950: Epoch 294 
2025-01-24 16:07:33.727788: Current learning rate: 0.00731 
2025-01-24 16:08:22.310932: train_loss -0.7759 
2025-01-24 16:08:22.316730: val_loss -0.7269 
2025-01-24 16:08:22.320259: Pseudo dice [np.float32(0.9338), np.float32(0.8887)] 
2025-01-24 16:08:22.322874: Epoch time: 48.59 s 
2025-01-24 16:08:23.514339:  
2025-01-24 16:08:23.517831: Epoch 295 
2025-01-24 16:08:23.520833: Current learning rate: 0.0073 
2025-01-24 16:09:11.894771: train_loss -0.8178 
2025-01-24 16:09:11.900415: val_loss -0.772 
2025-01-24 16:09:11.903363: Pseudo dice [np.float32(0.9456), np.float32(0.9062)] 
2025-01-24 16:09:11.906041: Epoch time: 48.38 s 
2025-01-24 16:09:13.098718:  
2025-01-24 16:09:13.102241: Epoch 296 
2025-01-24 16:09:13.105043: Current learning rate: 0.00729 
2025-01-24 16:10:01.664518: train_loss -0.7981 
2025-01-24 16:10:01.671820: val_loss -0.7702 
2025-01-24 16:10:01.675054: Pseudo dice [np.float32(0.9435), np.float32(0.8858)] 
2025-01-24 16:10:01.677921: Epoch time: 48.57 s 
2025-01-24 16:10:02.871836:  
2025-01-24 16:10:02.875279: Epoch 297 
2025-01-24 16:10:02.878326: Current learning rate: 0.00728 
2025-01-24 16:10:51.483572: train_loss -0.8135 
2025-01-24 16:10:51.489840: val_loss -0.7882 
2025-01-24 16:10:51.492840: Pseudo dice [np.float32(0.9526), np.float32(0.917)] 
2025-01-24 16:10:51.495768: Epoch time: 48.61 s 
2025-01-24 16:10:52.686148:  
2025-01-24 16:10:52.689358: Epoch 298 
2025-01-24 16:10:52.692261: Current learning rate: 0.00727 
2025-01-24 16:11:41.873090: train_loss -0.8162 
2025-01-24 16:11:41.878556: val_loss -0.6928 
2025-01-24 16:11:41.881575: Pseudo dice [np.float32(0.941), np.float32(0.7985)] 
2025-01-24 16:11:41.884134: Epoch time: 49.19 s 
2025-01-24 16:11:43.083619:  
2025-01-24 16:11:43.086762: Epoch 299 
2025-01-24 16:11:43.089774: Current learning rate: 0.00726 
2025-01-24 16:12:31.939115: train_loss -0.821 
2025-01-24 16:12:31.944482: val_loss -0.7082 
2025-01-24 16:12:31.946991: Pseudo dice [np.float32(0.9415), np.float32(0.8803)] 
2025-01-24 16:12:31.949816: Epoch time: 48.86 s 
2025-01-24 16:12:33.688554:  
2025-01-24 16:12:33.692232: Epoch 300 
2025-01-24 16:12:33.695361: Current learning rate: 0.00725 
2025-01-24 16:13:22.201199: train_loss -0.8192 
2025-01-24 16:13:22.206497: val_loss -0.7555 
2025-01-24 16:13:22.209569: Pseudo dice [np.float32(0.937), np.float32(0.8993)] 
2025-01-24 16:13:22.212337: Epoch time: 48.51 s 
2025-01-24 16:13:23.407716:  
2025-01-24 16:13:23.411217: Epoch 301 
2025-01-24 16:13:23.414533: Current learning rate: 0.00724 
2025-01-24 16:14:12.294448: train_loss -0.8006 
2025-01-24 16:14:12.300114: val_loss -0.7124 
2025-01-24 16:14:12.302981: Pseudo dice [np.float32(0.9478), np.float32(0.8708)] 
2025-01-24 16:14:12.305615: Epoch time: 48.89 s 
2025-01-24 16:14:13.528855:  
2025-01-24 16:14:13.532168: Epoch 302 
2025-01-24 16:14:13.534959: Current learning rate: 0.00724 
2025-01-24 16:15:02.732230: train_loss -0.7967 
2025-01-24 16:15:02.738028: val_loss -0.7465 
2025-01-24 16:15:02.741278: Pseudo dice [np.float32(0.9253), np.float32(0.8525)] 
2025-01-24 16:15:02.744298: Epoch time: 49.2 s 
2025-01-24 16:15:03.976129:  
2025-01-24 16:15:03.979395: Epoch 303 
2025-01-24 16:15:03.982497: Current learning rate: 0.00723 
2025-01-24 16:15:52.987608: train_loss -0.7875 
2025-01-24 16:15:52.993040: val_loss -0.6974 
2025-01-24 16:15:52.995745: Pseudo dice [np.float32(0.9407), np.float32(0.8932)] 
2025-01-24 16:15:52.998887: Epoch time: 49.01 s 
2025-01-24 16:15:54.193974:  
2025-01-24 16:15:54.198430: Epoch 304 
2025-01-24 16:15:54.201220: Current learning rate: 0.00722 
2025-01-24 16:16:42.695675: train_loss -0.7793 
2025-01-24 16:16:42.700315: val_loss -0.6913 
2025-01-24 16:16:42.702885: Pseudo dice [np.float32(0.9315), np.float32(0.8221)] 
2025-01-24 16:16:42.705376: Epoch time: 48.5 s 
2025-01-24 16:16:43.933259:  
2025-01-24 16:16:43.935925: Epoch 305 
2025-01-24 16:16:43.938551: Current learning rate: 0.00721 
2025-01-24 16:17:32.688610: train_loss -0.7975 
2025-01-24 16:17:32.694643: val_loss -0.7501 
2025-01-24 16:17:32.697970: Pseudo dice [np.float32(0.9419), np.float32(0.9257)] 
2025-01-24 16:17:32.700943: Epoch time: 48.76 s 
2025-01-24 16:17:33.890118:  
2025-01-24 16:17:33.893287: Epoch 306 
2025-01-24 16:17:33.896161: Current learning rate: 0.0072 
2025-01-24 16:18:22.583072: train_loss -0.8219 
2025-01-24 16:18:22.589036: val_loss -0.7825 
2025-01-24 16:18:22.592072: Pseudo dice [np.float32(0.9491), np.float32(0.9235)] 
2025-01-24 16:18:22.594691: Epoch time: 48.69 s 
2025-01-24 16:18:23.789027:  
2025-01-24 16:18:23.791926: Epoch 307 
2025-01-24 16:18:23.794972: Current learning rate: 0.00719 
2025-01-24 16:19:12.971805: train_loss -0.8183 
2025-01-24 16:19:12.978772: val_loss -0.7351 
2025-01-24 16:19:12.981832: Pseudo dice [np.float32(0.9483), np.float32(0.9302)] 
2025-01-24 16:19:12.984441: Epoch time: 49.18 s 
2025-01-24 16:19:14.181885:  
2025-01-24 16:19:14.185057: Epoch 308 
2025-01-24 16:19:14.188272: Current learning rate: 0.00718 
2025-01-24 16:20:03.882262: train_loss -0.8108 
2025-01-24 16:20:03.887706: val_loss -0.7268 
2025-01-24 16:20:03.890589: Pseudo dice [np.float32(0.9322), np.float32(0.8679)] 
2025-01-24 16:20:03.893024: Epoch time: 49.7 s 
2025-01-24 16:20:05.089555:  
2025-01-24 16:20:05.092518: Epoch 309 
2025-01-24 16:20:05.095329: Current learning rate: 0.00717 
2025-01-24 16:20:53.503018: train_loss -0.7685 
2025-01-24 16:20:53.508418: val_loss -0.6282 
2025-01-24 16:20:53.511731: Pseudo dice [np.float32(0.891), np.float32(0.8292)] 
2025-01-24 16:20:53.515099: Epoch time: 48.41 s 
2025-01-24 16:20:54.715282:  
2025-01-24 16:20:54.719747: Epoch 310 
2025-01-24 16:20:54.722793: Current learning rate: 0.00716 
2025-01-24 16:21:43.345022: train_loss -0.7355 
2025-01-24 16:21:43.350190: val_loss -0.627 
2025-01-24 16:21:43.352950: Pseudo dice [np.float32(0.9245), np.float32(0.506)] 
2025-01-24 16:21:43.355790: Epoch time: 48.63 s 
2025-01-24 16:21:44.548731:  
2025-01-24 16:21:44.551840: Epoch 311 
2025-01-24 16:21:44.555150: Current learning rate: 0.00715 
2025-01-24 16:22:33.173568: train_loss -0.7746 
2025-01-24 16:22:33.178989: val_loss -0.7412 
2025-01-24 16:22:33.181583: Pseudo dice [np.float32(0.9346), np.float32(0.8726)] 
2025-01-24 16:22:33.184595: Epoch time: 48.63 s 
2025-01-24 16:22:34.972959:  
2025-01-24 16:22:34.976078: Epoch 312 
2025-01-24 16:22:34.978699: Current learning rate: 0.00714 
2025-01-24 16:23:23.786075: train_loss -0.7971 
2025-01-24 16:23:23.791187: val_loss -0.7563 
2025-01-24 16:23:23.793971: Pseudo dice [np.float32(0.9391), np.float32(0.9121)] 
2025-01-24 16:23:23.796797: Epoch time: 48.81 s 
2025-01-24 16:23:24.995720:  
2025-01-24 16:23:24.998587: Epoch 313 
2025-01-24 16:23:25.001223: Current learning rate: 0.00713 
2025-01-24 16:24:13.566851: train_loss -0.7805 
2025-01-24 16:24:13.572404: val_loss -0.7094 
2025-01-24 16:24:13.575361: Pseudo dice [np.float32(0.9209), np.float32(0.8748)] 
2025-01-24 16:24:13.578264: Epoch time: 48.57 s 
2025-01-24 16:24:14.774576:  
2025-01-24 16:24:14.777550: Epoch 314 
2025-01-24 16:24:14.780160: Current learning rate: 0.00712 
2025-01-24 16:25:03.689736: train_loss -0.8015 
2025-01-24 16:25:03.695341: val_loss -0.7177 
2025-01-24 16:25:03.698093: Pseudo dice [np.float32(0.9321), np.float32(0.9118)] 
2025-01-24 16:25:03.701082: Epoch time: 48.92 s 
2025-01-24 16:25:04.934130:  
2025-01-24 16:25:04.937531: Epoch 315 
2025-01-24 16:25:04.940758: Current learning rate: 0.00711 
2025-01-24 16:25:53.712119: train_loss -0.788 
2025-01-24 16:25:53.717368: val_loss -0.7647 
2025-01-24 16:25:53.720249: Pseudo dice [np.float32(0.932), np.float32(0.8837)] 
2025-01-24 16:25:53.722799: Epoch time: 48.78 s 
2025-01-24 16:25:54.963348:  
2025-01-24 16:25:54.967453: Epoch 316 
2025-01-24 16:25:54.969858: Current learning rate: 0.0071 
2025-01-24 16:26:43.679361: train_loss -0.7995 
2025-01-24 16:26:43.684338: val_loss -0.7091 
2025-01-24 16:26:43.687207: Pseudo dice [np.float32(0.9264), np.float32(0.908)] 
2025-01-24 16:26:43.689643: Epoch time: 48.72 s 
2025-01-24 16:26:44.893073:  
2025-01-24 16:26:44.895956: Epoch 317 
2025-01-24 16:26:44.898651: Current learning rate: 0.0071 
2025-01-24 16:27:33.201785: train_loss -0.8127 
2025-01-24 16:27:33.207180: val_loss -0.7454 
2025-01-24 16:27:33.210524: Pseudo dice [np.float32(0.9484), np.float32(0.9204)] 
2025-01-24 16:27:33.213254: Epoch time: 48.31 s 
2025-01-24 16:27:34.412297:  
2025-01-24 16:27:34.415708: Epoch 318 
2025-01-24 16:27:34.418730: Current learning rate: 0.00709 
2025-01-24 16:28:23.039095: train_loss -0.8021 
2025-01-24 16:28:23.043755: val_loss -0.6844 
2025-01-24 16:28:23.046389: Pseudo dice [np.float32(0.9466), np.float32(0.8492)] 
2025-01-24 16:28:23.049016: Epoch time: 48.63 s 
2025-01-24 16:28:24.255258:  
2025-01-24 16:28:24.258461: Epoch 319 
2025-01-24 16:28:24.261578: Current learning rate: 0.00708 
2025-01-24 16:29:12.709295: train_loss -0.7829 
2025-01-24 16:29:12.714925: val_loss -0.7657 
2025-01-24 16:29:12.718034: Pseudo dice [np.float32(0.9457), np.float32(0.8528)] 
2025-01-24 16:29:12.721109: Epoch time: 48.46 s 
2025-01-24 16:29:13.970651:  
2025-01-24 16:29:13.973862: Epoch 320 
2025-01-24 16:29:13.976899: Current learning rate: 0.00707 
2025-01-24 16:30:03.036721: train_loss -0.7985 
2025-01-24 16:30:03.042388: val_loss -0.7849 
2025-01-24 16:30:03.045199: Pseudo dice [np.float32(0.9481), np.float32(0.9174)] 
2025-01-24 16:30:03.047946: Epoch time: 49.07 s 
2025-01-24 16:30:04.258001:  
2025-01-24 16:30:04.261100: Epoch 321 
2025-01-24 16:30:04.264346: Current learning rate: 0.00706 
2025-01-24 16:30:52.411181: train_loss -0.8064 
2025-01-24 16:30:52.416845: val_loss -0.6767 
2025-01-24 16:30:52.419945: Pseudo dice [np.float32(0.927), np.float32(0.8527)] 
2025-01-24 16:30:52.422920: Epoch time: 48.15 s 
2025-01-24 16:30:53.619150:  
2025-01-24 16:30:53.622596: Epoch 322 
2025-01-24 16:30:53.625934: Current learning rate: 0.00705 
2025-01-24 16:31:42.680016: train_loss -0.8119 
2025-01-24 16:31:42.685354: val_loss -0.7479 
2025-01-24 16:31:42.688292: Pseudo dice [np.float32(0.939), np.float32(0.8827)] 
2025-01-24 16:31:42.691036: Epoch time: 49.06 s 
2025-01-24 16:31:43.887092:  
2025-01-24 16:31:43.889927: Epoch 323 
2025-01-24 16:31:43.892524: Current learning rate: 0.00704 
2025-01-24 16:32:32.245053: train_loss -0.8162 
2025-01-24 16:32:32.250134: val_loss -0.7228 
2025-01-24 16:32:32.253149: Pseudo dice [np.float32(0.935), np.float32(0.8534)] 
2025-01-24 16:32:32.255728: Epoch time: 48.36 s 
2025-01-24 16:32:33.461283:  
2025-01-24 16:32:33.464557: Epoch 324 
2025-01-24 16:32:33.467405: Current learning rate: 0.00703 
2025-01-24 16:33:23.050742: train_loss -0.8027 
2025-01-24 16:33:23.056415: val_loss -0.7426 
2025-01-24 16:33:23.062611: Pseudo dice [np.float32(0.9471), np.float32(0.908)] 
2025-01-24 16:33:23.065579: Epoch time: 49.59 s 
2025-01-24 16:33:24.284544:  
2025-01-24 16:33:24.287261: Epoch 325 
2025-01-24 16:33:24.290071: Current learning rate: 0.00702 
2025-01-24 16:34:12.786442: train_loss -0.8321 
2025-01-24 16:34:12.790802: val_loss -0.7556 
2025-01-24 16:34:12.793171: Pseudo dice [np.float32(0.9393), np.float32(0.8832)] 
2025-01-24 16:34:12.795561: Epoch time: 48.5 s 
2025-01-24 16:34:14.013811:  
2025-01-24 16:34:14.016621: Epoch 326 
2025-01-24 16:34:14.019354: Current learning rate: 0.00701 
2025-01-24 16:35:02.735040: train_loss -0.8148 
2025-01-24 16:35:02.740226: val_loss -0.7706 
2025-01-24 16:35:02.742818: Pseudo dice [np.float32(0.9394), np.float32(0.9073)] 
2025-01-24 16:35:02.745545: Epoch time: 48.72 s 
2025-01-24 16:35:03.980220:  
2025-01-24 16:35:03.983476: Epoch 327 
2025-01-24 16:35:03.986394: Current learning rate: 0.007 
2025-01-24 16:35:52.923841: train_loss -0.808 
2025-01-24 16:35:52.929124: val_loss -0.7685 
2025-01-24 16:35:52.931809: Pseudo dice [np.float32(0.954), np.float32(0.8795)] 
2025-01-24 16:35:52.934767: Epoch time: 48.94 s 
2025-01-24 16:35:54.156795:  
2025-01-24 16:35:54.159296: Epoch 328 
2025-01-24 16:35:54.161907: Current learning rate: 0.00699 
2025-01-24 16:36:43.163696: train_loss -0.8193 
2025-01-24 16:36:43.168287: val_loss -0.7082 
2025-01-24 16:36:43.170850: Pseudo dice [np.float32(0.923), np.float32(0.9009)] 
2025-01-24 16:36:43.173259: Epoch time: 49.01 s 
2025-01-24 16:36:44.364166:  
2025-01-24 16:36:44.367173: Epoch 329 
2025-01-24 16:36:44.369951: Current learning rate: 0.00698 
2025-01-24 16:37:33.296530: train_loss -0.812 
2025-01-24 16:37:33.301057: val_loss -0.7089 
2025-01-24 16:37:33.303760: Pseudo dice [np.float32(0.9395), np.float32(0.9131)] 
2025-01-24 16:37:33.306149: Epoch time: 48.93 s 
2025-01-24 16:37:34.513611:  
2025-01-24 16:37:34.516115: Epoch 330 
2025-01-24 16:37:34.518772: Current learning rate: 0.00697 
2025-01-24 16:38:23.129204: train_loss -0.8145 
2025-01-24 16:38:23.134644: val_loss -0.726 
2025-01-24 16:38:23.137662: Pseudo dice [np.float32(0.9504), np.float32(0.9128)] 
2025-01-24 16:38:23.140346: Epoch time: 48.62 s 
2025-01-24 16:38:24.927776:  
2025-01-24 16:38:24.931048: Epoch 331 
2025-01-24 16:38:24.934338: Current learning rate: 0.00696 
2025-01-24 16:39:13.583724: train_loss -0.8031 
2025-01-24 16:39:13.589499: val_loss -0.7547 
2025-01-24 16:39:13.592412: Pseudo dice [np.float32(0.9473), np.float32(0.9062)] 
2025-01-24 16:39:13.595147: Epoch time: 48.66 s 
2025-01-24 16:39:14.792740:  
2025-01-24 16:39:14.795443: Epoch 332 
2025-01-24 16:39:14.798071: Current learning rate: 0.00696 
2025-01-24 16:40:03.476537: train_loss -0.8166 
2025-01-24 16:40:03.482360: val_loss -0.7547 
2025-01-24 16:40:03.485360: Pseudo dice [np.float32(0.9551), np.float32(0.9213)] 
2025-01-24 16:40:03.488327: Epoch time: 48.68 s 
2025-01-24 16:40:03.491287: Yayy! New best EMA pseudo Dice: 0.9165999889373779 
2025-01-24 16:40:05.273994:  
2025-01-24 16:40:05.277036: Epoch 333 
2025-01-24 16:40:05.279887: Current learning rate: 0.00695 
2025-01-24 16:40:53.703171: train_loss -0.8046 
2025-01-24 16:40:53.708389: val_loss -0.7446 
2025-01-24 16:40:53.711540: Pseudo dice [np.float32(0.9378), np.float32(0.8917)] 
2025-01-24 16:40:53.714294: Epoch time: 48.43 s 
2025-01-24 16:40:54.906535:  
2025-01-24 16:40:54.909813: Epoch 334 
2025-01-24 16:40:54.912906: Current learning rate: 0.00694 
2025-01-24 16:41:43.313815: train_loss -0.8039 
2025-01-24 16:41:43.318876: val_loss -0.6752 
2025-01-24 16:41:43.322040: Pseudo dice [np.float32(0.939), np.float32(0.8335)] 
2025-01-24 16:41:43.324764: Epoch time: 48.41 s 
2025-01-24 16:41:44.533765:  
2025-01-24 16:41:44.536929: Epoch 335 
2025-01-24 16:41:44.539927: Current learning rate: 0.00693 
2025-01-24 16:42:33.180945: train_loss -0.804 
2025-01-24 16:42:33.186318: val_loss -0.7068 
2025-01-24 16:42:33.189496: Pseudo dice [np.float32(0.9446), np.float32(0.8683)] 
2025-01-24 16:42:33.192088: Epoch time: 48.65 s 
2025-01-24 16:42:34.412428:  
2025-01-24 16:42:34.415671: Epoch 336 
2025-01-24 16:42:34.418697: Current learning rate: 0.00692 
2025-01-24 16:43:23.060305: train_loss -0.8014 
2025-01-24 16:43:23.065785: val_loss -0.7302 
2025-01-24 16:43:23.068764: Pseudo dice [np.float32(0.9478), np.float32(0.8423)] 
2025-01-24 16:43:23.071381: Epoch time: 48.65 s 
2025-01-24 16:43:24.329204:  
2025-01-24 16:43:24.332267: Epoch 337 
2025-01-24 16:43:24.335128: Current learning rate: 0.00691 
2025-01-24 16:44:12.664934: train_loss -0.8008 
2025-01-24 16:44:12.669958: val_loss -0.7004 
2025-01-24 16:44:12.672701: Pseudo dice [np.float32(0.9463), np.float32(0.8806)] 
2025-01-24 16:44:12.675538: Epoch time: 48.34 s 
2025-01-24 16:44:13.935961:  
2025-01-24 16:44:13.939214: Epoch 338 
2025-01-24 16:44:13.941977: Current learning rate: 0.0069 
2025-01-24 16:45:02.098783: train_loss -0.8088 
2025-01-24 16:45:02.104016: val_loss -0.7518 
2025-01-24 16:45:02.106679: Pseudo dice [np.float32(0.9333), np.float32(0.8702)] 
2025-01-24 16:45:02.109511: Epoch time: 48.16 s 
2025-01-24 16:45:03.362343:  
2025-01-24 16:45:03.365258: Epoch 339 
2025-01-24 16:45:03.368063: Current learning rate: 0.00689 
2025-01-24 16:45:51.681894: train_loss -0.7928 
2025-01-24 16:45:51.686759: val_loss -0.7679 
2025-01-24 16:45:51.689556: Pseudo dice [np.float32(0.9334), np.float32(0.9181)] 
2025-01-24 16:45:51.692132: Epoch time: 48.32 s 
2025-01-24 16:45:52.913347:  
2025-01-24 16:45:52.916462: Epoch 340 
2025-01-24 16:45:52.919312: Current learning rate: 0.00688 
2025-01-24 16:46:42.194254: train_loss -0.8107 
2025-01-24 16:46:42.200052: val_loss -0.7033 
2025-01-24 16:46:42.203176: Pseudo dice [np.float32(0.9306), np.float32(0.8712)] 
2025-01-24 16:46:42.205941: Epoch time: 49.28 s 
2025-01-24 16:46:43.463264:  
2025-01-24 16:46:43.466759: Epoch 341 
2025-01-24 16:46:43.469662: Current learning rate: 0.00687 
2025-01-24 16:47:32.304694: train_loss -0.8166 
2025-01-24 16:47:32.310189: val_loss -0.7178 
2025-01-24 16:47:32.312710: Pseudo dice [np.float32(0.9436), np.float32(0.9041)] 
2025-01-24 16:47:32.315488: Epoch time: 48.84 s 
2025-01-24 16:47:33.529940:  
2025-01-24 16:47:33.532942: Epoch 342 
2025-01-24 16:47:33.535931: Current learning rate: 0.00686 
2025-01-24 16:48:22.573171: train_loss -0.8241 
2025-01-24 16:48:22.578835: val_loss -0.7476 
2025-01-24 16:48:22.581855: Pseudo dice [np.float32(0.9355), np.float32(0.9081)] 
2025-01-24 16:48:22.584603: Epoch time: 49.04 s 
2025-01-24 16:48:23.801471:  
2025-01-24 16:48:23.804395: Epoch 343 
2025-01-24 16:48:23.807476: Current learning rate: 0.00685 
2025-01-24 16:49:12.434725: train_loss -0.8114 
2025-01-24 16:49:12.439722: val_loss -0.7339 
2025-01-24 16:49:12.442199: Pseudo dice [np.float32(0.9475), np.float32(0.9136)] 
2025-01-24 16:49:12.444685: Epoch time: 48.63 s 
2025-01-24 16:49:13.705155:  
2025-01-24 16:49:13.708549: Epoch 344 
2025-01-24 16:49:13.711066: Current learning rate: 0.00684 
2025-01-24 16:50:01.946339: train_loss -0.813 
2025-01-24 16:50:01.953039: val_loss -0.7267 
2025-01-24 16:50:01.956350: Pseudo dice [np.float32(0.939), np.float32(0.9241)] 
2025-01-24 16:50:01.959352: Epoch time: 48.24 s 
2025-01-24 16:50:03.179828:  
2025-01-24 16:50:03.183332: Epoch 345 
2025-01-24 16:50:03.186443: Current learning rate: 0.00683 
2025-01-24 16:50:52.045377: train_loss -0.8156 
2025-01-24 16:50:52.051008: val_loss -0.739 
2025-01-24 16:50:52.053951: Pseudo dice [np.float32(0.9448), np.float32(0.8552)] 
2025-01-24 16:50:52.056793: Epoch time: 48.87 s 
2025-01-24 16:50:53.269812:  
2025-01-24 16:50:53.272832: Epoch 346 
2025-01-24 16:50:53.275881: Current learning rate: 0.00682 
2025-01-24 16:51:41.942346: train_loss -0.8008 
2025-01-24 16:51:41.948090: val_loss -0.732 
2025-01-24 16:51:41.951421: Pseudo dice [np.float32(0.9253), np.float32(0.8713)] 
2025-01-24 16:51:41.954633: Epoch time: 48.67 s 
2025-01-24 16:51:43.162913:  
2025-01-24 16:51:43.166014: Epoch 347 
2025-01-24 16:51:43.168944: Current learning rate: 0.00681 
2025-01-24 16:52:31.960515: train_loss -0.7953 
2025-01-24 16:52:31.966386: val_loss -0.7394 
2025-01-24 16:52:31.969294: Pseudo dice [np.float32(0.9489), np.float32(0.8934)] 
2025-01-24 16:52:31.971943: Epoch time: 48.8 s 
2025-01-24 16:52:33.187515:  
2025-01-24 16:52:33.190696: Epoch 348 
2025-01-24 16:52:33.194064: Current learning rate: 0.0068 
2025-01-24 16:53:22.129864: train_loss -0.8206 
2025-01-24 16:53:22.135089: val_loss -0.7009 
2025-01-24 16:53:22.137904: Pseudo dice [np.float32(0.9264), np.float32(0.8224)] 
2025-01-24 16:53:22.140423: Epoch time: 48.94 s 
2025-01-24 16:53:23.933003:  
2025-01-24 16:53:23.936053: Epoch 349 
2025-01-24 16:53:23.938957: Current learning rate: 0.0068 
2025-01-24 16:54:12.530544: train_loss -0.8077 
2025-01-24 16:54:12.537405: val_loss -0.7098 
2025-01-24 16:54:12.540374: Pseudo dice [np.float32(0.9358), np.float32(0.837)] 
2025-01-24 16:54:12.543280: Epoch time: 48.6 s 
2025-01-24 16:54:14.380243:  
2025-01-24 16:54:14.383181: Epoch 350 
2025-01-24 16:54:14.385597: Current learning rate: 0.00679 
2025-01-24 16:55:03.244381: train_loss -0.8014 
2025-01-24 16:55:03.249655: val_loss -0.764 
2025-01-24 16:55:03.252202: Pseudo dice [np.float32(0.9355), np.float32(0.8528)] 
2025-01-24 16:55:03.254694: Epoch time: 48.87 s 
2025-01-24 16:55:04.479121:  
2025-01-24 16:55:04.482233: Epoch 351 
2025-01-24 16:55:04.485242: Current learning rate: 0.00678 
2025-01-24 16:55:53.163134: train_loss -0.8022 
2025-01-24 16:55:53.169004: val_loss -0.7092 
2025-01-24 16:55:53.172010: Pseudo dice [np.float32(0.9251), np.float32(0.8716)] 
2025-01-24 16:55:53.174980: Epoch time: 48.69 s 
2025-01-24 16:55:54.415284:  
2025-01-24 16:55:54.417968: Epoch 352 
2025-01-24 16:55:54.420771: Current learning rate: 0.00677 
2025-01-24 16:56:43.693407: train_loss -0.8054 
2025-01-24 16:56:43.699016: val_loss -0.7143 
2025-01-24 16:56:43.701920: Pseudo dice [np.float32(0.952), np.float32(0.8637)] 
2025-01-24 16:56:43.704969: Epoch time: 49.28 s 
2025-01-24 16:56:44.950128:  
2025-01-24 16:56:44.953947: Epoch 353 
2025-01-24 16:56:44.956863: Current learning rate: 0.00676 
2025-01-24 16:57:33.907267: train_loss -0.8219 
2025-01-24 16:57:33.912314: val_loss -0.7785 
2025-01-24 16:57:33.915162: Pseudo dice [np.float32(0.9406), np.float32(0.9135)] 
2025-01-24 16:57:33.917953: Epoch time: 48.96 s 
2025-01-24 16:57:35.133249:  
2025-01-24 16:57:35.136335: Epoch 354 
2025-01-24 16:57:35.139135: Current learning rate: 0.00675 
2025-01-24 16:58:24.145781: train_loss -0.8059 
2025-01-24 16:58:24.150702: val_loss -0.7717 
2025-01-24 16:58:24.153136: Pseudo dice [np.float32(0.9384), np.float32(0.9185)] 
2025-01-24 16:58:24.155553: Epoch time: 49.01 s 
2025-01-24 16:58:25.386496:  
2025-01-24 16:58:25.389637: Epoch 355 
2025-01-24 16:58:25.392561: Current learning rate: 0.00674 
2025-01-24 16:59:13.865959: train_loss -0.8199 
2025-01-24 16:59:13.870716: val_loss -0.7267 
2025-01-24 16:59:13.873176: Pseudo dice [np.float32(0.94), np.float32(0.8765)] 
2025-01-24 16:59:13.875777: Epoch time: 48.48 s 
2025-01-24 16:59:15.135151:  
2025-01-24 16:59:15.138384: Epoch 356 
2025-01-24 16:59:15.141315: Current learning rate: 0.00673 
2025-01-24 17:00:03.562795: train_loss -0.8007 
2025-01-24 17:00:03.568063: val_loss -0.7275 
2025-01-24 17:00:03.570916: Pseudo dice [np.float32(0.9324), np.float32(0.8826)] 
2025-01-24 17:00:03.573828: Epoch time: 48.43 s 
2025-01-24 17:00:04.796360:  
2025-01-24 17:00:04.799221: Epoch 357 
2025-01-24 17:00:04.801958: Current learning rate: 0.00672 
2025-01-24 17:00:53.422302: train_loss -0.8273 
2025-01-24 17:00:53.427090: val_loss -0.7013 
2025-01-24 17:00:53.429693: Pseudo dice [np.float32(0.945), np.float32(0.8669)] 
2025-01-24 17:00:53.432148: Epoch time: 48.63 s 
2025-01-24 17:00:54.647678:  
2025-01-24 17:00:54.651207: Epoch 358 
2025-01-24 17:00:54.654734: Current learning rate: 0.00671 
2025-01-24 17:01:43.623957: train_loss -0.7869 
2025-01-24 17:01:43.628542: val_loss -0.6961 
2025-01-24 17:01:43.630825: Pseudo dice [np.float32(0.9394), np.float32(0.8596)] 
2025-01-24 17:01:43.633451: Epoch time: 48.98 s 
2025-01-24 17:01:44.848401:  
2025-01-24 17:01:44.851352: Epoch 359 
2025-01-24 17:01:44.854254: Current learning rate: 0.0067 
2025-01-24 17:02:33.648503: train_loss -0.8037 
2025-01-24 17:02:33.653247: val_loss -0.7467 
2025-01-24 17:02:33.655947: Pseudo dice [np.float32(0.9376), np.float32(0.845)] 
2025-01-24 17:02:33.658592: Epoch time: 48.8 s 
2025-01-24 17:02:34.880719:  
2025-01-24 17:02:34.883565: Epoch 360 
2025-01-24 17:02:34.886119: Current learning rate: 0.00669 
2025-01-24 17:03:23.553293: train_loss -0.7996 
2025-01-24 17:03:23.558589: val_loss -0.7697 
2025-01-24 17:03:23.561853: Pseudo dice [np.float32(0.9401), np.float32(0.9196)] 
2025-01-24 17:03:23.564413: Epoch time: 48.67 s 
2025-01-24 17:03:24.816002:  
2025-01-24 17:03:24.819225: Epoch 361 
2025-01-24 17:03:24.821825: Current learning rate: 0.00668 
2025-01-24 17:04:14.532914: train_loss -0.7988 
2025-01-24 17:04:14.537493: val_loss -0.7078 
2025-01-24 17:04:14.540022: Pseudo dice [np.float32(0.943), np.float32(0.8739)] 
2025-01-24 17:04:14.542367: Epoch time: 49.72 s 
2025-01-24 17:04:15.780828:  
2025-01-24 17:04:15.783547: Epoch 362 
2025-01-24 17:04:15.786233: Current learning rate: 0.00667 
2025-01-24 17:05:04.221770: train_loss -0.7993 
2025-01-24 17:05:04.226551: val_loss -0.7268 
2025-01-24 17:05:04.229207: Pseudo dice [np.float32(0.9461), np.float32(0.8181)] 
2025-01-24 17:05:04.231798: Epoch time: 48.44 s 
2025-01-24 17:05:05.449203:  
2025-01-24 17:05:05.452496: Epoch 363 
2025-01-24 17:05:05.455719: Current learning rate: 0.00666 
2025-01-24 17:05:54.504443: train_loss -0.8071 
2025-01-24 17:05:54.510736: val_loss -0.7302 
2025-01-24 17:05:54.514292: Pseudo dice [np.float32(0.9465), np.float32(0.8863)] 
2025-01-24 17:05:54.517293: Epoch time: 49.06 s 
2025-01-24 17:05:55.738263:  
2025-01-24 17:05:55.741574: Epoch 364 
2025-01-24 17:05:55.744370: Current learning rate: 0.00665 
2025-01-24 17:06:44.556148: train_loss -0.8086 
2025-01-24 17:06:44.561166: val_loss -0.7013 
2025-01-24 17:06:44.563606: Pseudo dice [np.float32(0.9409), np.float32(0.8652)] 
2025-01-24 17:06:44.566314: Epoch time: 48.82 s 
2025-01-24 17:06:45.844935:  
2025-01-24 17:06:45.847958: Epoch 365 
2025-01-24 17:06:45.850937: Current learning rate: 0.00665 
2025-01-24 17:07:34.031026: train_loss -0.8072 
2025-01-24 17:07:34.036018: val_loss -0.7567 
2025-01-24 17:07:34.038838: Pseudo dice [np.float32(0.9499), np.float32(0.9155)] 
2025-01-24 17:07:34.041311: Epoch time: 48.19 s 
2025-01-24 17:07:35.259953:  
2025-01-24 17:07:35.262868: Epoch 366 
2025-01-24 17:07:35.265654: Current learning rate: 0.00664 
2025-01-24 17:08:23.773465: train_loss -0.7949 
2025-01-24 17:08:23.778404: val_loss -0.7762 
2025-01-24 17:08:23.780941: Pseudo dice [np.float32(0.9428), np.float32(0.8882)] 
2025-01-24 17:08:23.783646: Epoch time: 48.51 s 
2025-01-24 17:08:25.592273:  
2025-01-24 17:08:25.595072: Epoch 367 
2025-01-24 17:08:25.597561: Current learning rate: 0.00663 
2025-01-24 17:09:14.268895: train_loss -0.8224 
2025-01-24 17:09:14.274289: val_loss -0.7767 
2025-01-24 17:09:14.277067: Pseudo dice [np.float32(0.9377), np.float32(0.9297)] 
2025-01-24 17:09:14.279860: Epoch time: 48.68 s 
2025-01-24 17:09:15.501598:  
2025-01-24 17:09:15.504991: Epoch 368 
2025-01-24 17:09:15.508140: Current learning rate: 0.00662 
2025-01-24 17:10:03.659924: train_loss -0.8003 
2025-01-24 17:10:03.665305: val_loss -0.723 
2025-01-24 17:10:03.667909: Pseudo dice [np.float32(0.9463), np.float32(0.9074)] 
2025-01-24 17:10:03.670689: Epoch time: 48.16 s 
2025-01-24 17:10:04.931460:  
2025-01-24 17:10:04.934689: Epoch 369 
2025-01-24 17:10:04.937808: Current learning rate: 0.00661 
2025-01-24 17:10:54.046989: train_loss -0.794 
2025-01-24 17:10:54.051328: val_loss -0.7227 
2025-01-24 17:10:54.053671: Pseudo dice [np.float32(0.9465), np.float32(0.906)] 
2025-01-24 17:10:54.056093: Epoch time: 49.12 s 
2025-01-24 17:10:55.327933:  
2025-01-24 17:10:55.331070: Epoch 370 
2025-01-24 17:10:55.333527: Current learning rate: 0.0066 
2025-01-24 17:11:44.194733: train_loss -0.8183 
2025-01-24 17:11:44.201040: val_loss -0.747 
2025-01-24 17:11:44.204355: Pseudo dice [np.float32(0.9531), np.float32(0.9)] 
2025-01-24 17:11:44.207291: Epoch time: 48.87 s 
2025-01-24 17:11:45.504404:  
2025-01-24 17:11:45.507546: Epoch 371 
2025-01-24 17:11:45.510143: Current learning rate: 0.00659 
2025-01-24 17:12:34.413408: train_loss -0.8227 
2025-01-24 17:12:34.418864: val_loss -0.7319 
2025-01-24 17:12:34.421557: Pseudo dice [np.float32(0.9493), np.float32(0.9135)] 
2025-01-24 17:12:34.424559: Epoch time: 48.91 s 
2025-01-24 17:12:34.427250: Yayy! New best EMA pseudo Dice: 0.9176999926567078 
2025-01-24 17:12:36.234018:  
2025-01-24 17:12:36.237066: Epoch 372 
2025-01-24 17:12:36.240077: Current learning rate: 0.00658 
2025-01-24 17:13:25.759599: train_loss -0.8004 
2025-01-24 17:13:25.765224: val_loss -0.7368 
2025-01-24 17:13:25.767795: Pseudo dice [np.float32(0.9435), np.float32(0.8781)] 
2025-01-24 17:13:25.770116: Epoch time: 49.53 s 
2025-01-24 17:13:27.034812:  
2025-01-24 17:13:27.038320: Epoch 373 
2025-01-24 17:13:27.041099: Current learning rate: 0.00657 
2025-01-24 17:14:15.807652: train_loss -0.8005 
2025-01-24 17:14:15.814765: val_loss -0.717 
2025-01-24 17:14:15.817730: Pseudo dice [np.float32(0.9266), np.float32(0.8335)] 
2025-01-24 17:14:15.820141: Epoch time: 48.77 s 
2025-01-24 17:14:17.086487:  
2025-01-24 17:14:17.089476: Epoch 374 
2025-01-24 17:14:17.092384: Current learning rate: 0.00656 
2025-01-24 17:15:05.387392: train_loss -0.8138 
2025-01-24 17:15:05.392884: val_loss -0.752 
2025-01-24 17:15:05.395683: Pseudo dice [np.float32(0.9453), np.float32(0.87)] 
2025-01-24 17:15:05.398499: Epoch time: 48.3 s 
2025-01-24 17:15:06.627550:  
2025-01-24 17:15:06.630514: Epoch 375 
2025-01-24 17:15:06.633237: Current learning rate: 0.00655 
2025-01-24 17:15:55.136400: train_loss -0.8157 
2025-01-24 17:15:55.141465: val_loss -0.7107 
2025-01-24 17:15:55.143984: Pseudo dice [np.float32(0.9292), np.float32(0.8306)] 
2025-01-24 17:15:55.146515: Epoch time: 48.51 s 
2025-01-24 17:15:56.372610:  
2025-01-24 17:15:56.375611: Epoch 376 
2025-01-24 17:15:56.378248: Current learning rate: 0.00654 
2025-01-24 17:16:45.013616: train_loss -0.8117 
2025-01-24 17:16:45.078143: val_loss -0.7303 
2025-01-24 17:16:45.081055: Pseudo dice [np.float32(0.9478), np.float32(0.9052)] 
2025-01-24 17:16:45.083813: Epoch time: 48.64 s 
2025-01-24 17:16:46.337392:  
2025-01-24 17:16:46.340541: Epoch 377 
2025-01-24 17:16:46.343513: Current learning rate: 0.00653 
2025-01-24 17:17:35.297549: train_loss -0.8048 
2025-01-24 17:17:35.302848: val_loss -0.6983 
2025-01-24 17:17:35.305349: Pseudo dice [np.float32(0.9438), np.float32(0.9064)] 
2025-01-24 17:17:35.307963: Epoch time: 48.96 s 
2025-01-24 17:17:36.528408:  
2025-01-24 17:17:36.531560: Epoch 378 
2025-01-24 17:17:36.534536: Current learning rate: 0.00652 
2025-01-24 17:18:25.668714: train_loss -0.8094 
2025-01-24 17:18:25.674393: val_loss -0.6731 
2025-01-24 17:18:25.677176: Pseudo dice [np.float32(0.9505), np.float32(0.7616)] 
2025-01-24 17:18:25.680169: Epoch time: 49.14 s 
2025-01-24 17:18:26.935106:  
2025-01-24 17:18:26.937620: Epoch 379 
2025-01-24 17:18:26.940356: Current learning rate: 0.00651 
2025-01-24 17:19:15.718988: train_loss -0.8079 
2025-01-24 17:19:15.724993: val_loss -0.7441 
2025-01-24 17:19:15.728077: Pseudo dice [np.float32(0.9436), np.float32(0.8377)] 
2025-01-24 17:19:15.730996: Epoch time: 48.78 s 
2025-01-24 17:19:16.993718:  
2025-01-24 17:19:16.996887: Epoch 380 
2025-01-24 17:19:16.999675: Current learning rate: 0.0065 
2025-01-24 17:20:05.443274: train_loss -0.8247 
2025-01-24 17:20:05.448426: val_loss -0.7632 
2025-01-24 17:20:05.451100: Pseudo dice [np.float32(0.9299), np.float32(0.8843)] 
2025-01-24 17:20:05.453857: Epoch time: 48.45 s 
2025-01-24 17:20:06.673895:  
2025-01-24 17:20:06.677539: Epoch 381 
2025-01-24 17:20:06.680367: Current learning rate: 0.00649 
2025-01-24 17:20:55.405049: train_loss -0.8171 
2025-01-24 17:20:55.410296: val_loss -0.7983 
2025-01-24 17:20:55.412890: Pseudo dice [np.float32(0.9462), np.float32(0.9281)] 
2025-01-24 17:20:55.415381: Epoch time: 48.73 s 
2025-01-24 17:20:56.657458:  
2025-01-24 17:20:56.660340: Epoch 382 
2025-01-24 17:20:56.663032: Current learning rate: 0.00648 
2025-01-24 17:21:45.126707: train_loss -0.8247 
2025-01-24 17:21:45.132596: val_loss -0.713 
2025-01-24 17:21:45.135329: Pseudo dice [np.float32(0.9474), np.float32(0.8331)] 
2025-01-24 17:21:45.138333: Epoch time: 48.47 s 
2025-01-24 17:21:46.368734:  
2025-01-24 17:21:46.371892: Epoch 383 
2025-01-24 17:21:46.374842: Current learning rate: 0.00648 
2025-01-24 17:22:34.835601: train_loss -0.7923 
2025-01-24 17:22:34.841233: val_loss -0.716 
2025-01-24 17:22:34.843867: Pseudo dice [np.float32(0.932), np.float32(0.8684)] 
2025-01-24 17:22:34.846539: Epoch time: 48.47 s 
2025-01-24 17:22:36.073416:  
2025-01-24 17:22:36.076608: Epoch 384 
2025-01-24 17:22:36.079472: Current learning rate: 0.00647 
2025-01-24 17:23:25.477676: train_loss -0.8061 
2025-01-24 17:23:25.483622: val_loss -0.7005 
2025-01-24 17:23:25.486556: Pseudo dice [np.float32(0.9391), np.float32(0.8744)] 
2025-01-24 17:23:25.489261: Epoch time: 49.41 s 
2025-01-24 17:23:27.301284:  
2025-01-24 17:23:27.303840: Epoch 385 
2025-01-24 17:23:27.306459: Current learning rate: 0.00646 
2025-01-24 17:24:16.094619: train_loss -0.7999 
2025-01-24 17:24:16.099568: val_loss -0.6918 
2025-01-24 17:24:16.102236: Pseudo dice [np.float32(0.9309), np.float32(0.8359)] 
2025-01-24 17:24:16.105030: Epoch time: 48.79 s 
2025-01-24 17:24:17.352326:  
2025-01-24 17:24:17.354963: Epoch 386 
2025-01-24 17:24:17.357554: Current learning rate: 0.00645 
2025-01-24 17:25:05.614352: train_loss -0.8044 
2025-01-24 17:25:05.619306: val_loss -0.708 
2025-01-24 17:25:05.621945: Pseudo dice [np.float32(0.9395), np.float32(0.6614)] 
2025-01-24 17:25:05.624580: Epoch time: 48.26 s 
2025-01-24 17:25:06.871778:  
2025-01-24 17:25:06.875221: Epoch 387 
2025-01-24 17:25:06.878182: Current learning rate: 0.00644 
2025-01-24 17:25:55.734934: train_loss -0.8106 
2025-01-24 17:25:55.739773: val_loss -0.6897 
2025-01-24 17:25:55.742175: Pseudo dice [np.float32(0.9384), np.float32(0.8714)] 
2025-01-24 17:25:55.744413: Epoch time: 48.86 s 
2025-01-24 17:25:56.980114:  
2025-01-24 17:25:56.982993: Epoch 388 
2025-01-24 17:25:56.985242: Current learning rate: 0.00643 
2025-01-24 17:26:45.691710: train_loss -0.8062 
2025-01-24 17:26:45.697497: val_loss -0.7231 
2025-01-24 17:26:45.700222: Pseudo dice [np.float32(0.9547), np.float32(0.73)] 
2025-01-24 17:26:45.702777: Epoch time: 48.71 s 
2025-01-24 17:26:46.945549:  
2025-01-24 17:26:46.948511: Epoch 389 
2025-01-24 17:26:46.951334: Current learning rate: 0.00642 
2025-01-24 17:27:35.738768: train_loss -0.809 
2025-01-24 17:27:35.744098: val_loss -0.7632 
2025-01-24 17:27:35.746867: Pseudo dice [np.float32(0.954), np.float32(0.8557)] 
2025-01-24 17:27:35.749612: Epoch time: 48.79 s 
2025-01-24 17:27:37.014536:  
2025-01-24 17:27:37.017555: Epoch 390 
2025-01-24 17:27:37.020582: Current learning rate: 0.00641 
2025-01-24 17:28:25.699990: train_loss -0.8176 
2025-01-24 17:28:25.704464: val_loss -0.7604 
2025-01-24 17:28:25.706973: Pseudo dice [np.float32(0.9415), np.float32(0.8968)] 
2025-01-24 17:28:25.709333: Epoch time: 48.69 s 
2025-01-24 17:28:26.940404:  
2025-01-24 17:28:26.943668: Epoch 391 
2025-01-24 17:28:26.946524: Current learning rate: 0.0064 
2025-01-24 17:29:15.841750: train_loss -0.803 
2025-01-24 17:29:15.847240: val_loss -0.7146 
2025-01-24 17:29:15.850127: Pseudo dice [np.float32(0.9325), np.float32(0.8252)] 
2025-01-24 17:29:15.852885: Epoch time: 48.9 s 
2025-01-24 17:29:17.131199:  
2025-01-24 17:29:17.134719: Epoch 392 
2025-01-24 17:29:17.137547: Current learning rate: 0.00639 
2025-01-24 17:30:05.939478: train_loss -0.8163 
2025-01-24 17:30:05.944692: val_loss -0.7117 
2025-01-24 17:30:05.947302: Pseudo dice [np.float32(0.9482), np.float32(0.9024)] 
2025-01-24 17:30:05.949895: Epoch time: 48.81 s 
2025-01-24 17:30:07.189689:  
2025-01-24 17:30:07.192851: Epoch 393 
2025-01-24 17:30:07.195882: Current learning rate: 0.00638 
2025-01-24 17:30:56.036705: train_loss -0.8057 
2025-01-24 17:30:56.041757: val_loss -0.7351 
2025-01-24 17:30:56.044304: Pseudo dice [np.float32(0.9352), np.float32(0.8809)] 
2025-01-24 17:30:56.046634: Epoch time: 48.85 s 
2025-01-24 17:30:57.282886:  
2025-01-24 17:30:57.285433: Epoch 394 
2025-01-24 17:30:57.287875: Current learning rate: 0.00637 
2025-01-24 17:31:46.095638: train_loss -0.7937 
2025-01-24 17:31:46.100142: val_loss -0.7239 
2025-01-24 17:31:46.102977: Pseudo dice [np.float32(0.9372), np.float32(0.8642)] 
2025-01-24 17:31:46.105551: Epoch time: 48.81 s 
2025-01-24 17:31:47.396580:  
2025-01-24 17:31:47.400231: Epoch 395 
2025-01-24 17:31:47.403184: Current learning rate: 0.00636 
2025-01-24 17:32:36.040677: train_loss -0.807 
2025-01-24 17:32:36.045748: val_loss -0.7906 
2025-01-24 17:32:36.048814: Pseudo dice [np.float32(0.9388), np.float32(0.8674)] 
2025-01-24 17:32:36.051515: Epoch time: 48.65 s 
2025-01-24 17:32:37.288189:  
2025-01-24 17:32:37.291270: Epoch 396 
2025-01-24 17:32:37.294243: Current learning rate: 0.00635 
2025-01-24 17:33:25.931015: train_loss -0.8192 
2025-01-24 17:33:25.935979: val_loss -0.7461 
2025-01-24 17:33:25.938773: Pseudo dice [np.float32(0.951), np.float32(0.885)] 
2025-01-24 17:33:25.941162: Epoch time: 48.64 s 
2025-01-24 17:33:27.188276:  
2025-01-24 17:33:27.191238: Epoch 397 
2025-01-24 17:33:27.194147: Current learning rate: 0.00634 
2025-01-24 17:34:15.792452: train_loss -0.8223 
2025-01-24 17:34:15.798204: val_loss -0.7355 
2025-01-24 17:34:15.800884: Pseudo dice [np.float32(0.9383), np.float32(0.8629)] 
2025-01-24 17:34:15.803617: Epoch time: 48.61 s 
2025-01-24 17:34:17.046707:  
2025-01-24 17:34:17.049870: Epoch 398 
2025-01-24 17:34:17.052525: Current learning rate: 0.00633 
2025-01-24 17:35:05.719785: train_loss -0.8275 
2025-01-24 17:35:05.725648: val_loss -0.7371 
2025-01-24 17:35:05.728341: Pseudo dice [np.float32(0.9445), np.float32(0.8928)] 
2025-01-24 17:35:05.731218: Epoch time: 48.67 s 
2025-01-24 17:35:06.988170:  
2025-01-24 17:35:06.990664: Epoch 399 
2025-01-24 17:35:06.993461: Current learning rate: 0.00632 
2025-01-24 17:35:56.029656: train_loss -0.813 
2025-01-24 17:35:56.034163: val_loss -0.6334 
2025-01-24 17:35:56.036364: Pseudo dice [np.float32(0.92), np.float32(0.8647)] 
2025-01-24 17:35:56.038700: Epoch time: 49.04 s 
2025-01-24 17:35:57.881807:  
2025-01-24 17:35:57.884865: Epoch 400 
2025-01-24 17:35:57.887768: Current learning rate: 0.00631 
2025-01-24 17:36:46.645352: train_loss -0.8127 
2025-01-24 17:36:46.649866: val_loss -0.7964 
2025-01-24 17:36:46.652360: Pseudo dice [np.float32(0.9421), np.float32(0.916)] 
2025-01-24 17:36:46.654870: Epoch time: 48.76 s 
2025-01-24 17:36:47.948033:  
2025-01-24 17:36:47.951392: Epoch 401 
2025-01-24 17:36:47.954144: Current learning rate: 0.0063 
2025-01-24 17:37:36.577911: train_loss -0.819 
2025-01-24 17:37:36.582747: val_loss -0.7509 
2025-01-24 17:37:36.585225: Pseudo dice [np.float32(0.9404), np.float32(0.9102)] 
2025-01-24 17:37:36.588001: Epoch time: 48.63 s 
2025-01-24 17:37:38.427746:  
2025-01-24 17:37:38.431685: Epoch 402 
2025-01-24 17:37:38.434493: Current learning rate: 0.0063 
2025-01-24 17:38:27.616650: train_loss -0.8235 
2025-01-24 17:38:27.622615: val_loss -0.7831 
2025-01-24 17:38:27.625356: Pseudo dice [np.float32(0.9451), np.float32(0.9184)] 
2025-01-24 17:38:27.628141: Epoch time: 49.19 s 
2025-01-24 17:38:28.909481:  
2025-01-24 17:38:28.912473: Epoch 403 
2025-01-24 17:38:28.915411: Current learning rate: 0.00629 
2025-01-24 17:39:17.251404: train_loss -0.8299 
2025-01-24 17:39:17.256115: val_loss -0.7614 
2025-01-24 17:39:17.258754: Pseudo dice [np.float32(0.9313), np.float32(0.9065)] 
2025-01-24 17:39:17.261495: Epoch time: 48.34 s 
2025-01-24 17:39:18.495677:  
2025-01-24 17:39:18.498105: Epoch 404 
2025-01-24 17:39:18.500699: Current learning rate: 0.00628 
2025-01-24 17:40:07.473725: train_loss -0.8298 
2025-01-24 17:40:07.478941: val_loss -0.7056 
2025-01-24 17:40:07.481680: Pseudo dice [np.float32(0.9428), np.float32(0.8813)] 
2025-01-24 17:40:07.484266: Epoch time: 48.98 s 
2025-01-24 17:40:08.764333:  
2025-01-24 17:40:08.767155: Epoch 405 
2025-01-24 17:40:08.769944: Current learning rate: 0.00627 
2025-01-24 17:40:58.198836: train_loss -0.8285 
2025-01-24 17:40:58.204479: val_loss -0.7329 
2025-01-24 17:40:58.207234: Pseudo dice [np.float32(0.9395), np.float32(0.9065)] 
2025-01-24 17:40:58.210206: Epoch time: 49.44 s 
2025-01-24 17:40:59.474262:  
2025-01-24 17:40:59.479220: Epoch 406 
2025-01-24 17:40:59.482628: Current learning rate: 0.00626 
2025-01-24 17:41:48.575622: train_loss -0.7878 
2025-01-24 17:41:48.581164: val_loss -0.7496 
2025-01-24 17:41:48.584022: Pseudo dice [np.float32(0.9397), np.float32(0.9033)] 
2025-01-24 17:41:48.586528: Epoch time: 49.11 s 
2025-01-24 17:41:49.912639:  
2025-01-24 17:41:49.917485: Epoch 407 
2025-01-24 17:41:49.921185: Current learning rate: 0.00625 
2025-01-24 17:42:38.461348: train_loss -0.8006 
2025-01-24 17:42:38.466079: val_loss -0.7148 
2025-01-24 17:42:38.468796: Pseudo dice [np.float32(0.9589), np.float32(0.8655)] 
2025-01-24 17:42:38.471189: Epoch time: 48.55 s 
2025-01-24 17:42:39.801951:  
2025-01-24 17:42:39.806701: Epoch 408 
2025-01-24 17:42:39.809797: Current learning rate: 0.00624 
2025-01-24 17:43:28.545102: train_loss -0.8197 
2025-01-24 17:43:28.550224: val_loss -0.7421 
2025-01-24 17:43:28.553046: Pseudo dice [np.float32(0.9457), np.float32(0.8836)] 
2025-01-24 17:43:28.555938: Epoch time: 48.75 s 
2025-01-24 17:43:29.835450:  
2025-01-24 17:43:29.838038: Epoch 409 
2025-01-24 17:43:29.840490: Current learning rate: 0.00623 
2025-01-24 17:44:19.247704: train_loss -0.8151 
2025-01-24 17:44:19.253512: val_loss -0.7339 
2025-01-24 17:44:19.256078: Pseudo dice [np.float32(0.9445), np.float32(0.8843)] 
2025-01-24 17:44:19.258538: Epoch time: 49.41 s 
2025-01-24 17:44:20.515793:  
2025-01-24 17:44:20.518747: Epoch 410 
2025-01-24 17:44:20.521516: Current learning rate: 0.00622 
2025-01-24 17:45:09.530633: train_loss -0.8221 
2025-01-24 17:45:09.535066: val_loss -0.7357 
2025-01-24 17:45:09.537332: Pseudo dice [np.float32(0.9361), np.float32(0.8569)] 
2025-01-24 17:45:09.539667: Epoch time: 49.02 s 
2025-01-24 17:45:10.746058:  
2025-01-24 17:45:10.748423: Epoch 411 
2025-01-24 17:45:10.750699: Current learning rate: 0.00621 
2025-01-24 17:45:59.248708: train_loss -0.8302 
2025-01-24 17:45:59.253335: val_loss -0.7027 
2025-01-24 17:45:59.255865: Pseudo dice [np.float32(0.9475), np.float32(0.8302)] 
2025-01-24 17:45:59.258404: Epoch time: 48.5 s 
2025-01-24 17:46:00.424657:  
2025-01-24 17:46:00.427975: Epoch 412 
2025-01-24 17:46:00.430868: Current learning rate: 0.0062 
2025-01-24 17:46:49.592912: train_loss -0.8036 
2025-01-24 17:46:49.597328: val_loss -0.7066 
2025-01-24 17:46:49.599703: Pseudo dice [np.float32(0.9465), np.float32(0.887)] 
2025-01-24 17:46:49.602142: Epoch time: 49.17 s 
2025-01-24 17:46:50.791472:  
2025-01-24 17:46:50.794348: Epoch 413 
2025-01-24 17:46:50.797233: Current learning rate: 0.00619 
2025-01-24 17:47:39.838723: train_loss -0.8076 
2025-01-24 17:47:39.843218: val_loss -0.7478 
2025-01-24 17:47:39.845936: Pseudo dice [np.float32(0.9478), np.float32(0.891)] 
2025-01-24 17:47:39.848660: Epoch time: 49.05 s 
2025-01-24 17:47:41.044668:  
2025-01-24 17:47:41.048555: Epoch 414 
2025-01-24 17:47:41.051501: Current learning rate: 0.00618 
2025-01-24 17:48:29.288316: train_loss -0.8065 
2025-01-24 17:48:29.293461: val_loss -0.7649 
2025-01-24 17:48:29.296592: Pseudo dice [np.float32(0.945), np.float32(0.9159)] 
2025-01-24 17:48:29.299422: Epoch time: 48.24 s 
2025-01-24 17:48:30.472312:  
2025-01-24 17:48:30.475507: Epoch 415 
2025-01-24 17:48:30.478340: Current learning rate: 0.00617 
2025-01-24 17:49:19.079946: train_loss -0.812 
2025-01-24 17:49:19.084815: val_loss -0.7626 
2025-01-24 17:49:19.087563: Pseudo dice [np.float32(0.9384), np.float32(0.8774)] 
2025-01-24 17:49:19.090135: Epoch time: 48.61 s 
2025-01-24 17:49:20.262105:  
2025-01-24 17:49:20.265678: Epoch 416 
2025-01-24 17:49:20.268589: Current learning rate: 0.00616 
2025-01-24 17:50:08.833449: train_loss -0.8209 
2025-01-24 17:50:08.838499: val_loss -0.7307 
2025-01-24 17:50:08.841311: Pseudo dice [np.float32(0.9302), np.float32(0.8599)] 
2025-01-24 17:50:08.843838: Epoch time: 48.57 s 
2025-01-24 17:50:10.014872:  
2025-01-24 17:50:10.018202: Epoch 417 
2025-01-24 17:50:10.021337: Current learning rate: 0.00615 
2025-01-24 17:50:58.440508: train_loss -0.8028 
2025-01-24 17:50:58.445513: val_loss -0.6927 
2025-01-24 17:50:58.448130: Pseudo dice [np.float32(0.9379), np.float32(0.8983)] 
2025-01-24 17:50:58.450712: Epoch time: 48.43 s 
2025-01-24 17:50:59.627421:  
2025-01-24 17:50:59.630274: Epoch 418 
2025-01-24 17:50:59.633060: Current learning rate: 0.00614 
2025-01-24 17:51:48.364006: train_loss -0.804 
2025-01-24 17:51:48.368984: val_loss -0.7816 
2025-01-24 17:51:48.371486: Pseudo dice [np.float32(0.9478), np.float32(0.9134)] 
2025-01-24 17:51:48.373950: Epoch time: 48.74 s 
2025-01-24 17:51:49.552894:  
2025-01-24 17:51:49.555330: Epoch 419 
2025-01-24 17:51:49.557614: Current learning rate: 0.00613 
2025-01-24 17:52:38.450693: train_loss -0.8052 
2025-01-24 17:52:38.455800: val_loss -0.7866 
2025-01-24 17:52:38.458410: Pseudo dice [np.float32(0.9436), np.float32(0.9149)] 
2025-01-24 17:52:38.460897: Epoch time: 48.9 s 
2025-01-24 17:52:39.648049:  
2025-01-24 17:52:39.651289: Epoch 420 
2025-01-24 17:52:39.654137: Current learning rate: 0.00612 
2025-01-24 17:53:28.647527: train_loss -0.8023 
2025-01-24 17:53:28.651588: val_loss -0.7651 
2025-01-24 17:53:28.653789: Pseudo dice [np.float32(0.9451), np.float32(0.8906)] 
2025-01-24 17:53:28.655962: Epoch time: 49.0 s 
2025-01-24 17:53:30.407189:  
2025-01-24 17:53:30.410558: Epoch 421 
2025-01-24 17:53:30.413164: Current learning rate: 0.00612 
2025-01-24 17:54:19.344263: train_loss -0.8074 
2025-01-24 17:54:19.348903: val_loss -0.7726 
2025-01-24 17:54:19.351657: Pseudo dice [np.float32(0.9536), np.float32(0.9237)] 
2025-01-24 17:54:19.354143: Epoch time: 48.94 s 
2025-01-24 17:54:20.559203:  
2025-01-24 17:54:20.562628: Epoch 422 
2025-01-24 17:54:20.565443: Current learning rate: 0.00611 
2025-01-24 17:55:09.133896: train_loss -0.8218 
2025-01-24 17:55:09.139867: val_loss -0.7616 
2025-01-24 17:55:09.143086: Pseudo dice [np.float32(0.9429), np.float32(0.8986)] 
2025-01-24 17:55:09.145976: Epoch time: 48.58 s 
2025-01-24 17:55:09.148961: Yayy! New best EMA pseudo Dice: 0.9176999926567078 
2025-01-24 17:55:10.897293:  
2025-01-24 17:55:10.900801: Epoch 423 
2025-01-24 17:55:10.903432: Current learning rate: 0.0061 
2025-01-24 17:55:59.200828: train_loss -0.8176 
2025-01-24 17:55:59.205545: val_loss -0.7728 
2025-01-24 17:55:59.208113: Pseudo dice [np.float32(0.9401), np.float32(0.8891)] 
2025-01-24 17:55:59.211126: Epoch time: 48.3 s 
2025-01-24 17:56:00.380101:  
2025-01-24 17:56:00.383220: Epoch 424 
2025-01-24 17:56:00.385607: Current learning rate: 0.00609 
2025-01-24 17:56:49.129151: train_loss -0.8246 
2025-01-24 17:56:49.134552: val_loss -0.7662 
2025-01-24 17:56:49.137195: Pseudo dice [np.float32(0.945), np.float32(0.8926)] 
2025-01-24 17:56:49.139972: Epoch time: 48.75 s 
2025-01-24 17:56:50.341889:  
2025-01-24 17:56:50.344780: Epoch 425 
2025-01-24 17:56:50.347616: Current learning rate: 0.00608 
2025-01-24 17:57:39.022051: train_loss -0.8274 
2025-01-24 17:57:39.026654: val_loss -0.7265 
2025-01-24 17:57:39.029346: Pseudo dice [np.float32(0.9431), np.float32(0.8901)] 
2025-01-24 17:57:39.031568: Epoch time: 48.68 s 
2025-01-24 17:57:40.252177:  
2025-01-24 17:57:40.255634: Epoch 426 
2025-01-24 17:57:40.258063: Current learning rate: 0.00607 
2025-01-24 17:58:29.667910: train_loss -0.8051 
2025-01-24 17:58:29.672781: val_loss -0.7435 
2025-01-24 17:58:29.675562: Pseudo dice [np.float32(0.9499), np.float32(0.8618)] 
2025-01-24 17:58:29.678393: Epoch time: 49.42 s 
2025-01-24 17:58:30.861031:  
2025-01-24 17:58:30.864813: Epoch 427 
2025-01-24 17:58:30.867783: Current learning rate: 0.00606 
2025-01-24 17:59:19.688484: train_loss -0.82 
2025-01-24 17:59:19.693143: val_loss -0.7124 
2025-01-24 17:59:19.695673: Pseudo dice [np.float32(0.9316), np.float32(0.8812)] 
2025-01-24 17:59:19.698252: Epoch time: 48.83 s 
2025-01-24 17:59:20.917578:  
2025-01-24 17:59:20.920041: Epoch 428 
2025-01-24 17:59:20.922488: Current learning rate: 0.00605 
2025-01-24 18:00:09.290426: train_loss -0.834 
2025-01-24 18:00:09.296234: val_loss -0.7638 
2025-01-24 18:00:09.298676: Pseudo dice [np.float32(0.9557), np.float32(0.9408)] 
2025-01-24 18:00:09.301401: Epoch time: 48.37 s 
2025-01-24 18:00:09.304059: Yayy! New best EMA pseudo Dice: 0.9186000227928162 
2025-01-24 18:00:11.140245:  
2025-01-24 18:00:11.143080: Epoch 429 
2025-01-24 18:00:11.145715: Current learning rate: 0.00604 
2025-01-24 18:00:59.488837: train_loss -0.8205 
2025-01-24 18:00:59.493721: val_loss -0.7416 
2025-01-24 18:00:59.496389: Pseudo dice [np.float32(0.9467), np.float32(0.918)] 
2025-01-24 18:00:59.498889: Epoch time: 48.35 s 
2025-01-24 18:00:59.501371: Yayy! New best EMA pseudo Dice: 0.9200000166893005 
2025-01-24 18:01:01.310199:  
2025-01-24 18:01:01.312729: Epoch 430 
2025-01-24 18:01:01.315012: Current learning rate: 0.00603 
2025-01-24 18:01:49.829000: train_loss -0.8223 
2025-01-24 18:01:49.833999: val_loss -0.7117 
2025-01-24 18:01:49.837016: Pseudo dice [np.float32(0.9492), np.float32(0.8966)] 
2025-01-24 18:01:49.839802: Epoch time: 48.52 s 
2025-01-24 18:01:49.842362: Yayy! New best EMA pseudo Dice: 0.9203000068664551 
2025-01-24 18:01:51.685593:  
2025-01-24 18:01:51.688184: Epoch 431 
2025-01-24 18:01:51.690558: Current learning rate: 0.00602 
2025-01-24 18:02:40.539737: train_loss -0.8319 
2025-01-24 18:02:40.543789: val_loss -0.7671 
2025-01-24 18:02:40.546119: Pseudo dice [np.float32(0.9535), np.float32(0.8945)] 
2025-01-24 18:02:40.548079: Epoch time: 48.86 s 
2025-01-24 18:02:40.550551: Yayy! New best EMA pseudo Dice: 0.9205999970436096 
2025-01-24 18:02:42.339348:  
2025-01-24 18:02:42.342074: Epoch 432 
2025-01-24 18:02:42.344462: Current learning rate: 0.00601 
2025-01-24 18:03:31.198029: train_loss -0.8147 
2025-01-24 18:03:31.202526: val_loss -0.7569 
2025-01-24 18:03:31.204978: Pseudo dice [np.float32(0.9532), np.float32(0.926)] 
2025-01-24 18:03:31.207502: Epoch time: 48.86 s 
2025-01-24 18:03:31.209842: Yayy! New best EMA pseudo Dice: 0.9225000143051147 
2025-01-24 18:03:33.001836:  
2025-01-24 18:03:33.004808: Epoch 433 
2025-01-24 18:03:33.007133: Current learning rate: 0.006 
2025-01-24 18:04:22.100333: train_loss -0.8126 
2025-01-24 18:04:22.105123: val_loss -0.7493 
2025-01-24 18:04:22.107784: Pseudo dice [np.float32(0.9455), np.float32(0.9138)] 
2025-01-24 18:04:22.110740: Epoch time: 49.1 s 
2025-01-24 18:04:22.113367: Yayy! New best EMA pseudo Dice: 0.9232000112533569 
2025-01-24 18:04:23.949807:  
2025-01-24 18:04:23.952919: Epoch 434 
2025-01-24 18:04:23.955647: Current learning rate: 0.00599 
2025-01-24 18:05:12.335475: train_loss -0.8037 
2025-01-24 18:05:12.340110: val_loss -0.7578 
2025-01-24 18:05:12.342606: Pseudo dice [np.float32(0.9454), np.float32(0.8968)] 
2025-01-24 18:05:12.344969: Epoch time: 48.39 s 
2025-01-24 18:05:13.559537:  
2025-01-24 18:05:13.562297: Epoch 435 
2025-01-24 18:05:13.564957: Current learning rate: 0.00598 
2025-01-24 18:06:02.417182: train_loss -0.8109 
2025-01-24 18:06:02.421710: val_loss -0.7807 
2025-01-24 18:06:02.424326: Pseudo dice [np.float32(0.9539), np.float32(0.8999)] 
2025-01-24 18:06:02.426753: Epoch time: 48.86 s 
2025-01-24 18:06:02.429214: Yayy! New best EMA pseudo Dice: 0.9233999848365784 
2025-01-24 18:06:04.244727:  
2025-01-24 18:06:04.247589: Epoch 436 
2025-01-24 18:06:04.250230: Current learning rate: 0.00597 
2025-01-24 18:06:52.925645: train_loss -0.8292 
2025-01-24 18:06:52.930016: val_loss -0.7439 
2025-01-24 18:06:52.932252: Pseudo dice [np.float32(0.93), np.float32(0.894)] 
2025-01-24 18:06:52.934589: Epoch time: 48.68 s 
2025-01-24 18:06:54.146298:  
2025-01-24 18:06:54.148752: Epoch 437 
2025-01-24 18:06:54.151104: Current learning rate: 0.00596 
2025-01-24 18:07:43.163343: train_loss -0.8031 
2025-01-24 18:07:43.169131: val_loss -0.7341 
2025-01-24 18:07:43.171861: Pseudo dice [np.float32(0.938), np.float32(0.8991)] 
2025-01-24 18:07:43.174443: Epoch time: 49.02 s 
2025-01-24 18:07:44.381146:  
2025-01-24 18:07:44.384010: Epoch 438 
2025-01-24 18:07:44.386774: Current learning rate: 0.00595 
2025-01-24 18:08:32.874050: train_loss -0.8131 
2025-01-24 18:08:32.878405: val_loss -0.7231 
2025-01-24 18:08:32.880889: Pseudo dice [np.float32(0.9415), np.float32(0.9073)] 
2025-01-24 18:08:32.883186: Epoch time: 48.49 s 
2025-01-24 18:08:34.094941:  
2025-01-24 18:08:34.097561: Epoch 439 
2025-01-24 18:08:34.100475: Current learning rate: 0.00594 
2025-01-24 18:09:22.889183: train_loss -0.8189 
2025-01-24 18:09:22.893955: val_loss -0.718 
2025-01-24 18:09:22.896551: Pseudo dice [np.float32(0.9483), np.float32(0.8793)] 
2025-01-24 18:09:22.898808: Epoch time: 48.8 s 
2025-01-24 18:09:24.739126:  
2025-01-24 18:09:24.742177: Epoch 440 
2025-01-24 18:09:24.745132: Current learning rate: 0.00593 
2025-01-24 18:10:12.971630: train_loss -0.8018 
2025-01-24 18:10:12.976018: val_loss -0.7345 
2025-01-24 18:10:12.978355: Pseudo dice [np.float32(0.9207), np.float32(0.8624)] 
2025-01-24 18:10:12.980907: Epoch time: 48.23 s 
2025-01-24 18:10:14.196774:  
2025-01-24 18:10:14.199668: Epoch 441 
2025-01-24 18:10:14.202494: Current learning rate: 0.00592 
2025-01-24 18:11:03.714297: train_loss -0.8092 
2025-01-24 18:11:03.718654: val_loss -0.7521 
2025-01-24 18:11:03.720767: Pseudo dice [np.float32(0.9481), np.float32(0.8368)] 
2025-01-24 18:11:03.722864: Epoch time: 49.52 s 
2025-01-24 18:11:04.948061:  
2025-01-24 18:11:04.951667: Epoch 442 
2025-01-24 18:11:04.954958: Current learning rate: 0.00592 
2025-01-24 18:11:53.447061: train_loss -0.8062 
2025-01-24 18:11:53.451422: val_loss -0.7308 
2025-01-24 18:11:53.454044: Pseudo dice [np.float32(0.948), np.float32(0.8992)] 
2025-01-24 18:11:53.456421: Epoch time: 48.5 s 
2025-01-24 18:11:54.668447:  
2025-01-24 18:11:54.671090: Epoch 443 
2025-01-24 18:11:54.673459: Current learning rate: 0.00591 
2025-01-24 18:12:43.191240: train_loss -0.8067 
2025-01-24 18:12:43.196474: val_loss -0.7314 
2025-01-24 18:12:43.199087: Pseudo dice [np.float32(0.9282), np.float32(0.8893)] 
2025-01-24 18:12:43.201653: Epoch time: 48.52 s 
2025-01-24 18:12:44.404731:  
2025-01-24 18:12:44.407563: Epoch 444 
2025-01-24 18:12:44.410580: Current learning rate: 0.0059 
2025-01-24 18:13:33.547711: train_loss -0.8053 
2025-01-24 18:13:33.553113: val_loss -0.6921 
2025-01-24 18:13:33.555906: Pseudo dice [np.float32(0.9483), np.float32(0.8428)] 
2025-01-24 18:13:33.558398: Epoch time: 49.14 s 
2025-01-24 18:13:34.756463:  
2025-01-24 18:13:34.759050: Epoch 445 
2025-01-24 18:13:34.761441: Current learning rate: 0.00589 
2025-01-24 18:14:23.349105: train_loss -0.8127 
2025-01-24 18:14:23.353771: val_loss -0.749 
2025-01-24 18:14:23.356283: Pseudo dice [np.float32(0.9415), np.float32(0.8284)] 
2025-01-24 18:14:23.358688: Epoch time: 48.59 s 
2025-01-24 18:14:24.553931:  
2025-01-24 18:14:24.557254: Epoch 446 
2025-01-24 18:14:24.560171: Current learning rate: 0.00588 
2025-01-24 18:15:13.155612: train_loss -0.8248 
2025-01-24 18:15:13.160295: val_loss -0.7434 
2025-01-24 18:15:13.162937: Pseudo dice [np.float32(0.9422), np.float32(0.9051)] 
2025-01-24 18:15:13.165381: Epoch time: 48.6 s 
2025-01-24 18:15:14.362372:  
2025-01-24 18:15:14.365212: Epoch 447 
2025-01-24 18:15:14.367831: Current learning rate: 0.00587 
2025-01-24 18:16:03.413579: train_loss -0.8282 
2025-01-24 18:16:03.418972: val_loss -0.7594 
2025-01-24 18:16:03.421775: Pseudo dice [np.float32(0.9504), np.float32(0.9167)] 
2025-01-24 18:16:03.424516: Epoch time: 49.05 s 
2025-01-24 18:16:04.623082:  
2025-01-24 18:16:04.625578: Epoch 448 
2025-01-24 18:16:04.628101: Current learning rate: 0.00586 
2025-01-24 18:16:53.580999: train_loss -0.8143 
2025-01-24 18:16:53.585474: val_loss -0.7042 
2025-01-24 18:16:53.587818: Pseudo dice [np.float32(0.9491), np.float32(0.9035)] 
2025-01-24 18:16:53.589906: Epoch time: 48.96 s 
2025-01-24 18:16:54.785095:  
2025-01-24 18:16:54.788193: Epoch 449 
2025-01-24 18:16:54.791259: Current learning rate: 0.00585 
2025-01-24 18:17:44.037085: train_loss -0.8258 
2025-01-24 18:17:44.042520: val_loss -0.7308 
2025-01-24 18:17:44.045071: Pseudo dice [np.float32(0.9565), np.float32(0.9362)] 
2025-01-24 18:17:44.047510: Epoch time: 49.25 s 
2025-01-24 18:17:45.799524:  
2025-01-24 18:17:45.802476: Epoch 450 
2025-01-24 18:17:45.805225: Current learning rate: 0.00584 
2025-01-24 18:18:34.717017: train_loss -0.8266 
2025-01-24 18:18:34.722411: val_loss -0.7415 
2025-01-24 18:18:34.725345: Pseudo dice [np.float32(0.9484), np.float32(0.9289)] 
2025-01-24 18:18:34.727847: Epoch time: 48.92 s 
2025-01-24 18:18:35.891452:  
2025-01-24 18:18:35.894315: Epoch 451 
2025-01-24 18:18:35.897179: Current learning rate: 0.00583 
2025-01-24 18:19:24.881677: train_loss -0.811 
2025-01-24 18:19:24.886334: val_loss -0.7603 
2025-01-24 18:19:24.888910: Pseudo dice [np.float32(0.9515), np.float32(0.9275)] 
2025-01-24 18:19:24.891551: Epoch time: 48.99 s 
2025-01-24 18:19:26.049809:  
2025-01-24 18:19:26.052443: Epoch 452 
2025-01-24 18:19:26.054935: Current learning rate: 0.00582 
2025-01-24 18:20:14.729665: train_loss -0.813 
2025-01-24 18:20:14.734249: val_loss -0.739 
2025-01-24 18:20:14.736588: Pseudo dice [np.float32(0.9555), np.float32(0.9239)] 
2025-01-24 18:20:14.738928: Epoch time: 48.68 s 
2025-01-24 18:20:14.741303: Yayy! New best EMA pseudo Dice: 0.9241999983787537 
2025-01-24 18:20:16.543493:  
2025-01-24 18:20:16.546390: Epoch 453 
2025-01-24 18:20:16.549244: Current learning rate: 0.00581 
2025-01-24 18:21:04.973485: train_loss -0.8158 
2025-01-24 18:21:04.979232: val_loss -0.7596 
2025-01-24 18:21:04.982102: Pseudo dice [np.float32(0.9559), np.float32(0.9315)] 
2025-01-24 18:21:04.984547: Epoch time: 48.43 s 
2025-01-24 18:21:04.987183: Yayy! New best EMA pseudo Dice: 0.9261000156402588 
2025-01-24 18:21:06.721931:  
2025-01-24 18:21:06.725070: Epoch 454 
2025-01-24 18:21:06.728054: Current learning rate: 0.0058 
2025-01-24 18:21:55.495012: train_loss -0.8148 
2025-01-24 18:21:55.499246: val_loss -0.7699 
2025-01-24 18:21:55.501658: Pseudo dice [np.float32(0.9458), np.float32(0.8874)] 
2025-01-24 18:21:55.503833: Epoch time: 48.77 s 
2025-01-24 18:21:56.718669:  
2025-01-24 18:21:56.721618: Epoch 455 
2025-01-24 18:21:56.724352: Current learning rate: 0.00579 
2025-01-24 18:22:45.273612: train_loss -0.8126 
2025-01-24 18:22:45.278933: val_loss -0.6896 
2025-01-24 18:22:45.282407: Pseudo dice [np.float32(0.9379), np.float32(0.8664)] 
2025-01-24 18:22:45.285674: Epoch time: 48.56 s 
2025-01-24 18:22:46.453586:  
2025-01-24 18:22:46.457065: Epoch 456 
2025-01-24 18:22:46.460288: Current learning rate: 0.00578 
2025-01-24 18:23:35.298417: train_loss -0.8239 
2025-01-24 18:23:35.302733: val_loss -0.7305 
2025-01-24 18:23:35.305355: Pseudo dice [np.float32(0.93), np.float32(0.8639)] 
2025-01-24 18:23:35.307814: Epoch time: 48.85 s 
2025-01-24 18:23:36.478785:  
2025-01-24 18:23:36.481335: Epoch 457 
2025-01-24 18:23:36.483760: Current learning rate: 0.00577 
2025-01-24 18:24:24.887022: train_loss -0.8187 
2025-01-24 18:24:24.891814: val_loss -0.6745 
2025-01-24 18:24:24.894549: Pseudo dice [np.float32(0.9445), np.float32(0.7537)] 
2025-01-24 18:24:24.897360: Epoch time: 48.41 s 
2025-01-24 18:24:26.046975:  
2025-01-24 18:24:26.049926: Epoch 458 
2025-01-24 18:24:26.052694: Current learning rate: 0.00576 
2025-01-24 18:25:14.988166: train_loss -0.8017 
2025-01-24 18:25:14.993948: val_loss -0.7807 
2025-01-24 18:25:14.996590: Pseudo dice [np.float32(0.9498), np.float32(0.9094)] 
2025-01-24 18:25:14.999274: Epoch time: 48.94 s 
2025-01-24 18:25:16.731244:  
2025-01-24 18:25:16.734206: Epoch 459 
2025-01-24 18:25:16.736890: Current learning rate: 0.00575 
2025-01-24 18:26:05.502041: train_loss -0.8043 
2025-01-24 18:26:05.506577: val_loss -0.7575 
2025-01-24 18:26:05.509194: Pseudo dice [np.float32(0.9389), np.float32(0.9018)] 
2025-01-24 18:26:05.511585: Epoch time: 48.77 s 
2025-01-24 18:26:06.670417:  
2025-01-24 18:26:06.673677: Epoch 460 
2025-01-24 18:26:06.676488: Current learning rate: 0.00574 
2025-01-24 18:26:55.357917: train_loss -0.8146 
2025-01-24 18:26:55.362797: val_loss -0.7392 
2025-01-24 18:26:55.365626: Pseudo dice [np.float32(0.9347), np.float32(0.8721)] 
2025-01-24 18:26:55.368152: Epoch time: 48.69 s 
2025-01-24 18:26:56.526088:  
2025-01-24 18:26:56.528907: Epoch 461 
2025-01-24 18:26:56.531550: Current learning rate: 0.00573 
2025-01-24 18:27:44.752941: train_loss -0.8186 
2025-01-24 18:27:44.757993: val_loss -0.7448 
2025-01-24 18:27:44.760582: Pseudo dice [np.float32(0.9469), np.float32(0.92)] 
2025-01-24 18:27:44.763135: Epoch time: 48.23 s 
2025-01-24 18:27:45.931275:  
2025-01-24 18:27:45.934128: Epoch 462 
2025-01-24 18:27:45.936727: Current learning rate: 0.00572 
2025-01-24 18:28:34.221840: train_loss -0.8242 
2025-01-24 18:28:34.226229: val_loss -0.7722 
2025-01-24 18:28:34.229009: Pseudo dice [np.float32(0.9523), np.float32(0.9209)] 
2025-01-24 18:28:34.231485: Epoch time: 48.29 s 
2025-01-24 18:28:35.386033:  
2025-01-24 18:28:35.388775: Epoch 463 
2025-01-24 18:28:35.391300: Current learning rate: 0.00571 
2025-01-24 18:29:24.246483: train_loss -0.8239 
2025-01-24 18:29:24.250747: val_loss -0.7543 
2025-01-24 18:29:24.253348: Pseudo dice [np.float32(0.9385), np.float32(0.9248)] 
2025-01-24 18:29:24.255692: Epoch time: 48.86 s 
2025-01-24 18:29:25.412400:  
2025-01-24 18:29:25.415379: Epoch 464 
2025-01-24 18:29:25.418033: Current learning rate: 0.0057 
2025-01-24 18:30:14.217922: train_loss -0.8247 
2025-01-24 18:30:14.222521: val_loss -0.7474 
2025-01-24 18:30:14.224936: Pseudo dice [np.float32(0.9438), np.float32(0.9149)] 
2025-01-24 18:30:14.227378: Epoch time: 48.81 s 
2025-01-24 18:30:15.395054:  
2025-01-24 18:30:15.397585: Epoch 465 
2025-01-24 18:30:15.400696: Current learning rate: 0.0057 
2025-01-24 18:31:04.037691: train_loss -0.8278 
2025-01-24 18:31:04.042976: val_loss -0.7605 
2025-01-24 18:31:04.045985: Pseudo dice [np.float32(0.9512), np.float32(0.9331)] 
2025-01-24 18:31:04.048549: Epoch time: 48.64 s 
2025-01-24 18:31:05.206762:  
2025-01-24 18:31:05.209519: Epoch 466 
2025-01-24 18:31:05.212281: Current learning rate: 0.00569 
2025-01-24 18:31:54.036932: train_loss -0.8101 
2025-01-24 18:31:54.041409: val_loss -0.7256 
2025-01-24 18:31:54.043748: Pseudo dice [np.float32(0.9391), np.float32(0.8711)] 
2025-01-24 18:31:54.046093: Epoch time: 48.83 s 
2025-01-24 18:31:55.205212:  
2025-01-24 18:31:55.208200: Epoch 467 
2025-01-24 18:31:55.210672: Current learning rate: 0.00568 
2025-01-24 18:32:43.743974: train_loss -0.8348 
2025-01-24 18:32:43.748679: val_loss -0.7919 
2025-01-24 18:32:43.750952: Pseudo dice [np.float32(0.9576), np.float32(0.914)] 
2025-01-24 18:32:43.753327: Epoch time: 48.54 s 
2025-01-24 18:32:44.915220:  
2025-01-24 18:32:44.917531: Epoch 468 
2025-01-24 18:32:44.920262: Current learning rate: 0.00567 
2025-01-24 18:33:33.597108: train_loss -0.8213 
2025-01-24 18:33:33.602752: val_loss -0.7582 
2025-01-24 18:33:33.605591: Pseudo dice [np.float32(0.9481), np.float32(0.883)] 
2025-01-24 18:33:33.608157: Epoch time: 48.68 s 
2025-01-24 18:33:34.766361:  
2025-01-24 18:33:34.769270: Epoch 469 
2025-01-24 18:33:34.772171: Current learning rate: 0.00566 
2025-01-24 18:34:23.925376: train_loss -0.8318 
2025-01-24 18:34:23.930472: val_loss -0.7435 
2025-01-24 18:34:23.933253: Pseudo dice [np.float32(0.9518), np.float32(0.9124)] 
2025-01-24 18:34:23.936005: Epoch time: 49.16 s 
2025-01-24 18:34:25.116686:  
2025-01-24 18:34:25.119354: Epoch 470 
2025-01-24 18:34:25.121818: Current learning rate: 0.00565 
2025-01-24 18:35:13.583051: train_loss -0.8028 
2025-01-24 18:35:13.587792: val_loss -0.7485 
2025-01-24 18:35:13.590119: Pseudo dice [np.float32(0.9293), np.float32(0.8524)] 
2025-01-24 18:35:13.592566: Epoch time: 48.47 s 
2025-01-24 18:35:14.763358:  
2025-01-24 18:35:14.766329: Epoch 471 
2025-01-24 18:35:14.769371: Current learning rate: 0.00564 
2025-01-24 18:36:03.130072: train_loss -0.8141 
2025-01-24 18:36:03.134922: val_loss -0.7314 
2025-01-24 18:36:03.137475: Pseudo dice [np.float32(0.9425), np.float32(0.8785)] 
2025-01-24 18:36:03.140136: Epoch time: 48.37 s 
2025-01-24 18:36:04.297929:  
2025-01-24 18:36:04.300635: Epoch 472 
2025-01-24 18:36:04.303157: Current learning rate: 0.00563 
2025-01-24 18:36:52.974478: train_loss -0.8188 
2025-01-24 18:36:52.978666: val_loss -0.7273 
2025-01-24 18:36:52.981008: Pseudo dice [np.float32(0.9506), np.float32(0.8432)] 
2025-01-24 18:36:52.983172: Epoch time: 48.68 s 
2025-01-24 18:36:54.134628:  
2025-01-24 18:36:54.137258: Epoch 473 
2025-01-24 18:36:54.139968: Current learning rate: 0.00562 
2025-01-24 18:37:42.475530: train_loss -0.8292 
2025-01-24 18:37:42.481294: val_loss -0.7231 
2025-01-24 18:37:42.484070: Pseudo dice [np.float32(0.9345), np.float32(0.9086)] 
2025-01-24 18:37:42.487068: Epoch time: 48.34 s 
2025-01-24 18:37:43.692485:  
2025-01-24 18:37:43.695867: Epoch 474 
2025-01-24 18:37:43.698314: Current learning rate: 0.00561 
2025-01-24 18:38:32.288585: train_loss -0.8334 
2025-01-24 18:38:32.293679: val_loss -0.7691 
2025-01-24 18:38:32.296001: Pseudo dice [np.float32(0.9488), np.float32(0.8983)] 
2025-01-24 18:38:32.298447: Epoch time: 48.6 s 
2025-01-24 18:38:33.491077:  
2025-01-24 18:38:33.494234: Epoch 475 
2025-01-24 18:38:33.497587: Current learning rate: 0.0056 
2025-01-24 18:39:22.119300: train_loss -0.8335 
2025-01-24 18:39:22.124401: val_loss -0.8009 
2025-01-24 18:39:22.127068: Pseudo dice [np.float32(0.9362), np.float32(0.9014)] 
2025-01-24 18:39:22.129709: Epoch time: 48.63 s 
2025-01-24 18:39:23.336783:  
2025-01-24 18:39:23.340058: Epoch 476 
2025-01-24 18:39:23.342865: Current learning rate: 0.00559 
2025-01-24 18:40:12.644035: train_loss -0.817 
2025-01-24 18:40:12.649518: val_loss -0.7423 
2025-01-24 18:40:12.652515: Pseudo dice [np.float32(0.9411), np.float32(0.9128)] 
2025-01-24 18:40:12.655183: Epoch time: 49.31 s 
2025-01-24 18:40:13.817321:  
2025-01-24 18:40:13.820035: Epoch 477 
2025-01-24 18:40:13.822592: Current learning rate: 0.00558 
2025-01-24 18:41:02.273462: train_loss -0.8182 
2025-01-24 18:41:02.278291: val_loss -0.7567 
2025-01-24 18:41:02.281065: Pseudo dice [np.float32(0.9468), np.float32(0.9136)] 
2025-01-24 18:41:02.283828: Epoch time: 48.46 s 
2025-01-24 18:41:03.496730:  
2025-01-24 18:41:03.499582: Epoch 478 
2025-01-24 18:41:03.502244: Current learning rate: 0.00557 
2025-01-24 18:41:52.641342: train_loss -0.8162 
2025-01-24 18:41:52.645831: val_loss -0.7498 
2025-01-24 18:41:52.648426: Pseudo dice [np.float32(0.9467), np.float32(0.8963)] 
2025-01-24 18:41:52.650586: Epoch time: 49.15 s 
2025-01-24 18:41:54.389310:  
2025-01-24 18:41:54.394245: Epoch 479 
2025-01-24 18:41:54.396403: Current learning rate: 0.00556 
2025-01-24 18:42:43.075043: train_loss -0.8085 
2025-01-24 18:42:43.079268: val_loss -0.7664 
2025-01-24 18:42:43.081784: Pseudo dice [np.float32(0.9277), np.float32(0.8938)] 
2025-01-24 18:42:43.084389: Epoch time: 48.69 s 
2025-01-24 18:42:44.255719:  
2025-01-24 18:42:44.258852: Epoch 480 
2025-01-24 18:42:44.261306: Current learning rate: 0.00555 
2025-01-24 18:43:33.039136: train_loss -0.8287 
2025-01-24 18:43:33.043713: val_loss -0.7165 
2025-01-24 18:43:33.046427: Pseudo dice [np.float32(0.9541), np.float32(0.8918)] 
2025-01-24 18:43:33.048987: Epoch time: 48.78 s 
2025-01-24 18:43:34.226685:  
2025-01-24 18:43:34.229551: Epoch 481 
2025-01-24 18:43:34.232131: Current learning rate: 0.00554 
2025-01-24 18:44:22.264896: train_loss -0.8171 
2025-01-24 18:44:22.269627: val_loss -0.7586 
2025-01-24 18:44:22.272176: Pseudo dice [np.float32(0.9499), np.float32(0.9249)] 
2025-01-24 18:44:22.274679: Epoch time: 48.04 s 
2025-01-24 18:44:23.480035:  
2025-01-24 18:44:23.483650: Epoch 482 
2025-01-24 18:44:23.486505: Current learning rate: 0.00553 
2025-01-24 18:45:11.969949: train_loss -0.7996 
2025-01-24 18:45:11.974874: val_loss -0.7349 
2025-01-24 18:45:11.977395: Pseudo dice [np.float32(0.9443), np.float32(0.9179)] 
2025-01-24 18:45:11.979992: Epoch time: 48.49 s 
2025-01-24 18:45:13.154285:  
2025-01-24 18:45:13.157256: Epoch 483 
2025-01-24 18:45:13.159991: Current learning rate: 0.00552 
2025-01-24 18:46:01.767906: train_loss -0.822 
2025-01-24 18:46:01.772775: val_loss -0.737 
2025-01-24 18:46:01.775640: Pseudo dice [np.float32(0.9499), np.float32(0.8707)] 
2025-01-24 18:46:01.778888: Epoch time: 48.62 s 
2025-01-24 18:46:02.964442:  
2025-01-24 18:46:02.968967: Epoch 484 
2025-01-24 18:46:02.971747: Current learning rate: 0.00551 
2025-01-24 18:46:52.021203: train_loss -0.8138 
2025-01-24 18:46:52.026534: val_loss -0.7354 
2025-01-24 18:46:52.029418: Pseudo dice [np.float32(0.9532), np.float32(0.8027)] 
2025-01-24 18:46:52.031852: Epoch time: 49.06 s 
2025-01-24 18:46:53.221752:  
2025-01-24 18:46:53.224466: Epoch 485 
2025-01-24 18:46:53.227193: Current learning rate: 0.0055 
2025-01-24 18:47:42.337176: train_loss -0.8001 
2025-01-24 18:47:42.342070: val_loss -0.773 
2025-01-24 18:47:42.345132: Pseudo dice [np.float32(0.9429), np.float32(0.9264)] 
2025-01-24 18:47:42.347825: Epoch time: 49.12 s 
2025-01-24 18:47:43.557800:  
2025-01-24 18:47:43.560937: Epoch 486 
2025-01-24 18:47:43.563998: Current learning rate: 0.00549 
2025-01-24 18:48:32.454020: train_loss -0.8101 
2025-01-24 18:48:32.458853: val_loss -0.7524 
2025-01-24 18:48:32.461542: Pseudo dice [np.float32(0.9489), np.float32(0.8851)] 
2025-01-24 18:48:32.464046: Epoch time: 48.9 s 
2025-01-24 18:48:33.677026:  
2025-01-24 18:48:33.679816: Epoch 487 
2025-01-24 18:48:33.682380: Current learning rate: 0.00548 
2025-01-24 18:49:22.414688: train_loss -0.8154 
2025-01-24 18:49:22.419357: val_loss -0.7278 
2025-01-24 18:49:22.421740: Pseudo dice [np.float32(0.9499), np.float32(0.8588)] 
2025-01-24 18:49:22.424106: Epoch time: 48.74 s 
2025-01-24 18:49:23.612842:  
2025-01-24 18:49:23.615376: Epoch 488 
2025-01-24 18:49:23.617731: Current learning rate: 0.00547 
2025-01-24 18:50:12.777585: train_loss -0.8261 
2025-01-24 18:50:12.782084: val_loss -0.7781 
2025-01-24 18:50:12.784879: Pseudo dice [np.float32(0.9375), np.float32(0.8954)] 
2025-01-24 18:50:12.787358: Epoch time: 49.17 s 
2025-01-24 18:50:13.997685:  
2025-01-24 18:50:14.000323: Epoch 489 
2025-01-24 18:50:14.002827: Current learning rate: 0.00546 
2025-01-24 18:51:02.670864: train_loss -0.8215 
2025-01-24 18:51:02.675939: val_loss -0.7551 
2025-01-24 18:51:02.678415: Pseudo dice [np.float32(0.9536), np.float32(0.912)] 
2025-01-24 18:51:02.681022: Epoch time: 48.67 s 
2025-01-24 18:51:03.856115:  
2025-01-24 18:51:03.859488: Epoch 490 
2025-01-24 18:51:03.861911: Current learning rate: 0.00546 
2025-01-24 18:51:52.025086: train_loss -0.8289 
2025-01-24 18:51:52.030170: val_loss -0.7857 
2025-01-24 18:51:52.032847: Pseudo dice [np.float32(0.9467), np.float32(0.9028)] 
2025-01-24 18:51:52.035811: Epoch time: 48.17 s 
2025-01-24 18:51:53.247395:  
2025-01-24 18:51:53.251095: Epoch 491 
2025-01-24 18:51:53.254202: Current learning rate: 0.00545 
2025-01-24 18:52:42.100935: train_loss -0.8095 
2025-01-24 18:52:42.105756: val_loss -0.7496 
2025-01-24 18:52:42.108130: Pseudo dice [np.float32(0.943), np.float32(0.9211)] 
2025-01-24 18:52:42.110534: Epoch time: 48.85 s 
2025-01-24 18:52:43.318658:  
2025-01-24 18:52:43.321971: Epoch 492 
2025-01-24 18:52:43.324775: Current learning rate: 0.00544 
2025-01-24 18:53:32.189868: train_loss -0.8172 
2025-01-24 18:53:32.194763: val_loss -0.6832 
2025-01-24 18:53:32.197340: Pseudo dice [np.float32(0.9411), np.float32(0.7727)] 
2025-01-24 18:53:32.199573: Epoch time: 48.87 s 
2025-01-24 18:53:33.426091:  
2025-01-24 18:53:33.428930: Epoch 493 
2025-01-24 18:53:33.431296: Current learning rate: 0.00543 
2025-01-24 18:54:22.164804: train_loss -0.8118 
2025-01-24 18:54:22.168928: val_loss -0.7266 
2025-01-24 18:54:22.171514: Pseudo dice [np.float32(0.9312), np.float32(0.863)] 
2025-01-24 18:54:22.173923: Epoch time: 48.74 s 
2025-01-24 18:54:23.354425:  
2025-01-24 18:54:23.357493: Epoch 494 
2025-01-24 18:54:23.360397: Current learning rate: 0.00542 
2025-01-24 18:55:12.511643: train_loss -0.8087 
2025-01-24 18:55:12.516489: val_loss -0.7424 
2025-01-24 18:55:12.519115: Pseudo dice [np.float32(0.9357), np.float32(0.8552)] 
2025-01-24 18:55:12.521641: Epoch time: 49.16 s 
2025-01-24 18:55:13.695472:  
2025-01-24 18:55:13.698476: Epoch 495 
2025-01-24 18:55:13.701181: Current learning rate: 0.00541 
2025-01-24 18:56:02.648887: train_loss -0.8115 
2025-01-24 18:56:02.654450: val_loss -0.7777 
2025-01-24 18:56:02.657556: Pseudo dice [np.float32(0.9428), np.float32(0.8839)] 
2025-01-24 18:56:02.660244: Epoch time: 48.95 s 
2025-01-24 18:56:03.835702:  
2025-01-24 18:56:03.838377: Epoch 496 
2025-01-24 18:56:03.840967: Current learning rate: 0.0054 
2025-01-24 18:56:52.699630: train_loss -0.8134 
2025-01-24 18:56:52.704386: val_loss -0.7113 
2025-01-24 18:56:52.707004: Pseudo dice [np.float32(0.9485), np.float32(0.8822)] 
2025-01-24 18:56:52.709563: Epoch time: 48.86 s 
2025-01-24 18:56:53.883715:  
2025-01-24 18:56:53.886151: Epoch 497 
2025-01-24 18:56:53.888556: Current learning rate: 0.00539 
2025-01-24 18:57:42.536676: train_loss -0.8122 
2025-01-24 18:57:42.540831: val_loss -0.7101 
2025-01-24 18:57:42.543346: Pseudo dice [np.float32(0.9295), np.float32(0.7852)] 
2025-01-24 18:57:42.545764: Epoch time: 48.65 s 
2025-01-24 18:57:44.310201:  
2025-01-24 18:57:44.312974: Epoch 498 
2025-01-24 18:57:44.315488: Current learning rate: 0.00538 
2025-01-24 18:58:32.808297: train_loss -0.7748 
2025-01-24 18:58:32.813272: val_loss -0.7614 
2025-01-24 18:58:32.815555: Pseudo dice [np.float32(0.9513), np.float32(0.9294)] 
2025-01-24 18:58:32.817950: Epoch time: 48.5 s 
2025-01-24 18:58:34.001025:  
2025-01-24 18:58:34.003658: Epoch 499 
2025-01-24 18:58:34.005871: Current learning rate: 0.00537 
2025-01-24 18:59:23.391273: train_loss -0.8123 
2025-01-24 18:59:23.395596: val_loss -0.7837 
2025-01-24 18:59:23.398024: Pseudo dice [np.float32(0.9534), np.float32(0.9172)] 
2025-01-24 18:59:23.400562: Epoch time: 49.39 s 
2025-01-24 18:59:25.190123:  
2025-01-24 18:59:25.193087: Epoch 500 
2025-01-24 18:59:25.195796: Current learning rate: 0.00536 
2025-01-24 19:00:13.988885: train_loss -0.8088 
2025-01-24 19:00:13.993710: val_loss -0.7694 
2025-01-24 19:00:13.996138: Pseudo dice [np.float32(0.9431), np.float32(0.915)] 
2025-01-24 19:00:13.998451: Epoch time: 48.8 s 
2025-01-24 19:00:15.194291:  
2025-01-24 19:00:15.196751: Epoch 501 
2025-01-24 19:00:15.199354: Current learning rate: 0.00535 
2025-01-24 19:01:03.828682: train_loss -0.828 
2025-01-24 19:01:03.833585: val_loss -0.6798 
2025-01-24 19:01:03.836144: Pseudo dice [np.float32(0.9383), np.float32(0.8462)] 
2025-01-24 19:01:03.838768: Epoch time: 48.64 s 
2025-01-24 19:01:05.023603:  
2025-01-24 19:01:05.026843: Epoch 502 
2025-01-24 19:01:05.029289: Current learning rate: 0.00534 
2025-01-24 19:01:53.538185: train_loss -0.8311 
2025-01-24 19:01:53.543153: val_loss -0.7559 
2025-01-24 19:01:53.545998: Pseudo dice [np.float32(0.9499), np.float32(0.9241)] 
2025-01-24 19:01:53.548570: Epoch time: 48.52 s 
2025-01-24 19:01:54.731397:  
2025-01-24 19:01:54.734412: Epoch 503 
2025-01-24 19:01:54.737033: Current learning rate: 0.00533 
2025-01-24 19:02:43.541203: train_loss -0.8217 
2025-01-24 19:02:43.546211: val_loss -0.7124 
2025-01-24 19:02:43.548819: Pseudo dice [np.float32(0.9387), np.float32(0.9043)] 
2025-01-24 19:02:43.551156: Epoch time: 48.81 s 
2025-01-24 19:02:44.730711:  
2025-01-24 19:02:44.733315: Epoch 504 
2025-01-24 19:02:44.735840: Current learning rate: 0.00532 
2025-01-24 19:03:33.410755: train_loss -0.8047 
2025-01-24 19:03:33.416023: val_loss -0.7426 
2025-01-24 19:03:33.418596: Pseudo dice [np.float32(0.9319), np.float32(0.8795)] 
2025-01-24 19:03:33.421098: Epoch time: 48.68 s 
2025-01-24 19:03:34.633940:  
2025-01-24 19:03:34.636936: Epoch 505 
2025-01-24 19:03:34.639756: Current learning rate: 0.00531 
2025-01-24 19:04:23.291320: train_loss -0.8145 
2025-01-24 19:04:23.298513: val_loss -0.7369 
2025-01-24 19:04:23.301401: Pseudo dice [np.float32(0.9446), np.float32(0.8996)] 
2025-01-24 19:04:23.304247: Epoch time: 48.66 s 
2025-01-24 19:04:24.485063:  
2025-01-24 19:04:24.488224: Epoch 506 
2025-01-24 19:04:24.491010: Current learning rate: 0.0053 
2025-01-24 19:05:12.628144: train_loss -0.8153 
2025-01-24 19:05:12.633285: val_loss -0.7107 
2025-01-24 19:05:12.636172: Pseudo dice [np.float32(0.9033), np.float32(0.8078)] 
2025-01-24 19:05:12.638832: Epoch time: 48.14 s 
2025-01-24 19:05:13.813479:  
2025-01-24 19:05:13.816733: Epoch 507 
2025-01-24 19:05:13.819430: Current learning rate: 0.00529 
2025-01-24 19:06:02.780802: train_loss -0.8097 
2025-01-24 19:06:02.785367: val_loss -0.7218 
2025-01-24 19:06:02.787967: Pseudo dice [np.float32(0.9501), np.float32(0.8293)] 
2025-01-24 19:06:02.790403: Epoch time: 48.97 s 
2025-01-24 19:06:03.966712:  
2025-01-24 19:06:03.970014: Epoch 508 
2025-01-24 19:06:03.973088: Current learning rate: 0.00528 
2025-01-24 19:06:52.545554: train_loss -0.7909 
2025-01-24 19:06:52.550562: val_loss -0.6855 
2025-01-24 19:06:52.553176: Pseudo dice [np.float32(0.9338), np.float32(0.7935)] 
2025-01-24 19:06:52.555711: Epoch time: 48.58 s 
2025-01-24 19:06:53.784859:  
2025-01-24 19:06:53.787814: Epoch 509 
2025-01-24 19:06:53.790756: Current learning rate: 0.00527 
2025-01-24 19:07:42.774215: train_loss -0.8033 
2025-01-24 19:07:42.778856: val_loss -0.6947 
2025-01-24 19:07:42.781511: Pseudo dice [np.float32(0.9351), np.float32(0.7852)] 
2025-01-24 19:07:42.784386: Epoch time: 48.99 s 
2025-01-24 19:07:44.055289:  
2025-01-24 19:07:44.058044: Epoch 510 
2025-01-24 19:07:44.060753: Current learning rate: 0.00526 
2025-01-24 19:08:32.657354: train_loss -0.8042 
2025-01-24 19:08:32.662047: val_loss -0.7248 
2025-01-24 19:08:32.664393: Pseudo dice [np.float32(0.9411), np.float32(0.915)] 
2025-01-24 19:08:32.666575: Epoch time: 48.6 s 
2025-01-24 19:08:33.905111:  
2025-01-24 19:08:33.908005: Epoch 511 
2025-01-24 19:08:33.910752: Current learning rate: 0.00525 
2025-01-24 19:09:22.272617: train_loss -0.8108 
2025-01-24 19:09:22.276714: val_loss -0.7388 
2025-01-24 19:09:22.278933: Pseudo dice [np.float32(0.9435), np.float32(0.8835)] 
2025-01-24 19:09:22.281387: Epoch time: 48.37 s 
2025-01-24 19:09:23.494556:  
2025-01-24 19:09:23.497124: Epoch 512 
2025-01-24 19:09:23.499327: Current learning rate: 0.00524 
2025-01-24 19:10:12.419063: train_loss -0.8118 
2025-01-24 19:10:12.423801: val_loss -0.6958 
2025-01-24 19:10:12.426452: Pseudo dice [np.float32(0.9325), np.float32(0.8788)] 
2025-01-24 19:10:12.428699: Epoch time: 48.93 s 
2025-01-24 19:10:13.650600:  
2025-01-24 19:10:13.653059: Epoch 513 
2025-01-24 19:10:13.655427: Current learning rate: 0.00523 
2025-01-24 19:11:02.906318: train_loss -0.8185 
2025-01-24 19:11:02.910975: val_loss -0.7652 
2025-01-24 19:11:02.914251: Pseudo dice [np.float32(0.9425), np.float32(0.91)] 
2025-01-24 19:11:02.916492: Epoch time: 49.26 s 
2025-01-24 19:11:04.155716:  
2025-01-24 19:11:04.158492: Epoch 514 
2025-01-24 19:11:04.161584: Current learning rate: 0.00522 
2025-01-24 19:11:52.684612: train_loss -0.8252 
2025-01-24 19:11:52.688672: val_loss -0.7296 
2025-01-24 19:11:52.690737: Pseudo dice [np.float32(0.9372), np.float32(0.8969)] 
2025-01-24 19:11:52.692806: Epoch time: 48.53 s 
2025-01-24 19:11:53.920312:  
2025-01-24 19:11:53.922944: Epoch 515 
2025-01-24 19:11:53.925443: Current learning rate: 0.00521 
2025-01-24 19:12:42.329916: train_loss -0.8053 
2025-01-24 19:12:42.334697: val_loss -0.7574 
2025-01-24 19:12:42.337311: Pseudo dice [np.float32(0.9489), np.float32(0.8514)] 
2025-01-24 19:12:42.340048: Epoch time: 48.41 s 
2025-01-24 19:12:43.564720:  
2025-01-24 19:12:43.567609: Epoch 516 
2025-01-24 19:12:43.570683: Current learning rate: 0.0052 
2025-01-24 19:13:32.413942: train_loss -0.8039 
2025-01-24 19:13:32.418027: val_loss -0.7294 
2025-01-24 19:13:32.420748: Pseudo dice [np.float32(0.9434), np.float32(0.913)] 
2025-01-24 19:13:32.423096: Epoch time: 48.85 s 
2025-01-24 19:13:34.330250:  
2025-01-24 19:13:34.332974: Epoch 517 
2025-01-24 19:13:34.335645: Current learning rate: 0.00519 
2025-01-24 19:14:23.384159: train_loss -0.8063 
2025-01-24 19:14:23.388278: val_loss -0.734 
2025-01-24 19:14:23.390416: Pseudo dice [np.float32(0.9367), np.float32(0.9266)] 
2025-01-24 19:14:23.392893: Epoch time: 49.05 s 
2025-01-24 19:14:24.616718:  
2025-01-24 19:14:24.619584: Epoch 518 
2025-01-24 19:14:24.622581: Current learning rate: 0.00518 
2025-01-24 19:15:13.222252: train_loss -0.8127 
2025-01-24 19:15:13.227368: val_loss -0.7218 
2025-01-24 19:15:13.230092: Pseudo dice [np.float32(0.9464), np.float32(0.9086)] 
2025-01-24 19:15:13.232630: Epoch time: 48.61 s 
2025-01-24 19:15:14.451115:  
2025-01-24 19:15:14.453968: Epoch 519 
2025-01-24 19:15:14.456363: Current learning rate: 0.00518 
2025-01-24 19:16:03.484479: train_loss -0.8088 
2025-01-24 19:16:03.489349: val_loss -0.7713 
2025-01-24 19:16:03.492004: Pseudo dice [np.float32(0.9478), np.float32(0.9174)] 
2025-01-24 19:16:03.494623: Epoch time: 49.03 s 
2025-01-24 19:16:04.715820:  
2025-01-24 19:16:04.718898: Epoch 520 
2025-01-24 19:16:04.721705: Current learning rate: 0.00517 
2025-01-24 19:16:52.974216: train_loss -0.8314 
2025-01-24 19:16:52.978811: val_loss -0.7863 
2025-01-24 19:16:52.981351: Pseudo dice [np.float32(0.9507), np.float32(0.9057)] 
2025-01-24 19:16:52.983897: Epoch time: 48.26 s 
2025-01-24 19:16:54.215611:  
2025-01-24 19:16:54.218279: Epoch 521 
2025-01-24 19:16:54.220712: Current learning rate: 0.00516 
2025-01-24 19:17:42.546629: train_loss -0.8228 
2025-01-24 19:17:42.550828: val_loss -0.7317 
2025-01-24 19:17:42.553625: Pseudo dice [np.float32(0.9564), np.float32(0.8891)] 
2025-01-24 19:17:42.555915: Epoch time: 48.33 s 
2025-01-24 19:17:43.786140:  
2025-01-24 19:17:43.789092: Epoch 522 
2025-01-24 19:17:43.791863: Current learning rate: 0.00515 
2025-01-24 19:18:32.459815: train_loss -0.8273 
2025-01-24 19:18:32.463919: val_loss -0.7835 
2025-01-24 19:18:32.466160: Pseudo dice [np.float32(0.9534), np.float32(0.939)] 
2025-01-24 19:18:32.468603: Epoch time: 48.67 s 
2025-01-24 19:18:33.708482:  
2025-01-24 19:18:33.711177: Epoch 523 
2025-01-24 19:18:33.713890: Current learning rate: 0.00514 
2025-01-24 19:19:22.854714: train_loss -0.84 
2025-01-24 19:19:22.859402: val_loss -0.7596 
2025-01-24 19:19:22.861842: Pseudo dice [np.float32(0.9572), np.float32(0.9252)] 
2025-01-24 19:19:22.864495: Epoch time: 49.15 s 
2025-01-24 19:19:24.092396:  
2025-01-24 19:19:24.095242: Epoch 524 
2025-01-24 19:19:24.098125: Current learning rate: 0.00513 
2025-01-24 19:20:12.276803: train_loss -0.8195 
2025-01-24 19:20:12.280910: val_loss -0.7676 
2025-01-24 19:20:12.283522: Pseudo dice [np.float32(0.9512), np.float32(0.925)] 
2025-01-24 19:20:12.285780: Epoch time: 48.19 s 
2025-01-24 19:20:13.518218:  
2025-01-24 19:20:13.520707: Epoch 525 
2025-01-24 19:20:13.523134: Current learning rate: 0.00512 
2025-01-24 19:21:02.073956: train_loss -0.8225 
2025-01-24 19:21:02.079333: val_loss -0.725 
2025-01-24 19:21:02.081872: Pseudo dice [np.float32(0.9382), np.float32(0.8934)] 
2025-01-24 19:21:02.084605: Epoch time: 48.56 s 
2025-01-24 19:21:03.306455:  
2025-01-24 19:21:03.309384: Epoch 526 
2025-01-24 19:21:03.312152: Current learning rate: 0.00511 
2025-01-24 19:21:52.612407: train_loss -0.8365 
2025-01-24 19:21:52.618429: val_loss -0.7539 
2025-01-24 19:21:52.620819: Pseudo dice [np.float32(0.947), np.float32(0.9179)] 
2025-01-24 19:21:52.622827: Epoch time: 49.31 s 
2025-01-24 19:21:53.819603:  
2025-01-24 19:21:53.822310: Epoch 527 
2025-01-24 19:21:53.825050: Current learning rate: 0.0051 
2025-01-24 19:22:42.435149: train_loss -0.8282 
2025-01-24 19:22:42.439898: val_loss -0.7307 
2025-01-24 19:22:42.442538: Pseudo dice [np.float32(0.9413), np.float32(0.9024)] 
2025-01-24 19:22:42.445107: Epoch time: 48.62 s 
2025-01-24 19:22:43.684902:  
2025-01-24 19:22:43.688108: Epoch 528 
2025-01-24 19:22:43.690764: Current learning rate: 0.00509 
2025-01-24 19:23:31.886900: train_loss -0.8076 
2025-01-24 19:23:31.891961: val_loss -0.7311 
2025-01-24 19:23:31.894267: Pseudo dice [np.float32(0.9442), np.float32(0.8983)] 
2025-01-24 19:23:31.896541: Epoch time: 48.2 s 
2025-01-24 19:23:33.126853:  
2025-01-24 19:23:33.129670: Epoch 529 
2025-01-24 19:23:33.132845: Current learning rate: 0.00508 
2025-01-24 19:24:21.418224: train_loss -0.8041 
2025-01-24 19:24:21.422362: val_loss -0.7416 
2025-01-24 19:24:21.424812: Pseudo dice [np.float32(0.9475), np.float32(0.9182)] 
2025-01-24 19:24:21.427086: Epoch time: 48.29 s 
2025-01-24 19:24:22.649438:  
2025-01-24 19:24:22.652585: Epoch 530 
2025-01-24 19:24:22.655221: Current learning rate: 0.00507 
2025-01-24 19:25:11.322282: train_loss -0.8482 
2025-01-24 19:25:11.327652: val_loss -0.7751 
2025-01-24 19:25:11.330241: Pseudo dice [np.float32(0.9422), np.float32(0.8928)] 
2025-01-24 19:25:11.332937: Epoch time: 48.67 s 
2025-01-24 19:25:12.556054:  
2025-01-24 19:25:12.559260: Epoch 531 
2025-01-24 19:25:12.562353: Current learning rate: 0.00506 
2025-01-24 19:26:01.013997: train_loss -0.8396 
2025-01-24 19:26:01.020565: val_loss -0.716 
2025-01-24 19:26:01.023166: Pseudo dice [np.float32(0.9495), np.float32(0.8704)] 
2025-01-24 19:26:01.025873: Epoch time: 48.46 s 
2025-01-24 19:26:02.245945:  
2025-01-24 19:26:02.248730: Epoch 532 
2025-01-24 19:26:02.251244: Current learning rate: 0.00505 
2025-01-24 19:26:51.151256: train_loss -0.8346 
2025-01-24 19:26:51.156013: val_loss -0.7606 
2025-01-24 19:26:51.158980: Pseudo dice [np.float32(0.9467), np.float32(0.9374)] 
2025-01-24 19:26:51.161418: Epoch time: 48.91 s 
2025-01-24 19:26:52.395300:  
2025-01-24 19:26:52.398912: Epoch 533 
2025-01-24 19:26:52.401321: Current learning rate: 0.00504 
2025-01-24 19:27:40.927267: train_loss -0.8376 
2025-01-24 19:27:40.934268: val_loss -0.7162 
2025-01-24 19:27:40.937166: Pseudo dice [np.float32(0.9525), np.float32(0.9324)] 
2025-01-24 19:27:40.939758: Epoch time: 48.53 s 
2025-01-24 19:27:42.203493:  
2025-01-24 19:27:42.205892: Epoch 534 
2025-01-24 19:27:42.208228: Current learning rate: 0.00503 
2025-01-24 19:28:31.026757: train_loss -0.8276 
2025-01-24 19:28:31.031093: val_loss -0.7972 
2025-01-24 19:28:31.034043: Pseudo dice [np.float32(0.9558), np.float32(0.921)] 
2025-01-24 19:28:31.036608: Epoch time: 48.82 s 
2025-01-24 19:28:31.040239: Yayy! New best EMA pseudo Dice: 0.9271000027656555 
2025-01-24 19:28:32.887213:  
2025-01-24 19:28:32.889656: Epoch 535 
2025-01-24 19:28:32.892341: Current learning rate: 0.00502 
2025-01-24 19:29:21.166352: train_loss -0.8298 
2025-01-24 19:29:21.173300: val_loss -0.782 
2025-01-24 19:29:21.175603: Pseudo dice [np.float32(0.957), np.float32(0.926)] 
2025-01-24 19:29:21.177791: Epoch time: 48.28 s 
2025-01-24 19:29:21.179977: Yayy! New best EMA pseudo Dice: 0.928600013256073 
2025-01-24 19:29:23.618766:  
2025-01-24 19:29:23.621508: Epoch 536 
2025-01-24 19:29:23.623996: Current learning rate: 0.00501 
2025-01-24 19:30:12.404013: train_loss -0.8342 
2025-01-24 19:30:12.408800: val_loss -0.7419 
2025-01-24 19:30:12.411516: Pseudo dice [np.float32(0.9513), np.float32(0.873)] 
2025-01-24 19:30:12.414141: Epoch time: 48.79 s 
2025-01-24 19:30:13.637951:  
2025-01-24 19:30:13.641071: Epoch 537 
2025-01-24 19:30:13.643622: Current learning rate: 0.005 
2025-01-24 19:31:02.426939: train_loss -0.8424 
2025-01-24 19:31:02.431779: val_loss -0.7379 
2025-01-24 19:31:02.434676: Pseudo dice [np.float32(0.943), np.float32(0.8623)] 
2025-01-24 19:31:02.437158: Epoch time: 48.79 s 
2025-01-24 19:31:03.656649:  
2025-01-24 19:31:03.659638: Epoch 538 
2025-01-24 19:31:03.662509: Current learning rate: 0.00499 
2025-01-24 19:31:52.634606: train_loss -0.8279 
2025-01-24 19:31:52.638935: val_loss -0.795 
2025-01-24 19:31:52.641168: Pseudo dice [np.float32(0.9503), np.float32(0.9031)] 
2025-01-24 19:31:52.643370: Epoch time: 48.98 s 
2025-01-24 19:31:53.867297:  
2025-01-24 19:31:53.870306: Epoch 539 
2025-01-24 19:31:53.872777: Current learning rate: 0.00498 
2025-01-24 19:32:43.129030: train_loss -0.8244 
2025-01-24 19:32:43.133676: val_loss -0.7486 
2025-01-24 19:32:43.136370: Pseudo dice [np.float32(0.9509), np.float32(0.8929)] 
2025-01-24 19:32:43.138815: Epoch time: 49.26 s 
2025-01-24 19:32:44.361935:  
2025-01-24 19:32:44.364757: Epoch 540 
2025-01-24 19:32:44.367580: Current learning rate: 0.00497 
2025-01-24 19:33:32.993155: train_loss -0.8192 
2025-01-24 19:33:32.998779: val_loss -0.7303 
2025-01-24 19:33:33.001922: Pseudo dice [np.float32(0.9491), np.float32(0.9036)] 
2025-01-24 19:33:33.004573: Epoch time: 48.63 s 
2025-01-24 19:33:34.199596:  
2025-01-24 19:33:34.203072: Epoch 541 
2025-01-24 19:33:34.205966: Current learning rate: 0.00496 
2025-01-24 19:34:22.932115: train_loss -0.8325 
2025-01-24 19:34:22.937279: val_loss -0.7091 
2025-01-24 19:34:22.939986: Pseudo dice [np.float32(0.9096), np.float32(0.8602)] 
2025-01-24 19:34:22.942764: Epoch time: 48.73 s 
2025-01-24 19:34:24.158502:  
2025-01-24 19:34:24.162134: Epoch 542 
2025-01-24 19:34:24.165336: Current learning rate: 0.00495 
2025-01-24 19:35:12.409646: train_loss -0.8189 
2025-01-24 19:35:12.414329: val_loss -0.7742 
2025-01-24 19:35:12.416672: Pseudo dice [np.float32(0.9459), np.float32(0.9205)] 
2025-01-24 19:35:12.418900: Epoch time: 48.25 s 
2025-01-24 19:35:13.601499:  
2025-01-24 19:35:13.603987: Epoch 543 
2025-01-24 19:35:13.606408: Current learning rate: 0.00494 
2025-01-24 19:36:02.354607: train_loss -0.8086 
2025-01-24 19:36:02.361369: val_loss -0.7597 
2025-01-24 19:36:02.364033: Pseudo dice [np.float32(0.9575), np.float32(0.8334)] 
2025-01-24 19:36:02.366394: Epoch time: 48.75 s 
2025-01-24 19:36:03.543825:  
2025-01-24 19:36:03.546524: Epoch 544 
2025-01-24 19:36:03.549115: Current learning rate: 0.00493 
2025-01-24 19:36:52.307149: train_loss -0.8035 
2025-01-24 19:36:52.312304: val_loss -0.716 
2025-01-24 19:36:52.314593: Pseudo dice [np.float32(0.927), np.float32(0.8786)] 
2025-01-24 19:36:52.317057: Epoch time: 48.76 s 
2025-01-24 19:36:53.528543:  
2025-01-24 19:36:53.531364: Epoch 545 
2025-01-24 19:36:53.534406: Current learning rate: 0.00492 
2025-01-24 19:37:42.362592: train_loss -0.824 
2025-01-24 19:37:42.367234: val_loss -0.8068 
2025-01-24 19:37:42.369711: Pseudo dice [np.float32(0.9469), np.float32(0.9384)] 
2025-01-24 19:37:42.372236: Epoch time: 48.83 s 
2025-01-24 19:37:43.584040:  
2025-01-24 19:37:43.586813: Epoch 546 
2025-01-24 19:37:43.589501: Current learning rate: 0.00491 
2025-01-24 19:38:32.238956: train_loss -0.8309 
2025-01-24 19:38:32.246356: val_loss -0.7434 
2025-01-24 19:38:32.249180: Pseudo dice [np.float32(0.95), np.float32(0.8813)] 
2025-01-24 19:38:32.251762: Epoch time: 48.66 s 
2025-01-24 19:38:33.436513:  
2025-01-24 19:38:33.439079: Epoch 547 
2025-01-24 19:38:33.441483: Current learning rate: 0.0049 
2025-01-24 19:39:21.738297: train_loss -0.8333 
2025-01-24 19:39:21.744402: val_loss -0.718 
2025-01-24 19:39:21.746755: Pseudo dice [np.float32(0.9447), np.float32(0.9004)] 
2025-01-24 19:39:21.749491: Epoch time: 48.3 s 
2025-01-24 19:39:22.927037:  
2025-01-24 19:39:22.929847: Epoch 548 
2025-01-24 19:39:22.932445: Current learning rate: 0.00489 
2025-01-24 19:40:12.060981: train_loss -0.8267 
2025-01-24 19:40:12.066593: val_loss -0.7285 
2025-01-24 19:40:12.069588: Pseudo dice [np.float32(0.9398), np.float32(0.9031)] 
2025-01-24 19:40:12.072161: Epoch time: 49.13 s 
2025-01-24 19:40:13.254734:  
2025-01-24 19:40:13.258170: Epoch 549 
2025-01-24 19:40:13.261194: Current learning rate: 0.00488 
2025-01-24 19:41:01.998507: train_loss -0.8281 
2025-01-24 19:41:02.005538: val_loss -0.73 
2025-01-24 19:41:02.008159: Pseudo dice [np.float32(0.9414), np.float32(0.7961)] 
2025-01-24 19:41:02.010860: Epoch time: 48.74 s 
2025-01-24 19:41:03.779235:  
2025-01-24 19:41:03.782149: Epoch 550 
2025-01-24 19:41:03.785285: Current learning rate: 0.00487 
2025-01-24 19:41:51.858984: train_loss -0.8145 
2025-01-24 19:41:51.865706: val_loss -0.726 
2025-01-24 19:41:51.868226: Pseudo dice [np.float32(0.9501), np.float32(0.8664)] 
2025-01-24 19:41:51.870722: Epoch time: 48.08 s 
2025-01-24 19:41:53.101679:  
2025-01-24 19:41:53.104523: Epoch 551 
2025-01-24 19:41:53.107121: Current learning rate: 0.00486 
2025-01-24 19:42:42.153794: train_loss -0.8302 
2025-01-24 19:42:42.159668: val_loss -0.7844 
2025-01-24 19:42:42.162656: Pseudo dice [np.float32(0.9454), np.float32(0.9237)] 
2025-01-24 19:42:42.165202: Epoch time: 49.05 s 
2025-01-24 19:42:43.404140:  
2025-01-24 19:42:43.407479: Epoch 552 
2025-01-24 19:42:43.410398: Current learning rate: 0.00485 
2025-01-24 19:43:31.823279: train_loss -0.8175 
2025-01-24 19:43:31.830479: val_loss -0.7318 
2025-01-24 19:43:31.833122: Pseudo dice [np.float32(0.9483), np.float32(0.8201)] 
2025-01-24 19:43:31.835485: Epoch time: 48.42 s 
2025-01-24 19:43:33.064497:  
2025-01-24 19:43:33.067353: Epoch 553 
2025-01-24 19:43:33.069734: Current learning rate: 0.00484 
2025-01-24 19:44:21.642702: train_loss -0.8289 
2025-01-24 19:44:21.647329: val_loss -0.7284 
2025-01-24 19:44:21.649832: Pseudo dice [np.float32(0.9345), np.float32(0.8593)] 
2025-01-24 19:44:21.652182: Epoch time: 48.58 s 
2025-01-24 19:44:22.876988:  
2025-01-24 19:44:22.879843: Epoch 554 
2025-01-24 19:44:22.882644: Current learning rate: 0.00484 
2025-01-24 19:45:11.233276: train_loss -0.8312 
2025-01-24 19:45:11.240161: val_loss -0.778 
2025-01-24 19:45:11.242942: Pseudo dice [np.float32(0.9549), np.float32(0.8889)] 
2025-01-24 19:45:11.245803: Epoch time: 48.36 s 
2025-01-24 19:45:13.227856:  
2025-01-24 19:45:13.231429: Epoch 555 
2025-01-24 19:45:13.234165: Current learning rate: 0.00483 
2025-01-24 19:46:01.832469: train_loss -0.8224 
2025-01-24 19:46:01.838696: val_loss -0.7306 
2025-01-24 19:46:01.841106: Pseudo dice [np.float32(0.9577), np.float32(0.8776)] 
2025-01-24 19:46:01.843571: Epoch time: 48.61 s 
2025-01-24 19:46:03.112839:  
2025-01-24 19:46:03.115819: Epoch 556 
2025-01-24 19:46:03.118232: Current learning rate: 0.00482 
2025-01-24 19:46:51.593850: train_loss -0.8342 
2025-01-24 19:46:51.598295: val_loss -0.7655 
2025-01-24 19:46:51.600518: Pseudo dice [np.float32(0.9418), np.float32(0.9308)] 
2025-01-24 19:46:51.602831: Epoch time: 48.48 s 
2025-01-24 19:46:52.817832:  
2025-01-24 19:46:52.820996: Epoch 557 
2025-01-24 19:46:52.823669: Current learning rate: 0.00481 
2025-01-24 19:47:41.554466: train_loss -0.8209 
2025-01-24 19:47:41.561803: val_loss -0.7522 
2025-01-24 19:47:41.564862: Pseudo dice [np.float32(0.9562), np.float32(0.8991)] 
2025-01-24 19:47:41.567640: Epoch time: 48.74 s 
2025-01-24 19:47:42.761429:  
2025-01-24 19:47:42.764413: Epoch 558 
2025-01-24 19:47:42.767606: Current learning rate: 0.0048 
2025-01-24 19:48:31.335291: train_loss -0.8194 
2025-01-24 19:48:31.342190: val_loss -0.7612 
2025-01-24 19:48:31.345386: Pseudo dice [np.float32(0.9379), np.float32(0.8823)] 
2025-01-24 19:48:31.347928: Epoch time: 48.57 s 
2025-01-24 19:48:32.534898:  
2025-01-24 19:48:32.538002: Epoch 559 
2025-01-24 19:48:32.540916: Current learning rate: 0.00479 
2025-01-24 19:49:21.501232: train_loss -0.8034 
2025-01-24 19:49:21.507862: val_loss -0.7364 
2025-01-24 19:49:21.510380: Pseudo dice [np.float32(0.9379), np.float32(0.8926)] 
2025-01-24 19:49:21.512985: Epoch time: 48.97 s 
2025-01-24 19:49:22.699083:  
2025-01-24 19:49:22.701513: Epoch 560 
2025-01-24 19:49:22.703910: Current learning rate: 0.00478 
2025-01-24 19:50:11.162558: train_loss -0.8368 
2025-01-24 19:50:11.169467: val_loss -0.7744 
2025-01-24 19:50:11.172193: Pseudo dice [np.float32(0.9469), np.float32(0.9114)] 
2025-01-24 19:50:11.174903: Epoch time: 48.46 s 
2025-01-24 19:50:12.364518:  
2025-01-24 19:50:12.367931: Epoch 561 
2025-01-24 19:50:12.370877: Current learning rate: 0.00477 
2025-01-24 19:51:00.934136: train_loss -0.8043 
2025-01-24 19:51:00.941700: val_loss -0.8144 
2025-01-24 19:51:00.944407: Pseudo dice [np.float32(0.9501), np.float32(0.9176)] 
2025-01-24 19:51:00.947005: Epoch time: 48.57 s 
2025-01-24 19:51:02.134418:  
2025-01-24 19:51:02.137298: Epoch 562 
2025-01-24 19:51:02.140150: Current learning rate: 0.00476 
2025-01-24 19:51:51.020977: train_loss -0.8066 
2025-01-24 19:51:51.027855: val_loss -0.7269 
2025-01-24 19:51:51.030768: Pseudo dice [np.float32(0.9491), np.float32(0.8912)] 
2025-01-24 19:51:51.034572: Epoch time: 48.89 s 
2025-01-24 19:51:52.226297:  
2025-01-24 19:51:52.229484: Epoch 563 
2025-01-24 19:51:52.232648: Current learning rate: 0.00475 
2025-01-24 19:52:41.135441: train_loss -0.8019 
2025-01-24 19:52:41.141697: val_loss -0.7527 
2025-01-24 19:52:41.143935: Pseudo dice [np.float32(0.9411), np.float32(0.8423)] 
2025-01-24 19:52:41.146172: Epoch time: 48.91 s 
2025-01-24 19:52:42.327346:  
2025-01-24 19:52:42.329629: Epoch 564 
2025-01-24 19:52:42.331921: Current learning rate: 0.00474 
2025-01-24 19:53:30.905071: train_loss -0.8165 
2025-01-24 19:53:30.912182: val_loss -0.7484 
2025-01-24 19:53:30.915132: Pseudo dice [np.float32(0.9329), np.float32(0.8923)] 
2025-01-24 19:53:30.917983: Epoch time: 48.58 s 
2025-01-24 19:53:32.136172:  
2025-01-24 19:53:32.139112: Epoch 565 
2025-01-24 19:53:32.141772: Current learning rate: 0.00473 
2025-01-24 19:54:20.892542: train_loss -0.8027 
2025-01-24 19:54:20.899418: val_loss -0.748 
2025-01-24 19:54:20.902482: Pseudo dice [np.float32(0.9435), np.float32(0.9324)] 
2025-01-24 19:54:20.905468: Epoch time: 48.76 s 
2025-01-24 19:54:22.090758:  
2025-01-24 19:54:22.094327: Epoch 566 
2025-01-24 19:54:22.099016: Current learning rate: 0.00472 
2025-01-24 19:55:10.758388: train_loss -0.8235 
2025-01-24 19:55:10.766929: val_loss -0.8013 
2025-01-24 19:55:10.769821: Pseudo dice [np.float32(0.9546), np.float32(0.9133)] 
2025-01-24 19:55:10.772735: Epoch time: 48.67 s 
2025-01-24 19:55:11.956048:  
2025-01-24 19:55:11.959128: Epoch 567 
2025-01-24 19:55:11.961692: Current learning rate: 0.00471 
2025-01-24 19:56:00.959660: train_loss -0.8126 
2025-01-24 19:56:00.965694: val_loss -0.7375 
2025-01-24 19:56:00.968338: Pseudo dice [np.float32(0.9334), np.float32(0.9165)] 
2025-01-24 19:56:00.970697: Epoch time: 49.0 s 
2025-01-24 19:56:02.157093:  
2025-01-24 19:56:02.159550: Epoch 568 
2025-01-24 19:56:02.161913: Current learning rate: 0.0047 
2025-01-24 19:56:50.899847: train_loss -0.8352 
2025-01-24 19:56:50.906157: val_loss -0.8046 
2025-01-24 19:56:50.908710: Pseudo dice [np.float32(0.9515), np.float32(0.9292)] 
2025-01-24 19:56:50.911341: Epoch time: 48.74 s 
2025-01-24 19:56:52.089710:  
2025-01-24 19:56:52.092497: Epoch 569 
2025-01-24 19:56:52.095112: Current learning rate: 0.00469 
2025-01-24 19:57:40.864841: train_loss -0.8276 
2025-01-24 19:57:40.872213: val_loss -0.7506 
2025-01-24 19:57:40.874765: Pseudo dice [np.float32(0.937), np.float32(0.8748)] 
2025-01-24 19:57:40.877562: Epoch time: 48.78 s 
2025-01-24 19:57:42.066685:  
2025-01-24 19:57:42.069518: Epoch 570 
2025-01-24 19:57:42.072293: Current learning rate: 0.00468 
2025-01-24 19:58:31.453401: train_loss -0.8282 
2025-01-24 19:58:31.459821: val_loss -0.7019 
2025-01-24 19:58:31.462364: Pseudo dice [np.float32(0.9436), np.float32(0.8898)] 
2025-01-24 19:58:31.464955: Epoch time: 49.39 s 
2025-01-24 19:58:32.670187:  
2025-01-24 19:58:32.673057: Epoch 571 
2025-01-24 19:58:32.675702: Current learning rate: 0.00467 
2025-01-24 19:59:21.169649: train_loss -0.8272 
2025-01-24 19:59:21.175813: val_loss -0.7288 
2025-01-24 19:59:21.178596: Pseudo dice [np.float32(0.9342), np.float32(0.8921)] 
2025-01-24 19:59:21.180955: Epoch time: 48.5 s 
2025-01-24 19:59:22.363316:  
2025-01-24 19:59:22.366456: Epoch 572 
2025-01-24 19:59:22.369165: Current learning rate: 0.00466 
2025-01-24 20:00:11.486399: train_loss -0.8455 
2025-01-24 20:00:11.491577: val_loss -0.7169 
2025-01-24 20:00:11.494180: Pseudo dice [np.float32(0.9378), np.float32(0.8266)] 
2025-01-24 20:00:11.497157: Epoch time: 49.12 s 
2025-01-24 20:00:12.702332:  
2025-01-24 20:00:12.705633: Epoch 573 
2025-01-24 20:00:12.708606: Current learning rate: 0.00465 
2025-01-24 20:01:01.438953: train_loss -0.839 
2025-01-24 20:01:01.446329: val_loss -0.7387 
2025-01-24 20:01:01.449284: Pseudo dice [np.float32(0.952), np.float32(0.9208)] 
2025-01-24 20:01:01.452260: Epoch time: 48.74 s 
2025-01-24 20:01:03.254988:  
2025-01-24 20:01:03.258400: Epoch 574 
2025-01-24 20:01:03.261360: Current learning rate: 0.00464 
2025-01-24 20:01:52.222289: train_loss -0.8219 
2025-01-24 20:01:52.228553: val_loss -0.7996 
2025-01-24 20:01:52.231341: Pseudo dice [np.float32(0.9469), np.float32(0.9274)] 
2025-01-24 20:01:52.233834: Epoch time: 48.97 s 
2025-01-24 20:01:53.444407:  
2025-01-24 20:01:53.447886: Epoch 575 
2025-01-24 20:01:53.450693: Current learning rate: 0.00463 
2025-01-24 20:02:42.382077: train_loss -0.8392 
2025-01-24 20:02:42.388366: val_loss -0.7961 
2025-01-24 20:02:42.390852: Pseudo dice [np.float32(0.9519), np.float32(0.9288)] 
2025-01-24 20:02:42.393505: Epoch time: 48.94 s 
2025-01-24 20:02:43.635505:  
2025-01-24 20:02:43.638564: Epoch 576 
2025-01-24 20:02:43.641467: Current learning rate: 0.00462 
2025-01-24 20:03:32.503803: train_loss -0.8216 
2025-01-24 20:03:32.510084: val_loss -0.7697 
2025-01-24 20:03:32.512799: Pseudo dice [np.float32(0.9567), np.float32(0.9309)] 
2025-01-24 20:03:32.515523: Epoch time: 48.87 s 
2025-01-24 20:03:33.711024:  
2025-01-24 20:03:33.714115: Epoch 577 
2025-01-24 20:03:33.716794: Current learning rate: 0.00461 
2025-01-24 20:04:22.158278: train_loss -0.8295 
2025-01-24 20:04:22.165114: val_loss -0.7596 
2025-01-24 20:04:22.167599: Pseudo dice [np.float32(0.9541), np.float32(0.9361)] 
2025-01-24 20:04:22.170062: Epoch time: 48.45 s 
2025-01-24 20:04:23.370733:  
2025-01-24 20:04:23.373470: Epoch 578 
2025-01-24 20:04:23.375992: Current learning rate: 0.0046 
2025-01-24 20:05:12.119151: train_loss -0.8184 
2025-01-24 20:05:12.123642: val_loss -0.7496 
2025-01-24 20:05:12.126165: Pseudo dice [np.float32(0.9491), np.float32(0.9229)] 
2025-01-24 20:05:12.128618: Epoch time: 48.75 s 
2025-01-24 20:05:13.331306:  
2025-01-24 20:05:13.334569: Epoch 579 
2025-01-24 20:05:13.337286: Current learning rate: 0.00459 
2025-01-24 20:06:01.735820: train_loss -0.8206 
2025-01-24 20:06:01.742570: val_loss -0.7086 
2025-01-24 20:06:01.745050: Pseudo dice [np.float32(0.9425), np.float32(0.8591)] 
2025-01-24 20:06:01.748137: Epoch time: 48.41 s 
2025-01-24 20:06:02.954101:  
2025-01-24 20:06:02.956871: Epoch 580 
2025-01-24 20:06:02.959461: Current learning rate: 0.00458 
2025-01-24 20:06:51.429547: train_loss -0.825 
2025-01-24 20:06:51.434378: val_loss -0.7375 
2025-01-24 20:06:51.436885: Pseudo dice [np.float32(0.9364), np.float32(0.8855)] 
2025-01-24 20:06:51.439119: Epoch time: 48.48 s 
2025-01-24 20:06:52.642773:  
2025-01-24 20:06:52.646244: Epoch 581 
2025-01-24 20:06:52.649253: Current learning rate: 0.00457 
2025-01-24 20:07:41.015145: train_loss -0.8441 
2025-01-24 20:07:41.019514: val_loss -0.711 
2025-01-24 20:07:41.021840: Pseudo dice [np.float32(0.9542), np.float32(0.7991)] 
2025-01-24 20:07:41.024148: Epoch time: 48.37 s 
2025-01-24 20:07:42.250902:  
2025-01-24 20:07:42.253383: Epoch 582 
2025-01-24 20:07:42.255795: Current learning rate: 0.00456 
2025-01-24 20:08:30.731220: train_loss -0.83 
2025-01-24 20:08:30.735986: val_loss -0.7364 
2025-01-24 20:08:30.738420: Pseudo dice [np.float32(0.9443), np.float32(0.8515)] 
2025-01-24 20:08:30.740621: Epoch time: 48.48 s 
2025-01-24 20:08:31.946845:  
2025-01-24 20:08:31.949841: Epoch 583 
2025-01-24 20:08:31.952954: Current learning rate: 0.00455 
2025-01-24 20:09:20.359384: train_loss -0.8202 
2025-01-24 20:09:20.365469: val_loss -0.7607 
2025-01-24 20:09:20.367901: Pseudo dice [np.float32(0.9413), np.float32(0.8987)] 
2025-01-24 20:09:20.370409: Epoch time: 48.41 s 
2025-01-24 20:09:21.562970:  
2025-01-24 20:09:21.565519: Epoch 584 
2025-01-24 20:09:21.568025: Current learning rate: 0.00454 
2025-01-24 20:10:10.436575: train_loss -0.8058 
2025-01-24 20:10:10.441365: val_loss -0.7703 
2025-01-24 20:10:10.443857: Pseudo dice [np.float32(0.95), np.float32(0.9039)] 
2025-01-24 20:10:10.446488: Epoch time: 48.87 s 
2025-01-24 20:10:11.644174:  
2025-01-24 20:10:11.646918: Epoch 585 
2025-01-24 20:10:11.649529: Current learning rate: 0.00453 
2025-01-24 20:11:00.195822: train_loss -0.8199 
2025-01-24 20:11:00.200472: val_loss -0.7341 
2025-01-24 20:11:00.203097: Pseudo dice [np.float32(0.9493), np.float32(0.9091)] 
2025-01-24 20:11:00.205812: Epoch time: 48.55 s 
2025-01-24 20:11:01.406878:  
2025-01-24 20:11:01.409934: Epoch 586 
2025-01-24 20:11:01.412513: Current learning rate: 0.00452 
2025-01-24 20:11:50.345260: train_loss -0.8347 
2025-01-24 20:11:50.349705: val_loss -0.7349 
2025-01-24 20:11:50.352206: Pseudo dice [np.float32(0.9482), np.float32(0.9173)] 
2025-01-24 20:11:50.354791: Epoch time: 48.94 s 
2025-01-24 20:11:51.559083:  
2025-01-24 20:11:51.563025: Epoch 587 
2025-01-24 20:11:51.565828: Current learning rate: 0.00451 
2025-01-24 20:12:40.224295: train_loss -0.8199 
2025-01-24 20:12:40.229832: val_loss -0.7604 
2025-01-24 20:12:40.232932: Pseudo dice [np.float32(0.95), np.float32(0.9143)] 
2025-01-24 20:12:40.235981: Epoch time: 48.67 s 
2025-01-24 20:12:41.445663:  
2025-01-24 20:12:41.448270: Epoch 588 
2025-01-24 20:12:41.450601: Current learning rate: 0.0045 
2025-01-24 20:13:30.316234: train_loss -0.8226 
2025-01-24 20:13:30.321600: val_loss -0.7604 
2025-01-24 20:13:30.324628: Pseudo dice [np.float32(0.9525), np.float32(0.8866)] 
2025-01-24 20:13:30.327629: Epoch time: 48.87 s 
2025-01-24 20:13:31.556299:  
2025-01-24 20:13:31.559034: Epoch 589 
2025-01-24 20:13:31.561822: Current learning rate: 0.00449 
2025-01-24 20:14:20.339676: train_loss -0.8184 
2025-01-24 20:14:20.345983: val_loss -0.6071 
2025-01-24 20:14:20.348533: Pseudo dice [np.float32(0.8402), np.float32(0.5746)] 
2025-01-24 20:14:20.351164: Epoch time: 48.78 s 
2025-01-24 20:14:21.553726:  
2025-01-24 20:14:21.556568: Epoch 590 
2025-01-24 20:14:21.559194: Current learning rate: 0.00448 
2025-01-24 20:15:10.215533: train_loss -0.8002 
2025-01-24 20:15:10.220958: val_loss -0.7548 
2025-01-24 20:15:10.223614: Pseudo dice [np.float32(0.9513), np.float32(0.9076)] 
2025-01-24 20:15:10.226319: Epoch time: 48.66 s 
2025-01-24 20:15:11.436582:  
2025-01-24 20:15:11.439560: Epoch 591 
2025-01-24 20:15:11.442212: Current learning rate: 0.00447 
2025-01-24 20:16:00.452418: train_loss -0.8046 
2025-01-24 20:16:00.457620: val_loss -0.7188 
2025-01-24 20:16:00.460472: Pseudo dice [np.float32(0.9308), np.float32(0.8882)] 
2025-01-24 20:16:00.463174: Epoch time: 49.02 s 
2025-01-24 20:16:02.445562:  
2025-01-24 20:16:02.448767: Epoch 592 
2025-01-24 20:16:02.451533: Current learning rate: 0.00446 
2025-01-24 20:16:51.258911: train_loss -0.8131 
2025-01-24 20:16:51.263756: val_loss -0.7783 
2025-01-24 20:16:51.266440: Pseudo dice [np.float32(0.9419), np.float32(0.8409)] 
2025-01-24 20:16:51.269054: Epoch time: 48.81 s 
2025-01-24 20:16:52.466282:  
2025-01-24 20:16:52.469041: Epoch 593 
2025-01-24 20:16:52.471656: Current learning rate: 0.00445 
2025-01-24 20:17:41.264287: train_loss -0.8068 
2025-01-24 20:17:41.269307: val_loss -0.6917 
2025-01-24 20:17:41.272140: Pseudo dice [np.float32(0.9176), np.float32(0.6863)] 
2025-01-24 20:17:41.274821: Epoch time: 48.8 s 
2025-01-24 20:17:42.471336:  
2025-01-24 20:17:42.474375: Epoch 594 
2025-01-24 20:17:42.477312: Current learning rate: 0.00444 
2025-01-24 20:18:31.226593: train_loss -0.7954 
2025-01-24 20:18:31.232364: val_loss -0.7934 
2025-01-24 20:18:31.234910: Pseudo dice [np.float32(0.9412), np.float32(0.9036)] 
2025-01-24 20:18:31.237564: Epoch time: 48.76 s 
2025-01-24 20:18:32.444062:  
2025-01-24 20:18:32.446701: Epoch 595 
2025-01-24 20:18:32.449246: Current learning rate: 0.00443 
2025-01-24 20:19:20.786514: train_loss -0.8319 
2025-01-24 20:19:20.791523: val_loss -0.7407 
2025-01-24 20:19:20.794098: Pseudo dice [np.float32(0.9476), np.float32(0.8584)] 
2025-01-24 20:19:20.796460: Epoch time: 48.34 s 
2025-01-24 20:19:22.038579:  
2025-01-24 20:19:22.041588: Epoch 596 
2025-01-24 20:19:22.044335: Current learning rate: 0.00442 
2025-01-24 20:20:10.539882: train_loss -0.8356 
2025-01-24 20:20:10.545259: val_loss -0.7186 
2025-01-24 20:20:10.547825: Pseudo dice [np.float32(0.9511), np.float32(0.9277)] 
2025-01-24 20:20:10.550104: Epoch time: 48.5 s 
2025-01-24 20:20:11.742271:  
2025-01-24 20:20:11.745185: Epoch 597 
2025-01-24 20:20:11.747989: Current learning rate: 0.00441 
2025-01-24 20:21:00.332952: train_loss -0.8221 
2025-01-24 20:21:00.338705: val_loss -0.7674 
2025-01-24 20:21:00.341673: Pseudo dice [np.float32(0.9398), np.float32(0.895)] 
2025-01-24 20:21:00.344335: Epoch time: 48.59 s 
2025-01-24 20:21:01.542332:  
2025-01-24 20:21:01.544867: Epoch 598 
2025-01-24 20:21:01.547094: Current learning rate: 0.0044 
2025-01-24 20:21:50.486078: train_loss -0.8226 
2025-01-24 20:21:50.491846: val_loss -0.7978 
2025-01-24 20:21:50.494404: Pseudo dice [np.float32(0.9478), np.float32(0.8964)] 
2025-01-24 20:21:50.496896: Epoch time: 48.94 s 
2025-01-24 20:21:51.731104:  
2025-01-24 20:21:51.734376: Epoch 599 
2025-01-24 20:21:51.736998: Current learning rate: 0.00439 
2025-01-24 20:22:40.221359: train_loss -0.8166 
2025-01-24 20:22:40.226634: val_loss -0.7606 
2025-01-24 20:22:40.229064: Pseudo dice [np.float32(0.9395), np.float32(0.876)] 
2025-01-24 20:22:40.231585: Epoch time: 48.49 s 
2025-01-24 20:22:42.026387:  
2025-01-24 20:22:42.029243: Epoch 600 
2025-01-24 20:22:42.031870: Current learning rate: 0.00438 
2025-01-24 20:23:30.697587: train_loss -0.8264 
2025-01-24 20:23:30.702143: val_loss -0.7581 
2025-01-24 20:23:30.704781: Pseudo dice [np.float32(0.9492), np.float32(0.9074)] 
2025-01-24 20:23:30.707103: Epoch time: 48.67 s 
2025-01-24 20:23:31.902373:  
2025-01-24 20:23:31.905160: Epoch 601 
2025-01-24 20:23:31.907459: Current learning rate: 0.00437 
2025-01-24 20:24:20.202555: train_loss -0.8316 
2025-01-24 20:24:20.207884: val_loss -0.7632 
2025-01-24 20:24:20.210855: Pseudo dice [np.float32(0.9456), np.float32(0.9312)] 
2025-01-24 20:24:20.213310: Epoch time: 48.3 s 
2025-01-24 20:24:21.417837:  
2025-01-24 20:24:21.420740: Epoch 602 
2025-01-24 20:24:21.423359: Current learning rate: 0.00436 
2025-01-24 20:25:10.071338: train_loss -0.8252 
2025-01-24 20:25:10.077405: val_loss -0.7574 
2025-01-24 20:25:10.079765: Pseudo dice [np.float32(0.9405), np.float32(0.8942)] 
2025-01-24 20:25:10.082089: Epoch time: 48.65 s 
2025-01-24 20:25:11.314200:  
2025-01-24 20:25:11.317099: Epoch 603 
2025-01-24 20:25:11.319322: Current learning rate: 0.00435 
2025-01-24 20:26:00.311426: train_loss -0.8239 
2025-01-24 20:26:00.316358: val_loss -0.7606 
2025-01-24 20:26:00.319237: Pseudo dice [np.float32(0.9549), np.float32(0.9114)] 
2025-01-24 20:26:00.321725: Epoch time: 49.0 s 
2025-01-24 20:26:01.523086:  
2025-01-24 20:26:01.526112: Epoch 604 
2025-01-24 20:26:01.529003: Current learning rate: 0.00434 
2025-01-24 20:26:50.142586: train_loss -0.8227 
2025-01-24 20:26:50.149741: val_loss -0.7279 
2025-01-24 20:26:50.152524: Pseudo dice [np.float32(0.9442), np.float32(0.8816)] 
2025-01-24 20:26:50.155064: Epoch time: 48.62 s 
2025-01-24 20:26:51.360429:  
2025-01-24 20:26:51.363938: Epoch 605 
2025-01-24 20:26:51.366398: Current learning rate: 0.00433 
2025-01-24 20:27:39.935551: train_loss -0.8248 
2025-01-24 20:27:39.940788: val_loss -0.7589 
2025-01-24 20:27:39.943300: Pseudo dice [np.float32(0.9408), np.float32(0.8918)] 
2025-01-24 20:27:39.945719: Epoch time: 48.58 s 
2025-01-24 20:27:41.226181:  
2025-01-24 20:27:41.229169: Epoch 606 
2025-01-24 20:27:41.231730: Current learning rate: 0.00432 
2025-01-24 20:28:29.621997: train_loss -0.8198 
2025-01-24 20:28:29.630251: val_loss -0.7369 
2025-01-24 20:28:29.632908: Pseudo dice [np.float32(0.9454), np.float32(0.8927)] 
2025-01-24 20:28:29.635626: Epoch time: 48.4 s 
2025-01-24 20:28:30.874860:  
2025-01-24 20:28:30.877414: Epoch 607 
2025-01-24 20:28:30.879956: Current learning rate: 0.00431 
2025-01-24 20:29:20.110041: train_loss -0.8356 
2025-01-24 20:29:20.116875: val_loss -0.7163 
2025-01-24 20:29:20.119622: Pseudo dice [np.float32(0.942), np.float32(0.8032)] 
2025-01-24 20:29:20.122015: Epoch time: 49.24 s 
2025-01-24 20:29:21.360091:  
2025-01-24 20:29:21.362854: Epoch 608 
2025-01-24 20:29:21.365450: Current learning rate: 0.0043 
2025-01-24 20:30:09.892618: train_loss -0.8123 
2025-01-24 20:30:09.898987: val_loss -0.711 
2025-01-24 20:30:09.901407: Pseudo dice [np.float32(0.9214), np.float32(0.8403)] 
2025-01-24 20:30:09.903842: Epoch time: 48.53 s 
2025-01-24 20:30:11.100251:  
2025-01-24 20:30:11.103045: Epoch 609 
2025-01-24 20:30:11.105599: Current learning rate: 0.00429 
2025-01-24 20:30:59.753640: train_loss -0.8137 
2025-01-24 20:30:59.760354: val_loss -0.7837 
2025-01-24 20:30:59.763193: Pseudo dice [np.float32(0.95), np.float32(0.8915)] 
2025-01-24 20:30:59.766129: Epoch time: 48.65 s 
2025-01-24 20:31:00.988586:  
2025-01-24 20:31:00.991459: Epoch 610 
2025-01-24 20:31:00.993961: Current learning rate: 0.00429 
2025-01-24 20:31:49.434232: train_loss -0.8313 
2025-01-24 20:31:49.440859: val_loss -0.7533 
2025-01-24 20:31:49.443347: Pseudo dice [np.float32(0.9521), np.float32(0.8356)] 
2025-01-24 20:31:49.445968: Epoch time: 48.45 s 
2025-01-24 20:31:51.215489:  
2025-01-24 20:31:51.218205: Epoch 611 
2025-01-24 20:31:51.220890: Current learning rate: 0.00428 
2025-01-24 20:32:40.156674: train_loss -0.823 
2025-01-24 20:32:40.163489: val_loss -0.7675 
2025-01-24 20:32:40.166128: Pseudo dice [np.float32(0.9402), np.float32(0.9159)] 
2025-01-24 20:32:40.168796: Epoch time: 48.94 s 
2025-01-24 20:32:41.391316:  
2025-01-24 20:32:41.394505: Epoch 612 
2025-01-24 20:32:41.397458: Current learning rate: 0.00427 
2025-01-24 20:33:29.749265: train_loss -0.8413 
2025-01-24 20:33:29.753849: val_loss -0.7401 
2025-01-24 20:33:29.756379: Pseudo dice [np.float32(0.9409), np.float32(0.919)] 
2025-01-24 20:33:29.758826: Epoch time: 48.36 s 
2025-01-24 20:33:30.962855:  
2025-01-24 20:33:30.965331: Epoch 613 
2025-01-24 20:33:30.967591: Current learning rate: 0.00426 
2025-01-24 20:34:19.903186: train_loss -0.8366 
2025-01-24 20:34:19.908206: val_loss -0.7887 
2025-01-24 20:34:19.910815: Pseudo dice [np.float32(0.9473), np.float32(0.9312)] 
2025-01-24 20:34:19.913268: Epoch time: 48.94 s 
2025-01-24 20:34:21.116180:  
2025-01-24 20:34:21.119389: Epoch 614 
2025-01-24 20:34:21.121932: Current learning rate: 0.00425 
2025-01-24 20:35:10.252279: train_loss -0.8158 
2025-01-24 20:35:10.259921: val_loss -0.7778 
2025-01-24 20:35:10.262805: Pseudo dice [np.float32(0.9536), np.float32(0.9407)] 
2025-01-24 20:35:10.265281: Epoch time: 49.14 s 
2025-01-24 20:35:11.466750:  
2025-01-24 20:35:11.470005: Epoch 615 
2025-01-24 20:35:11.473282: Current learning rate: 0.00424 
2025-01-24 20:35:59.862153: train_loss -0.8342 
2025-01-24 20:35:59.867361: val_loss -0.7358 
2025-01-24 20:35:59.870194: Pseudo dice [np.float32(0.9467), np.float32(0.9198)] 
2025-01-24 20:35:59.872618: Epoch time: 48.4 s 
2025-01-24 20:36:01.073221:  
2025-01-24 20:36:01.075769: Epoch 616 
2025-01-24 20:36:01.078208: Current learning rate: 0.00423 
2025-01-24 20:36:49.896701: train_loss -0.8367 
2025-01-24 20:36:49.901184: val_loss -0.7702 
2025-01-24 20:36:49.905952: Pseudo dice [np.float32(0.9495), np.float32(0.9101)] 
2025-01-24 20:36:49.908317: Epoch time: 48.82 s 
2025-01-24 20:36:51.112713:  
2025-01-24 20:36:51.117050: Epoch 617 
2025-01-24 20:36:51.119869: Current learning rate: 0.00422 
2025-01-24 20:37:39.594081: train_loss -0.8312 
2025-01-24 20:37:39.598364: val_loss -0.7579 
2025-01-24 20:37:39.600952: Pseudo dice [np.float32(0.942), np.float32(0.9058)] 
2025-01-24 20:37:39.603346: Epoch time: 48.48 s 
2025-01-24 20:37:40.811483:  
2025-01-24 20:37:40.813956: Epoch 618 
2025-01-24 20:37:40.816407: Current learning rate: 0.00421 
2025-01-24 20:38:29.907112: train_loss -0.8314 
2025-01-24 20:38:29.912616: val_loss -0.7974 
2025-01-24 20:38:29.915680: Pseudo dice [np.float32(0.9608), np.float32(0.923)] 
2025-01-24 20:38:29.918477: Epoch time: 49.1 s 
2025-01-24 20:38:31.120368:  
2025-01-24 20:38:31.123725: Epoch 619 
2025-01-24 20:38:31.126859: Current learning rate: 0.0042 
2025-01-24 20:39:19.717999: train_loss -0.8382 
2025-01-24 20:39:19.726207: val_loss -0.7842 
2025-01-24 20:39:19.729427: Pseudo dice [np.float32(0.9457), np.float32(0.9154)] 
2025-01-24 20:39:19.732172: Epoch time: 48.6 s 
2025-01-24 20:39:20.971768:  
2025-01-24 20:39:20.974739: Epoch 620 
2025-01-24 20:39:20.977511: Current learning rate: 0.00419 
2025-01-24 20:40:09.424253: train_loss -0.8391 
2025-01-24 20:40:09.432325: val_loss -0.7902 
2025-01-24 20:40:09.435127: Pseudo dice [np.float32(0.9551), np.float32(0.892)] 
2025-01-24 20:40:09.437917: Epoch time: 48.45 s 
2025-01-24 20:40:10.643960:  
2025-01-24 20:40:10.647900: Epoch 621 
2025-01-24 20:40:10.650429: Current learning rate: 0.00418 
2025-01-24 20:40:59.804104: train_loss -0.8502 
2025-01-24 20:40:59.812075: val_loss -0.7725 
2025-01-24 20:40:59.814697: Pseudo dice [np.float32(0.9455), np.float32(0.8753)] 
2025-01-24 20:40:59.817322: Epoch time: 49.16 s 
2025-01-24 20:41:01.024275:  
2025-01-24 20:41:01.026992: Epoch 622 
2025-01-24 20:41:01.029807: Current learning rate: 0.00417 
2025-01-24 20:41:49.843856: train_loss -0.8292 
2025-01-24 20:41:49.851737: val_loss -0.7521 
2025-01-24 20:41:49.854624: Pseudo dice [np.float32(0.9474), np.float32(0.9233)] 
2025-01-24 20:41:49.857564: Epoch time: 48.82 s 
2025-01-24 20:41:51.060236:  
2025-01-24 20:41:51.065111: Epoch 623 
2025-01-24 20:41:51.068143: Current learning rate: 0.00416 
2025-01-24 20:42:39.698922: train_loss -0.8367 
2025-01-24 20:42:39.704170: val_loss -0.7334 
2025-01-24 20:42:39.706798: Pseudo dice [np.float32(0.9523), np.float32(0.9193)] 
2025-01-24 20:42:39.709174: Epoch time: 48.64 s 
2025-01-24 20:42:40.942996:  
2025-01-24 20:42:40.946026: Epoch 624 
2025-01-24 20:42:40.948774: Current learning rate: 0.00415 
2025-01-24 20:43:29.051724: train_loss -0.8364 
2025-01-24 20:43:29.059598: val_loss -0.765 
2025-01-24 20:43:29.062326: Pseudo dice [np.float32(0.9558), np.float32(0.9096)] 
2025-01-24 20:43:29.064790: Epoch time: 48.11 s 
2025-01-24 20:43:30.304744:  
2025-01-24 20:43:30.307575: Epoch 625 
2025-01-24 20:43:30.310952: Current learning rate: 0.00414 
2025-01-24 20:44:18.946207: train_loss -0.8317 
2025-01-24 20:44:18.955063: val_loss -0.7474 
2025-01-24 20:44:18.957977: Pseudo dice [np.float32(0.9528), np.float32(0.9127)] 
2025-01-24 20:44:18.960698: Epoch time: 48.64 s 
2025-01-24 20:44:20.165653:  
2025-01-24 20:44:20.168276: Epoch 626 
2025-01-24 20:44:20.170783: Current learning rate: 0.00413 
2025-01-24 20:45:08.336416: train_loss -0.8258 
2025-01-24 20:45:08.344663: val_loss -0.7978 
2025-01-24 20:45:08.347537: Pseudo dice [np.float32(0.9561), np.float32(0.9367)] 
2025-01-24 20:45:08.350098: Epoch time: 48.17 s 
2025-01-24 20:45:09.550351:  
2025-01-24 20:45:09.553853: Epoch 627 
2025-01-24 20:45:09.557211: Current learning rate: 0.00412 
2025-01-24 20:45:58.481779: train_loss -0.8301 
2025-01-24 20:45:58.489391: val_loss -0.7233 
2025-01-24 20:45:58.491896: Pseudo dice [np.float32(0.9161), np.float32(0.9065)] 
2025-01-24 20:45:58.494251: Epoch time: 48.93 s 
2025-01-24 20:45:59.738597:  
2025-01-24 20:45:59.741423: Epoch 628 
2025-01-24 20:45:59.743917: Current learning rate: 0.00411 
2025-01-24 20:46:48.568356: train_loss -0.8231 
2025-01-24 20:46:48.574735: val_loss -0.7789 
2025-01-24 20:46:48.577646: Pseudo dice [np.float32(0.9496), np.float32(0.9261)] 
2025-01-24 20:46:48.580276: Epoch time: 48.83 s 
2025-01-24 20:46:50.461450:  
2025-01-24 20:46:50.464740: Epoch 629 
2025-01-24 20:46:50.467426: Current learning rate: 0.0041 
2025-01-24 20:47:39.577976: train_loss -0.8475 
2025-01-24 20:47:39.582985: val_loss -0.7635 
2025-01-24 20:47:39.586293: Pseudo dice [np.float32(0.9479), np.float32(0.9208)] 
2025-01-24 20:47:39.589217: Epoch time: 49.12 s 
2025-01-24 20:47:40.821704:  
2025-01-24 20:47:40.824457: Epoch 630 
2025-01-24 20:47:40.826949: Current learning rate: 0.00409 
2025-01-24 20:48:29.476429: train_loss -0.8371 
2025-01-24 20:48:29.481196: val_loss -0.7033 
2025-01-24 20:48:29.483683: Pseudo dice [np.float32(0.9515), np.float32(0.8018)] 
2025-01-24 20:48:29.486276: Epoch time: 48.66 s 
2025-01-24 20:48:30.698037:  
2025-01-24 20:48:30.701067: Epoch 631 
2025-01-24 20:48:30.703756: Current learning rate: 0.00408 
2025-01-24 20:49:19.552387: train_loss -0.829 
2025-01-24 20:49:19.557064: val_loss -0.7787 
2025-01-24 20:49:19.559804: Pseudo dice [np.float32(0.9629), np.float32(0.9082)] 
2025-01-24 20:49:19.562237: Epoch time: 48.86 s 
2025-01-24 20:49:20.773325:  
2025-01-24 20:49:20.776558: Epoch 632 
2025-01-24 20:49:20.779400: Current learning rate: 0.00407 
2025-01-24 20:50:09.815706: train_loss -0.8518 
2025-01-24 20:50:09.820732: val_loss -0.7512 
2025-01-24 20:50:09.823171: Pseudo dice [np.float32(0.9485), np.float32(0.9028)] 
2025-01-24 20:50:09.825623: Epoch time: 49.04 s 
2025-01-24 20:50:11.034403:  
2025-01-24 20:50:11.037502: Epoch 633 
2025-01-24 20:50:11.040095: Current learning rate: 0.00406 
2025-01-24 20:50:59.795701: train_loss -0.831 
2025-01-24 20:50:59.801321: val_loss -0.7798 
2025-01-24 20:50:59.804196: Pseudo dice [np.float32(0.9548), np.float32(0.9269)] 
2025-01-24 20:50:59.806836: Epoch time: 48.76 s 
2025-01-24 20:51:01.057513:  
2025-01-24 20:51:01.061761: Epoch 634 
2025-01-24 20:51:01.064295: Current learning rate: 0.00405 
2025-01-24 20:51:49.825582: train_loss -0.8381 
2025-01-24 20:51:49.830236: val_loss -0.7657 
2025-01-24 20:51:49.832732: Pseudo dice [np.float32(0.9505), np.float32(0.914)] 
2025-01-24 20:51:49.835243: Epoch time: 48.77 s 
2025-01-24 20:51:51.076731:  
2025-01-24 20:51:51.082174: Epoch 635 
2025-01-24 20:51:51.084929: Current learning rate: 0.00404 
2025-01-24 20:52:39.955890: train_loss -0.8271 
2025-01-24 20:52:39.962029: val_loss -0.7521 
2025-01-24 20:52:39.964641: Pseudo dice [np.float32(0.9525), np.float32(0.9303)] 
2025-01-24 20:52:39.967060: Epoch time: 48.88 s 
2025-01-24 20:52:41.217459:  
2025-01-24 20:52:41.221809: Epoch 636 
2025-01-24 20:52:41.224634: Current learning rate: 0.00403 
2025-01-24 20:53:30.501853: train_loss -0.8586 
2025-01-24 20:53:30.510004: val_loss -0.7756 
2025-01-24 20:53:30.512563: Pseudo dice [np.float32(0.9493), np.float32(0.9144)] 
2025-01-24 20:53:30.515020: Epoch time: 49.29 s 
2025-01-24 20:53:30.517565: Yayy! New best EMA pseudo Dice: 0.928600013256073 
2025-01-24 20:53:32.354952:  
2025-01-24 20:53:32.360718: Epoch 637 
2025-01-24 20:53:32.363334: Current learning rate: 0.00402 
2025-01-24 20:54:21.385219: train_loss -0.8357 
2025-01-24 20:54:21.392460: val_loss -0.7792 
2025-01-24 20:54:21.395386: Pseudo dice [np.float32(0.947), np.float32(0.8994)] 
2025-01-24 20:54:21.398129: Epoch time: 49.03 s 
2025-01-24 20:54:22.666563:  
2025-01-24 20:54:22.670386: Epoch 638 
2025-01-24 20:54:22.673294: Current learning rate: 0.00401 
2025-01-24 20:55:11.756243: train_loss -0.8361 
2025-01-24 20:55:11.764852: val_loss -0.7527 
2025-01-24 20:55:11.767699: Pseudo dice [np.float32(0.9619), np.float32(0.9147)] 
2025-01-24 20:55:11.770502: Epoch time: 49.09 s 
2025-01-24 20:55:11.773183: Yayy! New best EMA pseudo Dice: 0.929099977016449 
2025-01-24 20:55:13.652272:  
2025-01-24 20:55:13.656894: Epoch 639 
2025-01-24 20:55:13.659344: Current learning rate: 0.004 
2025-01-24 20:56:02.797409: train_loss -0.8285 
2025-01-24 20:56:02.804882: val_loss -0.7601 
2025-01-24 20:56:02.807502: Pseudo dice [np.float32(0.9585), np.float32(0.9032)] 
2025-01-24 20:56:02.810117: Epoch time: 49.15 s 
2025-01-24 20:56:02.812535: Yayy! New best EMA pseudo Dice: 0.9291999936103821 
2025-01-24 20:56:04.631365:  
2025-01-24 20:56:04.633975: Epoch 640 
2025-01-24 20:56:04.636562: Current learning rate: 0.00399 
2025-01-24 20:56:53.330513: train_loss -0.817 
2025-01-24 20:56:53.338700: val_loss -0.7582 
2025-01-24 20:56:53.341265: Pseudo dice [np.float32(0.9509), np.float32(0.9161)] 
2025-01-24 20:56:53.344090: Epoch time: 48.7 s 
2025-01-24 20:56:53.346552: Yayy! New best EMA pseudo Dice: 0.9297000169754028 
2025-01-24 20:56:55.180880:  
2025-01-24 20:56:55.183683: Epoch 641 
2025-01-24 20:56:55.186244: Current learning rate: 0.00398 
2025-01-24 20:57:44.137290: train_loss -0.8121 
2025-01-24 20:57:44.144347: val_loss -0.7529 
2025-01-24 20:57:44.146818: Pseudo dice [np.float32(0.9421), np.float32(0.8875)] 
2025-01-24 20:57:44.149466: Epoch time: 48.96 s 
2025-01-24 20:57:45.398258:  
2025-01-24 20:57:45.401474: Epoch 642 
2025-01-24 20:57:45.404464: Current learning rate: 0.00397 
2025-01-24 20:58:33.846785: train_loss -0.8204 
2025-01-24 20:58:33.853344: val_loss -0.7292 
2025-01-24 20:58:33.855830: Pseudo dice [np.float32(0.9524), np.float32(0.8679)] 
2025-01-24 20:58:33.858474: Epoch time: 48.45 s 
2025-01-24 20:58:35.100333:  
2025-01-24 20:58:35.103386: Epoch 643 
2025-01-24 20:58:35.105835: Current learning rate: 0.00396 
2025-01-24 20:59:24.045851: train_loss -0.8116 
2025-01-24 20:59:24.050058: val_loss -0.7102 
2025-01-24 20:59:24.052633: Pseudo dice [np.float32(0.9252), np.float32(0.8691)] 
2025-01-24 20:59:24.054938: Epoch time: 48.95 s 
2025-01-24 20:59:25.255384:  
2025-01-24 20:59:25.259907: Epoch 644 
2025-01-24 20:59:25.262717: Current learning rate: 0.00395 
2025-01-24 21:00:13.595117: train_loss -0.8113 
2025-01-24 21:00:13.602805: val_loss -0.7602 
2025-01-24 21:00:13.605331: Pseudo dice [np.float32(0.9452), np.float32(0.9027)] 
2025-01-24 21:00:13.607953: Epoch time: 48.34 s 
2025-01-24 21:00:14.812385:  
2025-01-24 21:00:14.815774: Epoch 645 
2025-01-24 21:00:14.818718: Current learning rate: 0.00394 
2025-01-24 21:01:03.149298: train_loss -0.7995 
2025-01-24 21:01:03.156815: val_loss -0.792 
2025-01-24 21:01:03.159608: Pseudo dice [np.float32(0.936), np.float32(0.932)] 
2025-01-24 21:01:03.162218: Epoch time: 48.34 s 
2025-01-24 21:01:04.379422:  
2025-01-24 21:01:04.382792: Epoch 646 
2025-01-24 21:01:04.385722: Current learning rate: 0.00393 
2025-01-24 21:01:52.605321: train_loss -0.8178 
2025-01-24 21:01:52.612272: val_loss -0.7183 
2025-01-24 21:01:52.614895: Pseudo dice [np.float32(0.9488), np.float32(0.8352)] 
2025-01-24 21:01:52.617221: Epoch time: 48.23 s 
2025-01-24 21:01:53.819622:  
2025-01-24 21:01:53.822299: Epoch 647 
2025-01-24 21:01:53.824713: Current learning rate: 0.00392 
2025-01-24 21:02:43.093177: train_loss -0.8053 
2025-01-24 21:02:43.100311: val_loss -0.718 
2025-01-24 21:02:43.102821: Pseudo dice [np.float32(0.934), np.float32(0.8963)] 
2025-01-24 21:02:43.105406: Epoch time: 49.27 s 
2025-01-24 21:02:44.868513:  
2025-01-24 21:02:44.871272: Epoch 648 
2025-01-24 21:02:44.873672: Current learning rate: 0.00391 
2025-01-24 21:03:33.675217: train_loss -0.8269 
2025-01-24 21:03:33.683595: val_loss -0.6685 
2025-01-24 21:03:33.686336: Pseudo dice [np.float32(0.9567), np.float32(0.8818)] 
2025-01-24 21:03:33.688583: Epoch time: 48.81 s 
2025-01-24 21:03:34.906132:  
2025-01-24 21:03:34.908984: Epoch 649 
2025-01-24 21:03:34.911603: Current learning rate: 0.0039 
2025-01-24 21:04:23.664370: train_loss -0.8278 
2025-01-24 21:04:23.670963: val_loss -0.7936 
2025-01-24 21:04:23.673544: Pseudo dice [np.float32(0.9446), np.float32(0.9219)] 
2025-01-24 21:04:23.676277: Epoch time: 48.76 s 
2025-01-24 21:04:25.500371:  
2025-01-24 21:04:25.503721: Epoch 650 
2025-01-24 21:04:25.506432: Current learning rate: 0.00389 
2025-01-24 21:05:14.290697: train_loss -0.8319 
2025-01-24 21:05:14.296868: val_loss -0.7667 
2025-01-24 21:05:14.299767: Pseudo dice [np.float32(0.9528), np.float32(0.9297)] 
2025-01-24 21:05:14.302734: Epoch time: 48.79 s 
2025-01-24 21:05:15.553619:  
2025-01-24 21:05:15.556818: Epoch 651 
2025-01-24 21:05:15.559475: Current learning rate: 0.00388 
2025-01-24 21:06:04.408865: train_loss -0.8219 
2025-01-24 21:06:04.414716: val_loss -0.8 
2025-01-24 21:06:04.418036: Pseudo dice [np.float32(0.9526), np.float32(0.9377)] 
2025-01-24 21:06:04.420863: Epoch time: 48.86 s 
2025-01-24 21:06:05.636345:  
2025-01-24 21:06:05.639940: Epoch 652 
2025-01-24 21:06:05.642659: Current learning rate: 0.00387 
2025-01-24 21:06:53.892021: train_loss -0.8268 
2025-01-24 21:06:53.900842: val_loss -0.7491 
2025-01-24 21:06:53.904577: Pseudo dice [np.float32(0.9526), np.float32(0.9278)] 
2025-01-24 21:06:53.907326: Epoch time: 48.26 s 
2025-01-24 21:06:55.136952:  
2025-01-24 21:06:55.141961: Epoch 653 
2025-01-24 21:06:55.144954: Current learning rate: 0.00386 
2025-01-24 21:07:44.087884: train_loss -0.8272 
2025-01-24 21:07:44.095218: val_loss -0.7708 
2025-01-24 21:07:44.097726: Pseudo dice [np.float32(0.9518), np.float32(0.9311)] 
2025-01-24 21:07:44.100032: Epoch time: 48.95 s 
2025-01-24 21:07:45.302722:  
2025-01-24 21:07:45.305548: Epoch 654 
2025-01-24 21:07:45.308623: Current learning rate: 0.00385 
2025-01-24 21:08:33.970008: train_loss -0.8325 
2025-01-24 21:08:33.977734: val_loss -0.7382 
2025-01-24 21:08:33.980529: Pseudo dice [np.float32(0.9557), np.float32(0.918)] 
2025-01-24 21:08:33.983123: Epoch time: 48.67 s 
2025-01-24 21:08:35.204395:  
2025-01-24 21:08:35.207598: Epoch 655 
2025-01-24 21:08:35.210495: Current learning rate: 0.00384 
2025-01-24 21:09:23.848020: train_loss -0.8466 
2025-01-24 21:09:23.854881: val_loss -0.7747 
2025-01-24 21:09:23.857425: Pseudo dice [np.float32(0.9541), np.float32(0.9327)] 
2025-01-24 21:09:23.860784: Epoch time: 48.64 s 
2025-01-24 21:09:23.863500: Yayy! New best EMA pseudo Dice: 0.930899977684021 
2025-01-24 21:09:25.663268:  
2025-01-24 21:09:25.668269: Epoch 656 
2025-01-24 21:09:25.670723: Current learning rate: 0.00383 
2025-01-24 21:10:14.236392: train_loss -0.8112 
2025-01-24 21:10:14.243701: val_loss -0.7583 
2025-01-24 21:10:14.246747: Pseudo dice [np.float32(0.9501), np.float32(0.9207)] 
2025-01-24 21:10:14.249524: Epoch time: 48.57 s 
2025-01-24 21:10:14.252137: Yayy! New best EMA pseudo Dice: 0.9314000010490417 
2025-01-24 21:10:16.076791:  
2025-01-24 21:10:16.081779: Epoch 657 
2025-01-24 21:10:16.084225: Current learning rate: 0.00382 
2025-01-24 21:11:04.562528: train_loss -0.8152 
2025-01-24 21:11:04.571232: val_loss -0.7588 
2025-01-24 21:11:04.574243: Pseudo dice [np.float32(0.9422), np.float32(0.9073)] 
2025-01-24 21:11:04.576864: Epoch time: 48.49 s 
2025-01-24 21:11:05.792047:  
2025-01-24 21:11:05.797410: Epoch 658 
2025-01-24 21:11:05.800568: Current learning rate: 0.00381 
2025-01-24 21:11:54.379786: train_loss -0.8193 
2025-01-24 21:11:54.388348: val_loss -0.6988 
2025-01-24 21:11:54.391234: Pseudo dice [np.float32(0.9533), np.float32(0.8865)] 
2025-01-24 21:11:54.393963: Epoch time: 48.59 s 
2025-01-24 21:11:55.641949:  
2025-01-24 21:11:55.647168: Epoch 659 
2025-01-24 21:11:55.649869: Current learning rate: 0.0038 
2025-01-24 21:12:44.116328: train_loss -0.8189 
2025-01-24 21:12:44.123575: val_loss -0.7832 
2025-01-24 21:12:44.126125: Pseudo dice [np.float32(0.9573), np.float32(0.9528)] 
2025-01-24 21:12:44.128924: Epoch time: 48.48 s 
2025-01-24 21:12:44.131371: Yayy! New best EMA pseudo Dice: 0.932200014591217 
2025-01-24 21:12:45.950799:  
2025-01-24 21:12:45.955803: Epoch 660 
2025-01-24 21:12:45.958880: Current learning rate: 0.00379 
2025-01-24 21:13:34.452603: train_loss -0.8073 
2025-01-24 21:13:34.460848: val_loss -0.7212 
2025-01-24 21:13:34.463689: Pseudo dice [np.float32(0.9278), np.float32(0.8425)] 
2025-01-24 21:13:34.466503: Epoch time: 48.5 s 
2025-01-24 21:13:35.677775:  
2025-01-24 21:13:35.680385: Epoch 661 
2025-01-24 21:13:35.682554: Current learning rate: 0.00378 
2025-01-24 21:14:23.918081: train_loss -0.8021 
2025-01-24 21:14:23.927008: val_loss -0.7991 
2025-01-24 21:14:23.929814: Pseudo dice [np.float32(0.9484), np.float32(0.9032)] 
2025-01-24 21:14:23.932336: Epoch time: 48.24 s 
2025-01-24 21:14:25.145848:  
2025-01-24 21:14:25.148567: Epoch 662 
2025-01-24 21:14:25.151129: Current learning rate: 0.00377 
2025-01-24 21:15:13.609853: train_loss -0.8141 
2025-01-24 21:15:13.616827: val_loss -0.7418 
2025-01-24 21:15:13.619554: Pseudo dice [np.float32(0.9503), np.float32(0.8986)] 
2025-01-24 21:15:13.622010: Epoch time: 48.46 s 
2025-01-24 21:15:14.837491:  
2025-01-24 21:15:14.840720: Epoch 663 
2025-01-24 21:15:14.843790: Current learning rate: 0.00376 
2025-01-24 21:16:03.653090: train_loss -0.8343 
2025-01-24 21:16:03.660521: val_loss -0.7435 
2025-01-24 21:16:03.663371: Pseudo dice [np.float32(0.9432), np.float32(0.8844)] 
2025-01-24 21:16:03.665958: Epoch time: 48.82 s 
2025-01-24 21:16:04.882282:  
2025-01-24 21:16:04.885070: Epoch 664 
2025-01-24 21:16:04.888145: Current learning rate: 0.00375 
2025-01-24 21:16:53.432235: train_loss -0.8208 
2025-01-24 21:16:53.439282: val_loss -0.7671 
2025-01-24 21:16:53.442309: Pseudo dice [np.float32(0.9479), np.float32(0.93)] 
2025-01-24 21:16:53.445149: Epoch time: 48.55 s 
2025-01-24 21:16:55.207278:  
2025-01-24 21:16:55.211051: Epoch 665 
2025-01-24 21:16:55.213512: Current learning rate: 0.00374 
2025-01-24 21:17:44.050177: train_loss -0.8286 
2025-01-24 21:17:44.055615: val_loss -0.7533 
2025-01-24 21:17:44.058279: Pseudo dice [np.float32(0.9371), np.float32(0.9075)] 
2025-01-24 21:17:44.060832: Epoch time: 48.84 s 
2025-01-24 21:17:45.273552:  
2025-01-24 21:17:45.276577: Epoch 666 
2025-01-24 21:17:45.279223: Current learning rate: 0.00373 
2025-01-24 21:18:34.093442: train_loss -0.8303 
2025-01-24 21:18:34.099355: val_loss -0.7678 
2025-01-24 21:18:34.101910: Pseudo dice [np.float32(0.9509), np.float32(0.923)] 
2025-01-24 21:18:34.104721: Epoch time: 48.82 s 
2025-01-24 21:18:35.330423:  
2025-01-24 21:18:35.334949: Epoch 667 
2025-01-24 21:18:35.337539: Current learning rate: 0.00372 
2025-01-24 21:19:23.680993: train_loss -0.8247 
2025-01-24 21:19:23.685923: val_loss -0.7712 
2025-01-24 21:19:23.688738: Pseudo dice [np.float32(0.9467), np.float32(0.9313)] 
2025-01-24 21:19:23.691507: Epoch time: 48.35 s 
2025-01-24 21:19:24.938950:  
2025-01-24 21:19:24.943841: Epoch 668 
2025-01-24 21:19:24.946594: Current learning rate: 0.00371 
2025-01-24 21:20:13.737962: train_loss -0.8323 
2025-01-24 21:20:13.743812: val_loss -0.7561 
2025-01-24 21:20:13.745905: Pseudo dice [np.float32(0.9548), np.float32(0.9013)] 
2025-01-24 21:20:13.748062: Epoch time: 48.8 s 
2025-01-24 21:20:15.016645:  
2025-01-24 21:20:15.019171: Epoch 669 
2025-01-24 21:20:15.021833: Current learning rate: 0.0037 
2025-01-24 21:21:03.636613: train_loss -0.8445 
2025-01-24 21:21:03.642193: val_loss -0.7788 
2025-01-24 21:21:03.644572: Pseudo dice [np.float32(0.9573), np.float32(0.9408)] 
2025-01-24 21:21:03.647172: Epoch time: 48.62 s 
2025-01-24 21:21:04.909567:  
2025-01-24 21:21:04.912555: Epoch 670 
2025-01-24 21:21:04.915029: Current learning rate: 0.00369 
2025-01-24 21:21:53.951894: train_loss -0.8363 
2025-01-24 21:21:53.957708: val_loss -0.7276 
2025-01-24 21:21:53.960483: Pseudo dice [np.float32(0.952), np.float32(0.9208)] 
2025-01-24 21:21:53.962973: Epoch time: 49.04 s 
2025-01-24 21:21:55.217771:  
2025-01-24 21:21:55.220620: Epoch 671 
2025-01-24 21:21:55.223607: Current learning rate: 0.00368 
2025-01-24 21:22:44.308959: train_loss -0.8249 
2025-01-24 21:22:44.313707: val_loss -0.7534 
2025-01-24 21:22:44.316106: Pseudo dice [np.float32(0.9484), np.float32(0.9319)] 
2025-01-24 21:22:44.318248: Epoch time: 49.09 s 
2025-01-24 21:22:45.580460:  
2025-01-24 21:22:45.582827: Epoch 672 
2025-01-24 21:22:45.585298: Current learning rate: 0.00367 
2025-01-24 21:23:34.291882: train_loss -0.8371 
2025-01-24 21:23:34.296835: val_loss -0.749 
2025-01-24 21:23:34.299280: Pseudo dice [np.float32(0.9518), np.float32(0.9247)] 
2025-01-24 21:23:34.301679: Epoch time: 48.71 s 
2025-01-24 21:23:34.304243: Yayy! New best EMA pseudo Dice: 0.9327999949455261 
2025-01-24 21:23:36.167267:  
2025-01-24 21:23:36.172275: Epoch 673 
2025-01-24 21:23:36.174978: Current learning rate: 0.00366 
2025-01-24 21:24:25.057206: train_loss -0.8314 
2025-01-24 21:24:25.061670: val_loss -0.7682 
2025-01-24 21:24:25.064077: Pseudo dice [np.float32(0.9567), np.float32(0.9362)] 
2025-01-24 21:24:25.066349: Epoch time: 48.89 s 
2025-01-24 21:24:25.068743: Yayy! New best EMA pseudo Dice: 0.9340999722480774 
2025-01-24 21:24:27.002144:  
2025-01-24 21:24:27.006415: Epoch 674 
2025-01-24 21:24:27.009049: Current learning rate: 0.00365 
2025-01-24 21:25:15.986976: train_loss -0.8412 
2025-01-24 21:25:15.991329: val_loss -0.7771 
2025-01-24 21:25:15.993981: Pseudo dice [np.float32(0.9551), np.float32(0.9357)] 
2025-01-24 21:25:15.996475: Epoch time: 48.99 s 
2025-01-24 21:25:15.998797: Yayy! New best EMA pseudo Dice: 0.9352999925613403 
2025-01-24 21:25:17.793303:  
2025-01-24 21:25:17.797135: Epoch 675 
2025-01-24 21:25:17.799746: Current learning rate: 0.00364 
2025-01-24 21:26:06.597102: train_loss -0.8462 
2025-01-24 21:26:06.602529: val_loss -0.7712 
2025-01-24 21:26:06.605343: Pseudo dice [np.float32(0.9509), np.float32(0.9139)] 
2025-01-24 21:26:06.608090: Epoch time: 48.8 s 
2025-01-24 21:26:07.866126:  
2025-01-24 21:26:07.869676: Epoch 676 
2025-01-24 21:26:07.872588: Current learning rate: 0.00363 
2025-01-24 21:26:56.790898: train_loss -0.8501 
2025-01-24 21:26:56.796165: val_loss -0.7942 
2025-01-24 21:26:56.798893: Pseudo dice [np.float32(0.9546), np.float32(0.9376)] 
2025-01-24 21:26:56.801596: Epoch time: 48.93 s 
2025-01-24 21:26:56.804511: Yayy! New best EMA pseudo Dice: 0.9361000061035156 
2025-01-24 21:26:58.703491:  
2025-01-24 21:26:58.707350: Epoch 677 
2025-01-24 21:26:58.710264: Current learning rate: 0.00362 
2025-01-24 21:27:47.052705: train_loss -0.8485 
2025-01-24 21:27:47.057417: val_loss -0.7337 
2025-01-24 21:27:47.060265: Pseudo dice [np.float32(0.9547), np.float32(0.9495)] 
2025-01-24 21:27:47.062635: Epoch time: 48.35 s 
2025-01-24 21:27:47.065099: Yayy! New best EMA pseudo Dice: 0.9376999735832214 
2025-01-24 21:27:48.909389:  
2025-01-24 21:27:48.915327: Epoch 678 
2025-01-24 21:27:48.918272: Current learning rate: 0.00361 
2025-01-24 21:28:37.827288: train_loss -0.8257 
2025-01-24 21:28:37.832319: val_loss -0.7064 
2025-01-24 21:28:37.835024: Pseudo dice [np.float32(0.9473), np.float32(0.9183)] 
2025-01-24 21:28:37.838020: Epoch time: 48.92 s 
2025-01-24 21:28:39.069075:  
2025-01-24 21:28:39.072504: Epoch 679 
2025-01-24 21:28:39.075726: Current learning rate: 0.0036 
2025-01-24 21:29:27.694661: train_loss -0.8423 
2025-01-24 21:29:27.701452: val_loss -0.8108 
2025-01-24 21:29:27.703989: Pseudo dice [np.float32(0.9553), np.float32(0.9144)] 
2025-01-24 21:29:27.706543: Epoch time: 48.63 s 
2025-01-24 21:29:28.938968:  
2025-01-24 21:29:28.941625: Epoch 680 
2025-01-24 21:29:28.944422: Current learning rate: 0.00359 
2025-01-24 21:30:17.939672: train_loss -0.8327 
2025-01-24 21:30:17.946180: val_loss -0.778 
2025-01-24 21:30:17.949040: Pseudo dice [np.float32(0.9535), np.float32(0.9078)] 
2025-01-24 21:30:17.951714: Epoch time: 49.0 s 
2025-01-24 21:30:19.189423:  
2025-01-24 21:30:19.192833: Epoch 681 
2025-01-24 21:30:19.195083: Current learning rate: 0.00358 
2025-01-24 21:31:07.880877: train_loss -0.8359 
2025-01-24 21:31:07.885221: val_loss -0.7803 
2025-01-24 21:31:07.887528: Pseudo dice [np.float32(0.9435), np.float32(0.9343)] 
2025-01-24 21:31:07.889716: Epoch time: 48.69 s 
2025-01-24 21:31:09.118391:  
2025-01-24 21:31:09.120749: Epoch 682 
2025-01-24 21:31:09.123194: Current learning rate: 0.00357 
2025-01-24 21:31:57.705034: train_loss -0.8444 
2025-01-24 21:31:57.709579: val_loss -0.7755 
2025-01-24 21:31:57.712382: Pseudo dice [np.float32(0.9486), np.float32(0.9215)] 
2025-01-24 21:31:57.715399: Epoch time: 48.59 s 
2025-01-24 21:31:59.558269:  
2025-01-24 21:31:59.561084: Epoch 683 
2025-01-24 21:31:59.563807: Current learning rate: 0.00356 
2025-01-24 21:32:48.379927: train_loss -0.8358 
2025-01-24 21:32:48.386656: val_loss -0.7798 
2025-01-24 21:32:48.389084: Pseudo dice [np.float32(0.9521), np.float32(0.938)] 
2025-01-24 21:32:48.391625: Epoch time: 48.82 s 
2025-01-24 21:32:49.662236:  
2025-01-24 21:32:49.664649: Epoch 684 
2025-01-24 21:32:49.667008: Current learning rate: 0.00355 
2025-01-24 21:33:38.495230: train_loss -0.8341 
2025-01-24 21:33:38.499845: val_loss -0.7499 
2025-01-24 21:33:38.502333: Pseudo dice [np.float32(0.9482), np.float32(0.9077)] 
2025-01-24 21:33:38.504778: Epoch time: 48.83 s 
2025-01-24 21:33:39.736017:  
2025-01-24 21:33:39.739145: Epoch 685 
2025-01-24 21:33:39.742103: Current learning rate: 0.00354 
2025-01-24 21:34:29.329373: train_loss -0.8268 
2025-01-24 21:34:29.335566: val_loss -0.7498 
2025-01-24 21:34:29.338403: Pseudo dice [np.float32(0.9597), np.float32(0.9298)] 
2025-01-24 21:34:29.341195: Epoch time: 49.59 s 
2025-01-24 21:34:30.580916:  
2025-01-24 21:34:30.584322: Epoch 686 
2025-01-24 21:34:30.587180: Current learning rate: 0.00353 
2025-01-24 21:35:19.577288: train_loss -0.8215 
2025-01-24 21:35:19.582154: val_loss -0.7319 
2025-01-24 21:35:19.584946: Pseudo dice [np.float32(0.9468), np.float32(0.8477)] 
2025-01-24 21:35:19.587566: Epoch time: 49.0 s 
2025-01-24 21:35:20.819467:  
2025-01-24 21:35:20.822774: Epoch 687 
2025-01-24 21:35:20.825590: Current learning rate: 0.00352 
2025-01-24 21:36:09.687124: train_loss -0.8339 
2025-01-24 21:36:09.694603: val_loss -0.786 
2025-01-24 21:36:09.697459: Pseudo dice [np.float32(0.9519), np.float32(0.9282)] 
2025-01-24 21:36:09.700157: Epoch time: 48.87 s 
2025-01-24 21:36:10.927964:  
2025-01-24 21:36:10.931641: Epoch 688 
2025-01-24 21:36:10.934593: Current learning rate: 0.00351 
2025-01-24 21:36:59.174710: train_loss -0.8362 
2025-01-24 21:36:59.181023: val_loss -0.7532 
2025-01-24 21:36:59.185651: Pseudo dice [np.float32(0.9371), np.float32(0.9004)] 
2025-01-24 21:36:59.188730: Epoch time: 48.25 s 
2025-01-24 21:37:00.460791:  
2025-01-24 21:37:00.463624: Epoch 689 
2025-01-24 21:37:00.466566: Current learning rate: 0.0035 
2025-01-24 21:37:49.110194: train_loss -0.8278 
2025-01-24 21:37:49.118175: val_loss -0.7496 
2025-01-24 21:37:49.120779: Pseudo dice [np.float32(0.9433), np.float32(0.9133)] 
2025-01-24 21:37:49.123145: Epoch time: 48.65 s 
2025-01-24 21:37:50.390748:  
2025-01-24 21:37:50.393770: Epoch 690 
2025-01-24 21:37:50.396301: Current learning rate: 0.00349 
2025-01-24 21:38:39.037383: train_loss -0.821 
2025-01-24 21:38:39.041761: val_loss -0.7063 
2025-01-24 21:38:39.044183: Pseudo dice [np.float32(0.9523), np.float32(0.9148)] 
2025-01-24 21:38:39.046786: Epoch time: 48.65 s 
2025-01-24 21:38:40.273546:  
2025-01-24 21:38:40.276444: Epoch 691 
2025-01-24 21:38:40.279333: Current learning rate: 0.00348 
2025-01-24 21:39:28.975215: train_loss -0.8282 
2025-01-24 21:39:28.980188: val_loss -0.7333 
2025-01-24 21:39:28.983401: Pseudo dice [np.float32(0.9431), np.float32(0.9231)] 
2025-01-24 21:39:28.986429: Epoch time: 48.7 s 
2025-01-24 21:39:30.256411:  
2025-01-24 21:39:30.259146: Epoch 692 
2025-01-24 21:39:30.261797: Current learning rate: 0.00346 
2025-01-24 21:40:18.774880: train_loss -0.8283 
2025-01-24 21:40:18.780288: val_loss -0.7524 
2025-01-24 21:40:18.783041: Pseudo dice [np.float32(0.9505), np.float32(0.917)] 
2025-01-24 21:40:18.785500: Epoch time: 48.52 s 
2025-01-24 21:40:20.051111:  
2025-01-24 21:40:20.053836: Epoch 693 
2025-01-24 21:40:20.056572: Current learning rate: 0.00345 
2025-01-24 21:41:08.949618: train_loss -0.833 
2025-01-24 21:41:08.954658: val_loss -0.7895 
2025-01-24 21:41:08.957270: Pseudo dice [np.float32(0.9539), np.float32(0.9212)] 
2025-01-24 21:41:08.959806: Epoch time: 48.9 s 
2025-01-24 21:41:10.188699:  
2025-01-24 21:41:10.191868: Epoch 694 
2025-01-24 21:41:10.194739: Current learning rate: 0.00344 
2025-01-24 21:41:59.053970: train_loss -0.8287 
2025-01-24 21:41:59.058392: val_loss -0.7432 
2025-01-24 21:41:59.061029: Pseudo dice [np.float32(0.9266), np.float32(0.7641)] 
2025-01-24 21:41:59.063454: Epoch time: 48.87 s 
2025-01-24 21:42:00.293568:  
2025-01-24 21:42:00.296312: Epoch 695 
2025-01-24 21:42:00.299190: Current learning rate: 0.00343 
2025-01-24 21:42:49.301754: train_loss -0.832 
2025-01-24 21:42:49.306288: val_loss -0.7642 
2025-01-24 21:42:49.308800: Pseudo dice [np.float32(0.9487), np.float32(0.9244)] 
2025-01-24 21:42:49.311096: Epoch time: 49.01 s 
2025-01-24 21:42:50.550202:  
2025-01-24 21:42:50.554006: Epoch 696 
2025-01-24 21:42:50.556948: Current learning rate: 0.00342 
2025-01-24 21:43:38.824910: train_loss -0.8324 
2025-01-24 21:43:38.829787: val_loss -0.7936 
2025-01-24 21:43:38.832362: Pseudo dice [np.float32(0.9541), np.float32(0.889)] 
2025-01-24 21:43:38.835148: Epoch time: 48.28 s 
2025-01-24 21:43:40.108844:  
2025-01-24 21:43:40.112008: Epoch 697 
2025-01-24 21:43:40.114888: Current learning rate: 0.00341 
2025-01-24 21:44:29.163508: train_loss -0.8414 
2025-01-24 21:44:29.172526: val_loss -0.7641 
2025-01-24 21:44:29.176061: Pseudo dice [np.float32(0.9503), np.float32(0.9357)] 
2025-01-24 21:44:29.179507: Epoch time: 49.06 s 
2025-01-24 21:44:30.415541:  
2025-01-24 21:44:30.418838: Epoch 698 
2025-01-24 21:44:30.421509: Current learning rate: 0.0034 
2025-01-24 21:45:19.401806: train_loss -0.8187 
2025-01-24 21:45:19.408808: val_loss -0.7114 
2025-01-24 21:45:19.411761: Pseudo dice [np.float32(0.9495), np.float32(0.9166)] 
2025-01-24 21:45:19.414450: Epoch time: 48.99 s 
2025-01-24 21:45:20.674189:  
2025-01-24 21:45:20.677234: Epoch 699 
2025-01-24 21:45:20.681100: Current learning rate: 0.00339 
2025-01-24 21:46:09.054244: train_loss -0.8155 
2025-01-24 21:46:09.060813: val_loss -0.7595 
2025-01-24 21:46:09.063286: Pseudo dice [np.float32(0.9473), np.float32(0.915)] 
2025-01-24 21:46:09.065841: Epoch time: 48.38 s 
2025-01-24 21:46:11.475631:  
2025-01-24 21:46:11.481028: Epoch 700 
2025-01-24 21:46:11.483805: Current learning rate: 0.00338 
2025-01-24 21:47:00.270116: train_loss -0.8107 
2025-01-24 21:47:00.277305: val_loss -0.7176 
2025-01-24 21:47:00.280249: Pseudo dice [np.float32(0.9434), np.float32(0.8584)] 
2025-01-24 21:47:00.283412: Epoch time: 48.8 s 
2025-01-24 21:47:01.550555:  
2025-01-24 21:47:01.554957: Epoch 701 
2025-01-24 21:47:01.557678: Current learning rate: 0.00337 
2025-01-24 21:47:50.364307: train_loss -0.8186 
2025-01-24 21:47:50.371569: val_loss -0.7644 
2025-01-24 21:47:50.374245: Pseudo dice [np.float32(0.957), np.float32(0.8665)] 
2025-01-24 21:47:50.376768: Epoch time: 48.81 s 
2025-01-24 21:47:51.642428:  
2025-01-24 21:47:51.646132: Epoch 702 
2025-01-24 21:47:51.648880: Current learning rate: 0.00336 
2025-01-24 21:48:40.226373: train_loss -0.8058 
2025-01-24 21:48:40.232845: val_loss -0.7247 
2025-01-24 21:48:40.235272: Pseudo dice [np.float32(0.949), np.float32(0.914)] 
2025-01-24 21:48:40.237644: Epoch time: 48.58 s 
2025-01-24 21:48:41.511879:  
2025-01-24 21:48:41.514874: Epoch 703 
2025-01-24 21:48:41.517339: Current learning rate: 0.00335 
2025-01-24 21:49:29.898143: train_loss -0.8305 
2025-01-24 21:49:29.906211: val_loss -0.7469 
2025-01-24 21:49:29.909097: Pseudo dice [np.float32(0.9527), np.float32(0.9181)] 
2025-01-24 21:49:29.911941: Epoch time: 48.39 s 
2025-01-24 21:49:31.136722:  
2025-01-24 21:49:31.140439: Epoch 704 
2025-01-24 21:49:31.143449: Current learning rate: 0.00334 
2025-01-24 21:50:19.590642: train_loss -0.8412 
2025-01-24 21:50:19.596722: val_loss -0.7298 
2025-01-24 21:50:19.599000: Pseudo dice [np.float32(0.9357), np.float32(0.9178)] 
2025-01-24 21:50:19.601308: Epoch time: 48.45 s 
2025-01-24 21:50:20.873520:  
2025-01-24 21:50:20.877869: Epoch 705 
2025-01-24 21:50:20.880708: Current learning rate: 0.00333 
2025-01-24 21:51:09.440874: train_loss -0.822 
2025-01-24 21:51:09.447479: val_loss -0.7653 
2025-01-24 21:51:09.451239: Pseudo dice [np.float32(0.9489), np.float32(0.8805)] 
2025-01-24 21:51:09.454005: Epoch time: 48.57 s 
2025-01-24 21:51:10.692961:  
2025-01-24 21:51:10.695833: Epoch 706 
2025-01-24 21:51:10.698796: Current learning rate: 0.00332 
2025-01-24 21:51:59.257404: train_loss -0.8433 
2025-01-24 21:51:59.264588: val_loss -0.734 
2025-01-24 21:51:59.268944: Pseudo dice [np.float32(0.9557), np.float32(0.8929)] 
2025-01-24 21:51:59.271451: Epoch time: 48.57 s 
2025-01-24 21:52:00.514720:  
2025-01-24 21:52:00.517525: Epoch 707 
2025-01-24 21:52:00.520148: Current learning rate: 0.00331 
2025-01-24 21:52:49.077286: train_loss -0.8356 
2025-01-24 21:52:49.083013: val_loss -0.713 
2025-01-24 21:52:49.085476: Pseudo dice [np.float32(0.9543), np.float32(0.9232)] 
2025-01-24 21:52:49.087750: Epoch time: 48.56 s 
2025-01-24 21:52:50.316966:  
2025-01-24 21:52:50.319575: Epoch 708 
2025-01-24 21:52:50.322371: Current learning rate: 0.0033 
2025-01-24 21:53:39.199355: train_loss -0.8254 
2025-01-24 21:53:39.205895: val_loss -0.7614 
2025-01-24 21:53:39.208648: Pseudo dice [np.float32(0.9465), np.float32(0.8518)] 
2025-01-24 21:53:39.211058: Epoch time: 48.88 s 
2025-01-24 21:53:40.483153:  
2025-01-24 21:53:40.485826: Epoch 709 
2025-01-24 21:53:40.488424: Current learning rate: 0.00329 
2025-01-24 21:54:29.087291: train_loss -0.8417 
2025-01-24 21:54:29.095169: val_loss -0.7454 
2025-01-24 21:54:29.098090: Pseudo dice [np.float32(0.9554), np.float32(0.9234)] 
2025-01-24 21:54:29.100704: Epoch time: 48.61 s 
2025-01-24 21:54:30.340137:  
2025-01-24 21:54:30.343488: Epoch 710 
2025-01-24 21:54:30.347056: Current learning rate: 0.00328 
2025-01-24 21:55:19.518160: train_loss -0.8332 
2025-01-24 21:55:19.524972: val_loss -0.7646 
2025-01-24 21:55:19.527355: Pseudo dice [np.float32(0.9548), np.float32(0.9064)] 
2025-01-24 21:55:19.529771: Epoch time: 49.18 s 
2025-01-24 21:55:20.797791:  
2025-01-24 21:55:20.800483: Epoch 711 
2025-01-24 21:55:20.803331: Current learning rate: 0.00327 
2025-01-24 21:56:09.409872: train_loss -0.8369 
2025-01-24 21:56:09.416396: val_loss -0.7454 
2025-01-24 21:56:09.419289: Pseudo dice [np.float32(0.9524), np.float32(0.9007)] 
2025-01-24 21:56:09.422033: Epoch time: 48.61 s 
2025-01-24 21:56:10.661829:  
2025-01-24 21:56:10.664550: Epoch 712 
2025-01-24 21:56:10.667037: Current learning rate: 0.00326 
2025-01-24 21:56:59.558690: train_loss -0.8419 
2025-01-24 21:56:59.565902: val_loss -0.7941 
2025-01-24 21:56:59.569067: Pseudo dice [np.float32(0.9567), np.float32(0.9292)] 
2025-01-24 21:56:59.572024: Epoch time: 48.9 s 
2025-01-24 21:57:00.814939:  
2025-01-24 21:57:00.818024: Epoch 713 
2025-01-24 21:57:00.821031: Current learning rate: 0.00325 
2025-01-24 21:57:49.723646: train_loss -0.8276 
2025-01-24 21:57:49.731937: val_loss -0.7878 
2025-01-24 21:57:49.737177: Pseudo dice [np.float32(0.9476), np.float32(0.9109)] 
2025-01-24 21:57:49.739924: Epoch time: 48.91 s 
2025-01-24 21:57:50.986027:  
2025-01-24 21:57:50.989211: Epoch 714 
2025-01-24 21:57:50.992592: Current learning rate: 0.00324 
2025-01-24 21:58:39.897180: train_loss -0.8453 
2025-01-24 21:58:39.904619: val_loss -0.7258 
2025-01-24 21:58:39.907757: Pseudo dice [np.float32(0.9572), np.float32(0.8748)] 
2025-01-24 21:58:39.910708: Epoch time: 48.91 s 
2025-01-24 21:58:41.149879:  
2025-01-24 21:58:41.152936: Epoch 715 
2025-01-24 21:58:41.155625: Current learning rate: 0.00323 
2025-01-24 21:59:29.850191: train_loss -0.8357 
2025-01-24 21:59:29.857504: val_loss -0.7204 
2025-01-24 21:59:29.860508: Pseudo dice [np.float32(0.9384), np.float32(0.902)] 
2025-01-24 21:59:29.863041: Epoch time: 48.7 s 
2025-01-24 21:59:31.132944:  
2025-01-24 21:59:31.136036: Epoch 716 
2025-01-24 21:59:31.138751: Current learning rate: 0.00322 
2025-01-24 22:00:19.586300: train_loss -0.8408 
2025-01-24 22:00:19.592443: val_loss -0.7678 
2025-01-24 22:00:19.594992: Pseudo dice [np.float32(0.9586), np.float32(0.9342)] 
2025-01-24 22:00:19.597347: Epoch time: 48.45 s 
2025-01-24 22:00:20.828909:  
2025-01-24 22:00:20.831664: Epoch 717 
2025-01-24 22:00:20.834478: Current learning rate: 0.00321 
2025-01-24 22:01:09.790053: train_loss -0.833 
2025-01-24 22:01:09.797193: val_loss -0.7671 
2025-01-24 22:01:09.799784: Pseudo dice [np.float32(0.951), np.float32(0.9009)] 
2025-01-24 22:01:09.802081: Epoch time: 48.96 s 
2025-01-24 22:01:11.630302:  
2025-01-24 22:01:11.633229: Epoch 718 
2025-01-24 22:01:11.636130: Current learning rate: 0.0032 
2025-01-24 22:01:59.963267: train_loss -0.8412 
2025-01-24 22:01:59.971755: val_loss -0.7543 
2025-01-24 22:01:59.974370: Pseudo dice [np.float32(0.9511), np.float32(0.9135)] 
2025-01-24 22:01:59.977332: Epoch time: 48.33 s 
2025-01-24 22:02:01.208494:  
2025-01-24 22:02:01.211456: Epoch 719 
2025-01-24 22:02:01.214155: Current learning rate: 0.00319 
2025-01-24 22:02:50.244865: train_loss -0.8492 
2025-01-24 22:02:50.253066: val_loss -0.7459 
2025-01-24 22:02:50.255535: Pseudo dice [np.float32(0.9543), np.float32(0.8929)] 
2025-01-24 22:02:50.257897: Epoch time: 49.04 s 
2025-01-24 22:02:51.513456:  
2025-01-24 22:02:51.516839: Epoch 720 
2025-01-24 22:02:51.519724: Current learning rate: 0.00318 
2025-01-24 22:03:40.605783: train_loss -0.8306 
2025-01-24 22:03:40.613583: val_loss -0.7907 
2025-01-24 22:03:40.616218: Pseudo dice [np.float32(0.9482), np.float32(0.9251)] 
2025-01-24 22:03:40.618901: Epoch time: 49.1 s 
2025-01-24 22:03:41.862967:  
2025-01-24 22:03:41.866166: Epoch 721 
2025-01-24 22:03:41.868562: Current learning rate: 0.00317 
2025-01-24 22:04:30.358411: train_loss -0.8301 
2025-01-24 22:04:30.365823: val_loss -0.795 
2025-01-24 22:04:30.368198: Pseudo dice [np.float32(0.9389), np.float32(0.926)] 
2025-01-24 22:04:30.370647: Epoch time: 48.5 s 
2025-01-24 22:04:31.649532:  
2025-01-24 22:04:31.654590: Epoch 722 
2025-01-24 22:04:31.657540: Current learning rate: 0.00316 
2025-01-24 22:05:20.226338: train_loss -0.834 
2025-01-24 22:05:20.234912: val_loss -0.7512 
2025-01-24 22:05:20.237811: Pseudo dice [np.float32(0.9349), np.float32(0.9001)] 
2025-01-24 22:05:20.240579: Epoch time: 48.58 s 
2025-01-24 22:05:21.477696:  
2025-01-24 22:05:21.482777: Epoch 723 
2025-01-24 22:05:21.486091: Current learning rate: 0.00315 
2025-01-24 22:06:10.331800: train_loss -0.8382 
2025-01-24 22:06:10.341748: val_loss -0.7107 
2025-01-24 22:06:10.344975: Pseudo dice [np.float32(0.9539), np.float32(0.8051)] 
2025-01-24 22:06:10.348024: Epoch time: 48.86 s 
2025-01-24 22:06:11.590383:  
2025-01-24 22:06:11.593458: Epoch 724 
2025-01-24 22:06:11.596191: Current learning rate: 0.00314 
2025-01-24 22:07:00.023549: train_loss -0.8403 
2025-01-24 22:07:00.031766: val_loss -0.7365 
2025-01-24 22:07:00.034313: Pseudo dice [np.float32(0.9549), np.float32(0.882)] 
2025-01-24 22:07:00.036862: Epoch time: 48.43 s 
2025-01-24 22:07:01.323669:  
2025-01-24 22:07:01.327066: Epoch 725 
2025-01-24 22:07:01.330149: Current learning rate: 0.00313 
2025-01-24 22:07:50.257350: train_loss -0.8394 
2025-01-24 22:07:50.266363: val_loss -0.7445 
2025-01-24 22:07:50.269193: Pseudo dice [np.float32(0.9554), np.float32(0.8869)] 
2025-01-24 22:07:50.271599: Epoch time: 48.93 s 
2025-01-24 22:07:51.533889:  
2025-01-24 22:07:51.537408: Epoch 726 
2025-01-24 22:07:51.540231: Current learning rate: 0.00312 
2025-01-24 22:08:40.295708: train_loss -0.8463 
2025-01-24 22:08:40.304495: val_loss -0.7922 
2025-01-24 22:08:40.307459: Pseudo dice [np.float32(0.9649), np.float32(0.9424)] 
2025-01-24 22:08:40.310289: Epoch time: 48.76 s 
2025-01-24 22:08:41.618101:  
2025-01-24 22:08:41.621179: Epoch 727 
2025-01-24 22:08:41.623742: Current learning rate: 0.00311 
2025-01-24 22:09:30.216997: train_loss -0.8318 
2025-01-24 22:09:30.228163: val_loss -0.7173 
2025-01-24 22:09:30.231340: Pseudo dice [np.float32(0.9536), np.float32(0.9154)] 
2025-01-24 22:09:30.234571: Epoch time: 48.6 s 
2025-01-24 22:09:31.501273:  
2025-01-24 22:09:31.506168: Epoch 728 
2025-01-24 22:09:31.509315: Current learning rate: 0.0031 
2025-01-24 22:10:20.356535: train_loss -0.8408 
2025-01-24 22:10:20.366050: val_loss -0.7058 
2025-01-24 22:10:20.368823: Pseudo dice [np.float32(0.9539), np.float32(0.92)] 
2025-01-24 22:10:20.371676: Epoch time: 48.86 s 
2025-01-24 22:10:21.644507:  
2025-01-24 22:10:21.647191: Epoch 729 
2025-01-24 22:10:21.650209: Current learning rate: 0.00309 
2025-01-24 22:11:10.154264: train_loss -0.8339 
2025-01-24 22:11:10.162731: val_loss -0.7804 
2025-01-24 22:11:10.166101: Pseudo dice [np.float32(0.9435), np.float32(0.9162)] 
2025-01-24 22:11:10.169235: Epoch time: 48.51 s 
2025-01-24 22:11:11.431718:  
2025-01-24 22:11:11.434711: Epoch 730 
2025-01-24 22:11:11.437303: Current learning rate: 0.00308 
2025-01-24 22:11:59.986668: train_loss -0.8448 
2025-01-24 22:11:59.993286: val_loss -0.771 
2025-01-24 22:11:59.995898: Pseudo dice [np.float32(0.9421), np.float32(0.9133)] 
2025-01-24 22:11:59.998166: Epoch time: 48.56 s 
2025-01-24 22:12:01.250429:  
2025-01-24 22:12:01.252947: Epoch 731 
2025-01-24 22:12:01.255388: Current learning rate: 0.00307 
2025-01-24 22:12:49.651253: train_loss -0.8312 
2025-01-24 22:12:49.659302: val_loss -0.7887 
2025-01-24 22:12:49.661844: Pseudo dice [np.float32(0.9501), np.float32(0.9328)] 
2025-01-24 22:12:49.664496: Epoch time: 48.4 s 
2025-01-24 22:12:50.918961:  
2025-01-24 22:12:50.922214: Epoch 732 
2025-01-24 22:12:50.925037: Current learning rate: 0.00306 
2025-01-24 22:13:39.379360: train_loss -0.818 
2025-01-24 22:13:39.386252: val_loss -0.7819 
2025-01-24 22:13:39.388811: Pseudo dice [np.float32(0.9502), np.float32(0.8996)] 
2025-01-24 22:13:39.391431: Epoch time: 48.46 s 
2025-01-24 22:13:40.645941:  
2025-01-24 22:13:40.648700: Epoch 733 
2025-01-24 22:13:40.651104: Current learning rate: 0.00305 
2025-01-24 22:14:28.991474: train_loss -0.8264 
2025-01-24 22:14:28.999707: val_loss -0.7736 
2025-01-24 22:14:29.002369: Pseudo dice [np.float32(0.9532), np.float32(0.8866)] 
2025-01-24 22:14:29.004919: Epoch time: 48.35 s 
2025-01-24 22:14:30.260911:  
2025-01-24 22:14:30.263845: Epoch 734 
2025-01-24 22:14:30.266562: Current learning rate: 0.00304 
2025-01-24 22:15:18.797570: train_loss -0.8342 
2025-01-24 22:15:18.804514: val_loss -0.7933 
2025-01-24 22:15:18.806882: Pseudo dice [np.float32(0.944), np.float32(0.9288)] 
2025-01-24 22:15:18.809256: Epoch time: 48.54 s 
2025-01-24 22:15:20.060359:  
2025-01-24 22:15:20.063369: Epoch 735 
2025-01-24 22:15:20.065950: Current learning rate: 0.00303 
2025-01-24 22:16:08.606553: train_loss -0.834 
2025-01-24 22:16:08.615202: val_loss -0.7921 
2025-01-24 22:16:08.617858: Pseudo dice [np.float32(0.9544), np.float32(0.8979)] 
2025-01-24 22:16:08.620462: Epoch time: 48.55 s 
2025-01-24 22:16:10.632349:  
2025-01-24 22:16:10.635327: Epoch 736 
2025-01-24 22:16:10.637723: Current learning rate: 0.00302 
2025-01-24 22:16:59.582486: train_loss -0.8417 
2025-01-24 22:16:59.590815: val_loss -0.806 
2025-01-24 22:16:59.593586: Pseudo dice [np.float32(0.9557), np.float32(0.9501)] 
2025-01-24 22:16:59.596173: Epoch time: 48.95 s 
2025-01-24 22:17:00.859554:  
2025-01-24 22:17:00.862830: Epoch 737 
2025-01-24 22:17:00.865744: Current learning rate: 0.00301 
2025-01-24 22:17:49.854641: train_loss -0.8199 
2025-01-24 22:17:49.863346: val_loss -0.7676 
2025-01-24 22:17:49.865945: Pseudo dice [np.float32(0.9499), np.float32(0.9257)] 
2025-01-24 22:17:49.868491: Epoch time: 49.0 s 
2025-01-24 22:17:51.132897:  
2025-01-24 22:17:51.135251: Epoch 738 
2025-01-24 22:17:51.137696: Current learning rate: 0.003 
2025-01-24 22:18:39.375514: train_loss -0.8339 
2025-01-24 22:18:39.382179: val_loss -0.7656 
2025-01-24 22:18:39.384798: Pseudo dice [np.float32(0.9436), np.float32(0.9014)] 
2025-01-24 22:18:39.387253: Epoch time: 48.24 s 
2025-01-24 22:18:40.645349:  
2025-01-24 22:18:40.648460: Epoch 739 
2025-01-24 22:18:40.651125: Current learning rate: 0.00299 
2025-01-24 22:19:29.196211: train_loss -0.8416 
2025-01-24 22:19:29.203912: val_loss -0.7235 
2025-01-24 22:19:29.206308: Pseudo dice [np.float32(0.9562), np.float32(0.8427)] 
2025-01-24 22:19:29.208495: Epoch time: 48.55 s 
2025-01-24 22:19:30.468595:  
2025-01-24 22:19:30.471196: Epoch 740 
2025-01-24 22:19:30.473711: Current learning rate: 0.00297 
2025-01-24 22:20:18.867949: train_loss -0.8389 
2025-01-24 22:20:18.874907: val_loss -0.7837 
2025-01-24 22:20:18.877499: Pseudo dice [np.float32(0.9581), np.float32(0.8669)] 
2025-01-24 22:20:18.879999: Epoch time: 48.4 s 
2025-01-24 22:20:20.140689:  
2025-01-24 22:20:20.143999: Epoch 741 
2025-01-24 22:20:20.147341: Current learning rate: 0.00296 
2025-01-24 22:21:08.978027: train_loss -0.8233 
2025-01-24 22:21:08.985881: val_loss -0.7304 
2025-01-24 22:21:08.988539: Pseudo dice [np.float32(0.9543), np.float32(0.9173)] 
2025-01-24 22:21:08.991149: Epoch time: 48.84 s 
2025-01-24 22:21:10.252426:  
2025-01-24 22:21:10.255103: Epoch 742 
2025-01-24 22:21:10.257683: Current learning rate: 0.00295 
2025-01-24 22:21:58.917250: train_loss -0.8381 
2025-01-24 22:21:58.924329: val_loss -0.7896 
2025-01-24 22:21:58.926728: Pseudo dice [np.float32(0.9384), np.float32(0.894)] 
2025-01-24 22:21:58.929502: Epoch time: 48.67 s 
2025-01-24 22:22:00.229284:  
2025-01-24 22:22:00.232430: Epoch 743 
2025-01-24 22:22:00.235287: Current learning rate: 0.00294 
2025-01-24 22:22:48.762707: train_loss -0.8349 
2025-01-24 22:22:48.770730: val_loss -0.7517 
2025-01-24 22:22:48.773540: Pseudo dice [np.float32(0.9595), np.float32(0.9172)] 
2025-01-24 22:22:48.776184: Epoch time: 48.54 s 
2025-01-24 22:22:50.032609:  
2025-01-24 22:22:50.035335: Epoch 744 
2025-01-24 22:22:50.037864: Current learning rate: 0.00293 
2025-01-24 22:23:38.530024: train_loss -0.8318 
2025-01-24 22:23:38.536646: val_loss -0.7466 
2025-01-24 22:23:38.539319: Pseudo dice [np.float32(0.9416), np.float32(0.8696)] 
2025-01-24 22:23:38.541795: Epoch time: 48.5 s 
2025-01-24 22:23:39.779201:  
2025-01-24 22:23:39.782703: Epoch 745 
2025-01-24 22:23:39.785635: Current learning rate: 0.00292 
2025-01-24 22:24:28.777663: train_loss -0.8321 
2025-01-24 22:24:28.785596: val_loss -0.7945 
2025-01-24 22:24:28.788608: Pseudo dice [np.float32(0.9522), np.float32(0.9218)] 
2025-01-24 22:24:28.791613: Epoch time: 49.0 s 
2025-01-24 22:24:30.075239:  
2025-01-24 22:24:30.079368: Epoch 746 
2025-01-24 22:24:30.081976: Current learning rate: 0.00291 
2025-01-24 22:25:18.675076: train_loss -0.824 
2025-01-24 22:25:18.681574: val_loss -0.7085 
2025-01-24 22:25:18.684213: Pseudo dice [np.float32(0.9497), np.float32(0.8839)] 
2025-01-24 22:25:18.686769: Epoch time: 48.6 s 
2025-01-24 22:25:19.941040:  
2025-01-24 22:25:19.944548: Epoch 747 
2025-01-24 22:25:19.947892: Current learning rate: 0.0029 
2025-01-24 22:26:08.617818: train_loss -0.8598 
2025-01-24 22:26:08.624432: val_loss -0.7521 
2025-01-24 22:26:08.627176: Pseudo dice [np.float32(0.9515), np.float32(0.9101)] 
2025-01-24 22:26:08.629744: Epoch time: 48.68 s 
2025-01-24 22:26:09.908286:  
2025-01-24 22:26:09.911192: Epoch 748 
2025-01-24 22:26:09.914206: Current learning rate: 0.00289 
2025-01-24 22:26:58.829044: train_loss -0.8519 
2025-01-24 22:26:58.837398: val_loss -0.7833 
2025-01-24 22:26:58.841043: Pseudo dice [np.float32(0.9508), np.float32(0.9243)] 
2025-01-24 22:26:58.843521: Epoch time: 48.92 s 
2025-01-24 22:27:00.069838:  
2025-01-24 22:27:00.072585: Epoch 749 
2025-01-24 22:27:00.075049: Current learning rate: 0.00288 
2025-01-24 22:27:48.578064: train_loss -0.8268 
2025-01-24 22:27:48.585347: val_loss -0.7528 
2025-01-24 22:27:48.587763: Pseudo dice [np.float32(0.9572), np.float32(0.8828)] 
2025-01-24 22:27:48.590329: Epoch time: 48.51 s 
2025-01-24 22:27:50.432863:  
2025-01-24 22:27:50.437026: Epoch 750 
2025-01-24 22:27:50.439599: Current learning rate: 0.00287 
2025-01-24 22:28:38.604557: train_loss -0.8341 
2025-01-24 22:28:38.610379: val_loss -0.8067 
2025-01-24 22:28:38.613139: Pseudo dice [np.float32(0.9565), np.float32(0.9371)] 
2025-01-24 22:28:38.615797: Epoch time: 48.17 s 
2025-01-24 22:28:39.846352:  
2025-01-24 22:28:39.849312: Epoch 751 
2025-01-24 22:28:39.852082: Current learning rate: 0.00286 
2025-01-24 22:29:28.288523: train_loss -0.8357 
2025-01-24 22:29:28.296192: val_loss -0.7625 
2025-01-24 22:29:28.298883: Pseudo dice [np.float32(0.9589), np.float32(0.9336)] 
2025-01-24 22:29:28.301360: Epoch time: 48.44 s 
2025-01-24 22:29:29.537721:  
2025-01-24 22:29:29.540522: Epoch 752 
2025-01-24 22:29:29.543363: Current learning rate: 0.00285 
2025-01-24 22:30:18.157790: train_loss -0.833 
2025-01-24 22:30:18.164847: val_loss -0.7423 
2025-01-24 22:30:18.167278: Pseudo dice [np.float32(0.9597), np.float32(0.9355)] 
2025-01-24 22:30:18.169610: Epoch time: 48.62 s 
2025-01-24 22:30:19.410490:  
2025-01-24 22:30:19.413289: Epoch 753 
2025-01-24 22:30:19.416034: Current learning rate: 0.00284 
2025-01-24 22:31:08.208015: train_loss -0.8397 
2025-01-24 22:31:08.214859: val_loss -0.8017 
2025-01-24 22:31:08.217486: Pseudo dice [np.float32(0.9572), np.float32(0.9157)] 
2025-01-24 22:31:08.219896: Epoch time: 48.8 s 
2025-01-24 22:31:10.016805:  
2025-01-24 22:31:10.020023: Epoch 754 
2025-01-24 22:31:10.023035: Current learning rate: 0.00283 
2025-01-24 22:31:58.888238: train_loss -0.8417 
2025-01-24 22:31:58.894604: val_loss -0.7455 
2025-01-24 22:31:58.897020: Pseudo dice [np.float32(0.9575), np.float32(0.9348)] 
2025-01-24 22:31:58.899516: Epoch time: 48.87 s 
2025-01-24 22:32:00.131609:  
2025-01-24 22:32:00.135997: Epoch 755 
2025-01-24 22:32:00.138287: Current learning rate: 0.00282 
2025-01-24 22:32:48.691288: train_loss -0.8295 
2025-01-24 22:32:48.698922: val_loss -0.748 
2025-01-24 22:32:48.701807: Pseudo dice [np.float32(0.95), np.float32(0.9131)] 
2025-01-24 22:32:48.704541: Epoch time: 48.56 s 
2025-01-24 22:32:49.966012:  
2025-01-24 22:32:49.968844: Epoch 756 
2025-01-24 22:32:49.971484: Current learning rate: 0.00281 
2025-01-24 22:33:38.449328: train_loss -0.8258 
2025-01-24 22:33:38.455868: val_loss -0.7852 
2025-01-24 22:33:38.458571: Pseudo dice [np.float32(0.954), np.float32(0.9242)] 
2025-01-24 22:33:38.461138: Epoch time: 48.48 s 
2025-01-24 22:33:39.700890:  
2025-01-24 22:33:39.703570: Epoch 757 
2025-01-24 22:33:39.706203: Current learning rate: 0.0028 
2025-01-24 22:34:28.268456: train_loss -0.821 
2025-01-24 22:34:28.274901: val_loss -0.7918 
2025-01-24 22:34:28.277463: Pseudo dice [np.float32(0.9448), np.float32(0.9228)] 
2025-01-24 22:34:28.280179: Epoch time: 48.57 s 
2025-01-24 22:34:29.557022:  
2025-01-24 22:34:29.560071: Epoch 758 
2025-01-24 22:34:29.562775: Current learning rate: 0.00279 
2025-01-24 22:35:17.667268: train_loss -0.8357 
2025-01-24 22:35:17.676625: val_loss -0.7757 
2025-01-24 22:35:17.679284: Pseudo dice [np.float32(0.9563), np.float32(0.932)] 
2025-01-24 22:35:17.681735: Epoch time: 48.11 s 
2025-01-24 22:35:18.907468:  
2025-01-24 22:35:18.911073: Epoch 759 
2025-01-24 22:35:18.913950: Current learning rate: 0.00278 
2025-01-24 22:36:07.792777: train_loss -0.8224 
2025-01-24 22:36:07.799914: val_loss -0.6442 
2025-01-24 22:36:07.802338: Pseudo dice [np.float32(0.9446), np.float32(0.6798)] 
2025-01-24 22:36:07.804887: Epoch time: 48.89 s 
2025-01-24 22:36:09.081118:  
2025-01-24 22:36:09.084142: Epoch 760 
2025-01-24 22:36:09.086812: Current learning rate: 0.00277 
2025-01-24 22:36:57.766862: train_loss -0.822 
2025-01-24 22:36:57.774823: val_loss -0.7729 
2025-01-24 22:36:57.777735: Pseudo dice [np.float32(0.9526), np.float32(0.8959)] 
2025-01-24 22:36:57.780445: Epoch time: 48.69 s 
2025-01-24 22:36:59.016178:  
2025-01-24 22:36:59.019005: Epoch 761 
2025-01-24 22:36:59.021880: Current learning rate: 0.00276 
2025-01-24 22:37:47.796485: train_loss -0.8442 
2025-01-24 22:37:47.804047: val_loss -0.7807 
2025-01-24 22:37:47.806601: Pseudo dice [np.float32(0.9447), np.float32(0.9149)] 
2025-01-24 22:37:47.809074: Epoch time: 48.78 s 
2025-01-24 22:37:49.045513:  
2025-01-24 22:37:49.048327: Epoch 762 
2025-01-24 22:37:49.050769: Current learning rate: 0.00275 
2025-01-24 22:38:38.400839: train_loss -0.8321 
2025-01-24 22:38:38.408103: val_loss -0.7408 
2025-01-24 22:38:38.410473: Pseudo dice [np.float32(0.9482), np.float32(0.915)] 
2025-01-24 22:38:38.412845: Epoch time: 49.36 s 
2025-01-24 22:38:39.672767:  
2025-01-24 22:38:39.676150: Epoch 763 
2025-01-24 22:38:39.679740: Current learning rate: 0.00274 
2025-01-24 22:39:29.169956: train_loss -0.821 
2025-01-24 22:39:29.177735: val_loss -0.7891 
2025-01-24 22:39:29.180295: Pseudo dice [np.float32(0.9565), np.float32(0.938)] 
2025-01-24 22:39:29.182852: Epoch time: 49.5 s 
2025-01-24 22:39:30.476084:  
2025-01-24 22:39:30.479064: Epoch 764 
2025-01-24 22:39:30.482046: Current learning rate: 0.00273 
2025-01-24 22:40:19.539891: train_loss -0.832 
2025-01-24 22:40:19.547922: val_loss -0.7561 
2025-01-24 22:40:19.550417: Pseudo dice [np.float32(0.9265), np.float32(0.8885)] 
2025-01-24 22:40:19.553068: Epoch time: 49.06 s 
2025-01-24 22:40:20.806622:  
2025-01-24 22:40:20.809472: Epoch 765 
2025-01-24 22:40:20.812260: Current learning rate: 0.00272 
2025-01-24 22:41:10.162697: train_loss -0.8334 
2025-01-24 22:41:10.170430: val_loss -0.7502 
2025-01-24 22:41:10.173397: Pseudo dice [np.float32(0.9564), np.float32(0.9165)] 
2025-01-24 22:41:10.176190: Epoch time: 49.36 s 
2025-01-24 22:41:11.471340:  
2025-01-24 22:41:11.473865: Epoch 766 
2025-01-24 22:41:11.476268: Current learning rate: 0.00271 
2025-01-24 22:42:00.664267: train_loss -0.8322 
2025-01-24 22:42:00.671215: val_loss -0.749 
2025-01-24 22:42:00.673769: Pseudo dice [np.float32(0.9571), np.float32(0.9374)] 
2025-01-24 22:42:00.676433: Epoch time: 49.19 s 
2025-01-24 22:42:01.926972:  
2025-01-24 22:42:01.930145: Epoch 767 
2025-01-24 22:42:01.932892: Current learning rate: 0.0027 
2025-01-24 22:42:50.838501: train_loss -0.8503 
2025-01-24 22:42:50.845607: val_loss -0.7474 
2025-01-24 22:42:50.848109: Pseudo dice [np.float32(0.9488), np.float32(0.8762)] 
2025-01-24 22:42:50.850929: Epoch time: 48.91 s 
2025-01-24 22:42:52.112219:  
2025-01-24 22:42:52.115208: Epoch 768 
2025-01-24 22:42:52.117854: Current learning rate: 0.00268 
2025-01-24 22:43:40.742433: train_loss -0.8295 
2025-01-24 22:43:40.750952: val_loss -0.7949 
2025-01-24 22:43:40.753603: Pseudo dice [np.float32(0.949), np.float32(0.9263)] 
2025-01-24 22:43:40.756531: Epoch time: 48.63 s 
2025-01-24 22:43:41.999450:  
2025-01-24 22:43:42.002346: Epoch 769 
2025-01-24 22:43:42.005469: Current learning rate: 0.00267 
2025-01-24 22:44:31.159837: train_loss -0.8399 
2025-01-24 22:44:31.167379: val_loss -0.7643 
2025-01-24 22:44:31.170193: Pseudo dice [np.float32(0.9467), np.float32(0.9298)] 
2025-01-24 22:44:31.173279: Epoch time: 49.16 s 
2025-01-24 22:44:32.439171:  
2025-01-24 22:44:32.442656: Epoch 770 
2025-01-24 22:44:32.445768: Current learning rate: 0.00266 
2025-01-24 22:45:20.783711: train_loss -0.8508 
2025-01-24 22:45:20.792691: val_loss -0.8031 
2025-01-24 22:45:20.795658: Pseudo dice [np.float32(0.9559), np.float32(0.9159)] 
2025-01-24 22:45:20.798486: Epoch time: 48.35 s 
2025-01-24 22:45:22.634344:  
2025-01-24 22:45:22.637305: Epoch 771 
2025-01-24 22:45:22.640189: Current learning rate: 0.00265 
2025-01-24 22:46:11.748279: train_loss -0.8339 
2025-01-24 22:46:11.757896: val_loss -0.7575 
2025-01-24 22:46:11.761014: Pseudo dice [np.float32(0.9566), np.float32(0.9087)] 
2025-01-24 22:46:11.764009: Epoch time: 49.11 s 
2025-01-24 22:46:13.016882:  
2025-01-24 22:46:13.021460: Epoch 772 
2025-01-24 22:46:13.024671: Current learning rate: 0.00264 
2025-01-24 22:47:01.497276: train_loss -0.8258 
2025-01-24 22:47:01.505766: val_loss -0.765 
2025-01-24 22:47:01.509065: Pseudo dice [np.float32(0.9505), np.float32(0.9156)] 
2025-01-24 22:47:01.511533: Epoch time: 48.48 s 
2025-01-24 22:47:02.804706:  
2025-01-24 22:47:02.807228: Epoch 773 
2025-01-24 22:47:02.809557: Current learning rate: 0.00263 
2025-01-24 22:47:51.211949: train_loss -0.8184 
2025-01-24 22:47:51.219051: val_loss -0.8046 
2025-01-24 22:47:51.221240: Pseudo dice [np.float32(0.9628), np.float32(0.9261)] 
2025-01-24 22:47:51.223575: Epoch time: 48.41 s 
2025-01-24 22:47:52.527117:  
2025-01-24 22:47:52.529536: Epoch 774 
2025-01-24 22:47:52.532060: Current learning rate: 0.00262 
2025-01-24 22:48:41.627354: train_loss -0.8358 
2025-01-24 22:48:41.636215: val_loss -0.787 
2025-01-24 22:48:41.638791: Pseudo dice [np.float32(0.9426), np.float32(0.937)] 
2025-01-24 22:48:41.641276: Epoch time: 49.1 s 
2025-01-24 22:48:42.939236:  
2025-01-24 22:48:42.941919: Epoch 775 
2025-01-24 22:48:42.944414: Current learning rate: 0.00261 
2025-01-24 22:49:31.620723: train_loss -0.8404 
2025-01-24 22:49:31.627284: val_loss -0.7716 
2025-01-24 22:49:31.629837: Pseudo dice [np.float32(0.9595), np.float32(0.9448)] 
2025-01-24 22:49:31.632548: Epoch time: 48.68 s 
2025-01-24 22:49:32.924233:  
2025-01-24 22:49:32.927060: Epoch 776 
2025-01-24 22:49:32.929448: Current learning rate: 0.0026 
2025-01-24 22:50:22.276661: train_loss -0.8349 
2025-01-24 22:50:22.284245: val_loss -0.7952 
2025-01-24 22:50:22.286814: Pseudo dice [np.float32(0.9529), np.float32(0.9283)] 
2025-01-24 22:50:22.289232: Epoch time: 49.35 s 
2025-01-24 22:50:23.605616:  
2025-01-24 22:50:23.609215: Epoch 777 
2025-01-24 22:50:23.612375: Current learning rate: 0.00259 
2025-01-24 22:51:12.361247: train_loss -0.8496 
2025-01-24 22:51:12.368129: val_loss -0.7936 
2025-01-24 22:51:12.371417: Pseudo dice [np.float32(0.959), np.float32(0.9471)] 
2025-01-24 22:51:12.374189: Epoch time: 48.76 s 
2025-01-24 22:51:13.669483:  
2025-01-24 22:51:13.672185: Epoch 778 
2025-01-24 22:51:13.674423: Current learning rate: 0.00258 
2025-01-24 22:52:02.027956: train_loss -0.8444 
2025-01-24 22:52:02.036384: val_loss -0.7714 
2025-01-24 22:52:02.039024: Pseudo dice [np.float32(0.952), np.float32(0.9242)] 
2025-01-24 22:52:02.041566: Epoch time: 48.36 s 
2025-01-24 22:52:03.340275:  
2025-01-24 22:52:03.342957: Epoch 779 
2025-01-24 22:52:03.345471: Current learning rate: 0.00257 
2025-01-24 22:52:51.830506: train_loss -0.8417 
2025-01-24 22:52:51.837698: val_loss -0.7988 
2025-01-24 22:52:51.840585: Pseudo dice [np.float32(0.9499), np.float32(0.9221)] 
2025-01-24 22:52:51.843360: Epoch time: 48.49 s 
2025-01-24 22:52:53.141083:  
2025-01-24 22:52:53.144057: Epoch 780 
2025-01-24 22:52:53.147308: Current learning rate: 0.00256 
2025-01-24 22:53:41.845974: train_loss -0.8404 
2025-01-24 22:53:41.853484: val_loss -0.7647 
2025-01-24 22:53:41.855778: Pseudo dice [np.float32(0.9433), np.float32(0.8967)] 
2025-01-24 22:53:41.858415: Epoch time: 48.71 s 
2025-01-24 22:53:43.144017:  
2025-01-24 22:53:43.146693: Epoch 781 
2025-01-24 22:53:43.149088: Current learning rate: 0.00255 
2025-01-24 22:54:32.192521: train_loss -0.837 
2025-01-24 22:54:32.199036: val_loss -0.7682 
2025-01-24 22:54:32.201401: Pseudo dice [np.float32(0.9481), np.float32(0.9213)] 
2025-01-24 22:54:32.203805: Epoch time: 49.05 s 
2025-01-24 22:54:33.486552:  
2025-01-24 22:54:33.489377: Epoch 782 
2025-01-24 22:54:33.492391: Current learning rate: 0.00254 
2025-01-24 22:55:21.702647: train_loss -0.8347 
2025-01-24 22:55:21.710795: val_loss -0.7291 
2025-01-24 22:55:21.714252: Pseudo dice [np.float32(0.9527), np.float32(0.9172)] 
2025-01-24 22:55:21.717676: Epoch time: 48.22 s 
2025-01-24 22:55:23.008464:  
2025-01-24 22:55:23.010867: Epoch 783 
2025-01-24 22:55:23.013291: Current learning rate: 0.00253 
2025-01-24 22:56:11.512365: train_loss -0.8344 
2025-01-24 22:56:11.519020: val_loss -0.7588 
2025-01-24 22:56:11.521862: Pseudo dice [np.float32(0.9437), np.float32(0.8987)] 
2025-01-24 22:56:11.524477: Epoch time: 48.5 s 
2025-01-24 22:56:12.815160:  
2025-01-24 22:56:12.817949: Epoch 784 
2025-01-24 22:56:12.820586: Current learning rate: 0.00252 
2025-01-24 22:57:01.357345: train_loss -0.8272 
2025-01-24 22:57:01.365331: val_loss -0.7565 
2025-01-24 22:57:01.367792: Pseudo dice [np.float32(0.9452), np.float32(0.9065)] 
2025-01-24 22:57:01.370203: Epoch time: 48.54 s 
2025-01-24 22:57:02.660999:  
2025-01-24 22:57:02.663701: Epoch 785 
2025-01-24 22:57:02.666116: Current learning rate: 0.00251 
2025-01-24 22:57:51.528247: train_loss -0.8408 
2025-01-24 22:57:51.533959: val_loss -0.7905 
2025-01-24 22:57:51.536556: Pseudo dice [np.float32(0.943), np.float32(0.9206)] 
2025-01-24 22:57:51.539151: Epoch time: 48.87 s 
2025-01-24 22:57:52.837982:  
2025-01-24 22:57:52.841285: Epoch 786 
2025-01-24 22:57:52.844284: Current learning rate: 0.0025 
2025-01-24 22:58:41.732581: train_loss -0.8285 
2025-01-24 22:58:41.739836: val_loss -0.7635 
2025-01-24 22:58:41.742253: Pseudo dice [np.float32(0.952), np.float32(0.8904)] 
2025-01-24 22:58:41.744608: Epoch time: 48.9 s 
2025-01-24 22:58:43.049413:  
2025-01-24 22:58:43.052608: Epoch 787 
2025-01-24 22:58:43.055621: Current learning rate: 0.00249 
2025-01-24 22:59:32.183054: train_loss -0.8365 
2025-01-24 22:59:32.189167: val_loss -0.7594 
2025-01-24 22:59:32.192109: Pseudo dice [np.float32(0.9535), np.float32(0.8788)] 
2025-01-24 22:59:32.194517: Epoch time: 49.13 s 
2025-01-24 22:59:34.149792:  
2025-01-24 22:59:34.152698: Epoch 788 
2025-01-24 22:59:34.155655: Current learning rate: 0.00248 
2025-01-24 23:00:22.977210: train_loss -0.8424 
2025-01-24 23:00:22.984567: val_loss -0.7936 
2025-01-24 23:00:22.987069: Pseudo dice [np.float32(0.9566), np.float32(0.9201)] 
2025-01-24 23:00:22.989628: Epoch time: 48.83 s 
2025-01-24 23:00:24.268287:  
2025-01-24 23:00:24.270973: Epoch 789 
2025-01-24 23:00:24.273451: Current learning rate: 0.00247 
2025-01-24 23:01:13.011481: train_loss -0.8617 
2025-01-24 23:01:13.016553: val_loss -0.8005 
2025-01-24 23:01:13.019236: Pseudo dice [np.float32(0.9541), np.float32(0.8943)] 
2025-01-24 23:01:13.022359: Epoch time: 48.74 s 
2025-01-24 23:01:14.308521:  
2025-01-24 23:01:14.311026: Epoch 790 
2025-01-24 23:01:14.313395: Current learning rate: 0.00245 
2025-01-24 23:02:02.702404: train_loss -0.8381 
2025-01-24 23:02:02.710022: val_loss -0.7632 
2025-01-24 23:02:02.712891: Pseudo dice [np.float32(0.9507), np.float32(0.9118)] 
2025-01-24 23:02:02.715719: Epoch time: 48.39 s 
2025-01-24 23:02:04.002716:  
2025-01-24 23:02:04.006260: Epoch 791 
2025-01-24 23:02:04.009351: Current learning rate: 0.00244 
2025-01-24 23:02:52.510002: train_loss -0.8447 
2025-01-24 23:02:52.516820: val_loss -0.7905 
2025-01-24 23:02:52.519394: Pseudo dice [np.float32(0.9524), np.float32(0.9081)] 
2025-01-24 23:02:52.521718: Epoch time: 48.51 s 
2025-01-24 23:02:53.820072:  
2025-01-24 23:02:53.823198: Epoch 792 
2025-01-24 23:02:53.826208: Current learning rate: 0.00243 
2025-01-24 23:03:42.524484: train_loss -0.8407 
2025-01-24 23:03:42.535100: val_loss -0.7959 
2025-01-24 23:03:42.538312: Pseudo dice [np.float32(0.9463), np.float32(0.917)] 
2025-01-24 23:03:42.541006: Epoch time: 48.71 s 
2025-01-24 23:03:43.838243:  
2025-01-24 23:03:43.841713: Epoch 793 
2025-01-24 23:03:43.848063: Current learning rate: 0.00242 
2025-01-24 23:04:32.781994: train_loss -0.8252 
2025-01-24 23:04:32.789178: val_loss -0.7525 
2025-01-24 23:04:32.792118: Pseudo dice [np.float32(0.9403), np.float32(0.8595)] 
2025-01-24 23:04:32.794614: Epoch time: 48.94 s 
2025-01-24 23:04:34.083680:  
2025-01-24 23:04:34.087374: Epoch 794 
2025-01-24 23:04:34.090184: Current learning rate: 0.00241 
2025-01-24 23:05:22.831298: train_loss -0.8298 
2025-01-24 23:05:22.839480: val_loss -0.7273 
2025-01-24 23:05:22.841907: Pseudo dice [np.float32(0.9503), np.float32(0.8952)] 
2025-01-24 23:05:22.844280: Epoch time: 48.75 s 
2025-01-24 23:05:24.089070:  
2025-01-24 23:05:24.092072: Epoch 795 
2025-01-24 23:05:24.094966: Current learning rate: 0.0024 
2025-01-24 23:06:12.862098: train_loss -0.8393 
2025-01-24 23:06:12.867546: val_loss -0.7727 
2025-01-24 23:06:12.869958: Pseudo dice [np.float32(0.9447), np.float32(0.9292)] 
2025-01-24 23:06:12.872351: Epoch time: 48.77 s 
2025-01-24 23:06:14.161598:  
2025-01-24 23:06:14.165148: Epoch 796 
2025-01-24 23:06:14.168209: Current learning rate: 0.00239 
2025-01-24 23:07:03.135638: train_loss -0.8325 
2025-01-24 23:07:03.143407: val_loss -0.7576 
2025-01-24 23:07:03.146291: Pseudo dice [np.float32(0.9566), np.float32(0.9314)] 
2025-01-24 23:07:03.149028: Epoch time: 48.98 s 
2025-01-24 23:07:04.453728:  
2025-01-24 23:07:04.456749: Epoch 797 
2025-01-24 23:07:04.459348: Current learning rate: 0.00238 
2025-01-24 23:07:53.138896: train_loss -0.8303 
2025-01-24 23:07:53.144845: val_loss -0.7627 
2025-01-24 23:07:53.147517: Pseudo dice [np.float32(0.9516), np.float32(0.9223)] 
2025-01-24 23:07:53.150293: Epoch time: 48.69 s 
2025-01-24 23:07:54.444133:  
2025-01-24 23:07:54.447640: Epoch 798 
2025-01-24 23:07:54.451720: Current learning rate: 0.00237 
2025-01-24 23:08:42.588282: train_loss -0.8465 
2025-01-24 23:08:42.595641: val_loss -0.7459 
2025-01-24 23:08:42.599167: Pseudo dice [np.float32(0.9534), np.float32(0.8737)] 
2025-01-24 23:08:42.602015: Epoch time: 48.15 s 
2025-01-24 23:08:43.882492:  
2025-01-24 23:08:43.885416: Epoch 799 
2025-01-24 23:08:43.888119: Current learning rate: 0.00236 
2025-01-24 23:09:32.844065: train_loss -0.823 
2025-01-24 23:09:32.849563: val_loss -0.7243 
2025-01-24 23:09:32.851914: Pseudo dice [np.float32(0.9477), np.float32(0.842)] 
2025-01-24 23:09:32.854183: Epoch time: 48.96 s 
2025-01-24 23:09:34.725899:  
2025-01-24 23:09:34.728888: Epoch 800 
2025-01-24 23:09:34.731891: Current learning rate: 0.00235 
2025-01-24 23:10:23.051301: train_loss -0.8321 
2025-01-24 23:10:23.057984: val_loss -0.7802 
2025-01-24 23:10:23.060519: Pseudo dice [np.float32(0.9567), np.float32(0.8362)] 
2025-01-24 23:10:23.062835: Epoch time: 48.33 s 
2025-01-24 23:10:24.345450:  
2025-01-24 23:10:24.348533: Epoch 801 
2025-01-24 23:10:24.351691: Current learning rate: 0.00234 
2025-01-24 23:11:13.199143: train_loss -0.8483 
2025-01-24 23:11:13.204921: val_loss -0.7811 
2025-01-24 23:11:13.207750: Pseudo dice [np.float32(0.9564), np.float32(0.8195)] 
2025-01-24 23:11:13.210169: Epoch time: 48.85 s 
2025-01-24 23:11:14.502270:  
2025-01-24 23:11:14.505182: Epoch 802 
2025-01-24 23:11:14.507998: Current learning rate: 0.00233 
2025-01-24 23:12:03.037907: train_loss -0.8269 
2025-01-24 23:12:03.046068: val_loss -0.7475 
2025-01-24 23:12:03.048815: Pseudo dice [np.float32(0.9502), np.float32(0.917)] 
2025-01-24 23:12:03.051475: Epoch time: 48.54 s 
2025-01-24 23:12:04.341883:  
2025-01-24 23:12:04.344683: Epoch 803 
2025-01-24 23:12:04.347106: Current learning rate: 0.00232 
2025-01-24 23:12:53.109900: train_loss -0.8519 
2025-01-24 23:12:53.116013: val_loss -0.8035 
2025-01-24 23:12:53.118381: Pseudo dice [np.float32(0.9557), np.float32(0.9424)] 
2025-01-24 23:12:53.120699: Epoch time: 48.77 s 
2025-01-24 23:12:54.418395:  
2025-01-24 23:12:54.421129: Epoch 804 
2025-01-24 23:12:54.424134: Current learning rate: 0.00231 
2025-01-24 23:13:43.695457: train_loss -0.8337 
2025-01-24 23:13:43.702887: val_loss -0.7246 
2025-01-24 23:13:43.705708: Pseudo dice [np.float32(0.9326), np.float32(0.9089)] 
2025-01-24 23:13:43.707981: Epoch time: 49.28 s 
2025-01-24 23:13:45.009348:  
2025-01-24 23:13:45.012860: Epoch 805 
2025-01-24 23:13:45.016100: Current learning rate: 0.0023 
2025-01-24 23:14:34.213505: train_loss -0.8395 
2025-01-24 23:14:34.219461: val_loss -0.7786 
2025-01-24 23:14:34.222365: Pseudo dice [np.float32(0.9313), np.float32(0.8959)] 
2025-01-24 23:14:34.225020: Epoch time: 49.21 s 
2025-01-24 23:14:36.195284:  
2025-01-24 23:14:36.198861: Epoch 806 
2025-01-24 23:14:36.201665: Current learning rate: 0.00229 
2025-01-24 23:15:25.456605: train_loss -0.832 
2025-01-24 23:15:25.464600: val_loss -0.7904 
2025-01-24 23:15:25.467230: Pseudo dice [np.float32(0.9526), np.float32(0.9369)] 
2025-01-24 23:15:25.469795: Epoch time: 49.26 s 
2025-01-24 23:15:26.788558:  
2025-01-24 23:15:26.791380: Epoch 807 
2025-01-24 23:15:26.793986: Current learning rate: 0.00228 
2025-01-24 23:16:15.595420: train_loss -0.8444 
2025-01-24 23:16:15.602875: val_loss -0.7671 
2025-01-24 23:16:15.605509: Pseudo dice [np.float32(0.9501), np.float32(0.9333)] 
2025-01-24 23:16:15.608011: Epoch time: 48.81 s 
2025-01-24 23:16:16.885450:  
2025-01-24 23:16:16.889291: Epoch 808 
2025-01-24 23:16:16.892119: Current learning rate: 0.00226 
