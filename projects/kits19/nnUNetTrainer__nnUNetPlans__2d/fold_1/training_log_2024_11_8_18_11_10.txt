
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2024-11-08 18:11:13.396378: Using torch.compile... 
2024-11-08 18:11:43.784249: do_dummy_2d_data_aug: False 
2024-11-08 18:11:45.189964: Using splits from existing split file: /srv/scratch/z5362216/kits19/nnUNet_db/nnUNet_preprocessed/Dataset001_Kits19/splits_final.json 
2024-11-08 18:11:45.224997: The split file contains 5 splits. 
2024-11-08 18:11:45.227344: Desired fold for training: 1 
2024-11-08 18:11:45.229504: This split has 80 training and 20 validation cases. 

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 12, 'patch_size': [512, 512], 'median_image_size_in_voxels': [512.0, 512.0], 'spacing': [0.7939453125, 0.7939453125], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 8, 'features_per_stage': [32, 64, 128, 256, 512, 512, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset001_Kits19', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [3.0, 0.7939453125, 0.7939453125], 'original_median_shape_after_transp': [104, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [2, 0, 1], 'transpose_backward': [1, 2, 0], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 2553.0, 'mean': 104.46720886230469, 'median': 104.0, 'min': -277.0, 'percentile_00_5': -73.0, 'percentile_99_5': 292.0, 'std': 74.68063354492188}}} 
 
2024-11-08 18:12:01.323649: unpacking dataset... 
2024-11-08 18:12:34.479115: unpacking done... 
2024-11-08 18:12:34.676717: Unable to plot network architecture: nnUNet_compile is enabled! 
2024-11-08 18:12:34.807228:  
2024-11-08 18:12:34.828610: Epoch 600 
2024-11-08 18:12:34.831325: Current learning rate: 0.00438 
2024-11-08 18:16:04.848584: train_loss -0.9239 
2024-11-08 18:16:04.862801: val_loss -0.8455 
2024-11-08 18:16:04.885306: Pseudo dice [np.float32(0.9387), np.float32(0.8472)] 
2024-11-08 18:16:04.887977: Epoch time: 210.04 s 
2024-11-08 18:16:07.008325:  
2024-11-08 18:16:07.011961: Epoch 601 
2024-11-08 18:16:07.014560: Current learning rate: 0.00437 
2024-11-08 18:16:46.732845: train_loss -0.9302 
2024-11-08 18:16:46.741205: val_loss -0.8564 
2024-11-08 18:16:46.744321: Pseudo dice [np.float32(0.9414), np.float32(0.8662)] 
2024-11-08 18:16:46.746729: Epoch time: 39.73 s 
2024-11-08 18:16:47.955405:  
2024-11-08 18:16:47.957793: Epoch 602 
2024-11-08 18:16:47.959964: Current learning rate: 0.00436 
2024-11-08 18:17:27.758918: train_loss -0.9279 
2024-11-08 18:17:27.765911: val_loss -0.8165 
2024-11-08 18:17:27.768749: Pseudo dice [np.float32(0.943), np.float32(0.776)] 
2024-11-08 18:17:27.771839: Epoch time: 39.8 s 
2024-11-08 18:17:29.498199:  
2024-11-08 18:17:29.500652: Epoch 603 
2024-11-08 18:17:29.503041: Current learning rate: 0.00435 
2024-11-08 18:18:09.315099: train_loss -0.9046 
2024-11-08 18:18:09.322621: val_loss -0.8462 
2024-11-08 18:18:09.324921: Pseudo dice [np.float32(0.933), np.float32(0.8592)] 
2024-11-08 18:18:09.327227: Epoch time: 39.82 s 
2024-11-08 18:18:10.544647:  
2024-11-08 18:18:10.546986: Epoch 604 
2024-11-08 18:18:10.549813: Current learning rate: 0.00434 
2024-11-08 18:18:50.367396: train_loss -0.9144 
2024-11-08 18:18:50.373843: val_loss -0.8778 
2024-11-08 18:18:50.376080: Pseudo dice [np.float32(0.948), np.float32(0.8814)] 
2024-11-08 18:18:50.378449: Epoch time: 39.82 s 
2024-11-08 18:18:51.588679:  
2024-11-08 18:18:51.591119: Epoch 605 
2024-11-08 18:18:51.593551: Current learning rate: 0.00433 
2024-11-08 18:19:31.391436: train_loss -0.9228 
2024-11-08 18:19:31.397564: val_loss -0.8883 
2024-11-08 18:19:31.399991: Pseudo dice [np.float32(0.9497), np.float32(0.9003)] 
2024-11-08 18:19:31.402520: Epoch time: 39.8 s 
2024-11-08 18:19:32.627289:  
2024-11-08 18:19:32.630367: Epoch 606 
2024-11-08 18:19:32.632941: Current learning rate: 0.00432 
2024-11-08 18:20:12.447980: train_loss -0.9285 
2024-11-08 18:20:12.456745: val_loss -0.8374 
2024-11-08 18:20:12.459236: Pseudo dice [np.float32(0.9227), np.float32(0.851)] 
2024-11-08 18:20:12.462062: Epoch time: 39.82 s 
2024-11-08 18:20:13.679877:  
2024-11-08 18:20:13.682400: Epoch 607 
2024-11-08 18:20:13.684865: Current learning rate: 0.00431 
2024-11-08 18:20:53.522910: train_loss -0.9005 
2024-11-08 18:20:53.529519: val_loss -0.8459 
2024-11-08 18:20:53.531980: Pseudo dice [np.float32(0.9384), np.float32(0.8573)] 
2024-11-08 18:20:53.535172: Epoch time: 39.84 s 
2024-11-08 18:20:54.750098:  
2024-11-08 18:20:54.752657: Epoch 608 
2024-11-08 18:20:54.755276: Current learning rate: 0.0043 
2024-11-08 18:21:34.561746: train_loss -0.9006 
2024-11-08 18:21:34.567811: val_loss -0.7808 
2024-11-08 18:21:34.570417: Pseudo dice [np.float32(0.93), np.float32(0.7499)] 
2024-11-08 18:21:34.572881: Epoch time: 39.81 s 
2024-11-08 18:21:35.788217:  
2024-11-08 18:21:35.790743: Epoch 609 
2024-11-08 18:21:35.793325: Current learning rate: 0.00429 
2024-11-08 18:22:15.621906: train_loss -0.9014 
2024-11-08 18:22:15.625079: val_loss -0.8484 
2024-11-08 18:22:15.627879: Pseudo dice [np.float32(0.9434), np.float32(0.842)] 
2024-11-08 18:22:15.630449: Epoch time: 39.83 s 
2024-11-08 18:22:16.839382:  
2024-11-08 18:22:16.842279: Epoch 610 
2024-11-08 18:22:16.845094: Current learning rate: 0.00429 
2024-11-08 18:22:56.642087: train_loss -0.9124 
2024-11-08 18:22:56.651345: val_loss -0.8263 
2024-11-08 18:22:56.654155: Pseudo dice [np.float32(0.9359), np.float32(0.8342)] 
2024-11-08 18:22:56.656804: Epoch time: 39.8 s 
2024-11-08 18:22:57.869073:  
2024-11-08 18:22:57.872001: Epoch 611 
2024-11-08 18:22:57.874528: Current learning rate: 0.00428 
2024-11-08 18:23:37.672277: train_loss -0.9117 
2024-11-08 18:23:37.678948: val_loss -0.8532 
2024-11-08 18:23:37.681391: Pseudo dice [np.float32(0.9355), np.float32(0.8602)] 
2024-11-08 18:23:37.683918: Epoch time: 39.8 s 
2024-11-08 18:23:38.903287:  
2024-11-08 18:23:38.906133: Epoch 612 
2024-11-08 18:23:38.908699: Current learning rate: 0.00427 
2024-11-08 18:24:18.704312: train_loss -0.9132 
2024-11-08 18:24:18.711604: val_loss -0.8716 
2024-11-08 18:24:18.714032: Pseudo dice [np.float32(0.9448), np.float32(0.888)] 
2024-11-08 18:24:18.716438: Epoch time: 39.8 s 
2024-11-08 18:24:19.932995:  
2024-11-08 18:24:19.935671: Epoch 613 
2024-11-08 18:24:19.938294: Current learning rate: 0.00426 
2024-11-08 18:24:59.722803: train_loss -0.9119 
2024-11-08 18:24:59.727663: val_loss -0.8547 
2024-11-08 18:24:59.730265: Pseudo dice [np.float32(0.9336), np.float32(0.8436)] 
2024-11-08 18:24:59.732478: Epoch time: 39.79 s 
2024-11-08 18:25:00.951870:  
2024-11-08 18:25:00.954505: Epoch 614 
2024-11-08 18:25:00.957097: Current learning rate: 0.00425 
2024-11-08 18:25:40.748332: train_loss -0.9033 
2024-11-08 18:25:40.755315: val_loss -0.8678 
2024-11-08 18:25:40.757761: Pseudo dice [np.float32(0.9471), np.float32(0.8704)] 
2024-11-08 18:25:40.760102: Epoch time: 39.8 s 
2024-11-08 18:25:41.973933:  
2024-11-08 18:25:42.011196: Epoch 615 
2024-11-08 18:25:42.013714: Current learning rate: 0.00424 
2024-11-08 18:26:21.843560: train_loss -0.9159 
2024-11-08 18:26:21.849165: val_loss -0.8726 
2024-11-08 18:26:21.851463: Pseudo dice [np.float32(0.9473), np.float32(0.9166)] 
2024-11-08 18:26:21.853910: Epoch time: 39.87 s 
2024-11-08 18:26:23.068698:  
2024-11-08 18:26:23.071012: Epoch 616 
2024-11-08 18:26:23.073188: Current learning rate: 0.00423 
2024-11-08 18:27:02.912848: train_loss -0.926 
2024-11-08 18:27:02.919561: val_loss -0.8683 
2024-11-08 18:27:02.922052: Pseudo dice [np.float32(0.9438), np.float32(0.8917)] 
2024-11-08 18:27:02.925163: Epoch time: 39.85 s 
2024-11-08 18:27:04.140825:  
2024-11-08 18:27:04.144317: Epoch 617 
2024-11-08 18:27:04.146816: Current learning rate: 0.00422 
2024-11-08 18:27:43.993918: train_loss -0.9156 
2024-11-08 18:27:43.996728: val_loss -0.852 
2024-11-08 18:27:43.999566: Pseudo dice [np.float32(0.9494), np.float32(0.8683)] 
2024-11-08 18:27:44.002035: Epoch time: 39.85 s 
2024-11-08 18:27:45.216545:  
2024-11-08 18:27:45.218997: Epoch 618 
2024-11-08 18:27:45.221528: Current learning rate: 0.00421 
2024-11-08 18:28:25.073476: train_loss -0.9157 
2024-11-08 18:28:25.079989: val_loss -0.8195 
2024-11-08 18:28:25.084007: Pseudo dice [np.float32(0.938), np.float32(0.8083)] 
2024-11-08 18:28:25.089897: Epoch time: 39.86 s 
2024-11-08 18:28:26.306906:  
2024-11-08 18:28:26.309246: Epoch 619 
2024-11-08 18:28:26.311886: Current learning rate: 0.0042 
2024-11-08 18:29:06.166257: train_loss -0.9158 
2024-11-08 18:29:06.171255: val_loss -0.8558 
2024-11-08 18:29:06.173603: Pseudo dice [np.float32(0.9408), np.float32(0.8939)] 
2024-11-08 18:29:06.175987: Epoch time: 39.86 s 
2024-11-08 18:29:07.401976:  
2024-11-08 18:29:07.405276: Epoch 620 
2024-11-08 18:29:07.407625: Current learning rate: 0.00419 
2024-11-08 18:29:47.261841: train_loss -0.9188 
2024-11-08 18:29:47.268070: val_loss -0.8439 
2024-11-08 18:29:47.270446: Pseudo dice [np.float32(0.9458), np.float32(0.8053)] 
2024-11-08 18:29:47.272759: Epoch time: 39.86 s 
2024-11-08 18:29:48.496119:  
2024-11-08 18:29:48.498499: Epoch 621 
2024-11-08 18:29:48.501313: Current learning rate: 0.00418 
2024-11-08 18:30:28.349144: train_loss -0.9178 
2024-11-08 18:30:28.354858: val_loss -0.8569 
2024-11-08 18:30:28.357227: Pseudo dice [np.float32(0.9439), np.float32(0.8549)] 
2024-11-08 18:30:28.359529: Epoch time: 39.85 s 
2024-11-08 18:30:30.171917:  
2024-11-08 18:30:30.174436: Epoch 622 
2024-11-08 18:30:30.176885: Current learning rate: 0.00417 
2024-11-08 18:31:10.040871: train_loss -0.9186 
2024-11-08 18:31:10.049196: val_loss -0.8515 
2024-11-08 18:31:10.051887: Pseudo dice [np.float32(0.9447), np.float32(0.8959)] 
2024-11-08 18:31:10.054254: Epoch time: 39.87 s 
2024-11-08 18:31:11.266830:  
2024-11-08 18:31:11.269406: Epoch 623 
2024-11-08 18:31:11.272199: Current learning rate: 0.00416 
2024-11-08 18:31:51.126781: train_loss -0.9236 
2024-11-08 18:31:51.130911: val_loss -0.8097 
2024-11-08 18:31:51.135061: Pseudo dice [np.float32(0.9439), np.float32(0.7886)] 
2024-11-08 18:31:51.137282: Epoch time: 39.86 s 
2024-11-08 18:31:52.348231:  
2024-11-08 18:31:52.350713: Epoch 624 
2024-11-08 18:31:52.353070: Current learning rate: 0.00415 
2024-11-08 18:32:32.217674: train_loss -0.9228 
2024-11-08 18:32:32.223739: val_loss -0.8431 
2024-11-08 18:32:32.226160: Pseudo dice [np.float32(0.9445), np.float32(0.849)] 
2024-11-08 18:32:32.228625: Epoch time: 39.87 s 
2024-11-08 18:32:33.443414:  
2024-11-08 18:32:33.445908: Epoch 625 
2024-11-08 18:32:33.448229: Current learning rate: 0.00414 
2024-11-08 18:33:13.314159: train_loss -0.9162 
2024-11-08 18:33:13.318410: val_loss -0.8126 
2024-11-08 18:33:13.320652: Pseudo dice [np.float32(0.9426), np.float32(0.7957)] 
2024-11-08 18:33:13.322944: Epoch time: 39.87 s 
2024-11-08 18:33:14.536516:  
2024-11-08 18:33:14.539052: Epoch 626 
2024-11-08 18:33:14.541353: Current learning rate: 0.00413 
2024-11-08 18:33:54.397081: train_loss -0.917 
2024-11-08 18:33:54.412727: val_loss -0.8703 
2024-11-08 18:33:54.415017: Pseudo dice [np.float32(0.9471), np.float32(0.8771)] 
2024-11-08 18:33:54.417262: Epoch time: 39.86 s 
2024-11-08 18:33:55.631923:  
2024-11-08 18:33:55.634296: Epoch 627 
2024-11-08 18:33:55.636626: Current learning rate: 0.00412 
2024-11-08 18:34:35.529241: train_loss -0.9253 
2024-11-08 18:34:35.535458: val_loss -0.8763 
2024-11-08 18:34:35.538818: Pseudo dice [np.float32(0.9355), np.float32(0.8869)] 
2024-11-08 18:34:35.541156: Epoch time: 39.9 s 
2024-11-08 18:34:36.755637:  
2024-11-08 18:34:36.758213: Epoch 628 
2024-11-08 18:34:36.760896: Current learning rate: 0.00411 
2024-11-08 18:35:16.633160: train_loss -0.9269 
2024-11-08 18:35:16.639902: val_loss -0.8757 
2024-11-08 18:35:16.643244: Pseudo dice [np.float32(0.9517), np.float32(0.879)] 
2024-11-08 18:35:16.645812: Epoch time: 39.88 s 
2024-11-08 18:35:17.862513:  
2024-11-08 18:35:17.865000: Epoch 629 
2024-11-08 18:35:17.867310: Current learning rate: 0.0041 
2024-11-08 18:35:57.736209: train_loss -0.922 
2024-11-08 18:35:57.742074: val_loss -0.8633 
2024-11-08 18:35:57.744630: Pseudo dice [np.float32(0.9477), np.float32(0.8398)] 
2024-11-08 18:35:57.747106: Epoch time: 39.87 s 
2024-11-08 18:35:58.960170:  
2024-11-08 18:35:58.962707: Epoch 630 
2024-11-08 18:35:58.965346: Current learning rate: 0.00409 
2024-11-08 18:36:38.837912: train_loss -0.9264 
2024-11-08 18:36:38.844217: val_loss -0.8671 
2024-11-08 18:36:38.846585: Pseudo dice [np.float32(0.943), np.float32(0.8742)] 
2024-11-08 18:36:38.849099: Epoch time: 39.88 s 
2024-11-08 18:36:40.066332:  
2024-11-08 18:36:40.068729: Epoch 631 
2024-11-08 18:36:40.071073: Current learning rate: 0.00408 
2024-11-08 18:37:19.954659: train_loss -0.9216 
2024-11-08 18:37:19.961056: val_loss -0.8219 
2024-11-08 18:37:19.963537: Pseudo dice [np.float32(0.9475), np.float32(0.8227)] 
2024-11-08 18:37:19.965799: Epoch time: 39.89 s 
2024-11-08 18:37:21.179176:  
2024-11-08 18:37:21.182605: Epoch 632 
2024-11-08 18:37:21.185273: Current learning rate: 0.00407 
2024-11-08 18:38:01.063297: train_loss -0.9236 
2024-11-08 18:38:01.069514: val_loss -0.7805 
2024-11-08 18:38:01.071957: Pseudo dice [np.float32(0.9479), np.float32(0.7109)] 
2024-11-08 18:38:01.075207: Epoch time: 39.89 s 
2024-11-08 18:38:02.296768:  
2024-11-08 18:38:02.300737: Epoch 633 
2024-11-08 18:38:02.303294: Current learning rate: 0.00406 
2024-11-08 18:38:42.167597: train_loss -0.9309 
2024-11-08 18:38:42.172989: val_loss -0.8623 
2024-11-08 18:38:42.175411: Pseudo dice [np.float32(0.9463), np.float32(0.8836)] 
2024-11-08 18:38:42.177831: Epoch time: 39.87 s 
2024-11-08 18:38:43.397435:  
2024-11-08 18:38:43.399898: Epoch 634 
2024-11-08 18:38:43.402434: Current learning rate: 0.00405 
2024-11-08 18:39:23.252788: train_loss -0.9336 
2024-11-08 18:39:23.260205: val_loss -0.8744 
2024-11-08 18:39:23.262446: Pseudo dice [np.float32(0.9512), np.float32(0.8506)] 
2024-11-08 18:39:23.264901: Epoch time: 39.86 s 
2024-11-08 18:39:24.482960:  
2024-11-08 18:39:24.485589: Epoch 635 
2024-11-08 18:39:24.488409: Current learning rate: 0.00404 
2024-11-08 18:40:04.339239: train_loss -0.9387 
2024-11-08 18:40:04.346139: val_loss -0.8869 
2024-11-08 18:40:04.348708: Pseudo dice [np.float32(0.9485), np.float32(0.8971)] 
2024-11-08 18:40:04.351144: Epoch time: 39.86 s 
2024-11-08 18:40:05.565110:  
2024-11-08 18:40:05.567700: Epoch 636 
2024-11-08 18:40:05.571294: Current learning rate: 0.00403 
2024-11-08 18:40:45.426088: train_loss -0.9374 
2024-11-08 18:40:45.433583: val_loss -0.8976 
2024-11-08 18:40:45.436029: Pseudo dice [np.float32(0.9544), np.float32(0.9077)] 
2024-11-08 18:40:45.438727: Epoch time: 39.86 s 
2024-11-08 18:40:46.672137:  
2024-11-08 18:40:46.674503: Epoch 637 
2024-11-08 18:40:46.676797: Current learning rate: 0.00402 
2024-11-08 18:41:26.551487: train_loss -0.9306 
2024-11-08 18:41:26.558001: val_loss -0.8101 
2024-11-08 18:41:26.560582: Pseudo dice [np.float32(0.9255), np.float32(0.8147)] 
2024-11-08 18:41:26.562912: Epoch time: 39.88 s 
2024-11-08 18:41:27.771050:  
2024-11-08 18:41:27.773526: Epoch 638 
2024-11-08 18:41:27.775942: Current learning rate: 0.00401 
2024-11-08 18:42:07.654669: train_loss -0.9354 
2024-11-08 18:42:07.662052: val_loss -0.8647 
2024-11-08 18:42:07.664567: Pseudo dice [np.float32(0.9459), np.float32(0.8757)] 
2024-11-08 18:42:07.667073: Epoch time: 39.88 s 
2024-11-08 18:42:08.876578:  
2024-11-08 18:42:08.879058: Epoch 639 
2024-11-08 18:42:08.881748: Current learning rate: 0.004 
2024-11-08 18:42:48.726872: train_loss -0.9337 
2024-11-08 18:42:48.733222: val_loss -0.8446 
2024-11-08 18:42:48.735686: Pseudo dice [np.float32(0.9468), np.float32(0.827)] 
2024-11-08 18:42:48.738529: Epoch time: 39.85 s 
2024-11-08 18:42:49.954136:  
2024-11-08 18:42:49.956713: Epoch 640 
2024-11-08 18:42:49.959044: Current learning rate: 0.00399 
2024-11-08 18:43:29.806984: train_loss -0.9303 
2024-11-08 18:43:29.815621: val_loss -0.8874 
2024-11-08 18:43:29.817938: Pseudo dice [np.float32(0.9469), np.float32(0.8943)] 
2024-11-08 18:43:29.820349: Epoch time: 39.85 s 
2024-11-08 18:43:31.648837:  
2024-11-08 18:43:31.651417: Epoch 641 
2024-11-08 18:43:31.654363: Current learning rate: 0.00398 
2024-11-08 18:44:11.543897: train_loss -0.9333 
2024-11-08 18:44:11.550182: val_loss -0.8475 
2024-11-08 18:44:11.552670: Pseudo dice [np.float32(0.9479), np.float32(0.8308)] 
2024-11-08 18:44:11.554997: Epoch time: 39.9 s 
2024-11-08 18:44:12.765360:  
2024-11-08 18:44:12.767797: Epoch 642 
2024-11-08 18:44:12.770257: Current learning rate: 0.00397 
2024-11-08 18:44:52.671962: train_loss -0.9311 
2024-11-08 18:44:52.678856: val_loss -0.8832 
2024-11-08 18:44:52.681373: Pseudo dice [np.float32(0.9491), np.float32(0.9096)] 
2024-11-08 18:44:52.683746: Epoch time: 39.91 s 
2024-11-08 18:44:53.899286:  
2024-11-08 18:44:53.901735: Epoch 643 
2024-11-08 18:44:53.904111: Current learning rate: 0.00396 
2024-11-08 18:45:33.775151: train_loss -0.9338 
2024-11-08 18:45:33.783767: val_loss -0.8573 
2024-11-08 18:45:33.786338: Pseudo dice [np.float32(0.9472), np.float32(0.8746)] 
2024-11-08 18:45:33.789802: Epoch time: 39.88 s 
2024-11-08 18:45:34.997653:  
2024-11-08 18:45:35.000272: Epoch 644 
2024-11-08 18:45:35.002756: Current learning rate: 0.00395 
2024-11-08 18:46:14.859613: train_loss -0.942 
2024-11-08 18:46:14.871308: val_loss -0.8852 
2024-11-08 18:46:14.873668: Pseudo dice [np.float32(0.949), np.float32(0.8961)] 
2024-11-08 18:46:14.875938: Epoch time: 39.86 s 
2024-11-08 18:46:14.878421: Yayy! New best EMA pseudo Dice: 0.9049000144004822 
2024-11-08 18:46:16.822563:  
2024-11-08 18:46:16.825697: Epoch 645 
2024-11-08 18:46:16.829625: Current learning rate: 0.00394 
2024-11-08 18:46:56.680583: train_loss -0.933 
2024-11-08 18:46:56.688221: val_loss -0.8808 
2024-11-08 18:46:56.690799: Pseudo dice [np.float32(0.9486), np.float32(0.8746)] 
2024-11-08 18:46:56.693114: Epoch time: 39.86 s 
2024-11-08 18:46:56.695314: Yayy! New best EMA pseudo Dice: 0.9056000113487244 
2024-11-08 18:46:58.674871:  
2024-11-08 18:46:58.677275: Epoch 646 
2024-11-08 18:46:58.680043: Current learning rate: 0.00393 
2024-11-08 18:47:38.531967: train_loss -0.926 
2024-11-08 18:47:38.540413: val_loss -0.8303 
2024-11-08 18:47:38.543098: Pseudo dice [np.float32(0.9498), np.float32(0.8029)] 
2024-11-08 18:47:38.546402: Epoch time: 39.86 s 
2024-11-08 18:47:39.768814:  
2024-11-08 18:47:39.771381: Epoch 647 
2024-11-08 18:47:39.773880: Current learning rate: 0.00392 
2024-11-08 18:48:19.627195: train_loss -0.9373 
2024-11-08 18:48:19.635840: val_loss -0.8522 
2024-11-08 18:48:19.638440: Pseudo dice [np.float32(0.9402), np.float32(0.8632)] 
2024-11-08 18:48:19.640970: Epoch time: 39.86 s 
2024-11-08 18:48:20.853712:  
2024-11-08 18:48:20.856174: Epoch 648 
2024-11-08 18:48:20.858562: Current learning rate: 0.00391 
2024-11-08 18:49:00.738008: train_loss -0.9353 
2024-11-08 18:49:00.744885: val_loss -0.8516 
2024-11-08 18:49:00.747145: Pseudo dice [np.float32(0.9428), np.float32(0.8425)] 
2024-11-08 18:49:00.749491: Epoch time: 39.89 s 
2024-11-08 18:49:01.965673:  
2024-11-08 18:49:01.968155: Epoch 649 
2024-11-08 18:49:01.970797: Current learning rate: 0.0039 
2024-11-08 18:49:41.828317: train_loss -0.935 
2024-11-08 18:49:41.836500: val_loss -0.8369 
2024-11-08 18:49:41.839112: Pseudo dice [np.float32(0.9451), np.float32(0.809)] 
2024-11-08 18:49:41.841345: Epoch time: 39.86 s 
2024-11-08 18:49:43.942276:  
2024-11-08 18:49:43.945056: Epoch 650 
2024-11-08 18:49:43.947673: Current learning rate: 0.00389 
2024-11-08 18:50:23.780938: train_loss -0.9381 
2024-11-08 18:50:23.789040: val_loss -0.836 
2024-11-08 18:50:23.791465: Pseudo dice [np.float32(0.9477), np.float32(0.8101)] 
2024-11-08 18:50:23.793803: Epoch time: 39.84 s 
2024-11-08 18:50:25.045632:  
2024-11-08 18:50:25.047992: Epoch 651 
2024-11-08 18:50:25.050577: Current learning rate: 0.00388 
2024-11-08 18:51:04.785529: train_loss -0.9403 
2024-11-08 18:51:04.790047: val_loss -0.8569 
2024-11-08 18:51:04.792185: Pseudo dice [np.float32(0.9494), np.float32(0.8857)] 
2024-11-08 18:51:04.794557: Epoch time: 39.74 s 
2024-11-08 18:51:06.007625:  
2024-11-08 18:51:06.010136: Epoch 652 
2024-11-08 18:51:06.012666: Current learning rate: 0.00387 
2024-11-08 18:51:45.748725: train_loss -0.9399 
2024-11-08 18:51:45.754192: val_loss -0.8831 
2024-11-08 18:51:45.756563: Pseudo dice [np.float32(0.9511), np.float32(0.8897)] 
2024-11-08 18:51:45.758909: Epoch time: 39.74 s 
2024-11-08 18:51:46.973427:  
2024-11-08 18:51:46.975847: Epoch 653 
2024-11-08 18:51:46.978089: Current learning rate: 0.00386 
2024-11-08 18:52:26.741701: train_loss -0.9383 
2024-11-08 18:52:26.747531: val_loss -0.8572 
2024-11-08 18:52:26.749918: Pseudo dice [np.float32(0.9499), np.float32(0.8686)] 
2024-11-08 18:52:26.752989: Epoch time: 39.77 s 
2024-11-08 18:52:27.967774:  
2024-11-08 18:52:27.970356: Epoch 654 
2024-11-08 18:52:27.972892: Current learning rate: 0.00385 
2024-11-08 18:53:07.772398: train_loss -0.9237 
2024-11-08 18:53:07.780407: val_loss -0.8561 
2024-11-08 18:53:07.783031: Pseudo dice [np.float32(0.9489), np.float32(0.8733)] 
2024-11-08 18:53:07.785515: Epoch time: 39.81 s 
2024-11-08 18:53:08.994137:  
2024-11-08 18:53:08.996866: Epoch 655 
2024-11-08 18:53:08.999606: Current learning rate: 0.00384 
2024-11-08 18:53:48.802183: train_loss -0.9247 
2024-11-08 18:53:48.808542: val_loss -0.8857 
2024-11-08 18:53:48.811960: Pseudo dice [np.float32(0.9521), np.float32(0.8959)] 
2024-11-08 18:53:48.814399: Epoch time: 39.81 s 
2024-11-08 18:53:50.030606:  
2024-11-08 18:53:50.033247: Epoch 656 
2024-11-08 18:53:50.035593: Current learning rate: 0.00383 
2024-11-08 18:54:29.846206: train_loss -0.9278 
2024-11-08 18:54:29.853579: val_loss -0.8027 
2024-11-08 18:54:29.855920: Pseudo dice [np.float32(0.9365), np.float32(0.7644)] 
2024-11-08 18:54:29.858108: Epoch time: 39.82 s 
2024-11-08 18:54:31.070362:  
2024-11-08 18:54:31.072799: Epoch 657 
2024-11-08 18:54:31.075369: Current learning rate: 0.00382 
2024-11-08 18:55:10.885385: train_loss -0.933 
2024-11-08 18:55:10.892411: val_loss -0.8919 
2024-11-08 18:55:10.895038: Pseudo dice [np.float32(0.9494), np.float32(0.8979)] 
2024-11-08 18:55:10.897744: Epoch time: 39.82 s 
2024-11-08 18:55:12.110901:  
2024-11-08 18:55:12.113348: Epoch 658 
2024-11-08 18:55:12.116101: Current learning rate: 0.00381 
2024-11-08 18:55:51.944909: train_loss -0.9342 
2024-11-08 18:55:51.951960: val_loss -0.8561 
2024-11-08 18:55:51.954388: Pseudo dice [np.float32(0.9446), np.float32(0.8504)] 
2024-11-08 18:55:51.957799: Epoch time: 39.84 s 
2024-11-08 18:55:53.788795:  
2024-11-08 18:55:53.791523: Epoch 659 
2024-11-08 18:55:53.794231: Current learning rate: 0.0038 
2024-11-08 18:56:33.615579: train_loss -0.9315 
2024-11-08 18:56:33.621743: val_loss -0.833 
2024-11-08 18:56:33.624250: Pseudo dice [np.float32(0.9434), np.float32(0.7993)] 
2024-11-08 18:56:33.626721: Epoch time: 39.83 s 
2024-11-08 18:56:34.837885:  
2024-11-08 18:56:34.840380: Epoch 660 
2024-11-08 18:56:34.842835: Current learning rate: 0.00379 
2024-11-08 18:57:14.692669: train_loss -0.9262 
2024-11-08 18:57:14.699219: val_loss -0.8693 
2024-11-08 18:57:14.701640: Pseudo dice [np.float32(0.9483), np.float32(0.8736)] 
2024-11-08 18:57:14.703853: Epoch time: 39.86 s 
2024-11-08 18:57:15.921025:  
2024-11-08 18:57:15.923307: Epoch 661 
2024-11-08 18:57:15.925831: Current learning rate: 0.00378 
2024-11-08 18:57:55.790382: train_loss -0.9127 
2024-11-08 18:57:55.794301: val_loss -0.8625 
2024-11-08 18:57:55.796806: Pseudo dice [np.float32(0.9389), np.float32(0.8643)] 
2024-11-08 18:57:55.798896: Epoch time: 39.87 s 
2024-11-08 18:57:57.016326:  
2024-11-08 18:57:57.018896: Epoch 662 
2024-11-08 18:57:57.021085: Current learning rate: 0.00377 
2024-11-08 18:58:36.869886: train_loss -0.9084 
2024-11-08 18:58:36.875108: val_loss -0.8671 
2024-11-08 18:58:36.877321: Pseudo dice [np.float32(0.9392), np.float32(0.8994)] 
2024-11-08 18:58:36.879584: Epoch time: 39.85 s 
2024-11-08 18:58:38.094822:  
2024-11-08 18:58:38.097253: Epoch 663 
2024-11-08 18:58:38.099430: Current learning rate: 0.00376 
2024-11-08 18:59:17.965761: train_loss -0.9156 
2024-11-08 18:59:17.971497: val_loss -0.8225 
2024-11-08 18:59:17.973728: Pseudo dice [np.float32(0.9504), np.float32(0.808)] 
2024-11-08 18:59:17.976998: Epoch time: 39.87 s 
2024-11-08 18:59:19.188062:  
2024-11-08 18:59:19.190659: Epoch 664 
2024-11-08 18:59:19.193169: Current learning rate: 0.00375 
2024-11-08 18:59:59.051886: train_loss -0.9233 
2024-11-08 18:59:59.057561: val_loss -0.7501 
2024-11-08 18:59:59.059863: Pseudo dice [np.float32(0.945), np.float32(0.684)] 
2024-11-08 18:59:59.062201: Epoch time: 39.86 s 
2024-11-08 19:00:00.273175:  
2024-11-08 19:00:00.275536: Epoch 665 
2024-11-08 19:00:00.277767: Current learning rate: 0.00374 
2024-11-08 19:00:40.121360: train_loss -0.9291 
2024-11-08 19:00:40.125498: val_loss -0.8401 
2024-11-08 19:00:40.128123: Pseudo dice [np.float32(0.9464), np.float32(0.8519)] 
2024-11-08 19:00:40.130672: Epoch time: 39.85 s 
2024-11-08 19:00:41.344791:  
2024-11-08 19:00:41.347092: Epoch 666 
2024-11-08 19:00:41.349543: Current learning rate: 0.00373 
2024-11-08 19:01:21.111988: train_loss -0.9334 
2024-11-08 19:01:21.118100: val_loss -0.855 
2024-11-08 19:01:21.120650: Pseudo dice [np.float32(0.9433), np.float32(0.8694)] 
2024-11-08 19:01:21.123235: Epoch time: 39.77 s 
2024-11-08 19:01:22.341135:  
2024-11-08 19:01:22.343739: Epoch 667 
2024-11-08 19:01:22.346461: Current learning rate: 0.00372 
2024-11-08 19:02:02.124521: train_loss -0.9349 
2024-11-08 19:02:02.129713: val_loss -0.8596 
2024-11-08 19:02:02.132213: Pseudo dice [np.float32(0.9396), np.float32(0.8777)] 
2024-11-08 19:02:02.134516: Epoch time: 39.78 s 
2024-11-08 19:02:03.369380:  
2024-11-08 19:02:03.373197: Epoch 668 
2024-11-08 19:02:03.375746: Current learning rate: 0.00371 
2024-11-08 19:02:43.167566: train_loss -0.9256 
2024-11-08 19:02:43.173586: val_loss -0.8572 
2024-11-08 19:02:43.175906: Pseudo dice [np.float32(0.9505), np.float32(0.8363)] 
2024-11-08 19:02:43.178295: Epoch time: 39.8 s 
2024-11-08 19:02:44.414690:  
2024-11-08 19:02:44.417127: Epoch 669 
2024-11-08 19:02:44.419500: Current learning rate: 0.0037 
2024-11-08 19:03:24.193243: train_loss -0.9294 
2024-11-08 19:03:24.198037: val_loss -0.8147 
2024-11-08 19:03:24.200333: Pseudo dice [np.float32(0.9337), np.float32(0.8048)] 
2024-11-08 19:03:24.202862: Epoch time: 39.78 s 
2024-11-08 19:03:25.439786:  
2024-11-08 19:03:25.442505: Epoch 670 
2024-11-08 19:03:25.445021: Current learning rate: 0.00369 
2024-11-08 19:04:05.228613: train_loss -0.9219 
2024-11-08 19:04:05.235009: val_loss -0.8614 
2024-11-08 19:04:05.237439: Pseudo dice [np.float32(0.9298), np.float32(0.878)] 
2024-11-08 19:04:05.239894: Epoch time: 39.79 s 
2024-11-08 19:04:06.476216:  
2024-11-08 19:04:06.479054: Epoch 671 
2024-11-08 19:04:06.481498: Current learning rate: 0.00368 
2024-11-08 19:04:46.265500: train_loss -0.9144 
2024-11-08 19:04:46.269830: val_loss -0.8023 
2024-11-08 19:04:46.272044: Pseudo dice [np.float32(0.9399), np.float32(0.7964)] 
2024-11-08 19:04:46.274378: Epoch time: 39.79 s 
2024-11-08 19:04:47.512288:  
2024-11-08 19:04:47.514979: Epoch 672 
2024-11-08 19:04:47.517456: Current learning rate: 0.00367 
2024-11-08 19:05:27.319212: train_loss -0.9178 
2024-11-08 19:05:27.326899: val_loss -0.822 
2024-11-08 19:05:27.329391: Pseudo dice [np.float32(0.9409), np.float32(0.8421)] 
2024-11-08 19:05:27.331810: Epoch time: 39.81 s 
2024-11-08 19:05:28.565971:  
2024-11-08 19:05:28.568372: Epoch 673 
2024-11-08 19:05:28.570801: Current learning rate: 0.00366 
2024-11-08 19:06:08.391138: train_loss -0.928 
2024-11-08 19:06:08.394025: val_loss -0.8806 
2024-11-08 19:06:08.396255: Pseudo dice [np.float32(0.9506), np.float32(0.8934)] 
2024-11-08 19:06:08.398480: Epoch time: 39.83 s 
2024-11-08 19:06:09.632484:  
2024-11-08 19:06:09.635055: Epoch 674 
2024-11-08 19:06:09.637470: Current learning rate: 0.00365 
2024-11-08 19:06:49.459415: train_loss -0.922 
2024-11-08 19:06:49.468151: val_loss -0.8582 
2024-11-08 19:06:49.470311: Pseudo dice [np.float32(0.947), np.float32(0.8759)] 
2024-11-08 19:06:49.472647: Epoch time: 39.83 s 
2024-11-08 19:06:50.708112:  
2024-11-08 19:06:50.710361: Epoch 675 
2024-11-08 19:06:50.712606: Current learning rate: 0.00364 
2024-11-08 19:07:30.495525: train_loss -0.9209 
2024-11-08 19:07:30.498274: val_loss -0.819 
2024-11-08 19:07:30.500599: Pseudo dice [np.float32(0.9221), np.float32(0.8329)] 
2024-11-08 19:07:30.502961: Epoch time: 39.79 s 
2024-11-08 19:07:31.739152:  
2024-11-08 19:07:31.741491: Epoch 676 
2024-11-08 19:07:31.743985: Current learning rate: 0.00363 
2024-11-08 19:08:11.538869: train_loss -0.9254 
2024-11-08 19:08:11.546508: val_loss -0.8841 
2024-11-08 19:08:11.548732: Pseudo dice [np.float32(0.9497), np.float32(0.8953)] 
2024-11-08 19:08:11.551009: Epoch time: 39.8 s 
2024-11-08 19:08:12.781614:  
2024-11-08 19:08:12.784086: Epoch 677 
2024-11-08 19:08:12.786689: Current learning rate: 0.00362 
2024-11-08 19:08:52.579235: train_loss -0.9325 
2024-11-08 19:08:52.581856: val_loss -0.8877 
2024-11-08 19:08:52.584057: Pseudo dice [np.float32(0.9494), np.float32(0.8794)] 
2024-11-08 19:08:52.586586: Epoch time: 39.8 s 
2024-11-08 19:08:54.434399:  
2024-11-08 19:08:54.437065: Epoch 678 
2024-11-08 19:08:54.439780: Current learning rate: 0.00361 
2024-11-08 19:09:34.242506: train_loss -0.9337 
2024-11-08 19:09:34.248046: val_loss -0.7685 
2024-11-08 19:09:34.250541: Pseudo dice [np.float32(0.9308), np.float32(0.7422)] 
2024-11-08 19:09:34.252750: Epoch time: 39.81 s 
2024-11-08 19:09:35.485147:  
2024-11-08 19:09:35.487566: Epoch 679 
2024-11-08 19:09:35.489947: Current learning rate: 0.0036 
2024-11-08 19:10:15.298076: train_loss -0.9294 
2024-11-08 19:10:15.301464: val_loss -0.7931 
2024-11-08 19:10:15.303799: Pseudo dice [np.float32(0.9349), np.float32(0.7514)] 
2024-11-08 19:10:15.306129: Epoch time: 39.81 s 
2024-11-08 19:10:16.551865:  
2024-11-08 19:10:16.554357: Epoch 680 
2024-11-08 19:10:16.556888: Current learning rate: 0.00359 
2024-11-08 19:10:56.364439: train_loss -0.9281 
2024-11-08 19:10:56.370155: val_loss -0.8478 
2024-11-08 19:10:56.372465: Pseudo dice [np.float32(0.9486), np.float32(0.8541)] 
2024-11-08 19:10:56.375027: Epoch time: 39.81 s 
2024-11-08 19:10:57.611115:  
2024-11-08 19:10:57.613615: Epoch 681 
2024-11-08 19:10:57.615921: Current learning rate: 0.00358 
2024-11-08 19:11:37.446851: train_loss -0.9106 
2024-11-08 19:11:37.449915: val_loss -0.8672 
2024-11-08 19:11:37.452225: Pseudo dice [np.float32(0.9428), np.float32(0.8809)] 
2024-11-08 19:11:37.454387: Epoch time: 39.84 s 
2024-11-08 19:11:38.693719:  
2024-11-08 19:11:38.696232: Epoch 682 
2024-11-08 19:11:38.699022: Current learning rate: 0.00357 
2024-11-08 19:12:18.503711: train_loss -0.9288 
2024-11-08 19:12:18.509094: val_loss -0.8682 
2024-11-08 19:12:18.511347: Pseudo dice [np.float32(0.9475), np.float32(0.8773)] 
2024-11-08 19:12:18.513669: Epoch time: 39.81 s 
2024-11-08 19:12:19.741460:  
2024-11-08 19:12:19.743984: Epoch 683 
2024-11-08 19:12:19.746567: Current learning rate: 0.00356 
2024-11-08 19:12:59.562958: train_loss -0.9278 
2024-11-08 19:12:59.575075: val_loss -0.8419 
2024-11-08 19:12:59.577565: Pseudo dice [np.float32(0.9423), np.float32(0.8553)] 
2024-11-08 19:12:59.579986: Epoch time: 39.82 s 
2024-11-08 19:13:00.819786:  
2024-11-08 19:13:00.822329: Epoch 684 
2024-11-08 19:13:00.824700: Current learning rate: 0.00355 
2024-11-08 19:13:40.659391: train_loss -0.9252 
2024-11-08 19:13:40.664961: val_loss -0.8407 
2024-11-08 19:13:40.667063: Pseudo dice [np.float32(0.9481), np.float32(0.8524)] 
2024-11-08 19:13:40.669237: Epoch time: 39.84 s 
2024-11-08 19:13:41.899481:  
2024-11-08 19:13:41.902032: Epoch 685 
2024-11-08 19:13:41.904413: Current learning rate: 0.00354 
2024-11-08 19:14:21.736231: train_loss -0.929 
2024-11-08 19:14:21.741744: val_loss -0.8673 
2024-11-08 19:14:21.744007: Pseudo dice [np.float32(0.9452), np.float32(0.8632)] 
2024-11-08 19:14:21.746289: Epoch time: 39.84 s 
2024-11-08 19:14:22.981107:  
2024-11-08 19:14:22.983464: Epoch 686 
2024-11-08 19:14:22.986122: Current learning rate: 0.00353 
2024-11-08 19:15:02.819025: train_loss -0.9278 
2024-11-08 19:15:02.827254: val_loss -0.8881 
2024-11-08 19:15:02.830029: Pseudo dice [np.float32(0.9441), np.float32(0.8904)] 
2024-11-08 19:15:02.832331: Epoch time: 39.84 s 
2024-11-08 19:15:04.066722:  
2024-11-08 19:15:04.070493: Epoch 687 
2024-11-08 19:15:04.072735: Current learning rate: 0.00352 
2024-11-08 19:15:43.899813: train_loss -0.9199 
2024-11-08 19:15:43.902878: val_loss -0.7975 
2024-11-08 19:15:43.905393: Pseudo dice [np.float32(0.9378), np.float32(0.7717)] 
2024-11-08 19:15:43.908875: Epoch time: 39.83 s 
2024-11-08 19:15:45.153055:  
2024-11-08 19:15:45.155777: Epoch 688 
2024-11-08 19:15:45.158286: Current learning rate: 0.00351 
2024-11-08 19:16:24.984811: train_loss -0.9251 
2024-11-08 19:16:24.991843: val_loss -0.7342 
2024-11-08 19:16:24.994474: Pseudo dice [np.float32(0.9436), np.float32(0.6644)] 
2024-11-08 19:16:24.996942: Epoch time: 39.83 s 
2024-11-08 19:16:26.226752:  
2024-11-08 19:16:26.229530: Epoch 689 
2024-11-08 19:16:26.231935: Current learning rate: 0.0035 
2024-11-08 19:17:06.035244: train_loss -0.9256 
2024-11-08 19:17:06.038275: val_loss -0.7763 
2024-11-08 19:17:06.040691: Pseudo dice [np.float32(0.9319), np.float32(0.7279)] 
2024-11-08 19:17:06.043118: Epoch time: 39.81 s 
2024-11-08 19:17:07.276667:  
2024-11-08 19:17:07.279176: Epoch 690 
2024-11-08 19:17:07.281579: Current learning rate: 0.00349 
2024-11-08 19:17:47.062762: train_loss -0.9331 
2024-11-08 19:17:47.068424: val_loss -0.7863 
2024-11-08 19:17:47.070793: Pseudo dice [np.float32(0.9389), np.float32(0.7385)] 
2024-11-08 19:17:47.073122: Epoch time: 39.79 s 
2024-11-08 19:17:48.309139:  
2024-11-08 19:17:48.311679: Epoch 691 
2024-11-08 19:17:48.314402: Current learning rate: 0.00348 
2024-11-08 19:18:28.125141: train_loss -0.9345 
2024-11-08 19:18:28.136560: val_loss -0.8493 
2024-11-08 19:18:28.139014: Pseudo dice [np.float32(0.9505), np.float32(0.8667)] 
2024-11-08 19:18:28.141603: Epoch time: 39.82 s 
2024-11-08 19:18:29.378774:  
2024-11-08 19:18:29.381296: Epoch 692 
2024-11-08 19:18:29.383798: Current learning rate: 0.00346 
2024-11-08 19:19:09.118766: train_loss -0.9334 
2024-11-08 19:19:09.124161: val_loss -0.858 
2024-11-08 19:19:09.126772: Pseudo dice [np.float32(0.9505), np.float32(0.8326)] 
2024-11-08 19:19:09.129107: Epoch time: 39.74 s 
2024-11-08 19:19:10.360127:  
2024-11-08 19:19:10.362642: Epoch 693 
2024-11-08 19:19:10.365144: Current learning rate: 0.00345 
2024-11-08 19:19:50.077214: train_loss -0.9308 
2024-11-08 19:19:50.080148: val_loss -0.8912 
2024-11-08 19:19:50.082791: Pseudo dice [np.float32(0.9471), np.float32(0.8911)] 
2024-11-08 19:19:50.085169: Epoch time: 39.72 s 
2024-11-08 19:19:51.325121:  
2024-11-08 19:19:51.327450: Epoch 694 
2024-11-08 19:19:51.329829: Current learning rate: 0.00344 
2024-11-08 19:20:31.089697: train_loss -0.9299 
2024-11-08 19:20:31.104252: val_loss -0.877 
2024-11-08 19:20:31.106727: Pseudo dice [np.float32(0.9482), np.float32(0.8895)] 
2024-11-08 19:20:31.109165: Epoch time: 39.77 s 
2024-11-08 19:20:32.341794:  
2024-11-08 19:20:32.344210: Epoch 695 
2024-11-08 19:20:32.346587: Current learning rate: 0.00343 
2024-11-08 19:21:12.067311: train_loss -0.9356 
2024-11-08 19:21:12.070292: val_loss -0.8647 
2024-11-08 19:21:12.072703: Pseudo dice [np.float32(0.949), np.float32(0.8851)] 
2024-11-08 19:21:12.075039: Epoch time: 39.73 s 
2024-11-08 19:21:13.935862:  
2024-11-08 19:21:13.938481: Epoch 696 
2024-11-08 19:21:13.941110: Current learning rate: 0.00342 
2024-11-08 19:21:53.681088: train_loss -0.9293 
2024-11-08 19:21:53.686587: val_loss -0.8716 
2024-11-08 19:21:53.688951: Pseudo dice [np.float32(0.949), np.float32(0.891)] 
2024-11-08 19:21:53.691460: Epoch time: 39.75 s 
2024-11-08 19:21:54.919880:  
2024-11-08 19:21:54.922482: Epoch 697 
2024-11-08 19:21:54.924814: Current learning rate: 0.00341 
2024-11-08 19:22:34.667854: train_loss -0.9278 
2024-11-08 19:22:34.672764: val_loss -0.8669 
2024-11-08 19:22:34.675163: Pseudo dice [np.float32(0.9461), np.float32(0.8823)] 
2024-11-08 19:22:34.677369: Epoch time: 39.75 s 
2024-11-08 19:22:35.914759:  
2024-11-08 19:22:35.917266: Epoch 698 
2024-11-08 19:22:35.919871: Current learning rate: 0.0034 
2024-11-08 19:23:15.699121: train_loss -0.9338 
2024-11-08 19:23:15.715847: val_loss -0.8781 
2024-11-08 19:23:15.719064: Pseudo dice [np.float32(0.944), np.float32(0.898)] 
2024-11-08 19:23:15.722261: Epoch time: 39.79 s 
2024-11-08 19:23:16.956231:  
2024-11-08 19:23:16.959046: Epoch 699 
2024-11-08 19:23:16.963267: Current learning rate: 0.00339 
2024-11-08 19:23:56.733912: train_loss -0.9397 
2024-11-08 19:23:56.736940: val_loss -0.8791 
2024-11-08 19:23:56.739197: Pseudo dice [np.float32(0.9504), np.float32(0.8816)] 
2024-11-08 19:23:56.741485: Epoch time: 39.78 s 
2024-11-08 19:23:58.749579:  
2024-11-08 19:23:58.751958: Epoch 700 
2024-11-08 19:23:58.754179: Current learning rate: 0.00338 
2024-11-08 19:24:38.524371: train_loss -0.9371 
2024-11-08 19:24:38.531484: val_loss -0.8824 
2024-11-08 19:24:38.533893: Pseudo dice [np.float32(0.9504), np.float32(0.8806)] 
2024-11-08 19:24:38.536195: Epoch time: 39.78 s 
2024-11-08 19:24:39.770855:  
2024-11-08 19:24:39.773508: Epoch 701 
2024-11-08 19:24:39.776055: Current learning rate: 0.00337 
2024-11-08 19:25:19.543089: train_loss -0.9313 
2024-11-08 19:25:19.549746: val_loss -0.8755 
2024-11-08 19:25:19.551904: Pseudo dice [np.float32(0.951), np.float32(0.9078)] 
2024-11-08 19:25:19.554177: Epoch time: 39.77 s 
2024-11-08 19:25:20.789589:  
2024-11-08 19:25:20.792071: Epoch 702 
2024-11-08 19:25:20.794631: Current learning rate: 0.00336 
2024-11-08 19:26:00.596811: train_loss -0.9241 
2024-11-08 19:26:00.602360: val_loss -0.8439 
2024-11-08 19:26:00.604740: Pseudo dice [np.float32(0.9351), np.float32(0.8588)] 
2024-11-08 19:26:00.606991: Epoch time: 39.81 s 
2024-11-08 19:26:01.833607:  
2024-11-08 19:26:01.836109: Epoch 703 
2024-11-08 19:26:01.838597: Current learning rate: 0.00335 
2024-11-08 19:26:41.645344: train_loss -0.9282 
2024-11-08 19:26:41.648516: val_loss -0.8766 
2024-11-08 19:26:41.651071: Pseudo dice [np.float32(0.9447), np.float32(0.8916)] 
2024-11-08 19:26:41.653425: Epoch time: 39.81 s 
2024-11-08 19:26:42.887168:  
2024-11-08 19:26:42.889813: Epoch 704 
2024-11-08 19:26:42.892391: Current learning rate: 0.00334 
2024-11-08 19:27:22.691440: train_loss -0.9292 
2024-11-08 19:27:22.701505: val_loss -0.8606 
2024-11-08 19:27:22.703982: Pseudo dice [np.float32(0.9463), np.float32(0.8684)] 
2024-11-08 19:27:22.706420: Epoch time: 39.81 s 
2024-11-08 19:27:23.944631:  
2024-11-08 19:27:23.947049: Epoch 705 
2024-11-08 19:27:23.949496: Current learning rate: 0.00333 
2024-11-08 19:28:03.729686: train_loss -0.9241 
2024-11-08 19:28:03.732514: val_loss -0.8485 
2024-11-08 19:28:03.735134: Pseudo dice [np.float32(0.9432), np.float32(0.8675)] 
2024-11-08 19:28:03.737564: Epoch time: 39.79 s 
2024-11-08 19:28:04.974735:  
2024-11-08 19:28:04.978164: Epoch 706 
2024-11-08 19:28:04.980203: Current learning rate: 0.00332 
2024-11-08 19:28:44.764256: train_loss -0.9281 
2024-11-08 19:28:44.774144: val_loss -0.8653 
2024-11-08 19:28:44.776852: Pseudo dice [np.float32(0.9474), np.float32(0.8445)] 
2024-11-08 19:28:44.779041: Epoch time: 39.79 s 
2024-11-08 19:28:46.020187:  
2024-11-08 19:28:46.022370: Epoch 707 
2024-11-08 19:28:46.024629: Current learning rate: 0.00331 
2024-11-08 19:29:25.835109: train_loss -0.9347 
2024-11-08 19:29:25.838786: val_loss -0.8588 
2024-11-08 19:29:25.840998: Pseudo dice [np.float32(0.9403), np.float32(0.8666)] 
2024-11-08 19:29:25.843275: Epoch time: 39.82 s 
2024-11-08 19:29:27.083243:  
2024-11-08 19:29:27.085666: Epoch 708 
2024-11-08 19:29:27.088049: Current learning rate: 0.0033 
2024-11-08 19:30:06.870177: train_loss -0.9358 
2024-11-08 19:30:06.875396: val_loss -0.7952 
2024-11-08 19:30:06.877687: Pseudo dice [np.float32(0.94), np.float32(0.7706)] 
2024-11-08 19:30:06.879982: Epoch time: 39.79 s 
2024-11-08 19:30:08.110040:  
2024-11-08 19:30:08.112526: Epoch 709 
2024-11-08 19:30:08.114998: Current learning rate: 0.00329 
2024-11-08 19:30:47.905286: train_loss -0.9323 
2024-11-08 19:30:47.914699: val_loss -0.8837 
2024-11-08 19:30:47.917201: Pseudo dice [np.float32(0.95), np.float32(0.901)] 
2024-11-08 19:30:47.919459: Epoch time: 39.8 s 
2024-11-08 19:30:49.156001:  
2024-11-08 19:30:49.158259: Epoch 710 
2024-11-08 19:30:49.160624: Current learning rate: 0.00328 
2024-11-08 19:31:28.994392: train_loss -0.9327 
2024-11-08 19:31:29.000478: val_loss -0.8666 
2024-11-08 19:31:29.002877: Pseudo dice [np.float32(0.9502), np.float32(0.8508)] 
2024-11-08 19:31:29.005309: Epoch time: 39.84 s 
2024-11-08 19:31:30.335916:  
2024-11-08 19:31:30.338469: Epoch 711 
2024-11-08 19:31:30.340923: Current learning rate: 0.00327 
2024-11-08 19:32:10.354682: train_loss -0.9388 
2024-11-08 19:32:10.357401: val_loss -0.8693 
2024-11-08 19:32:10.359763: Pseudo dice [np.float32(0.9523), np.float32(0.8542)] 
2024-11-08 19:32:10.362069: Epoch time: 40.02 s 
2024-11-08 19:32:11.698910:  
2024-11-08 19:32:11.701344: Epoch 712 
2024-11-08 19:32:11.703622: Current learning rate: 0.00326 
2024-11-08 19:32:51.762126: train_loss -0.9343 
2024-11-08 19:32:51.771494: val_loss -0.8376 
2024-11-08 19:32:51.774587: Pseudo dice [np.float32(0.9535), np.float32(0.8585)] 
2024-11-08 19:32:51.776925: Epoch time: 40.06 s 
2024-11-08 19:32:53.110034:  
2024-11-08 19:32:53.112450: Epoch 713 
2024-11-08 19:32:53.114808: Current learning rate: 0.00325 
2024-11-08 19:33:33.180292: train_loss -0.9345 
2024-11-08 19:33:33.183006: val_loss -0.8262 
2024-11-08 19:33:33.185227: Pseudo dice [np.float32(0.9418), np.float32(0.7893)] 
2024-11-08 19:33:33.187530: Epoch time: 40.07 s 
2024-11-08 19:33:35.366859:  
2024-11-08 19:33:35.369331: Epoch 714 
2024-11-08 19:33:35.371458: Current learning rate: 0.00324 
2024-11-08 19:34:15.438206: train_loss -0.9334 
2024-11-08 19:34:15.444516: val_loss -0.8737 
2024-11-08 19:34:15.446986: Pseudo dice [np.float32(0.9409), np.float32(0.8738)] 
2024-11-08 19:34:15.449524: Epoch time: 40.07 s 
2024-11-08 19:34:16.782656:  
2024-11-08 19:34:16.784999: Epoch 715 
2024-11-08 19:34:16.787285: Current learning rate: 0.00323 
2024-11-08 19:34:56.871767: train_loss -0.9364 
2024-11-08 19:34:56.881960: val_loss -0.838 
2024-11-08 19:34:56.884271: Pseudo dice [np.float32(0.9327), np.float32(0.8124)] 
2024-11-08 19:34:56.886448: Epoch time: 40.09 s 
2024-11-08 19:34:58.222793:  
2024-11-08 19:34:58.225385: Epoch 716 
2024-11-08 19:34:58.227848: Current learning rate: 0.00322 
2024-11-08 19:35:38.280208: train_loss -0.9257 
2024-11-08 19:35:38.286363: val_loss -0.8614 
2024-11-08 19:35:38.288914: Pseudo dice [np.float32(0.9479), np.float32(0.8598)] 
2024-11-08 19:35:38.291247: Epoch time: 40.06 s 
2024-11-08 19:35:39.621643:  
2024-11-08 19:35:39.624224: Epoch 717 
2024-11-08 19:35:39.626714: Current learning rate: 0.00321 
2024-11-08 19:36:19.719769: train_loss -0.9415 
2024-11-08 19:36:19.724056: val_loss -0.8751 
2024-11-08 19:36:19.727246: Pseudo dice [np.float32(0.9466), np.float32(0.8711)] 
2024-11-08 19:36:19.729494: Epoch time: 40.1 s 
2024-11-08 19:36:21.061213:  
2024-11-08 19:36:21.063580: Epoch 718 
2024-11-08 19:36:21.065925: Current learning rate: 0.0032 
2024-11-08 19:37:01.144897: train_loss -0.9357 
2024-11-08 19:37:01.149915: val_loss -0.8337 
2024-11-08 19:37:01.152276: Pseudo dice [np.float32(0.9397), np.float32(0.8177)] 
2024-11-08 19:37:01.154482: Epoch time: 40.08 s 
2024-11-08 19:37:02.486922:  
2024-11-08 19:37:02.489413: Epoch 719 
2024-11-08 19:37:02.491688: Current learning rate: 0.00319 
2024-11-08 19:37:42.559112: train_loss -0.925 
2024-11-08 19:37:42.565717: val_loss -0.8204 
2024-11-08 19:37:42.568079: Pseudo dice [np.float32(0.9449), np.float32(0.8369)] 
2024-11-08 19:37:42.570502: Epoch time: 40.07 s 
2024-11-08 19:37:43.903403:  
2024-11-08 19:37:43.905914: Epoch 720 
2024-11-08 19:37:43.908381: Current learning rate: 0.00318 
2024-11-08 19:38:23.962601: train_loss -0.9356 
2024-11-08 19:38:23.968033: val_loss -0.8508 
2024-11-08 19:38:23.970256: Pseudo dice [np.float32(0.9465), np.float32(0.8228)] 
2024-11-08 19:38:23.973455: Epoch time: 40.06 s 
2024-11-08 19:38:25.306962:  
2024-11-08 19:38:25.309704: Epoch 721 
2024-11-08 19:38:25.312430: Current learning rate: 0.00317 
2024-11-08 19:39:05.337852: train_loss -0.9284 
2024-11-08 19:39:05.340639: val_loss -0.8424 
2024-11-08 19:39:05.343316: Pseudo dice [np.float32(0.9483), np.float32(0.8529)] 
2024-11-08 19:39:05.345518: Epoch time: 40.03 s 
2024-11-08 19:39:06.674269:  
2024-11-08 19:39:06.676506: Epoch 722 
2024-11-08 19:39:06.678741: Current learning rate: 0.00316 
2024-11-08 19:39:46.745690: train_loss -0.9353 
2024-11-08 19:39:46.753340: val_loss -0.8748 
2024-11-08 19:39:46.755568: Pseudo dice [np.float32(0.9546), np.float32(0.8736)] 
2024-11-08 19:39:46.757913: Epoch time: 40.07 s 
2024-11-08 19:39:48.087899:  
2024-11-08 19:39:48.090208: Epoch 723 
2024-11-08 19:39:48.092583: Current learning rate: 0.00315 
2024-11-08 19:40:28.168342: train_loss -0.9335 
2024-11-08 19:40:28.171383: val_loss -0.8752 
2024-11-08 19:40:28.173846: Pseudo dice [np.float32(0.953), np.float32(0.8884)] 
2024-11-08 19:40:28.176383: Epoch time: 40.08 s 
2024-11-08 19:40:29.504440:  
2024-11-08 19:40:29.507205: Epoch 724 
2024-11-08 19:40:29.510309: Current learning rate: 0.00314 
2024-11-08 19:41:09.601493: train_loss -0.9192 
2024-11-08 19:41:09.607005: val_loss -0.8627 
2024-11-08 19:41:09.610503: Pseudo dice [np.float32(0.9394), np.float32(0.8631)] 
2024-11-08 19:41:09.612712: Epoch time: 40.1 s 
2024-11-08 19:41:10.943624:  
2024-11-08 19:41:10.946113: Epoch 725 
2024-11-08 19:41:10.948374: Current learning rate: 0.00313 
2024-11-08 19:41:51.020975: train_loss -0.9241 
2024-11-08 19:41:51.025822: val_loss -0.869 
2024-11-08 19:41:51.028429: Pseudo dice [np.float32(0.9436), np.float32(0.8867)] 
2024-11-08 19:41:51.030822: Epoch time: 40.08 s 
2024-11-08 19:41:52.362531:  
2024-11-08 19:41:52.365672: Epoch 726 
2024-11-08 19:41:52.368437: Current learning rate: 0.00312 
2024-11-08 19:42:32.420477: train_loss -0.9219 
2024-11-08 19:42:32.426250: val_loss -0.8359 
2024-11-08 19:42:32.429253: Pseudo dice [np.float32(0.9423), np.float32(0.8544)] 
2024-11-08 19:42:32.431526: Epoch time: 40.06 s 
2024-11-08 19:42:33.767330:  
2024-11-08 19:42:33.769879: Epoch 727 
2024-11-08 19:42:33.772154: Current learning rate: 0.00311 
2024-11-08 19:43:13.855281: train_loss -0.9283 
2024-11-08 19:43:13.859503: val_loss -0.8639 
2024-11-08 19:43:13.862527: Pseudo dice [np.float32(0.9474), np.float32(0.8822)] 
2024-11-08 19:43:13.866677: Epoch time: 40.09 s 
2024-11-08 19:43:15.197002:  
2024-11-08 19:43:15.199522: Epoch 728 
2024-11-08 19:43:15.201920: Current learning rate: 0.0031 
2024-11-08 19:43:55.250783: train_loss -0.935 
2024-11-08 19:43:55.271941: val_loss -0.8703 
2024-11-08 19:43:55.274757: Pseudo dice [np.float32(0.9519), np.float32(0.8588)] 
2024-11-08 19:43:55.277469: Epoch time: 40.05 s 
2024-11-08 19:43:56.613044:  
2024-11-08 19:43:56.615625: Epoch 729 
2024-11-08 19:43:56.617968: Current learning rate: 0.00309 
2024-11-08 19:44:36.653548: train_loss -0.9351 
2024-11-08 19:44:36.656864: val_loss -0.8841 
2024-11-08 19:44:36.659034: Pseudo dice [np.float32(0.9488), np.float32(0.8847)] 
2024-11-08 19:44:36.661442: Epoch time: 40.04 s 
2024-11-08 19:44:37.991204:  
2024-11-08 19:44:37.993876: Epoch 730 
2024-11-08 19:44:37.996240: Current learning rate: 0.00308 
2024-11-08 19:45:18.020692: train_loss -0.9292 
2024-11-08 19:45:18.026288: val_loss -0.8146 
2024-11-08 19:45:18.028785: Pseudo dice [np.float32(0.9395), np.float32(0.8489)] 
2024-11-08 19:45:18.030949: Epoch time: 40.03 s 
2024-11-08 19:45:19.364532:  
2024-11-08 19:45:19.367569: Epoch 731 
2024-11-08 19:45:19.370105: Current learning rate: 0.00307 
2024-11-08 19:45:59.424900: train_loss -0.9312 
2024-11-08 19:45:59.434522: val_loss -0.8332 
2024-11-08 19:45:59.437063: Pseudo dice [np.float32(0.9486), np.float32(0.8027)] 
2024-11-08 19:45:59.439589: Epoch time: 40.06 s 
2024-11-08 19:46:00.766830:  
2024-11-08 19:46:00.769294: Epoch 732 
2024-11-08 19:46:00.771847: Current learning rate: 0.00306 
2024-11-08 19:46:40.833143: train_loss -0.9079 
2024-11-08 19:46:40.839203: val_loss -0.8079 
2024-11-08 19:46:40.841527: Pseudo dice [np.float32(0.9379), np.float32(0.7965)] 
2024-11-08 19:46:40.843947: Epoch time: 40.07 s 
2024-11-08 19:46:42.994437:  
2024-11-08 19:46:42.996822: Epoch 733 
2024-11-08 19:46:42.999437: Current learning rate: 0.00305 
2024-11-08 19:47:23.064566: train_loss -0.9204 
2024-11-08 19:47:23.074802: val_loss -0.8451 
2024-11-08 19:47:23.077116: Pseudo dice [np.float32(0.9412), np.float32(0.8345)] 
2024-11-08 19:47:23.079589: Epoch time: 40.07 s 
2024-11-08 19:47:24.409743:  
2024-11-08 19:47:24.412208: Epoch 734 
2024-11-08 19:47:24.414939: Current learning rate: 0.00304 
2024-11-08 19:48:04.492914: train_loss -0.9337 
2024-11-08 19:48:04.499208: val_loss -0.8608 
2024-11-08 19:48:04.502055: Pseudo dice [np.float32(0.9513), np.float32(0.8752)] 
2024-11-08 19:48:04.504632: Epoch time: 40.08 s 
2024-11-08 19:48:05.835985:  
2024-11-08 19:48:05.839885: Epoch 735 
2024-11-08 19:48:05.842644: Current learning rate: 0.00303 
2024-11-08 19:48:45.897384: train_loss -0.9362 
2024-11-08 19:48:45.913157: val_loss -0.8715 
2024-11-08 19:48:45.915886: Pseudo dice [np.float32(0.9425), np.float32(0.8822)] 
2024-11-08 19:48:45.918483: Epoch time: 40.06 s 
2024-11-08 19:48:47.249863:  
2024-11-08 19:48:47.252481: Epoch 736 
2024-11-08 19:48:47.255105: Current learning rate: 0.00302 
2024-11-08 19:49:27.338730: train_loss -0.9349 
2024-11-08 19:49:27.345052: val_loss -0.8565 
2024-11-08 19:49:27.347660: Pseudo dice [np.float32(0.9504), np.float32(0.8612)] 
2024-11-08 19:49:27.350008: Epoch time: 40.09 s 
2024-11-08 19:49:28.683281:  
2024-11-08 19:49:28.686045: Epoch 737 
2024-11-08 19:49:28.688403: Current learning rate: 0.00301 
2024-11-08 19:50:08.737925: train_loss -0.9385 
2024-11-08 19:50:08.748274: val_loss -0.8672 
2024-11-08 19:50:08.750903: Pseudo dice [np.float32(0.9551), np.float32(0.8875)] 
2024-11-08 19:50:08.753612: Epoch time: 40.06 s 
2024-11-08 19:50:10.088281:  
2024-11-08 19:50:10.090788: Epoch 738 
2024-11-08 19:50:10.093215: Current learning rate: 0.003 
2024-11-08 19:50:50.161561: train_loss -0.9326 
2024-11-08 19:50:50.168760: val_loss -0.8473 
2024-11-08 19:50:50.171219: Pseudo dice [np.float32(0.9513), np.float32(0.882)] 
2024-11-08 19:50:50.174682: Epoch time: 40.07 s 
2024-11-08 19:50:51.508196:  
2024-11-08 19:50:51.510803: Epoch 739 
2024-11-08 19:50:51.513043: Current learning rate: 0.00299 
2024-11-08 19:51:31.586700: train_loss -0.937 
2024-11-08 19:51:31.589333: val_loss -0.8458 
2024-11-08 19:51:31.591598: Pseudo dice [np.float32(0.9491), np.float32(0.8401)] 
2024-11-08 19:51:31.593937: Epoch time: 40.08 s 
2024-11-08 19:51:32.922054:  
2024-11-08 19:51:32.924422: Epoch 740 
2024-11-08 19:51:32.926834: Current learning rate: 0.00297 
2024-11-08 19:52:12.968961: train_loss -0.9404 
2024-11-08 19:52:12.974670: val_loss -0.8382 
2024-11-08 19:52:12.976945: Pseudo dice [np.float32(0.9484), np.float32(0.8412)] 
2024-11-08 19:52:12.979429: Epoch time: 40.05 s 
2024-11-08 19:52:14.310078:  
2024-11-08 19:52:14.312419: Epoch 741 
2024-11-08 19:52:14.314692: Current learning rate: 0.00296 
2024-11-08 19:52:54.393159: train_loss -0.9421 
2024-11-08 19:52:54.401891: val_loss -0.8087 
2024-11-08 19:52:54.404336: Pseudo dice [np.float32(0.9459), np.float32(0.8046)] 
2024-11-08 19:52:54.406810: Epoch time: 40.08 s 
2024-11-08 19:52:55.752748:  
2024-11-08 19:52:55.755080: Epoch 742 
2024-11-08 19:52:55.757487: Current learning rate: 0.00295 
2024-11-08 19:53:35.810550: train_loss -0.9407 
2024-11-08 19:53:35.816558: val_loss -0.848 
2024-11-08 19:53:35.818789: Pseudo dice [np.float32(0.9406), np.float32(0.8365)] 
2024-11-08 19:53:35.820937: Epoch time: 40.06 s 
2024-11-08 19:53:37.150448:  
2024-11-08 19:53:37.153746: Epoch 743 
2024-11-08 19:53:37.156146: Current learning rate: 0.00294 
2024-11-08 19:54:17.217459: train_loss -0.9466 
2024-11-08 19:54:17.226875: val_loss -0.8548 
2024-11-08 19:54:17.229445: Pseudo dice [np.float32(0.9354), np.float32(0.856)] 
2024-11-08 19:54:17.231830: Epoch time: 40.07 s 
2024-11-08 19:54:18.560727:  
2024-11-08 19:54:18.563340: Epoch 744 
2024-11-08 19:54:18.565711: Current learning rate: 0.00293 
2024-11-08 19:54:58.632439: train_loss -0.939 
2024-11-08 19:54:58.638878: val_loss -0.8575 
2024-11-08 19:54:58.641443: Pseudo dice [np.float32(0.9536), np.float32(0.8342)] 
2024-11-08 19:54:58.643781: Epoch time: 40.07 s 
2024-11-08 19:54:59.983878:  
2024-11-08 19:54:59.986593: Epoch 745 
2024-11-08 19:54:59.989084: Current learning rate: 0.00292 
2024-11-08 19:55:40.071512: train_loss -0.9414 
2024-11-08 19:55:40.074229: val_loss -0.8644 
2024-11-08 19:55:40.076670: Pseudo dice [np.float32(0.9512), np.float32(0.8902)] 
2024-11-08 19:55:40.078988: Epoch time: 40.09 s 
2024-11-08 19:55:41.419053:  
2024-11-08 19:55:41.421614: Epoch 746 
2024-11-08 19:55:41.423935: Current learning rate: 0.00291 
2024-11-08 19:56:21.455453: train_loss -0.9438 
2024-11-08 19:56:21.462078: val_loss -0.8374 
2024-11-08 19:56:21.464264: Pseudo dice [np.float32(0.9564), np.float32(0.8731)] 
2024-11-08 19:56:21.466650: Epoch time: 40.04 s 
2024-11-08 19:56:22.797244:  
2024-11-08 19:56:22.799614: Epoch 747 
2024-11-08 19:56:22.801993: Current learning rate: 0.0029 
2024-11-08 19:57:02.830485: train_loss -0.9441 
2024-11-08 19:57:02.838506: val_loss -0.824 
2024-11-08 19:57:02.840776: Pseudo dice [np.float32(0.9447), np.float32(0.7969)] 
2024-11-08 19:57:02.842988: Epoch time: 40.03 s 
2024-11-08 19:57:04.167338:  
2024-11-08 19:57:04.169711: Epoch 748 
2024-11-08 19:57:04.172053: Current learning rate: 0.00289 
2024-11-08 19:57:44.220758: train_loss -0.9309 
2024-11-08 19:57:44.227556: val_loss -0.8589 
2024-11-08 19:57:44.229992: Pseudo dice [np.float32(0.9502), np.float32(0.8632)] 
2024-11-08 19:57:44.232319: Epoch time: 40.05 s 
2024-11-08 19:57:45.558689:  
2024-11-08 19:57:45.561070: Epoch 749 
2024-11-08 19:57:45.563659: Current learning rate: 0.00288 
2024-11-08 19:58:25.592782: train_loss -0.9401 
2024-11-08 19:58:25.599380: val_loss -0.8727 
2024-11-08 19:58:25.601541: Pseudo dice [np.float32(0.9465), np.float32(0.8828)] 
2024-11-08 19:58:25.604212: Epoch time: 40.04 s 
2024-11-08 19:58:27.815832:  
2024-11-08 19:58:27.818439: Epoch 750 
2024-11-08 19:58:27.820929: Current learning rate: 0.00287 
2024-11-08 19:59:07.806283: train_loss -0.945 
2024-11-08 19:59:07.812563: val_loss -0.8458 
2024-11-08 19:59:07.815068: Pseudo dice [np.float32(0.9552), np.float32(0.851)] 
2024-11-08 19:59:07.817507: Epoch time: 39.99 s 
2024-11-08 19:59:09.148181:  
2024-11-08 19:59:09.150798: Epoch 751 
2024-11-08 19:59:09.153330: Current learning rate: 0.00286 
2024-11-08 19:59:49.208948: train_loss -0.9436 
2024-11-08 19:59:49.214360: val_loss -0.8632 
2024-11-08 19:59:49.217030: Pseudo dice [np.float32(0.9529), np.float32(0.8559)] 
2024-11-08 19:59:49.219531: Epoch time: 40.06 s 
2024-11-08 19:59:51.361205:  
2024-11-08 19:59:51.363881: Epoch 752 
2024-11-08 19:59:51.366242: Current learning rate: 0.00285 
2024-11-08 20:00:31.423389: train_loss -0.9302 
2024-11-08 20:00:31.428693: val_loss -0.8426 
2024-11-08 20:00:31.430950: Pseudo dice [np.float32(0.9459), np.float32(0.8396)] 
2024-11-08 20:00:31.433086: Epoch time: 40.06 s 
2024-11-08 20:00:32.765710:  
2024-11-08 20:00:32.768404: Epoch 753 
2024-11-08 20:00:32.770792: Current learning rate: 0.00284 
2024-11-08 20:01:12.862526: train_loss -0.9321 
2024-11-08 20:01:12.865271: val_loss -0.825 
2024-11-08 20:01:12.868686: Pseudo dice [np.float32(0.9472), np.float32(0.8139)] 
2024-11-08 20:01:12.870892: Epoch time: 40.1 s 
2024-11-08 20:01:14.195135:  
2024-11-08 20:01:14.197798: Epoch 754 
2024-11-08 20:01:14.200182: Current learning rate: 0.00283 
2024-11-08 20:01:54.275313: train_loss -0.9358 
2024-11-08 20:01:54.282025: val_loss -0.8509 
2024-11-08 20:01:54.284758: Pseudo dice [np.float32(0.9487), np.float32(0.8478)] 
2024-11-08 20:01:54.287795: Epoch time: 40.08 s 
2024-11-08 20:01:55.630292:  
2024-11-08 20:01:55.632865: Epoch 755 
2024-11-08 20:01:55.635383: Current learning rate: 0.00282 
2024-11-08 20:02:35.688341: train_loss -0.9354 
2024-11-08 20:02:35.694547: val_loss -0.8522 
2024-11-08 20:02:35.696731: Pseudo dice [np.float32(0.9456), np.float32(0.8647)] 
2024-11-08 20:02:35.699157: Epoch time: 40.06 s 
2024-11-08 20:02:37.029049:  
2024-11-08 20:02:37.031622: Epoch 756 
2024-11-08 20:02:37.033851: Current learning rate: 0.00281 
2024-11-08 20:03:17.123192: train_loss -0.9382 
2024-11-08 20:03:17.132225: val_loss -0.853 
2024-11-08 20:03:17.134640: Pseudo dice [np.float32(0.9504), np.float32(0.8589)] 
2024-11-08 20:03:17.136956: Epoch time: 40.1 s 
2024-11-08 20:03:18.462853:  
2024-11-08 20:03:18.465318: Epoch 757 
2024-11-08 20:03:18.467828: Current learning rate: 0.0028 
2024-11-08 20:03:58.590235: train_loss -0.9432 
2024-11-08 20:03:58.596465: val_loss -0.8897 
2024-11-08 20:03:58.598845: Pseudo dice [np.float32(0.9521), np.float32(0.9079)] 
2024-11-08 20:03:58.601640: Epoch time: 40.13 s 
2024-11-08 20:03:59.940880:  
2024-11-08 20:03:59.943226: Epoch 758 
2024-11-08 20:03:59.945628: Current learning rate: 0.00279 
2024-11-08 20:04:40.002843: train_loss -0.9394 
2024-11-08 20:04:40.009199: val_loss -0.8327 
2024-11-08 20:04:40.011510: Pseudo dice [np.float32(0.9508), np.float32(0.822)] 
2024-11-08 20:04:40.013873: Epoch time: 40.06 s 
2024-11-08 20:04:41.349226:  
2024-11-08 20:04:41.351775: Epoch 759 
2024-11-08 20:04:41.354196: Current learning rate: 0.00278 
2024-11-08 20:05:21.416534: train_loss -0.9387 
2024-11-08 20:05:21.419096: val_loss -0.8598 
2024-11-08 20:05:21.421404: Pseudo dice [np.float32(0.954), np.float32(0.8651)] 
2024-11-08 20:05:21.423665: Epoch time: 40.07 s 
2024-11-08 20:05:22.742104:  
2024-11-08 20:05:22.745752: Epoch 760 
2024-11-08 20:05:22.748350: Current learning rate: 0.00277 
2024-11-08 20:06:02.819459: train_loss -0.9321 
2024-11-08 20:06:02.824519: val_loss -0.8885 
2024-11-08 20:06:02.826759: Pseudo dice [np.float32(0.9449), np.float32(0.8992)] 
2024-11-08 20:06:02.829038: Epoch time: 40.08 s 
2024-11-08 20:06:04.159301:  
2024-11-08 20:06:04.161949: Epoch 761 
2024-11-08 20:06:04.164565: Current learning rate: 0.00276 
2024-11-08 20:06:44.199805: train_loss -0.9322 
2024-11-08 20:06:44.202745: val_loss -0.7774 
2024-11-08 20:06:44.205102: Pseudo dice [np.float32(0.9439), np.float32(0.744)] 
2024-11-08 20:06:44.207297: Epoch time: 40.04 s 
2024-11-08 20:06:45.541646:  
2024-11-08 20:06:45.544097: Epoch 762 
2024-11-08 20:06:45.546583: Current learning rate: 0.00275 
2024-11-08 20:07:25.648554: train_loss -0.9385 
2024-11-08 20:07:25.654803: val_loss -0.8372 
2024-11-08 20:07:25.657109: Pseudo dice [np.float32(0.9462), np.float32(0.8397)] 
2024-11-08 20:07:25.659520: Epoch time: 40.11 s 
2024-11-08 20:07:27.004057:  
2024-11-08 20:07:27.006384: Epoch 763 
2024-11-08 20:07:27.008832: Current learning rate: 0.00274 
2024-11-08 20:08:07.073530: train_loss -0.9392 
2024-11-08 20:08:07.077390: val_loss -0.8459 
2024-11-08 20:08:07.079785: Pseudo dice [np.float32(0.9484), np.float32(0.8395)] 
2024-11-08 20:08:07.082280: Epoch time: 40.07 s 
2024-11-08 20:08:08.435027:  
2024-11-08 20:08:08.437898: Epoch 764 
2024-11-08 20:08:08.440697: Current learning rate: 0.00273 
2024-11-08 20:08:48.511619: train_loss -0.9418 
2024-11-08 20:08:48.520338: val_loss -0.8711 
2024-11-08 20:08:48.523998: Pseudo dice [np.float32(0.948), np.float32(0.8769)] 
2024-11-08 20:08:48.526586: Epoch time: 40.08 s 
2024-11-08 20:08:49.873997:  
2024-11-08 20:08:49.876324: Epoch 765 
2024-11-08 20:08:49.878730: Current learning rate: 0.00272 
2024-11-08 20:09:29.936571: train_loss -0.9377 
2024-11-08 20:09:29.939224: val_loss -0.8463 
2024-11-08 20:09:29.941503: Pseudo dice [np.float32(0.9507), np.float32(0.8583)] 
2024-11-08 20:09:29.943759: Epoch time: 40.06 s 
2024-11-08 20:09:31.281180:  
2024-11-08 20:09:31.283412: Epoch 766 
2024-11-08 20:09:31.285908: Current learning rate: 0.00271 
2024-11-08 20:10:11.348918: train_loss -0.9452 
2024-11-08 20:10:11.354426: val_loss -0.8674 
2024-11-08 20:10:11.356652: Pseudo dice [np.float32(0.9553), np.float32(0.8612)] 
2024-11-08 20:10:11.358819: Epoch time: 40.07 s 
2024-11-08 20:10:12.710365:  
2024-11-08 20:10:12.713127: Epoch 767 
2024-11-08 20:10:12.715632: Current learning rate: 0.0027 
2024-11-08 20:10:52.767735: train_loss -0.9362 
2024-11-08 20:10:52.770407: val_loss -0.8504 
2024-11-08 20:10:52.773001: Pseudo dice [np.float32(0.9515), np.float32(0.8374)] 
2024-11-08 20:10:52.775471: Epoch time: 40.06 s 
2024-11-08 20:10:54.130661:  
2024-11-08 20:10:54.133159: Epoch 768 
2024-11-08 20:10:54.135537: Current learning rate: 0.00268 
2024-11-08 20:11:34.197139: train_loss -0.9409 
2024-11-08 20:11:34.202590: val_loss -0.8469 
2024-11-08 20:11:34.204851: Pseudo dice [np.float32(0.9394), np.float32(0.8632)] 
2024-11-08 20:11:34.207295: Epoch time: 40.07 s 
2024-11-08 20:11:35.553098:  
2024-11-08 20:11:35.555758: Epoch 769 
2024-11-08 20:11:35.558126: Current learning rate: 0.00267 
2024-11-08 20:12:15.607476: train_loss -0.9389 
2024-11-08 20:12:15.610329: val_loss -0.8608 
2024-11-08 20:12:15.612725: Pseudo dice [np.float32(0.9463), np.float32(0.8621)] 
2024-11-08 20:12:15.615213: Epoch time: 40.06 s 
2024-11-08 20:12:17.775090:  
2024-11-08 20:12:17.777893: Epoch 770 
2024-11-08 20:12:17.780530: Current learning rate: 0.00266 
2024-11-08 20:12:57.872605: train_loss -0.9396 
2024-11-08 20:12:57.880125: val_loss -0.8512 
2024-11-08 20:12:57.882674: Pseudo dice [np.float32(0.9501), np.float32(0.8456)] 
2024-11-08 20:12:57.885317: Epoch time: 40.1 s 
2024-11-08 20:12:59.237433:  
2024-11-08 20:12:59.240077: Epoch 771 
2024-11-08 20:12:59.242699: Current learning rate: 0.00265 
2024-11-08 20:13:39.326314: train_loss -0.9411 
2024-11-08 20:13:39.328805: val_loss -0.8609 
2024-11-08 20:13:39.331157: Pseudo dice [np.float32(0.9527), np.float32(0.8434)] 
2024-11-08 20:13:39.334524: Epoch time: 40.09 s 
2024-11-08 20:13:40.685098:  
2024-11-08 20:13:40.687545: Epoch 772 
2024-11-08 20:13:40.689940: Current learning rate: 0.00264 
2024-11-08 20:14:20.801868: train_loss -0.9399 
2024-11-08 20:14:20.807235: val_loss -0.7882 
2024-11-08 20:14:20.809469: Pseudo dice [np.float32(0.944), np.float32(0.7322)] 
2024-11-08 20:14:20.811962: Epoch time: 40.12 s 
2024-11-08 20:14:22.166278:  
2024-11-08 20:14:22.169184: Epoch 773 
2024-11-08 20:14:22.171649: Current learning rate: 0.00263 
2024-11-08 20:15:02.222799: train_loss -0.9434 
2024-11-08 20:15:02.225623: val_loss -0.8906 
2024-11-08 20:15:02.228145: Pseudo dice [np.float32(0.9494), np.float32(0.9029)] 
2024-11-08 20:15:02.230501: Epoch time: 40.06 s 
2024-11-08 20:15:03.572307:  
2024-11-08 20:15:03.574972: Epoch 774 
2024-11-08 20:15:03.577704: Current learning rate: 0.00262 
2024-11-08 20:15:43.644030: train_loss -0.942 
2024-11-08 20:15:43.650445: val_loss -0.8431 
2024-11-08 20:15:43.652871: Pseudo dice [np.float32(0.9439), np.float32(0.8448)] 
2024-11-08 20:15:43.655554: Epoch time: 40.07 s 
2024-11-08 20:15:44.998521:  
2024-11-08 20:15:45.001283: Epoch 775 
2024-11-08 20:15:45.005681: Current learning rate: 0.00261 
2024-11-08 20:16:25.079713: train_loss -0.9388 
2024-11-08 20:16:25.085914: val_loss -0.8521 
2024-11-08 20:16:25.088365: Pseudo dice [np.float32(0.9362), np.float32(0.8896)] 
2024-11-08 20:16:25.090656: Epoch time: 40.08 s 
2024-11-08 20:16:26.444380:  
2024-11-08 20:16:26.447182: Epoch 776 
2024-11-08 20:16:26.449690: Current learning rate: 0.0026 
2024-11-08 20:17:06.531155: train_loss -0.9432 
2024-11-08 20:17:06.537159: val_loss -0.8593 
2024-11-08 20:17:06.539471: Pseudo dice [np.float32(0.952), np.float32(0.8352)] 
2024-11-08 20:17:06.542069: Epoch time: 40.09 s 
2024-11-08 20:17:07.890812:  
2024-11-08 20:17:07.893109: Epoch 777 
2024-11-08 20:17:07.895517: Current learning rate: 0.00259 
2024-11-08 20:17:47.972625: train_loss -0.9453 
2024-11-08 20:17:47.977159: val_loss -0.8718 
2024-11-08 20:17:47.979686: Pseudo dice [np.float32(0.9543), np.float32(0.8991)] 
2024-11-08 20:17:47.982044: Epoch time: 40.08 s 
2024-11-08 20:17:49.328244:  
2024-11-08 20:17:49.330727: Epoch 778 
2024-11-08 20:17:49.332970: Current learning rate: 0.00258 
2024-11-08 20:18:29.419903: train_loss -0.9442 
2024-11-08 20:18:29.426774: val_loss -0.8875 
2024-11-08 20:18:29.429102: Pseudo dice [np.float32(0.9503), np.float32(0.8722)] 
2024-11-08 20:18:29.431269: Epoch time: 40.09 s 
2024-11-08 20:18:30.773653:  
2024-11-08 20:18:30.776927: Epoch 779 
2024-11-08 20:18:30.779280: Current learning rate: 0.00257 
2024-11-08 20:19:10.864005: train_loss -0.945 
2024-11-08 20:19:10.868094: val_loss -0.8765 
2024-11-08 20:19:10.870914: Pseudo dice [np.float32(0.9435), np.float32(0.894)] 
2024-11-08 20:19:10.873246: Epoch time: 40.09 s 
2024-11-08 20:19:12.348670:  
2024-11-08 20:19:12.351049: Epoch 780 
2024-11-08 20:19:12.353361: Current learning rate: 0.00256 
2024-11-08 20:19:52.429701: train_loss -0.9335 
2024-11-08 20:19:52.436830: val_loss -0.7874 
2024-11-08 20:19:52.438998: Pseudo dice [np.float32(0.9419), np.float32(0.7638)] 
2024-11-08 20:19:52.441181: Epoch time: 40.08 s 
2024-11-08 20:19:53.792185:  
2024-11-08 20:19:53.794679: Epoch 781 
2024-11-08 20:19:53.797226: Current learning rate: 0.00255 
2024-11-08 20:20:33.882862: train_loss -0.9363 
2024-11-08 20:20:33.885739: val_loss -0.906 
2024-11-08 20:20:33.888277: Pseudo dice [np.float32(0.9559), np.float32(0.9175)] 
2024-11-08 20:20:33.890710: Epoch time: 40.09 s 
2024-11-08 20:20:35.236216:  
2024-11-08 20:20:35.239108: Epoch 782 
2024-11-08 20:20:35.242040: Current learning rate: 0.00254 
2024-11-08 20:21:15.321926: train_loss -0.9396 
2024-11-08 20:21:15.327910: val_loss -0.8658 
2024-11-08 20:21:15.330139: Pseudo dice [np.float32(0.9489), np.float32(0.8586)] 
2024-11-08 20:21:15.333528: Epoch time: 40.09 s 
2024-11-08 20:21:16.684990:  
2024-11-08 20:21:16.687525: Epoch 783 
2024-11-08 20:21:16.689892: Current learning rate: 0.00253 
2024-11-08 20:21:56.794451: train_loss -0.9384 
2024-11-08 20:21:56.797851: val_loss -0.8006 
2024-11-08 20:21:56.800785: Pseudo dice [np.float32(0.9485), np.float32(0.7616)] 
2024-11-08 20:21:56.802953: Epoch time: 40.11 s 
2024-11-08 20:21:58.152729:  
2024-11-08 20:21:58.155504: Epoch 784 
2024-11-08 20:21:58.157763: Current learning rate: 0.00252 
2024-11-08 20:22:38.236545: train_loss -0.9334 
2024-11-08 20:22:38.243555: val_loss -0.8176 
2024-11-08 20:22:38.246072: Pseudo dice [np.float32(0.9436), np.float32(0.8233)] 
2024-11-08 20:22:38.248609: Epoch time: 40.09 s 
2024-11-08 20:22:39.595986:  
2024-11-08 20:22:39.598559: Epoch 785 
2024-11-08 20:22:39.600878: Current learning rate: 0.00251 
2024-11-08 20:23:19.668167: train_loss -0.9419 
2024-11-08 20:23:19.674326: val_loss -0.8682 
2024-11-08 20:23:19.676827: Pseudo dice [np.float32(0.9486), np.float32(0.8748)] 
2024-11-08 20:23:19.679223: Epoch time: 40.07 s 
2024-11-08 20:23:21.033442:  
2024-11-08 20:23:21.035631: Epoch 786 
2024-11-08 20:23:21.037926: Current learning rate: 0.0025 
2024-11-08 20:24:01.069568: train_loss -0.9444 
2024-11-08 20:24:01.080133: val_loss -0.8495 
2024-11-08 20:24:01.082517: Pseudo dice [np.float32(0.9514), np.float32(0.8432)] 
2024-11-08 20:24:01.085078: Epoch time: 40.04 s 
2024-11-08 20:24:02.435877:  
2024-11-08 20:24:02.438210: Epoch 787 
2024-11-08 20:24:02.440525: Current learning rate: 0.00249 
2024-11-08 20:24:42.462493: train_loss -0.9286 
2024-11-08 20:24:42.467725: val_loss -0.8256 
2024-11-08 20:24:42.470981: Pseudo dice [np.float32(0.9456), np.float32(0.8419)] 
2024-11-08 20:24:42.473571: Epoch time: 40.03 s 
2024-11-08 20:24:44.624782:  
2024-11-08 20:24:44.627197: Epoch 788 
2024-11-08 20:24:44.629444: Current learning rate: 0.00248 
2024-11-08 20:25:24.707614: train_loss -0.9327 
2024-11-08 20:25:24.714107: val_loss -0.8544 
2024-11-08 20:25:24.716588: Pseudo dice [np.float32(0.9463), np.float32(0.8859)] 
2024-11-08 20:25:24.719017: Epoch time: 40.08 s 
2024-11-08 20:25:26.069250:  
2024-11-08 20:25:26.071623: Epoch 789 
2024-11-08 20:25:26.073913: Current learning rate: 0.00247 
2024-11-08 20:26:06.123605: train_loss -0.9262 
2024-11-08 20:26:06.128007: val_loss -0.8675 
2024-11-08 20:26:06.130226: Pseudo dice [np.float32(0.9538), np.float32(0.8636)] 
2024-11-08 20:26:06.132672: Epoch time: 40.06 s 
2024-11-08 20:26:07.489436:  
2024-11-08 20:26:07.491972: Epoch 790 
2024-11-08 20:26:07.494470: Current learning rate: 0.00245 
2024-11-08 20:26:47.546087: train_loss -0.9433 
2024-11-08 20:26:47.553299: val_loss -0.8853 
2024-11-08 20:26:47.555701: Pseudo dice [np.float32(0.9472), np.float32(0.8889)] 
2024-11-08 20:26:47.558270: Epoch time: 40.06 s 
2024-11-08 20:26:48.910053:  
2024-11-08 20:26:48.912542: Epoch 791 
2024-11-08 20:26:48.914882: Current learning rate: 0.00244 
2024-11-08 20:27:29.015221: train_loss -0.9327 
2024-11-08 20:27:29.020288: val_loss -0.8569 
2024-11-08 20:27:29.022671: Pseudo dice [np.float32(0.9484), np.float32(0.8931)] 
2024-11-08 20:27:29.032603: Epoch time: 40.11 s 
2024-11-08 20:27:30.391709:  
2024-11-08 20:27:30.394288: Epoch 792 
2024-11-08 20:27:30.396691: Current learning rate: 0.00243 
2024-11-08 20:28:10.445355: train_loss -0.9445 
2024-11-08 20:28:10.451287: val_loss -0.887 
2024-11-08 20:28:10.453775: Pseudo dice [np.float32(0.9533), np.float32(0.9091)] 
2024-11-08 20:28:10.456359: Epoch time: 40.05 s 
2024-11-08 20:28:10.458650: Yayy! New best EMA pseudo Dice: 0.9065999984741211 
2024-11-08 20:28:12.671937:  
2024-11-08 20:28:12.674600: Epoch 793 
2024-11-08 20:28:12.676798: Current learning rate: 0.00242 
2024-11-08 20:28:52.747128: train_loss -0.9362 
2024-11-08 20:28:52.752076: val_loss -0.8231 
2024-11-08 20:28:52.754515: Pseudo dice [np.float32(0.9461), np.float32(0.8177)] 
2024-11-08 20:28:52.756903: Epoch time: 40.08 s 
2024-11-08 20:28:54.109824:  
2024-11-08 20:28:54.112450: Epoch 794 
2024-11-08 20:28:54.115004: Current learning rate: 0.00241 
2024-11-08 20:29:34.188431: train_loss -0.942 
2024-11-08 20:29:34.195811: val_loss -0.8552 
2024-11-08 20:29:34.200163: Pseudo dice [np.float32(0.9511), np.float32(0.8499)] 
2024-11-08 20:29:34.202547: Epoch time: 40.08 s 
2024-11-08 20:29:35.558572:  
2024-11-08 20:29:35.561206: Epoch 795 
2024-11-08 20:29:35.563756: Current learning rate: 0.0024 
2024-11-08 20:30:15.642619: train_loss -0.9359 
2024-11-08 20:30:15.647763: val_loss -0.8581 
2024-11-08 20:30:15.650884: Pseudo dice [np.float32(0.948), np.float32(0.871)] 
2024-11-08 20:30:15.653293: Epoch time: 40.09 s 
2024-11-08 20:30:17.005462:  
2024-11-08 20:30:17.007888: Epoch 796 
2024-11-08 20:30:17.012819: Current learning rate: 0.00239 
2024-11-08 20:30:57.059470: train_loss -0.943 
2024-11-08 20:30:57.064871: val_loss -0.8559 
2024-11-08 20:30:57.067214: Pseudo dice [np.float32(0.9508), np.float32(0.8754)] 
2024-11-08 20:30:57.069767: Epoch time: 40.06 s 
2024-11-08 20:30:58.419430:  
2024-11-08 20:30:58.421849: Epoch 797 
2024-11-08 20:30:58.424554: Current learning rate: 0.00238 
2024-11-08 20:31:38.482283: train_loss -0.9372 
2024-11-08 20:31:38.485353: val_loss -0.8679 
2024-11-08 20:31:38.488158: Pseudo dice [np.float32(0.9508), np.float32(0.8798)] 
2024-11-08 20:31:38.499348: Epoch time: 40.06 s 
2024-11-08 20:31:39.855302:  
2024-11-08 20:31:39.857700: Epoch 798 
2024-11-08 20:31:39.860218: Current learning rate: 0.00237 
2024-11-08 20:32:19.908484: train_loss -0.9382 
2024-11-08 20:32:19.917321: val_loss -0.85 
2024-11-08 20:32:19.920020: Pseudo dice [np.float32(0.9473), np.float32(0.8628)] 
2024-11-08 20:32:19.922642: Epoch time: 40.05 s 
2024-11-08 20:32:21.279288:  
2024-11-08 20:32:21.281917: Epoch 799 
2024-11-08 20:32:21.284243: Current learning rate: 0.00236 
2024-11-08 20:33:01.325660: train_loss -0.9418 
2024-11-08 20:33:01.331007: val_loss -0.8618 
2024-11-08 20:33:01.333399: Pseudo dice [np.float32(0.9501), np.float32(0.8487)] 
2024-11-08 20:33:01.336010: Epoch time: 40.05 s 
2024-11-08 20:33:03.517784:  
2024-11-08 20:33:03.520270: Epoch 800 
2024-11-08 20:33:03.523163: Current learning rate: 0.00235 
2024-11-08 20:33:43.516249: train_loss -0.9456 
2024-11-08 20:33:43.522608: val_loss -0.8648 
2024-11-08 20:33:43.524859: Pseudo dice [np.float32(0.9513), np.float32(0.8645)] 
2024-11-08 20:33:43.526946: Epoch time: 40.0 s 
2024-11-08 20:33:44.890445:  
2024-11-08 20:33:44.892994: Epoch 801 
2024-11-08 20:33:44.895301: Current learning rate: 0.00234 
2024-11-08 20:34:24.935559: train_loss -0.9383 
2024-11-08 20:34:24.940511: val_loss -0.8731 
2024-11-08 20:34:24.942668: Pseudo dice [np.float32(0.9498), np.float32(0.8801)] 
2024-11-08 20:34:24.945230: Epoch time: 40.05 s 
2024-11-08 20:34:24.947757: Yayy! New best EMA pseudo Dice: 0.9065999984741211 
2024-11-08 20:34:27.190325:  
2024-11-08 20:34:27.192769: Epoch 802 
2024-11-08 20:34:27.198911: Current learning rate: 0.00233 
2024-11-08 20:35:07.238680: train_loss -0.9427 
2024-11-08 20:35:07.245453: val_loss -0.8764 
2024-11-08 20:35:07.247831: Pseudo dice [np.float32(0.9543), np.float32(0.8753)] 
2024-11-08 20:35:07.249907: Epoch time: 40.05 s 
2024-11-08 20:35:07.251985: Yayy! New best EMA pseudo Dice: 0.9074000120162964 
2024-11-08 20:35:09.472397:  
2024-11-08 20:35:09.475584: Epoch 803 
2024-11-08 20:35:09.478038: Current learning rate: 0.00232 
2024-11-08 20:35:49.543095: train_loss -0.9443 
2024-11-08 20:35:49.546802: val_loss -0.8539 
2024-11-08 20:35:49.549189: Pseudo dice [np.float32(0.949), np.float32(0.8369)] 
2024-11-08 20:35:49.551783: Epoch time: 40.07 s 
2024-11-08 20:35:50.901238:  
2024-11-08 20:35:50.903964: Epoch 804 
2024-11-08 20:35:50.906582: Current learning rate: 0.00231 
2024-11-08 20:36:30.943427: train_loss -0.947 
2024-11-08 20:36:30.950209: val_loss -0.8777 
2024-11-08 20:36:30.952645: Pseudo dice [np.float32(0.9561), np.float32(0.8839)] 
2024-11-08 20:36:30.955218: Epoch time: 40.04 s 
2024-11-08 20:36:33.106530:  
2024-11-08 20:36:33.109345: Epoch 805 
2024-11-08 20:36:33.112134: Current learning rate: 0.0023 
2024-11-08 20:37:13.175029: train_loss -0.9426 
2024-11-08 20:37:13.181455: val_loss -0.8581 
2024-11-08 20:37:13.184046: Pseudo dice [np.float32(0.9474), np.float32(0.8669)] 
2024-11-08 20:37:13.186273: Epoch time: 40.07 s 
2024-11-08 20:37:14.542275:  
2024-11-08 20:37:14.544794: Epoch 806 
2024-11-08 20:37:14.547209: Current learning rate: 0.00229 
2024-11-08 20:37:54.630070: train_loss -0.9436 
2024-11-08 20:37:54.636529: val_loss -0.8485 
2024-11-08 20:37:54.639063: Pseudo dice [np.float32(0.9494), np.float32(0.8315)] 
2024-11-08 20:37:54.641327: Epoch time: 40.09 s 
2024-11-08 20:37:55.994091:  
2024-11-08 20:37:55.997031: Epoch 807 
2024-11-08 20:37:55.999588: Current learning rate: 0.00228 
2024-11-08 20:38:36.067220: train_loss -0.9419 
2024-11-08 20:38:36.070171: val_loss -0.8449 
2024-11-08 20:38:36.072644: Pseudo dice [np.float32(0.9522), np.float32(0.8325)] 
2024-11-08 20:38:36.074886: Epoch time: 40.07 s 
2024-11-08 20:38:37.436416:  
2024-11-08 20:38:37.438664: Epoch 808 
2024-11-08 20:38:37.441386: Current learning rate: 0.00226 
2024-11-08 20:39:17.507177: train_loss -0.9441 
2024-11-08 20:39:17.514055: val_loss -0.8429 
2024-11-08 20:39:17.516453: Pseudo dice [np.float32(0.947), np.float32(0.8611)] 
2024-11-08 20:39:17.518821: Epoch time: 40.07 s 
2024-11-08 20:39:18.876477:  
2024-11-08 20:39:18.879795: Epoch 809 
2024-11-08 20:39:18.882532: Current learning rate: 0.00225 
2024-11-08 20:39:58.944190: train_loss -0.9501 
2024-11-08 20:39:58.950303: val_loss -0.8817 
2024-11-08 20:39:58.952762: Pseudo dice [np.float32(0.9534), np.float32(0.8986)] 
2024-11-08 20:39:58.955156: Epoch time: 40.07 s 
2024-11-08 20:40:00.308571:  
2024-11-08 20:40:00.310999: Epoch 810 
2024-11-08 20:40:00.313458: Current learning rate: 0.00224 
2024-11-08 20:40:40.408740: train_loss -0.946 
2024-11-08 20:40:40.416883: val_loss -0.857 
2024-11-08 20:40:40.419695: Pseudo dice [np.float32(0.9532), np.float32(0.8571)] 
2024-11-08 20:40:40.422295: Epoch time: 40.1 s 
2024-11-08 20:40:41.778052:  
2024-11-08 20:40:41.780436: Epoch 811 
2024-11-08 20:40:41.782737: Current learning rate: 0.00223 
2024-11-08 20:41:21.858313: train_loss -0.9499 
2024-11-08 20:41:21.862940: val_loss -0.8487 
2024-11-08 20:41:21.865316: Pseudo dice [np.float32(0.9504), np.float32(0.844)] 
2024-11-08 20:41:21.867811: Epoch time: 40.08 s 
2024-11-08 20:41:23.217228:  
2024-11-08 20:41:23.219482: Epoch 812 
2024-11-08 20:41:23.221805: Current learning rate: 0.00222 
2024-11-08 20:42:03.314189: train_loss -0.9338 
2024-11-08 20:42:03.321169: val_loss -0.8603 
2024-11-08 20:42:03.323609: Pseudo dice [np.float32(0.9517), np.float32(0.8423)] 
2024-11-08 20:42:03.326146: Epoch time: 40.1 s 
2024-11-08 20:42:04.682276:  
2024-11-08 20:42:04.684743: Epoch 813 
2024-11-08 20:42:04.689645: Current learning rate: 0.00221 
2024-11-08 20:42:44.784008: train_loss -0.9437 
2024-11-08 20:42:44.787547: val_loss -0.8387 
2024-11-08 20:42:44.789928: Pseudo dice [np.float32(0.9442), np.float32(0.8028)] 
2024-11-08 20:42:44.792282: Epoch time: 40.1 s 
2024-11-08 20:42:46.235297:  
2024-11-08 20:42:46.237922: Epoch 814 
2024-11-08 20:42:46.240426: Current learning rate: 0.0022 
2024-11-08 20:43:26.355931: train_loss -0.9464 
2024-11-08 20:43:26.362301: val_loss -0.8465 
2024-11-08 20:43:26.364957: Pseudo dice [np.float32(0.9491), np.float32(0.8479)] 
2024-11-08 20:43:26.367375: Epoch time: 40.12 s 
2024-11-08 20:43:27.720186:  
2024-11-08 20:43:27.722926: Epoch 815 
2024-11-08 20:43:27.725254: Current learning rate: 0.00219 
2024-11-08 20:44:07.793093: train_loss -0.9505 
2024-11-08 20:44:07.795851: val_loss -0.853 
2024-11-08 20:44:07.798513: Pseudo dice [np.float32(0.951), np.float32(0.8427)] 
2024-11-08 20:44:07.800857: Epoch time: 40.07 s 
2024-11-08 20:44:09.158795:  
2024-11-08 20:44:09.161484: Epoch 816 
2024-11-08 20:44:09.163803: Current learning rate: 0.00218 
2024-11-08 20:44:49.250053: train_loss -0.9437 
2024-11-08 20:44:49.255342: val_loss -0.8628 
2024-11-08 20:44:49.257726: Pseudo dice [np.float32(0.9449), np.float32(0.8609)] 
2024-11-08 20:44:49.260002: Epoch time: 40.09 s 
2024-11-08 20:44:50.619087:  
2024-11-08 20:44:50.621686: Epoch 817 
2024-11-08 20:44:50.624337: Current learning rate: 0.00217 
2024-11-08 20:45:30.677542: train_loss -0.9468 
2024-11-08 20:45:30.680615: val_loss -0.8642 
2024-11-08 20:45:30.682967: Pseudo dice [np.float32(0.9554), np.float32(0.862)] 
2024-11-08 20:45:30.685477: Epoch time: 40.06 s 
2024-11-08 20:45:32.039148:  
2024-11-08 20:45:32.041589: Epoch 818 
2024-11-08 20:45:32.044001: Current learning rate: 0.00216 
2024-11-08 20:46:12.074541: train_loss -0.9475 
2024-11-08 20:46:12.081862: val_loss -0.8665 
2024-11-08 20:46:12.084048: Pseudo dice [np.float32(0.9491), np.float32(0.8838)] 
2024-11-08 20:46:12.086537: Epoch time: 40.04 s 
2024-11-08 20:46:13.445011:  
2024-11-08 20:46:13.448186: Epoch 819 
2024-11-08 20:46:13.450768: Current learning rate: 0.00215 
2024-11-08 20:46:53.500002: train_loss -0.9439 
2024-11-08 20:46:53.505191: val_loss -0.8596 
2024-11-08 20:46:53.507671: Pseudo dice [np.float32(0.9419), np.float32(0.8749)] 
2024-11-08 20:46:53.509931: Epoch time: 40.06 s 
2024-11-08 20:46:54.790164:  
2024-11-08 20:46:54.792979: Epoch 820 
2024-11-08 20:46:54.795542: Current learning rate: 0.00214 
2024-11-08 20:47:34.837492: train_loss -0.9449 
2024-11-08 20:47:34.842891: val_loss -0.861 
2024-11-08 20:47:34.845254: Pseudo dice [np.float32(0.9522), np.float32(0.8655)] 
2024-11-08 20:47:34.847574: Epoch time: 40.05 s 
2024-11-08 20:47:36.123879:  
2024-11-08 20:47:36.126252: Epoch 821 
2024-11-08 20:47:36.128572: Current learning rate: 0.00213 
2024-11-08 20:48:16.201330: train_loss -0.9517 
2024-11-08 20:48:16.207652: val_loss -0.8639 
2024-11-08 20:48:16.209998: Pseudo dice [np.float32(0.9528), np.float32(0.8814)] 
2024-11-08 20:48:16.212720: Epoch time: 40.08 s 
2024-11-08 20:48:17.489454:  
2024-11-08 20:48:17.491911: Epoch 822 
2024-11-08 20:48:17.494351: Current learning rate: 0.00212 
2024-11-08 20:48:57.551654: train_loss -0.9528 
2024-11-08 20:48:57.557658: val_loss -0.8975 
2024-11-08 20:48:57.560098: Pseudo dice [np.float32(0.9537), np.float32(0.9115)] 
2024-11-08 20:48:57.562439: Epoch time: 40.06 s 
2024-11-08 20:48:57.564862: Yayy! New best EMA pseudo Dice: 0.9082000255584717 
2024-11-08 20:48:59.663027:  
2024-11-08 20:48:59.665359: Epoch 823 
2024-11-08 20:48:59.667834: Current learning rate: 0.0021 
2024-11-08 20:49:40.447218: train_loss -0.9497 
2024-11-08 20:49:40.450898: val_loss -0.7725 
2024-11-08 20:49:40.453388: Pseudo dice [np.float32(0.9451), np.float32(0.7395)] 
2024-11-08 20:49:40.455506: Epoch time: 40.79 s 
2024-11-08 20:49:41.747231:  
2024-11-08 20:49:41.749713: Epoch 824 
2024-11-08 20:49:41.751923: Current learning rate: 0.00209 
2024-11-08 20:50:21.877737: train_loss -0.9431 
2024-11-08 20:50:21.883637: val_loss -0.835 
2024-11-08 20:50:21.886691: Pseudo dice [np.float32(0.9472), np.float32(0.8157)] 
2024-11-08 20:50:21.891596: Epoch time: 40.13 s 
2024-11-08 20:50:23.179661:  
2024-11-08 20:50:23.182348: Epoch 825 
2024-11-08 20:50:23.184583: Current learning rate: 0.00208 
2024-11-08 20:51:03.312682: train_loss -0.9466 
2024-11-08 20:51:03.315734: val_loss -0.8575 
2024-11-08 20:51:03.318116: Pseudo dice [np.float32(0.9577), np.float32(0.8671)] 
2024-11-08 20:51:03.322235: Epoch time: 40.13 s 
2024-11-08 20:51:04.607669:  
2024-11-08 20:51:04.610962: Epoch 826 
2024-11-08 20:51:04.613257: Current learning rate: 0.00207 
2024-11-08 20:51:44.742151: train_loss -0.945 
2024-11-08 20:51:44.751414: val_loss -0.8574 
2024-11-08 20:51:44.753836: Pseudo dice [np.float32(0.9484), np.float32(0.8395)] 
2024-11-08 20:51:44.755960: Epoch time: 40.14 s 
2024-11-08 20:51:46.045752:  
2024-11-08 20:51:46.049832: Epoch 827 
2024-11-08 20:51:46.052792: Current learning rate: 0.00206 
2024-11-08 20:52:26.142589: train_loss -0.9418 
2024-11-08 20:52:26.146029: val_loss -0.8627 
2024-11-08 20:52:26.148748: Pseudo dice [np.float32(0.9527), np.float32(0.8472)] 
2024-11-08 20:52:26.151739: Epoch time: 40.1 s 
2024-11-08 20:52:27.435534:  
2024-11-08 20:52:27.438064: Epoch 828 
2024-11-08 20:52:27.440836: Current learning rate: 0.00205 
2024-11-08 20:53:07.545438: train_loss -0.9462 
2024-11-08 20:53:07.551109: val_loss -0.8555 
2024-11-08 20:53:07.553802: Pseudo dice [np.float32(0.9427), np.float32(0.8481)] 
2024-11-08 20:53:07.556112: Epoch time: 40.11 s 
2024-11-08 20:53:08.832947:  
2024-11-08 20:53:08.835309: Epoch 829 
2024-11-08 20:53:08.838758: Current learning rate: 0.00204 
2024-11-08 20:53:48.973799: train_loss -0.9446 
2024-11-08 20:53:48.978481: val_loss -0.8514 
2024-11-08 20:53:48.981198: Pseudo dice [np.float32(0.9541), np.float32(0.8438)] 
2024-11-08 20:53:48.983625: Epoch time: 40.14 s 
2024-11-08 20:53:50.272708:  
2024-11-08 20:53:50.275248: Epoch 830 
2024-11-08 20:53:50.277759: Current learning rate: 0.00203 
2024-11-08 20:54:30.398303: train_loss -0.9542 
2024-11-08 20:54:30.406478: val_loss -0.8585 
2024-11-08 20:54:30.409977: Pseudo dice [np.float32(0.95), np.float32(0.8537)] 
2024-11-08 20:54:30.412449: Epoch time: 40.13 s 
2024-11-08 20:54:31.701289:  
2024-11-08 20:54:31.704347: Epoch 831 
2024-11-08 20:54:31.706960: Current learning rate: 0.00202 
2024-11-08 20:55:11.826298: train_loss -0.9503 
2024-11-08 20:55:11.831982: val_loss -0.8773 
2024-11-08 20:55:11.834374: Pseudo dice [np.float32(0.9503), np.float32(0.8799)] 
2024-11-08 20:55:11.836840: Epoch time: 40.13 s 
2024-11-08 20:55:13.122107:  
2024-11-08 20:55:13.124579: Epoch 832 
2024-11-08 20:55:13.127161: Current learning rate: 0.00201 
2024-11-08 20:55:53.243691: train_loss -0.9457 
2024-11-08 20:55:53.249525: val_loss -0.8702 
2024-11-08 20:55:53.251894: Pseudo dice [np.float32(0.9522), np.float32(0.8556)] 
2024-11-08 20:55:53.254894: Epoch time: 40.12 s 
2024-11-08 20:55:54.545692:  
2024-11-08 20:55:54.547994: Epoch 833 
2024-11-08 20:55:54.550764: Current learning rate: 0.002 
2024-11-08 20:56:34.661117: train_loss -0.9524 
2024-11-08 20:56:34.665636: val_loss -0.8638 
2024-11-08 20:56:34.668056: Pseudo dice [np.float32(0.9488), np.float32(0.8685)] 
2024-11-08 20:56:34.670346: Epoch time: 40.12 s 
2024-11-08 20:56:35.957544:  
2024-11-08 20:56:35.960069: Epoch 834 
2024-11-08 20:56:35.962784: Current learning rate: 0.00199 
2024-11-08 20:57:16.090377: train_loss -0.9498 
2024-11-08 20:57:16.096677: val_loss -0.8813 
2024-11-08 20:57:16.099024: Pseudo dice [np.float32(0.9486), np.float32(0.8784)] 
2024-11-08 20:57:16.101310: Epoch time: 40.13 s 
2024-11-08 20:57:17.384148:  
2024-11-08 20:57:17.386528: Epoch 835 
2024-11-08 20:57:17.389296: Current learning rate: 0.00198 
2024-11-08 20:57:57.490840: train_loss -0.9549 
2024-11-08 20:57:57.495449: val_loss -0.8539 
2024-11-08 20:57:57.497881: Pseudo dice [np.float32(0.9551), np.float32(0.8682)] 
2024-11-08 20:57:57.500472: Epoch time: 40.11 s 
2024-11-08 20:57:58.787646:  
2024-11-08 20:57:58.790476: Epoch 836 
2024-11-08 20:57:58.793569: Current learning rate: 0.00196 
2024-11-08 20:58:38.868265: train_loss -0.9484 
2024-11-08 20:58:38.873918: val_loss -0.8595 
2024-11-08 20:58:38.876209: Pseudo dice [np.float32(0.9494), np.float32(0.8519)] 
2024-11-08 20:58:38.878971: Epoch time: 40.08 s 
2024-11-08 20:58:40.159995:  
2024-11-08 20:58:40.162448: Epoch 837 
2024-11-08 20:58:40.164876: Current learning rate: 0.00195 
2024-11-08 20:59:20.241563: train_loss -0.9429 
2024-11-08 20:59:20.247880: val_loss -0.8714 
2024-11-08 20:59:20.250728: Pseudo dice [np.float32(0.9494), np.float32(0.8745)] 
2024-11-08 20:59:20.253970: Epoch time: 40.08 s 
2024-11-08 20:59:21.535240:  
2024-11-08 20:59:21.537893: Epoch 838 
2024-11-08 20:59:21.541249: Current learning rate: 0.00194 
2024-11-08 21:00:01.639014: train_loss -0.9361 
2024-11-08 21:00:01.645108: val_loss -0.8434 
2024-11-08 21:00:01.647704: Pseudo dice [np.float32(0.9494), np.float32(0.852)] 
2024-11-08 21:00:01.650326: Epoch time: 40.1 s 
2024-11-08 21:00:02.935297:  
2024-11-08 21:00:02.937812: Epoch 839 
2024-11-08 21:00:02.940464: Current learning rate: 0.00193 
2024-11-08 21:00:43.071918: train_loss -0.9433 
2024-11-08 21:00:43.077065: val_loss -0.8686 
2024-11-08 21:00:43.079389: Pseudo dice [np.float32(0.9546), np.float32(0.8771)] 
2024-11-08 21:00:43.081913: Epoch time: 40.14 s 
2024-11-08 21:00:44.365466:  
2024-11-08 21:00:44.368147: Epoch 840 
2024-11-08 21:00:44.370683: Current learning rate: 0.00192 
2024-11-08 21:01:24.469514: train_loss -0.9458 
2024-11-08 21:01:24.475902: val_loss -0.8551 
2024-11-08 21:01:24.481045: Pseudo dice [np.float32(0.9508), np.float32(0.8618)] 
2024-11-08 21:01:24.483431: Epoch time: 40.11 s 
2024-11-08 21:01:25.773278:  
2024-11-08 21:01:25.776156: Epoch 841 
2024-11-08 21:01:25.778912: Current learning rate: 0.00191 
2024-11-08 21:02:05.899742: train_loss -0.9458 
2024-11-08 21:02:05.911357: val_loss -0.8668 
2024-11-08 21:02:05.914105: Pseudo dice [np.float32(0.9487), np.float32(0.8666)] 
2024-11-08 21:02:05.916453: Epoch time: 40.13 s 
2024-11-08 21:02:07.203473:  
2024-11-08 21:02:07.207757: Epoch 842 
2024-11-08 21:02:07.210168: Current learning rate: 0.0019 
2024-11-08 21:02:47.324022: train_loss -0.9522 
2024-11-08 21:02:47.331366: val_loss -0.8286 
2024-11-08 21:02:47.334106: Pseudo dice [np.float32(0.9507), np.float32(0.8472)] 
2024-11-08 21:02:47.336927: Epoch time: 40.12 s 
2024-11-08 21:02:49.413056:  
2024-11-08 21:02:49.415747: Epoch 843 
2024-11-08 21:02:49.418351: Current learning rate: 0.00189 
2024-11-08 21:03:29.528461: train_loss -0.9531 
2024-11-08 21:03:29.534218: val_loss -0.8363 
2024-11-08 21:03:29.537299: Pseudo dice [np.float32(0.9536), np.float32(0.8286)] 
2024-11-08 21:03:29.541199: Epoch time: 40.12 s 
2024-11-08 21:03:30.826912:  
2024-11-08 21:03:30.829583: Epoch 844 
2024-11-08 21:03:30.831851: Current learning rate: 0.00188 
2024-11-08 21:04:10.922880: train_loss -0.9437 
2024-11-08 21:04:10.931753: val_loss -0.891 
2024-11-08 21:04:10.934681: Pseudo dice [np.float32(0.951), np.float32(0.9113)] 
2024-11-08 21:04:10.937022: Epoch time: 40.1 s 
2024-11-08 21:04:12.216397:  
2024-11-08 21:04:12.219465: Epoch 845 
2024-11-08 21:04:12.221913: Current learning rate: 0.00187 
2024-11-08 21:04:52.319283: train_loss -0.9514 
2024-11-08 21:04:52.323962: val_loss -0.8949 
2024-11-08 21:04:52.326596: Pseudo dice [np.float32(0.9521), np.float32(0.9042)] 
2024-11-08 21:04:52.328948: Epoch time: 40.1 s 
2024-11-08 21:04:52.331252: Yayy! New best EMA pseudo Dice: 0.9085999727249146 
2024-11-08 21:04:54.469486:  
2024-11-08 21:04:54.473490: Epoch 846 
2024-11-08 21:04:54.475919: Current learning rate: 0.00186 
2024-11-08 21:05:34.570812: train_loss -0.9501 
2024-11-08 21:05:34.577590: val_loss -0.8877 
2024-11-08 21:05:34.579864: Pseudo dice [np.float32(0.9508), np.float32(0.8911)] 
2024-11-08 21:05:34.582164: Epoch time: 40.1 s 
2024-11-08 21:05:34.584840: Yayy! New best EMA pseudo Dice: 0.9097999930381775 
2024-11-08 21:05:36.709749:  
2024-11-08 21:05:36.712380: Epoch 847 
2024-11-08 21:05:36.714685: Current learning rate: 0.00185 
2024-11-08 21:06:16.795688: train_loss -0.9453 
2024-11-08 21:06:16.800110: val_loss -0.8731 
2024-11-08 21:06:16.802428: Pseudo dice [np.float32(0.9501), np.float32(0.8729)] 
2024-11-08 21:06:16.806162: Epoch time: 40.09 s 
2024-11-08 21:06:16.808556: Yayy! New best EMA pseudo Dice: 0.9100000262260437 
2024-11-08 21:06:18.954998:  
2024-11-08 21:06:18.957587: Epoch 848 
2024-11-08 21:06:18.960104: Current learning rate: 0.00184 
2024-11-08 21:06:59.044366: train_loss -0.952 
2024-11-08 21:06:59.050320: val_loss -0.8783 
2024-11-08 21:06:59.052671: Pseudo dice [np.float32(0.9548), np.float32(0.8755)] 
2024-11-08 21:06:59.054999: Epoch time: 40.09 s 
2024-11-08 21:06:59.057560: Yayy! New best EMA pseudo Dice: 0.9104999899864197 
2024-11-08 21:07:01.185157:  
2024-11-08 21:07:01.187580: Epoch 849 
2024-11-08 21:07:01.189968: Current learning rate: 0.00182 
2024-11-08 21:07:41.259989: train_loss -0.9515 
2024-11-08 21:07:41.265160: val_loss -0.8766 
2024-11-08 21:07:41.267828: Pseudo dice [np.float32(0.9512), np.float32(0.8925)] 
2024-11-08 21:07:41.270678: Epoch time: 40.08 s 
2024-11-08 21:07:42.117399: Yayy! New best EMA pseudo Dice: 0.9115999937057495 
2024-11-08 21:07:44.279258:  
2024-11-08 21:07:44.281431: Epoch 850 
2024-11-08 21:07:44.283960: Current learning rate: 0.00181 
2024-11-08 21:08:24.412975: train_loss -0.9528 
2024-11-08 21:08:24.418958: val_loss -0.9002 
2024-11-08 21:08:24.421500: Pseudo dice [np.float32(0.9537), np.float32(0.9111)] 
2024-11-08 21:08:24.424043: Epoch time: 40.13 s 
2024-11-08 21:08:24.426294: Yayy! New best EMA pseudo Dice: 0.9136999845504761 
2024-11-08 21:08:26.675268:  
2024-11-08 21:08:26.678167: Epoch 851 
2024-11-08 21:08:26.680836: Current learning rate: 0.0018 
2024-11-08 21:09:06.761008: train_loss -0.9479 
2024-11-08 21:09:06.766827: val_loss -0.8555 
2024-11-08 21:09:06.769509: Pseudo dice [np.float32(0.9535), np.float32(0.8402)] 
2024-11-08 21:09:06.771893: Epoch time: 40.09 s 
2024-11-08 21:09:08.041421:  
2024-11-08 21:09:08.043735: Epoch 852 
2024-11-08 21:09:08.046267: Current learning rate: 0.00179 
2024-11-08 21:09:48.155397: train_loss -0.9498 
2024-11-08 21:09:48.160990: val_loss -0.8861 
2024-11-08 21:09:48.163362: Pseudo dice [np.float32(0.9491), np.float32(0.8951)] 
2024-11-08 21:09:48.165516: Epoch time: 40.12 s 
2024-11-08 21:09:49.440844:  
2024-11-08 21:09:49.443366: Epoch 853 
2024-11-08 21:09:49.447135: Current learning rate: 0.00178 
2024-11-08 21:10:29.527810: train_loss -0.953 
2024-11-08 21:10:29.532381: val_loss -0.9041 
2024-11-08 21:10:29.534906: Pseudo dice [np.float32(0.9534), np.float32(0.9098)] 
2024-11-08 21:10:29.537301: Epoch time: 40.09 s 
2024-11-08 21:10:29.539814: Yayy! New best EMA pseudo Dice: 0.914900004863739 
2024-11-08 21:10:31.663218:  
2024-11-08 21:10:31.665584: Epoch 854 
2024-11-08 21:10:31.667874: Current learning rate: 0.00177 
2024-11-08 21:11:11.761658: train_loss -0.9494 
2024-11-08 21:11:11.770398: val_loss -0.8588 
2024-11-08 21:11:11.772679: Pseudo dice [np.float32(0.9531), np.float32(0.8622)] 
2024-11-08 21:11:11.774927: Epoch time: 40.1 s 
2024-11-08 21:11:13.054800:  
2024-11-08 21:11:13.057693: Epoch 855 
2024-11-08 21:11:13.060852: Current learning rate: 0.00176 
2024-11-08 21:11:53.102676: train_loss -0.955 
2024-11-08 21:11:53.107445: val_loss -0.8808 
2024-11-08 21:11:53.109894: Pseudo dice [np.float32(0.9527), np.float32(0.8666)] 
2024-11-08 21:11:53.112500: Epoch time: 40.05 s 
2024-11-08 21:11:54.377352:  
2024-11-08 21:11:54.380001: Epoch 856 
2024-11-08 21:11:54.382518: Current learning rate: 0.00175 
2024-11-08 21:12:34.434691: train_loss -0.9517 
2024-11-08 21:12:34.440651: val_loss -0.859 
2024-11-08 21:12:34.442981: Pseudo dice [np.float32(0.9482), np.float32(0.8643)] 
2024-11-08 21:12:34.445269: Epoch time: 40.06 s 
2024-11-08 21:12:35.713279:  
2024-11-08 21:12:35.716132: Epoch 857 
2024-11-08 21:12:35.718614: Current learning rate: 0.00174 
2024-11-08 21:13:15.791855: train_loss -0.9492 
2024-11-08 21:13:15.796952: val_loss -0.8755 
2024-11-08 21:13:15.799155: Pseudo dice [np.float32(0.946), np.float32(0.89)] 
2024-11-08 21:13:15.801838: Epoch time: 40.08 s 
2024-11-08 21:13:17.063297:  
2024-11-08 21:13:17.066043: Epoch 858 
2024-11-08 21:13:17.068526: Current learning rate: 0.00173 
2024-11-08 21:13:57.114004: train_loss -0.9504 
2024-11-08 21:13:57.120161: val_loss -0.8672 
2024-11-08 21:13:57.123044: Pseudo dice [np.float32(0.956), np.float32(0.8568)] 
2024-11-08 21:13:57.126128: Epoch time: 40.05 s 
2024-11-08 21:13:58.391744:  
2024-11-08 21:13:58.394136: Epoch 859 
2024-11-08 21:13:58.396663: Current learning rate: 0.00172 
2024-11-08 21:14:38.446677: train_loss -0.9476 
2024-11-08 21:14:38.450887: val_loss -0.875 
2024-11-08 21:14:38.453238: Pseudo dice [np.float32(0.9541), np.float32(0.8603)] 
2024-11-08 21:14:38.455582: Epoch time: 40.06 s 
2024-11-08 21:14:39.716589:  
2024-11-08 21:14:39.719066: Epoch 860 
2024-11-08 21:14:39.721514: Current learning rate: 0.0017 
2024-11-08 21:15:19.758030: train_loss -0.9456 
2024-11-08 21:15:19.763966: val_loss -0.871 
2024-11-08 21:15:19.766182: Pseudo dice [np.float32(0.9558), np.float32(0.8826)] 
2024-11-08 21:15:19.768504: Epoch time: 40.04 s 
2024-11-08 21:15:21.781374:  
2024-11-08 21:15:21.784082: Epoch 861 
2024-11-08 21:15:21.786576: Current learning rate: 0.00169 
2024-11-08 21:16:01.825917: train_loss -0.9477 
2024-11-08 21:16:01.828944: val_loss -0.8898 
2024-11-08 21:16:01.831443: Pseudo dice [np.float32(0.956), np.float32(0.8873)] 
2024-11-08 21:16:01.834049: Epoch time: 40.05 s 
2024-11-08 21:16:03.087528:  
2024-11-08 21:16:03.090270: Epoch 862 
2024-11-08 21:16:03.093063: Current learning rate: 0.00168 
2024-11-08 21:16:43.139123: train_loss -0.9509 
2024-11-08 21:16:43.144837: val_loss -0.8797 
2024-11-08 21:16:43.147508: Pseudo dice [np.float32(0.9446), np.float32(0.8784)] 
2024-11-08 21:16:43.150022: Epoch time: 40.05 s 
2024-11-08 21:16:44.406541:  
2024-11-08 21:16:44.409891: Epoch 863 
2024-11-08 21:16:44.413062: Current learning rate: 0.00167 
2024-11-08 21:17:24.473675: train_loss -0.9511 
2024-11-08 21:17:24.476387: val_loss -0.8946 
2024-11-08 21:17:24.478796: Pseudo dice [np.float32(0.9575), np.float32(0.891)] 
2024-11-08 21:17:24.481204: Epoch time: 40.07 s 
2024-11-08 21:17:25.737984:  
2024-11-08 21:17:25.740323: Epoch 864 
2024-11-08 21:17:25.742814: Current learning rate: 0.00166 
2024-11-08 21:18:05.803179: train_loss -0.9556 
2024-11-08 21:18:05.808475: val_loss -0.885 
2024-11-08 21:18:05.810904: Pseudo dice [np.float32(0.9547), np.float32(0.9186)] 
2024-11-08 21:18:05.813212: Epoch time: 40.07 s 
2024-11-08 21:18:05.815480: Yayy! New best EMA pseudo Dice: 0.9168000221252441 
2024-11-08 21:18:07.988295:  
2024-11-08 21:18:07.992080: Epoch 865 
2024-11-08 21:18:07.994701: Current learning rate: 0.00165 
2024-11-08 21:18:48.034791: train_loss -0.9497 
2024-11-08 21:18:48.037712: val_loss -0.8537 
2024-11-08 21:18:48.040036: Pseudo dice [np.float32(0.9493), np.float32(0.8471)] 
2024-11-08 21:18:48.042489: Epoch time: 40.05 s 
2024-11-08 21:18:49.299723:  
2024-11-08 21:18:49.302318: Epoch 866 
2024-11-08 21:18:49.304639: Current learning rate: 0.00164 
2024-11-08 21:19:29.339351: train_loss -0.9526 
2024-11-08 21:19:29.345079: val_loss -0.8908 
2024-11-08 21:19:29.347546: Pseudo dice [np.float32(0.9498), np.float32(0.8982)] 
2024-11-08 21:19:29.349878: Epoch time: 40.04 s 
2024-11-08 21:19:30.607706:  
2024-11-08 21:19:30.610208: Epoch 867 
2024-11-08 21:19:30.612574: Current learning rate: 0.00163 
2024-11-08 21:20:10.655399: train_loss -0.953 
2024-11-08 21:20:10.658008: val_loss -0.8841 
2024-11-08 21:20:10.660286: Pseudo dice [np.float32(0.9545), np.float32(0.9044)] 
2024-11-08 21:20:10.662467: Epoch time: 40.05 s 
2024-11-08 21:20:10.664791: Yayy! New best EMA pseudo Dice: 0.9172000288963318 
2024-11-08 21:20:12.851971:  
2024-11-08 21:20:12.854636: Epoch 868 
2024-11-08 21:20:12.857094: Current learning rate: 0.00162 
2024-11-08 21:20:52.910436: train_loss -0.9533 
2024-11-08 21:20:52.916259: val_loss -0.8925 
2024-11-08 21:20:52.918738: Pseudo dice [np.float32(0.9573), np.float32(0.9003)] 
2024-11-08 21:20:52.921051: Epoch time: 40.06 s 
2024-11-08 21:20:52.923277: Yayy! New best EMA pseudo Dice: 0.91839998960495 
2024-11-08 21:20:55.006823:  
2024-11-08 21:20:55.009497: Epoch 869 
2024-11-08 21:20:55.011845: Current learning rate: 0.00161 
2024-11-08 21:21:35.059065: train_loss -0.9491 
2024-11-08 21:21:35.063521: val_loss -0.8714 
2024-11-08 21:21:35.065981: Pseudo dice [np.float32(0.9546), np.float32(0.8681)] 
2024-11-08 21:21:35.068318: Epoch time: 40.05 s 
2024-11-08 21:21:36.331817:  
2024-11-08 21:21:36.334172: Epoch 870 
2024-11-08 21:21:36.336502: Current learning rate: 0.00159 
2024-11-08 21:22:16.376039: train_loss -0.9453 
2024-11-08 21:22:16.382053: val_loss -0.8666 
2024-11-08 21:22:16.384311: Pseudo dice [np.float32(0.9517), np.float32(0.8648)] 
2024-11-08 21:22:16.386717: Epoch time: 40.05 s 
2024-11-08 21:22:17.642123:  
2024-11-08 21:22:17.644362: Epoch 871 
2024-11-08 21:22:17.646846: Current learning rate: 0.00158 
2024-11-08 21:22:57.683716: train_loss -0.9495 
2024-11-08 21:22:57.686594: val_loss -0.8827 
2024-11-08 21:22:57.689273: Pseudo dice [np.float32(0.9479), np.float32(0.8905)] 
2024-11-08 21:22:57.691552: Epoch time: 40.04 s 
2024-11-08 21:22:58.953724:  
2024-11-08 21:22:58.956243: Epoch 872 
2024-11-08 21:22:58.958620: Current learning rate: 0.00157 
2024-11-08 21:23:38.998154: train_loss -0.9515 
2024-11-08 21:23:39.002954: val_loss -0.8949 
2024-11-08 21:23:39.005187: Pseudo dice [np.float32(0.9545), np.float32(0.9033)] 
2024-11-08 21:23:39.007338: Epoch time: 40.05 s 
2024-11-08 21:23:40.269079:  
2024-11-08 21:23:40.271563: Epoch 873 
2024-11-08 21:23:40.274008: Current learning rate: 0.00156 
2024-11-08 21:24:20.315323: train_loss -0.9461 
2024-11-08 21:24:20.318147: val_loss -0.8479 
2024-11-08 21:24:20.320526: Pseudo dice [np.float32(0.9516), np.float32(0.8571)] 
2024-11-08 21:24:20.323120: Epoch time: 40.05 s 
2024-11-08 21:24:21.577610:  
2024-11-08 21:24:21.580148: Epoch 874 
2024-11-08 21:24:21.582747: Current learning rate: 0.00155 
2024-11-08 21:25:01.597430: train_loss -0.9519 
2024-11-08 21:25:01.603016: val_loss -0.8549 
2024-11-08 21:25:01.607214: Pseudo dice [np.float32(0.9479), np.float32(0.8634)] 
2024-11-08 21:25:01.609891: Epoch time: 40.02 s 
2024-11-08 21:25:02.867450:  
2024-11-08 21:25:02.870143: Epoch 875 
2024-11-08 21:25:02.872682: Current learning rate: 0.00154 
2024-11-08 21:25:42.852570: train_loss -0.9525 
2024-11-08 21:25:42.856739: val_loss -0.8968 
2024-11-08 21:25:42.859436: Pseudo dice [np.float32(0.9514), np.float32(0.8929)] 
2024-11-08 21:25:42.861553: Epoch time: 39.99 s 
2024-11-08 21:25:44.118547:  
2024-11-08 21:25:44.121300: Epoch 876 
2024-11-08 21:25:44.123712: Current learning rate: 0.00153 
2024-11-08 21:26:24.115594: train_loss -0.9514 
2024-11-08 21:26:24.120970: val_loss -0.8236 
2024-11-08 21:26:24.123377: Pseudo dice [np.float32(0.9416), np.float32(0.8196)] 
2024-11-08 21:26:24.125630: Epoch time: 40.0 s 
2024-11-08 21:26:25.387555:  
2024-11-08 21:26:25.390440: Epoch 877 
2024-11-08 21:26:25.392913: Current learning rate: 0.00152 
2024-11-08 21:27:05.365563: train_loss -0.9529 
2024-11-08 21:27:05.368446: val_loss -0.8902 
2024-11-08 21:27:05.370991: Pseudo dice [np.float32(0.9545), np.float32(0.8962)] 
2024-11-08 21:27:05.373392: Epoch time: 39.98 s 
2024-11-08 21:27:06.632629:  
2024-11-08 21:27:06.634845: Epoch 878 
2024-11-08 21:27:06.636980: Current learning rate: 0.00151 
2024-11-08 21:27:46.638068: train_loss -0.9462 
2024-11-08 21:27:46.643214: val_loss -0.8688 
2024-11-08 21:27:46.645337: Pseudo dice [np.float32(0.9538), np.float32(0.902)] 
2024-11-08 21:27:46.647482: Epoch time: 40.01 s 
2024-11-08 21:27:47.910261:  
2024-11-08 21:27:47.912661: Epoch 879 
2024-11-08 21:27:47.914936: Current learning rate: 0.00149 
2024-11-08 21:28:27.915153: train_loss -0.9515 
2024-11-08 21:28:27.919780: val_loss -0.8887 
2024-11-08 21:28:27.922631: Pseudo dice [np.float32(0.9455), np.float32(0.8964)] 
2024-11-08 21:28:27.924974: Epoch time: 40.01 s 
2024-11-08 21:28:29.180806:  
2024-11-08 21:28:29.183096: Epoch 880 
2024-11-08 21:28:29.185821: Current learning rate: 0.00148 
2024-11-08 21:29:09.177620: train_loss -0.9463 
2024-11-08 21:29:09.192907: val_loss -0.8664 
2024-11-08 21:29:09.195461: Pseudo dice [np.float32(0.9528), np.float32(0.8853)] 
2024-11-08 21:29:09.197798: Epoch time: 40.0 s 
2024-11-08 21:29:11.198220:  
2024-11-08 21:29:11.201433: Epoch 881 
2024-11-08 21:29:11.203895: Current learning rate: 0.00147 
2024-11-08 21:29:51.208099: train_loss -0.9451 
2024-11-08 21:29:51.210635: val_loss -0.8863 
2024-11-08 21:29:51.213160: Pseudo dice [np.float32(0.9499), np.float32(0.8916)] 
2024-11-08 21:29:51.215499: Epoch time: 40.01 s 
2024-11-08 21:29:52.474674:  
2024-11-08 21:29:52.477095: Epoch 882 
2024-11-08 21:29:52.479285: Current learning rate: 0.00146 
2024-11-08 21:30:32.489639: train_loss -0.9412 
2024-11-08 21:30:32.495369: val_loss -0.8784 
2024-11-08 21:30:32.497671: Pseudo dice [np.float32(0.9463), np.float32(0.9046)] 
2024-11-08 21:30:32.499779: Epoch time: 40.02 s 
2024-11-08 21:30:33.764801:  
2024-11-08 21:30:33.767350: Epoch 883 
2024-11-08 21:30:33.770052: Current learning rate: 0.00145 
2024-11-08 21:31:13.782936: train_loss -0.9455 
2024-11-08 21:31:13.785617: val_loss -0.8704 
2024-11-08 21:31:13.788033: Pseudo dice [np.float32(0.9514), np.float32(0.8767)] 
2024-11-08 21:31:13.790339: Epoch time: 40.02 s 
2024-11-08 21:31:15.043213:  
2024-11-08 21:31:15.045787: Epoch 884 
2024-11-08 21:31:15.048393: Current learning rate: 0.00144 
2024-11-08 21:31:55.085310: train_loss -0.9502 
2024-11-08 21:31:55.092001: val_loss -0.878 
2024-11-08 21:31:55.094388: Pseudo dice [np.float32(0.953), np.float32(0.8818)] 
2024-11-08 21:31:55.096641: Epoch time: 40.04 s 
2024-11-08 21:31:56.356491:  
2024-11-08 21:31:56.358898: Epoch 885 
2024-11-08 21:31:56.361334: Current learning rate: 0.00143 
2024-11-08 21:32:36.406990: train_loss -0.9512 
2024-11-08 21:32:36.410046: val_loss -0.8791 
2024-11-08 21:32:36.412716: Pseudo dice [np.float32(0.9532), np.float32(0.9017)] 
2024-11-08 21:32:36.415328: Epoch time: 40.05 s 
2024-11-08 21:32:37.670570:  
2024-11-08 21:32:37.673214: Epoch 886 
2024-11-08 21:32:37.675607: Current learning rate: 0.00142 
2024-11-08 21:33:17.688487: train_loss -0.9487 
2024-11-08 21:33:17.695235: val_loss -0.9034 
2024-11-08 21:33:17.697878: Pseudo dice [np.float32(0.9536), np.float32(0.9249)] 
2024-11-08 21:33:17.700454: Epoch time: 40.02 s 
2024-11-08 21:33:17.702897: Yayy! New best EMA pseudo Dice: 0.9204000234603882 
2024-11-08 21:33:19.815781:  
2024-11-08 21:33:19.818209: Epoch 887 
2024-11-08 21:33:19.820692: Current learning rate: 0.00141 
2024-11-08 21:33:59.840133: train_loss -0.9496 
2024-11-08 21:33:59.844467: val_loss -0.85 
2024-11-08 21:33:59.847021: Pseudo dice [np.float32(0.9488), np.float32(0.8492)] 
2024-11-08 21:33:59.849541: Epoch time: 40.03 s 
2024-11-08 21:34:01.109890:  
2024-11-08 21:34:01.112273: Epoch 888 
2024-11-08 21:34:01.114756: Current learning rate: 0.00139 
2024-11-08 21:34:41.166725: train_loss -0.9517 
2024-11-08 21:34:41.172492: val_loss -0.8635 
2024-11-08 21:34:41.174819: Pseudo dice [np.float32(0.9553), np.float32(0.875)] 
2024-11-08 21:34:41.177092: Epoch time: 40.06 s 
2024-11-08 21:34:42.434600:  
2024-11-08 21:34:42.437057: Epoch 889 
2024-11-08 21:34:42.439578: Current learning rate: 0.00138 
2024-11-08 21:35:22.480042: train_loss -0.9522 
2024-11-08 21:35:22.483041: val_loss -0.8732 
2024-11-08 21:35:22.485261: Pseudo dice [np.float32(0.9522), np.float32(0.8764)] 
2024-11-08 21:35:22.487679: Epoch time: 40.05 s 
2024-11-08 21:35:23.744862:  
2024-11-08 21:35:23.747415: Epoch 890 
2024-11-08 21:35:23.749799: Current learning rate: 0.00137 
2024-11-08 21:36:03.752676: train_loss -0.9533 
2024-11-08 21:36:03.758614: val_loss -0.8907 
2024-11-08 21:36:03.760995: Pseudo dice [np.float32(0.953), np.float32(0.8994)] 
2024-11-08 21:36:03.763256: Epoch time: 40.01 s 
2024-11-08 21:36:05.022065:  
2024-11-08 21:36:05.024745: Epoch 891 
2024-11-08 21:36:05.027407: Current learning rate: 0.00136 
2024-11-08 21:36:45.051962: train_loss -0.9539 
2024-11-08 21:36:45.060199: val_loss -0.894 
2024-11-08 21:36:45.062781: Pseudo dice [np.float32(0.9566), np.float32(0.8947)] 
2024-11-08 21:36:45.065488: Epoch time: 40.03 s 
2024-11-08 21:36:46.321713:  
2024-11-08 21:36:46.324028: Epoch 892 
2024-11-08 21:36:46.326512: Current learning rate: 0.00135 
2024-11-08 21:37:26.333364: train_loss -0.9547 
2024-11-08 21:37:26.339279: val_loss -0.8724 
2024-11-08 21:37:26.341876: Pseudo dice [np.float32(0.9549), np.float32(0.8931)] 
2024-11-08 21:37:26.344353: Epoch time: 40.01 s 
2024-11-08 21:37:27.597535:  
2024-11-08 21:37:27.600266: Epoch 893 
2024-11-08 21:37:27.602888: Current learning rate: 0.00134 
2024-11-08 21:38:07.602286: train_loss -0.9513 
2024-11-08 21:38:07.605327: val_loss -0.8796 
2024-11-08 21:38:07.607612: Pseudo dice [np.float32(0.9497), np.float32(0.884)] 
2024-11-08 21:38:07.610044: Epoch time: 40.01 s 
2024-11-08 21:38:08.859321:  
2024-11-08 21:38:08.863180: Epoch 894 
2024-11-08 21:38:08.865656: Current learning rate: 0.00133 
2024-11-08 21:38:48.900901: train_loss -0.9559 
2024-11-08 21:38:48.917047: val_loss -0.8878 
2024-11-08 21:38:48.919603: Pseudo dice [np.float32(0.9518), np.float32(0.9038)] 
2024-11-08 21:38:48.922174: Epoch time: 40.04 s 
2024-11-08 21:38:50.181262:  
2024-11-08 21:38:50.183844: Epoch 895 
2024-11-08 21:38:50.186118: Current learning rate: 0.00132 
2024-11-08 21:39:30.177377: train_loss -0.9492 
2024-11-08 21:39:30.181300: val_loss -0.8915 
2024-11-08 21:39:30.183756: Pseudo dice [np.float32(0.9515), np.float32(0.9101)] 
2024-11-08 21:39:30.186655: Epoch time: 40.0 s 
2024-11-08 21:39:30.188802: Yayy! New best EMA pseudo Dice: 0.9212999939918518 
2024-11-08 21:39:32.323691:  
2024-11-08 21:39:32.326495: Epoch 896 
2024-11-08 21:39:32.329165: Current learning rate: 0.0013 
2024-11-08 21:40:12.321660: train_loss -0.9495 
2024-11-08 21:40:12.334751: val_loss -0.8581 
2024-11-08 21:40:12.338820: Pseudo dice [np.float32(0.9455), np.float32(0.8585)] 
2024-11-08 21:40:12.341287: Epoch time: 40.0 s 
2024-11-08 21:40:13.593492:  
2024-11-08 21:40:13.595815: Epoch 897 
2024-11-08 21:40:13.598199: Current learning rate: 0.00129 
2024-11-08 21:40:53.608816: train_loss -0.9505 
2024-11-08 21:40:53.611664: val_loss -0.869 
2024-11-08 21:40:53.614080: Pseudo dice [np.float32(0.9525), np.float32(0.8867)] 
2024-11-08 21:40:53.616448: Epoch time: 40.02 s 
2024-11-08 21:40:54.872554:  
2024-11-08 21:40:54.875251: Epoch 898 
2024-11-08 21:40:54.877819: Current learning rate: 0.00128 
2024-11-08 21:41:34.822704: train_loss -0.9497 
2024-11-08 21:41:34.831730: val_loss -0.8938 
2024-11-08 21:41:34.834255: Pseudo dice [np.float32(0.9497), np.float32(0.9204)] 
2024-11-08 21:41:34.836820: Epoch time: 39.95 s 
2024-11-08 21:41:36.012262:  
2024-11-08 21:41:36.014951: Epoch 899 
2024-11-08 21:41:36.017412: Current learning rate: 0.00127 
2024-11-08 21:42:15.849121: train_loss -0.955 
2024-11-08 21:42:15.852107: val_loss -0.8674 
2024-11-08 21:42:15.854515: Pseudo dice [np.float32(0.9551), np.float32(0.8822)] 
2024-11-08 21:42:15.856912: Epoch time: 39.84 s 
2024-11-08 21:42:17.821499:  
2024-11-08 21:42:17.823801: Epoch 900 
2024-11-08 21:42:17.826315: Current learning rate: 0.00126 
2024-11-08 21:42:57.643736: train_loss -0.952 
2024-11-08 21:42:57.652348: val_loss -0.8654 
2024-11-08 21:42:57.654770: Pseudo dice [np.float32(0.9546), np.float32(0.8858)] 
2024-11-08 21:42:57.657341: Epoch time: 39.82 s 
2024-11-08 21:42:59.402446:  
2024-11-08 21:42:59.404912: Epoch 901 
2024-11-08 21:42:59.407283: Current learning rate: 0.00125 
2024-11-08 21:43:39.238983: train_loss -0.9517 
2024-11-08 21:43:39.242990: val_loss -0.8408 
2024-11-08 21:43:39.245344: Pseudo dice [np.float32(0.952), np.float32(0.8499)] 
2024-11-08 21:43:39.248322: Epoch time: 39.84 s 
2024-11-08 21:43:40.416213:  
2024-11-08 21:43:40.418719: Epoch 902 
2024-11-08 21:43:40.420967: Current learning rate: 0.00124 
2024-11-08 21:44:20.243829: train_loss -0.9548 
2024-11-08 21:44:20.252980: val_loss -0.8899 
2024-11-08 21:44:20.256566: Pseudo dice [np.float32(0.9461), np.float32(0.8996)] 
2024-11-08 21:44:20.258939: Epoch time: 39.83 s 
2024-11-08 21:44:21.433941:  
2024-11-08 21:44:21.436648: Epoch 903 
2024-11-08 21:44:21.439129: Current learning rate: 0.00122 
2024-11-08 21:45:01.256424: train_loss -0.9505 
2024-11-08 21:45:01.260446: val_loss -0.8666 
2024-11-08 21:45:01.262832: Pseudo dice [np.float32(0.9523), np.float32(0.8615)] 
2024-11-08 21:45:01.265167: Epoch time: 39.82 s 
2024-11-08 21:45:02.435364:  
2024-11-08 21:45:02.437908: Epoch 904 
2024-11-08 21:45:02.440237: Current learning rate: 0.00121 
2024-11-08 21:45:42.280991: train_loss -0.9541 
2024-11-08 21:45:42.287131: val_loss -0.8848 
2024-11-08 21:45:42.289408: Pseudo dice [np.float32(0.9544), np.float32(0.8863)] 
2024-11-08 21:45:42.291740: Epoch time: 39.85 s 
2024-11-08 21:45:43.459743:  
2024-11-08 21:45:43.462386: Epoch 905 
2024-11-08 21:45:43.464609: Current learning rate: 0.0012 
2024-11-08 21:46:23.314627: train_loss -0.956 
2024-11-08 21:46:23.319633: val_loss -0.8827 
2024-11-08 21:46:23.322070: Pseudo dice [np.float32(0.9485), np.float32(0.897)] 
2024-11-08 21:46:23.324717: Epoch time: 39.86 s 
2024-11-08 21:46:24.498329:  
2024-11-08 21:46:24.500640: Epoch 906 
2024-11-08 21:46:24.503236: Current learning rate: 0.00119 
2024-11-08 21:47:04.338263: train_loss -0.9568 
2024-11-08 21:47:04.344042: val_loss -0.8837 
2024-11-08 21:47:04.346304: Pseudo dice [np.float32(0.954), np.float32(0.9087)] 
2024-11-08 21:47:04.348656: Epoch time: 39.84 s 
2024-11-08 21:47:05.519448:  
2024-11-08 21:47:05.521837: Epoch 907 
2024-11-08 21:47:05.524124: Current learning rate: 0.00118 
2024-11-08 21:47:45.367754: train_loss -0.9525 
2024-11-08 21:47:45.370598: val_loss -0.8747 
2024-11-08 21:47:45.372870: Pseudo dice [np.float32(0.9504), np.float32(0.883)] 
2024-11-08 21:47:45.375020: Epoch time: 39.85 s 
2024-11-08 21:47:46.547482:  
2024-11-08 21:47:46.549900: Epoch 908 
2024-11-08 21:47:46.552185: Current learning rate: 0.00117 
2024-11-08 21:48:26.388893: train_loss -0.9561 
2024-11-08 21:48:26.394543: val_loss -0.8908 
2024-11-08 21:48:26.397109: Pseudo dice [np.float32(0.9531), np.float32(0.8992)] 
2024-11-08 21:48:26.399282: Epoch time: 39.84 s 
2024-11-08 21:48:27.578567:  
2024-11-08 21:48:27.580943: Epoch 909 
2024-11-08 21:48:27.583291: Current learning rate: 0.00116 
2024-11-08 21:49:07.405797: train_loss -0.9533 
2024-11-08 21:49:07.408575: val_loss -0.8958 
2024-11-08 21:49:07.410935: Pseudo dice [np.float32(0.9518), np.float32(0.9208)] 
2024-11-08 21:49:07.413178: Epoch time: 39.83 s 
2024-11-08 21:49:07.415481: Yayy! New best EMA pseudo Dice: 0.9218000173568726 
2024-11-08 21:49:09.358391:  
2024-11-08 21:49:09.362533: Epoch 910 
2024-11-08 21:49:09.364945: Current learning rate: 0.00115 
2024-11-08 21:49:49.151589: train_loss -0.957 
2024-11-08 21:49:49.158785: val_loss -0.8545 
2024-11-08 21:49:49.161098: Pseudo dice [np.float32(0.9482), np.float32(0.8671)] 
2024-11-08 21:49:49.163424: Epoch time: 39.79 s 
2024-11-08 21:49:50.328545:  
2024-11-08 21:49:50.332425: Epoch 911 
2024-11-08 21:49:50.334877: Current learning rate: 0.00113 
2024-11-08 21:50:30.129830: train_loss -0.9545 
2024-11-08 21:50:30.132576: val_loss -0.8771 
2024-11-08 21:50:30.134968: Pseudo dice [np.float32(0.95), np.float32(0.8829)] 
2024-11-08 21:50:30.137259: Epoch time: 39.8 s 
2024-11-08 21:50:31.302697:  
2024-11-08 21:50:31.305378: Epoch 912 
2024-11-08 21:50:31.307822: Current learning rate: 0.00112 
2024-11-08 21:51:11.116875: train_loss -0.9569 
2024-11-08 21:51:11.123829: val_loss -0.8682 
2024-11-08 21:51:11.126180: Pseudo dice [np.float32(0.9511), np.float32(0.8484)] 
2024-11-08 21:51:11.128586: Epoch time: 39.82 s 
2024-11-08 21:51:12.298790:  
2024-11-08 21:51:12.301349: Epoch 913 
2024-11-08 21:51:12.303779: Current learning rate: 0.00111 
2024-11-08 21:51:52.114594: train_loss -0.9536 
2024-11-08 21:51:52.121030: val_loss -0.8538 
2024-11-08 21:51:52.123520: Pseudo dice [np.float32(0.9481), np.float32(0.8422)] 
2024-11-08 21:51:52.125791: Epoch time: 39.82 s 
2024-11-08 21:51:53.296376:  
2024-11-08 21:51:53.298946: Epoch 914 
2024-11-08 21:51:53.301347: Current learning rate: 0.0011 
2024-11-08 21:52:33.135545: train_loss -0.9533 
2024-11-08 21:52:33.141865: val_loss -0.8935 
2024-11-08 21:52:33.144226: Pseudo dice [np.float32(0.9527), np.float32(0.9011)] 
2024-11-08 21:52:33.146532: Epoch time: 39.84 s 
2024-11-08 21:52:34.316491:  
2024-11-08 21:52:34.319308: Epoch 915 
2024-11-08 21:52:34.321578: Current learning rate: 0.00109 
2024-11-08 21:53:14.145156: train_loss -0.9553 
2024-11-08 21:53:14.149978: val_loss -0.8614 
2024-11-08 21:53:14.152764: Pseudo dice [np.float32(0.9471), np.float32(0.8585)] 
2024-11-08 21:53:14.155217: Epoch time: 39.83 s 
2024-11-08 21:53:15.329515:  
2024-11-08 21:53:15.332206: Epoch 916 
2024-11-08 21:53:15.334732: Current learning rate: 0.00108 
2024-11-08 21:53:55.155830: train_loss -0.9523 
2024-11-08 21:53:55.162211: val_loss -0.8546 
2024-11-08 21:53:55.164661: Pseudo dice [np.float32(0.9442), np.float32(0.8745)] 
2024-11-08 21:53:55.167039: Epoch time: 39.83 s 
2024-11-08 21:53:56.345268:  
2024-11-08 21:53:56.347964: Epoch 917 
2024-11-08 21:53:56.350806: Current learning rate: 0.00106 
2024-11-08 21:54:36.188797: train_loss -0.9528 
2024-11-08 21:54:36.191641: val_loss -0.8862 
2024-11-08 21:54:36.193911: Pseudo dice [np.float32(0.9482), np.float32(0.9029)] 
2024-11-08 21:54:36.196194: Epoch time: 39.84 s 
2024-11-08 21:54:37.368956:  
2024-11-08 21:54:37.371644: Epoch 918 
2024-11-08 21:54:37.374252: Current learning rate: 0.00105 
2024-11-08 21:55:17.205153: train_loss -0.9541 
2024-11-08 21:55:17.211246: val_loss -0.8782 
2024-11-08 21:55:17.213678: Pseudo dice [np.float32(0.9489), np.float32(0.8749)] 
2024-11-08 21:55:17.216098: Epoch time: 39.84 s 
2024-11-08 21:55:18.390079:  
2024-11-08 21:55:18.392712: Epoch 919 
2024-11-08 21:55:18.395218: Current learning rate: 0.00104 
2024-11-08 21:55:58.260680: train_loss -0.9543 
2024-11-08 21:55:58.263957: val_loss -0.892 
2024-11-08 21:55:58.266755: Pseudo dice [np.float32(0.9506), np.float32(0.8974)] 
2024-11-08 21:55:58.268926: Epoch time: 39.87 s 
2024-11-08 21:56:00.011713:  
2024-11-08 21:56:00.014387: Epoch 920 
2024-11-08 21:56:00.016945: Current learning rate: 0.00103 
2024-11-08 21:56:39.878744: train_loss -0.9502 
2024-11-08 21:56:39.884481: val_loss -0.8825 
2024-11-08 21:56:39.886742: Pseudo dice [np.float32(0.955), np.float32(0.8892)] 
2024-11-08 21:56:39.889110: Epoch time: 39.87 s 
2024-11-08 21:56:41.061503:  
2024-11-08 21:56:41.064054: Epoch 921 
2024-11-08 21:56:41.066752: Current learning rate: 0.00102 
2024-11-08 21:57:20.917890: train_loss -0.9562 
2024-11-08 21:57:20.920856: val_loss -0.8889 
2024-11-08 21:57:20.923204: Pseudo dice [np.float32(0.9457), np.float32(0.9074)] 
2024-11-08 21:57:20.925532: Epoch time: 39.86 s 
2024-11-08 21:57:22.134192:  
2024-11-08 21:57:22.136724: Epoch 922 
2024-11-08 21:57:22.139082: Current learning rate: 0.00101 
2024-11-08 21:58:01.980486: train_loss -0.9517 
2024-11-08 21:58:01.986509: val_loss -0.8702 
2024-11-08 21:58:01.989057: Pseudo dice [np.float32(0.9491), np.float32(0.8981)] 
2024-11-08 21:58:01.991848: Epoch time: 39.85 s 
2024-11-08 21:58:03.166242:  
2024-11-08 21:58:03.168552: Epoch 923 
2024-11-08 21:58:03.170964: Current learning rate: 0.001 
2024-11-08 21:58:43.013541: train_loss -0.954 
2024-11-08 21:58:43.017689: val_loss -0.8835 
2024-11-08 21:58:43.020063: Pseudo dice [np.float32(0.9479), np.float32(0.9029)] 
2024-11-08 21:58:43.022311: Epoch time: 39.85 s 
2024-11-08 21:58:44.193824:  
2024-11-08 21:58:44.196290: Epoch 924 
2024-11-08 21:58:44.198709: Current learning rate: 0.00098 
2024-11-08 21:59:24.046514: train_loss -0.9529 
2024-11-08 21:59:24.052318: val_loss -0.8782 
2024-11-08 21:59:24.054687: Pseudo dice [np.float32(0.9486), np.float32(0.8881)] 
2024-11-08 21:59:24.056871: Epoch time: 39.85 s 
2024-11-08 21:59:25.231394:  
2024-11-08 21:59:25.233917: Epoch 925 
2024-11-08 21:59:25.236397: Current learning rate: 0.00097 
2024-11-08 22:00:05.103662: train_loss -0.948 
2024-11-08 22:00:05.106799: val_loss -0.9006 
2024-11-08 22:00:05.109368: Pseudo dice [np.float32(0.9563), np.float32(0.9091)] 
2024-11-08 22:00:05.111629: Epoch time: 39.87 s 
2024-11-08 22:00:06.285954:  
2024-11-08 22:00:06.288425: Epoch 926 
2024-11-08 22:00:06.290995: Current learning rate: 0.00096 
2024-11-08 22:00:46.133463: train_loss -0.9499 
2024-11-08 22:00:46.141052: val_loss -0.8714 
2024-11-08 22:00:46.143467: Pseudo dice [np.float32(0.9548), np.float32(0.881)] 
2024-11-08 22:00:46.145730: Epoch time: 39.85 s 
2024-11-08 22:00:47.321552:  
2024-11-08 22:00:47.324065: Epoch 927 
2024-11-08 22:00:47.326535: Current learning rate: 0.00095 
2024-11-08 22:01:27.214267: train_loss -0.9577 
2024-11-08 22:01:27.219594: val_loss -0.8898 
2024-11-08 22:01:27.222120: Pseudo dice [np.float32(0.9498), np.float32(0.9135)] 
2024-11-08 22:01:27.224359: Epoch time: 39.89 s 
2024-11-08 22:01:28.399635:  
2024-11-08 22:01:28.402161: Epoch 928 
2024-11-08 22:01:28.404621: Current learning rate: 0.00094 
2024-11-08 22:02:08.267119: train_loss -0.9587 
2024-11-08 22:02:08.273578: val_loss -0.8797 
2024-11-08 22:02:08.275868: Pseudo dice [np.float32(0.952), np.float32(0.8914)] 
2024-11-08 22:02:08.278252: Epoch time: 39.87 s 
2024-11-08 22:02:09.445864:  
2024-11-08 22:02:09.448352: Epoch 929 
2024-11-08 22:02:09.451108: Current learning rate: 0.00092 
2024-11-08 22:02:49.330116: train_loss -0.955 
2024-11-08 22:02:49.335725: val_loss -0.886 
2024-11-08 22:02:49.339457: Pseudo dice [np.float32(0.9508), np.float32(0.8793)] 
2024-11-08 22:02:49.342079: Epoch time: 39.89 s 
2024-11-08 22:02:50.515261:  
2024-11-08 22:02:50.518131: Epoch 930 
2024-11-08 22:02:50.520574: Current learning rate: 0.00091 
2024-11-08 22:03:30.401308: train_loss -0.9585 
2024-11-08 22:03:30.414316: val_loss -0.8417 
2024-11-08 22:03:30.417041: Pseudo dice [np.float32(0.9451), np.float32(0.854)] 
2024-11-08 22:03:30.419644: Epoch time: 39.89 s 
2024-11-08 22:03:31.591732:  
2024-11-08 22:03:31.594271: Epoch 931 
2024-11-08 22:03:31.596690: Current learning rate: 0.0009 
2024-11-08 22:04:11.484561: train_loss -0.9544 
2024-11-08 22:04:11.489993: val_loss -0.8663 
2024-11-08 22:04:11.492593: Pseudo dice [np.float32(0.9551), np.float32(0.8783)] 
2024-11-08 22:04:11.495457: Epoch time: 39.89 s 
2024-11-08 22:04:12.670439:  
2024-11-08 22:04:12.673123: Epoch 932 
2024-11-08 22:04:12.675708: Current learning rate: 0.00089 
2024-11-08 22:04:52.551634: train_loss -0.9577 
2024-11-08 22:04:52.558532: val_loss -0.8718 
2024-11-08 22:04:52.560888: Pseudo dice [np.float32(0.9501), np.float32(0.8714)] 
2024-11-08 22:04:52.563212: Epoch time: 39.88 s 
2024-11-08 22:04:53.731687:  
2024-11-08 22:04:53.734530: Epoch 933 
2024-11-08 22:04:53.737314: Current learning rate: 0.00088 
2024-11-08 22:05:33.594128: train_loss -0.959 
2024-11-08 22:05:33.598115: val_loss -0.8714 
2024-11-08 22:05:33.601021: Pseudo dice [np.float32(0.954), np.float32(0.8616)] 
2024-11-08 22:05:33.603707: Epoch time: 39.86 s 
2024-11-08 22:05:34.779495:  
2024-11-08 22:05:34.782114: Epoch 934 
2024-11-08 22:05:34.784590: Current learning rate: 0.00087 
2024-11-08 22:06:14.653800: train_loss -0.961 
2024-11-08 22:06:14.659261: val_loss -0.8353 
2024-11-08 22:06:14.662145: Pseudo dice [np.float32(0.9541), np.float32(0.8616)] 
2024-11-08 22:06:14.664505: Epoch time: 39.88 s 
2024-11-08 22:06:15.837563:  
2024-11-08 22:06:15.840214: Epoch 935 
2024-11-08 22:06:15.842882: Current learning rate: 0.00085 
2024-11-08 22:06:55.733389: train_loss -0.9574 
2024-11-08 22:06:55.736209: val_loss -0.8778 
2024-11-08 22:06:55.738595: Pseudo dice [np.float32(0.9574), np.float32(0.8788)] 
2024-11-08 22:06:55.740852: Epoch time: 39.9 s 
2024-11-08 22:06:56.914470:  
2024-11-08 22:06:56.917355: Epoch 936 
2024-11-08 22:06:56.919713: Current learning rate: 0.00084 
2024-11-08 22:07:36.800266: train_loss -0.9553 
2024-11-08 22:07:36.828022: val_loss -0.8845 
2024-11-08 22:07:36.830548: Pseudo dice [np.float32(0.9486), np.float32(0.8939)] 
2024-11-08 22:07:36.833073: Epoch time: 39.89 s 
2024-11-08 22:07:38.009981:  
2024-11-08 22:07:38.012376: Epoch 937 
2024-11-08 22:07:38.014911: Current learning rate: 0.00083 
2024-11-08 22:08:17.875309: train_loss -0.9554 
2024-11-08 22:08:17.878121: val_loss -0.8782 
2024-11-08 22:08:17.880290: Pseudo dice [np.float32(0.9518), np.float32(0.9)] 
2024-11-08 22:08:17.882795: Epoch time: 39.87 s 
2024-11-08 22:08:19.058659:  
2024-11-08 22:08:19.061407: Epoch 938 
2024-11-08 22:08:19.063935: Current learning rate: 0.00082 
2024-11-08 22:08:58.929377: train_loss -0.9579 
2024-11-08 22:08:58.935571: val_loss -0.8736 
2024-11-08 22:08:58.938376: Pseudo dice [np.float32(0.9552), np.float32(0.8603)] 
2024-11-08 22:08:58.940737: Epoch time: 39.87 s 
2024-11-08 22:09:00.110107:  
2024-11-08 22:09:00.112634: Epoch 939 
2024-11-08 22:09:00.120748: Current learning rate: 0.00081 
2024-11-08 22:09:39.966852: train_loss -0.947 
2024-11-08 22:09:39.970544: val_loss -0.8955 
2024-11-08 22:09:39.972739: Pseudo dice [np.float32(0.9497), np.float32(0.904)] 
2024-11-08 22:09:39.975171: Epoch time: 39.86 s 
2024-11-08 22:09:41.149359:  
2024-11-08 22:09:41.151815: Epoch 940 
2024-11-08 22:09:41.154047: Current learning rate: 0.00079 
2024-11-08 22:10:21.013684: train_loss -0.9594 
2024-11-08 22:10:21.019048: val_loss -0.8975 
2024-11-08 22:10:21.021240: Pseudo dice [np.float32(0.9525), np.float32(0.9117)] 
2024-11-08 22:10:21.023650: Epoch time: 39.87 s 
2024-11-08 22:10:22.788315:  
2024-11-08 22:10:22.790896: Epoch 941 
2024-11-08 22:10:22.793322: Current learning rate: 0.00078 
2024-11-08 22:11:02.690968: train_loss -0.9541 
2024-11-08 22:11:02.694074: val_loss -0.8894 
2024-11-08 22:11:02.696424: Pseudo dice [np.float32(0.9538), np.float32(0.9058)] 
2024-11-08 22:11:02.699588: Epoch time: 39.9 s 
2024-11-08 22:11:03.871283:  
2024-11-08 22:11:03.874068: Epoch 942 
2024-11-08 22:11:03.876578: Current learning rate: 0.00077 
2024-11-08 22:11:43.739942: train_loss -0.9557 
2024-11-08 22:11:43.750318: val_loss -0.8829 
2024-11-08 22:11:43.752579: Pseudo dice [np.float32(0.9492), np.float32(0.8938)] 
2024-11-08 22:11:43.755044: Epoch time: 39.87 s 
2024-11-08 22:11:44.926294:  
2024-11-08 22:11:44.929204: Epoch 943 
2024-11-08 22:11:44.931904: Current learning rate: 0.00076 
2024-11-08 22:12:24.774980: train_loss -0.9526 
2024-11-08 22:12:24.777846: val_loss -0.872 
2024-11-08 22:12:24.780193: Pseudo dice [np.float32(0.9481), np.float32(0.8757)] 
2024-11-08 22:12:24.782580: Epoch time: 39.85 s 
2024-11-08 22:12:25.959212:  
2024-11-08 22:12:25.961453: Epoch 944 
2024-11-08 22:12:25.963832: Current learning rate: 0.00075 
2024-11-08 22:13:05.789611: train_loss -0.9577 
2024-11-08 22:13:05.796284: val_loss -0.877 
2024-11-08 22:13:05.799103: Pseudo dice [np.float32(0.9464), np.float32(0.8706)] 
2024-11-08 22:13:05.801767: Epoch time: 39.83 s 
2024-11-08 22:13:06.969047:  
2024-11-08 22:13:06.971334: Epoch 945 
2024-11-08 22:13:06.973586: Current learning rate: 0.00074 
2024-11-08 22:13:46.821934: train_loss -0.9496 
2024-11-08 22:13:46.825125: val_loss -0.8875 
2024-11-08 22:13:46.827505: Pseudo dice [np.float32(0.9568), np.float32(0.8936)] 
2024-11-08 22:13:46.829914: Epoch time: 39.85 s 
2024-11-08 22:13:48.004783:  
2024-11-08 22:13:48.007221: Epoch 946 
2024-11-08 22:13:48.009561: Current learning rate: 0.00072 
2024-11-08 22:14:27.857617: train_loss -0.9526 
2024-11-08 22:14:27.863478: val_loss -0.8921 
2024-11-08 22:14:27.865879: Pseudo dice [np.float32(0.954), np.float32(0.8967)] 
2024-11-08 22:14:27.868132: Epoch time: 39.85 s 
2024-11-08 22:14:29.044176:  
2024-11-08 22:14:29.046712: Epoch 947 
2024-11-08 22:14:29.048959: Current learning rate: 0.00071 
2024-11-08 22:15:08.898396: train_loss -0.9549 
2024-11-08 22:15:08.901124: val_loss -0.8855 
2024-11-08 22:15:08.903262: Pseudo dice [np.float32(0.9522), np.float32(0.8851)] 
2024-11-08 22:15:08.905465: Epoch time: 39.86 s 
2024-11-08 22:15:10.079076:  
2024-11-08 22:15:10.083059: Epoch 948 
2024-11-08 22:15:10.085449: Current learning rate: 0.0007 
2024-11-08 22:15:49.920703: train_loss -0.9563 
2024-11-08 22:15:49.928777: val_loss -0.88 
2024-11-08 22:15:49.931371: Pseudo dice [np.float32(0.9533), np.float32(0.9024)] 
2024-11-08 22:15:49.933662: Epoch time: 39.84 s 
2024-11-08 22:15:51.112971:  
2024-11-08 22:15:51.115655: Epoch 949 
2024-11-08 22:15:51.118024: Current learning rate: 0.00069 
2024-11-08 22:16:30.956248: train_loss -0.9561 
2024-11-08 22:16:30.960804: val_loss -0.8923 
2024-11-08 22:16:30.963082: Pseudo dice [np.float32(0.9572), np.float32(0.9046)] 
2024-11-08 22:16:30.965282: Epoch time: 39.84 s 
2024-11-08 22:16:32.993664:  
2024-11-08 22:16:32.996241: Epoch 950 
2024-11-08 22:16:32.998729: Current learning rate: 0.00067 
2024-11-08 22:17:12.826911: train_loss -0.9546 
2024-11-08 22:17:12.833048: val_loss -0.9008 
2024-11-08 22:17:12.835258: Pseudo dice [np.float32(0.9536), np.float32(0.9146)] 
2024-11-08 22:17:12.837497: Epoch time: 39.83 s 
2024-11-08 22:17:12.839876: Yayy! New best EMA pseudo Dice: 0.9226999878883362 
2024-11-08 22:17:14.801334:  
2024-11-08 22:17:14.803821: Epoch 951 
2024-11-08 22:17:14.806235: Current learning rate: 0.00066 
2024-11-08 22:17:54.667068: train_loss -0.9554 
2024-11-08 22:17:54.673578: val_loss -0.8656 
2024-11-08 22:17:54.676100: Pseudo dice [np.float32(0.95), np.float32(0.8804)] 
2024-11-08 22:17:54.678830: Epoch time: 39.87 s 
2024-11-08 22:17:55.852528:  
2024-11-08 22:17:55.855090: Epoch 952 
2024-11-08 22:17:55.857635: Current learning rate: 0.00065 
2024-11-08 22:18:35.710972: train_loss -0.9582 
2024-11-08 22:18:35.717635: val_loss -0.8801 
2024-11-08 22:18:35.719989: Pseudo dice [np.float32(0.9535), np.float32(0.9041)] 
2024-11-08 22:18:35.747625: Epoch time: 39.86 s 
2024-11-08 22:18:36.914591:  
2024-11-08 22:18:36.917235: Epoch 953 
2024-11-08 22:18:36.919803: Current learning rate: 0.00064 
2024-11-08 22:19:16.777866: train_loss -0.9592 
2024-11-08 22:19:16.782311: val_loss -0.8596 
2024-11-08 22:19:16.784519: Pseudo dice [np.float32(0.9443), np.float32(0.8715)] 
2024-11-08 22:19:16.786637: Epoch time: 39.86 s 
2024-11-08 22:19:17.974398:  
2024-11-08 22:19:17.977144: Epoch 954 
2024-11-08 22:19:17.979639: Current learning rate: 0.00063 
2024-11-08 22:19:57.829430: train_loss -0.9518 
2024-11-08 22:19:57.837058: val_loss -0.8538 
2024-11-08 22:19:57.839352: Pseudo dice [np.float32(0.9538), np.float32(0.8697)] 
2024-11-08 22:19:57.841660: Epoch time: 39.86 s 
2024-11-08 22:19:59.032545:  
2024-11-08 22:19:59.035084: Epoch 955 
2024-11-08 22:19:59.037513: Current learning rate: 0.00061 
2024-11-08 22:20:38.890449: train_loss -0.9568 
2024-11-08 22:20:38.895588: val_loss -0.8935 
2024-11-08 22:20:38.897876: Pseudo dice [np.float32(0.9534), np.float32(0.8941)] 
2024-11-08 22:20:38.900145: Epoch time: 39.86 s 
2024-11-08 22:20:40.090274:  
2024-11-08 22:20:40.092817: Epoch 956 
2024-11-08 22:20:40.095365: Current learning rate: 0.0006 
2024-11-08 22:21:19.926075: train_loss -0.9608 
2024-11-08 22:21:19.932092: val_loss -0.8643 
2024-11-08 22:21:19.934613: Pseudo dice [np.float32(0.9511), np.float32(0.874)] 
2024-11-08 22:21:19.937060: Epoch time: 39.84 s 
2024-11-08 22:21:21.126834:  
2024-11-08 22:21:21.129149: Epoch 957 
2024-11-08 22:21:21.131522: Current learning rate: 0.00059 
2024-11-08 22:22:00.970155: train_loss -0.9535 
2024-11-08 22:22:00.980258: val_loss -0.9009 
2024-11-08 22:22:00.982768: Pseudo dice [np.float32(0.9587), np.float32(0.8954)] 
2024-11-08 22:22:00.985346: Epoch time: 39.84 s 
2024-11-08 22:22:02.174891:  
2024-11-08 22:22:02.177453: Epoch 958 
2024-11-08 22:22:02.180045: Current learning rate: 0.00058 
2024-11-08 22:22:42.041693: train_loss -0.9565 
2024-11-08 22:22:42.054863: val_loss -0.8486 
2024-11-08 22:22:42.057274: Pseudo dice [np.float32(0.9521), np.float32(0.8585)] 
2024-11-08 22:22:42.059618: Epoch time: 39.87 s 
2024-11-08 22:22:43.248203:  
2024-11-08 22:22:43.250876: Epoch 959 
2024-11-08 22:22:43.253497: Current learning rate: 0.00056 
2024-11-08 22:23:23.109597: train_loss -0.9593 
2024-11-08 22:23:23.113621: val_loss -0.8885 
2024-11-08 22:23:23.115904: Pseudo dice [np.float32(0.95), np.float32(0.8997)] 
2024-11-08 22:23:23.118165: Epoch time: 39.86 s 
2024-11-08 22:23:24.305845:  
2024-11-08 22:23:24.308756: Epoch 960 
2024-11-08 22:23:24.311353: Current learning rate: 0.00055 
2024-11-08 22:24:04.645869: train_loss -0.9583 
2024-11-08 22:24:04.652446: val_loss -0.8735 
2024-11-08 22:24:04.655107: Pseudo dice [np.float32(0.9523), np.float32(0.8895)] 
2024-11-08 22:24:04.657495: Epoch time: 40.34 s 
2024-11-08 22:24:05.851125:  
2024-11-08 22:24:05.853654: Epoch 961 
2024-11-08 22:24:05.856037: Current learning rate: 0.00054 
2024-11-08 22:24:45.734840: train_loss -0.9583 
2024-11-08 22:24:45.739333: val_loss -0.8834 
2024-11-08 22:24:45.741593: Pseudo dice [np.float32(0.9519), np.float32(0.8735)] 
2024-11-08 22:24:45.743719: Epoch time: 39.88 s 
2024-11-08 22:24:46.935391:  
2024-11-08 22:24:46.938087: Epoch 962 
2024-11-08 22:24:46.940528: Current learning rate: 0.00053 
2024-11-08 22:25:26.821776: train_loss -0.9562 
2024-11-08 22:25:26.827444: val_loss -0.8593 
2024-11-08 22:25:26.829792: Pseudo dice [np.float32(0.9546), np.float32(0.872)] 
2024-11-08 22:25:26.832013: Epoch time: 39.89 s 
2024-11-08 22:25:28.023086:  
2024-11-08 22:25:28.025623: Epoch 963 
2024-11-08 22:25:28.028387: Current learning rate: 0.00051 
2024-11-08 22:26:07.918064: train_loss -0.9611 
2024-11-08 22:26:07.923434: val_loss -0.8813 
2024-11-08 22:26:07.925719: Pseudo dice [np.float32(0.9526), np.float32(0.8955)] 
2024-11-08 22:26:07.928045: Epoch time: 39.9 s 
2024-11-08 22:26:09.116812:  
2024-11-08 22:26:09.119591: Epoch 964 
2024-11-08 22:26:09.122180: Current learning rate: 0.0005 
2024-11-08 22:26:49.010083: train_loss -0.9602 
2024-11-08 22:26:49.018781: val_loss -0.8763 
2024-11-08 22:26:49.021289: Pseudo dice [np.float32(0.9486), np.float32(0.8867)] 
2024-11-08 22:26:49.023718: Epoch time: 39.89 s 
2024-11-08 22:26:50.214536:  
2024-11-08 22:26:50.217141: Epoch 965 
2024-11-08 22:26:50.219863: Current learning rate: 0.00049 
2024-11-08 22:27:30.095514: train_loss -0.9566 
2024-11-08 22:27:30.098685: val_loss -0.8853 
2024-11-08 22:27:30.101134: Pseudo dice [np.float32(0.9471), np.float32(0.9099)] 
2024-11-08 22:27:30.103584: Epoch time: 39.88 s 
2024-11-08 22:27:31.287210:  
2024-11-08 22:27:31.290055: Epoch 966 
2024-11-08 22:27:31.292910: Current learning rate: 0.00048 
2024-11-08 22:28:11.186316: train_loss -0.9549 
2024-11-08 22:28:11.193409: val_loss -0.8776 
2024-11-08 22:28:11.196247: Pseudo dice [np.float32(0.9525), np.float32(0.8778)] 
2024-11-08 22:28:11.198832: Epoch time: 39.9 s 
2024-11-08 22:28:12.388056:  
2024-11-08 22:28:12.391776: Epoch 967 
2024-11-08 22:28:12.394482: Current learning rate: 0.00046 
2024-11-08 22:28:52.296444: train_loss -0.9579 
2024-11-08 22:28:52.301332: val_loss -0.9027 
2024-11-08 22:28:52.303762: Pseudo dice [np.float32(0.9554), np.float32(0.9143)] 
2024-11-08 22:28:52.306384: Epoch time: 39.91 s 
2024-11-08 22:28:53.502067:  
2024-11-08 22:28:53.504865: Epoch 968 
2024-11-08 22:28:53.507656: Current learning rate: 0.00045 
2024-11-08 22:29:33.395984: train_loss -0.958 
2024-11-08 22:29:33.414123: val_loss -0.8896 
2024-11-08 22:29:33.416540: Pseudo dice [np.float32(0.9513), np.float32(0.8955)] 
2024-11-08 22:29:33.418807: Epoch time: 39.9 s 
2024-11-08 22:29:34.609618:  
2024-11-08 22:29:34.611945: Epoch 969 
2024-11-08 22:29:34.614124: Current learning rate: 0.00044 
2024-11-08 22:30:14.464858: train_loss -0.959 
2024-11-08 22:30:14.470738: val_loss -0.8686 
2024-11-08 22:30:14.473188: Pseudo dice [np.float32(0.9514), np.float32(0.8683)] 
2024-11-08 22:30:14.475709: Epoch time: 39.86 s 
2024-11-08 22:30:15.670951:  
2024-11-08 22:30:15.673487: Epoch 970 
2024-11-08 22:30:15.676123: Current learning rate: 0.00043 
2024-11-08 22:30:55.507030: train_loss -0.9598 
2024-11-08 22:30:55.513670: val_loss -0.8572 
2024-11-08 22:30:55.515986: Pseudo dice [np.float32(0.946), np.float32(0.8503)] 
2024-11-08 22:30:55.519003: Epoch time: 39.84 s 
2024-11-08 22:30:56.717574:  
2024-11-08 22:30:56.720318: Epoch 971 
2024-11-08 22:30:56.723183: Current learning rate: 0.00041 
2024-11-08 22:31:36.559340: train_loss -0.9566 
2024-11-08 22:31:36.576365: val_loss -0.8608 
2024-11-08 22:31:36.578971: Pseudo dice [np.float32(0.9493), np.float32(0.8509)] 
2024-11-08 22:31:36.581322: Epoch time: 39.84 s 
2024-11-08 22:31:37.769073:  
2024-11-08 22:31:37.771665: Epoch 972 
2024-11-08 22:31:37.774535: Current learning rate: 0.0004 
2024-11-08 22:32:17.628412: train_loss -0.9597 
2024-11-08 22:32:17.634981: val_loss -0.8714 
2024-11-08 22:32:17.637354: Pseudo dice [np.float32(0.9533), np.float32(0.8639)] 
2024-11-08 22:32:17.639704: Epoch time: 39.86 s 
2024-11-08 22:32:18.831328:  
2024-11-08 22:32:18.834023: Epoch 973 
2024-11-08 22:32:18.836823: Current learning rate: 0.00039 
2024-11-08 22:32:58.666400: train_loss -0.9566 
2024-11-08 22:32:58.672182: val_loss -0.8782 
2024-11-08 22:32:58.674896: Pseudo dice [np.float32(0.9513), np.float32(0.8806)] 
2024-11-08 22:32:58.677311: Epoch time: 39.84 s 
2024-11-08 22:32:59.873472:  
2024-11-08 22:32:59.875956: Epoch 974 
2024-11-08 22:32:59.878371: Current learning rate: 0.00037 
2024-11-08 22:33:39.725237: train_loss -0.9551 
2024-11-08 22:33:39.732101: val_loss -0.8682 
2024-11-08 22:33:39.734600: Pseudo dice [np.float32(0.9575), np.float32(0.8832)] 
2024-11-08 22:33:39.737098: Epoch time: 39.85 s 
2024-11-08 22:33:40.931297:  
2024-11-08 22:33:40.933815: Epoch 975 
2024-11-08 22:33:40.936358: Current learning rate: 0.00036 
2024-11-08 22:34:20.768544: train_loss -0.9552 
2024-11-08 22:34:20.778617: val_loss -0.8539 
2024-11-08 22:34:20.780989: Pseudo dice [np.float32(0.9509), np.float32(0.8269)] 
2024-11-08 22:34:20.783448: Epoch time: 39.84 s 
2024-11-08 22:34:21.974735:  
2024-11-08 22:34:21.977229: Epoch 976 
2024-11-08 22:34:21.979837: Current learning rate: 0.00035 
2024-11-08 22:35:01.806672: train_loss -0.9587 
2024-11-08 22:35:01.813493: val_loss -0.8513 
2024-11-08 22:35:01.815723: Pseudo dice [np.float32(0.9468), np.float32(0.8456)] 
2024-11-08 22:35:01.818121: Epoch time: 39.83 s 
2024-11-08 22:35:03.010773:  
2024-11-08 22:35:03.013460: Epoch 977 
2024-11-08 22:35:03.015986: Current learning rate: 0.00034 
2024-11-08 22:35:42.867846: train_loss -0.9592 
2024-11-08 22:35:42.870843: val_loss -0.8618 
2024-11-08 22:35:42.873148: Pseudo dice [np.float32(0.9501), np.float32(0.8573)] 
2024-11-08 22:35:42.875711: Epoch time: 39.86 s 
2024-11-08 22:35:44.064915:  
2024-11-08 22:35:44.067408: Epoch 978 
2024-11-08 22:35:44.070009: Current learning rate: 0.00032 
2024-11-08 22:36:23.939359: train_loss -0.9591 
2024-11-08 22:36:23.972848: val_loss -0.8733 
2024-11-08 22:36:23.975555: Pseudo dice [np.float32(0.9551), np.float32(0.8859)] 
2024-11-08 22:36:23.978166: Epoch time: 39.88 s 
2024-11-08 22:36:25.171294:  
2024-11-08 22:36:25.173727: Epoch 979 
2024-11-08 22:36:25.176187: Current learning rate: 0.00031 
2024-11-08 22:37:05.034447: train_loss -0.9578 
2024-11-08 22:37:05.040574: val_loss -0.8422 
2024-11-08 22:37:05.043808: Pseudo dice [np.float32(0.9535), np.float32(0.8422)] 
2024-11-08 22:37:05.046590: Epoch time: 39.86 s 
2024-11-08 22:37:06.802779:  
2024-11-08 22:37:06.805268: Epoch 980 
2024-11-08 22:37:06.807776: Current learning rate: 0.0003 
2024-11-08 22:37:46.643731: train_loss -0.9605 
2024-11-08 22:37:46.650364: val_loss -0.8603 
2024-11-08 22:37:46.652692: Pseudo dice [np.float32(0.9567), np.float32(0.8603)] 
2024-11-08 22:37:46.655170: Epoch time: 39.84 s 
2024-11-08 22:37:47.850440:  
2024-11-08 22:37:47.852926: Epoch 981 
2024-11-08 22:37:47.855489: Current learning rate: 0.00028 
2024-11-08 22:38:27.712844: train_loss -0.9619 
2024-11-08 22:38:27.723753: val_loss -0.8822 
2024-11-08 22:38:27.726323: Pseudo dice [np.float32(0.9515), np.float32(0.8839)] 
2024-11-08 22:38:27.728725: Epoch time: 39.86 s 
2024-11-08 22:38:28.921526:  
2024-11-08 22:38:28.923809: Epoch 982 
2024-11-08 22:38:28.926050: Current learning rate: 0.00027 
2024-11-08 22:39:08.770306: train_loss -0.9594 
2024-11-08 22:39:08.777330: val_loss -0.889 
2024-11-08 22:39:08.779876: Pseudo dice [np.float32(0.9502), np.float32(0.8808)] 
2024-11-08 22:39:08.782319: Epoch time: 39.85 s 
2024-11-08 22:39:09.974453:  
2024-11-08 22:39:09.976907: Epoch 983 
2024-11-08 22:39:09.979247: Current learning rate: 0.00026 
2024-11-08 22:39:49.841838: train_loss -0.9549 
2024-11-08 22:39:49.849162: val_loss -0.8745 
2024-11-08 22:39:49.851579: Pseudo dice [np.float32(0.9556), np.float32(0.8706)] 
2024-11-08 22:39:49.853996: Epoch time: 39.87 s 
2024-11-08 22:39:51.048465:  
2024-11-08 22:39:51.050858: Epoch 984 
2024-11-08 22:39:51.053379: Current learning rate: 0.00024 
2024-11-08 22:40:30.910527: train_loss -0.9595 
2024-11-08 22:40:30.917610: val_loss -0.8744 
2024-11-08 22:40:30.919907: Pseudo dice [np.float32(0.9514), np.float32(0.8602)] 
2024-11-08 22:40:30.922204: Epoch time: 39.86 s 
2024-11-08 22:40:32.117162:  
2024-11-08 22:40:32.119482: Epoch 985 
2024-11-08 22:40:32.121858: Current learning rate: 0.00023 
2024-11-08 22:41:11.976850: train_loss -0.9609 
2024-11-08 22:41:11.983030: val_loss -0.8376 
2024-11-08 22:41:11.985381: Pseudo dice [np.float32(0.9459), np.float32(0.8485)] 
2024-11-08 22:41:11.987628: Epoch time: 39.86 s 
2024-11-08 22:41:13.179595:  
2024-11-08 22:41:13.182940: Epoch 986 
2024-11-08 22:41:13.185268: Current learning rate: 0.00021 
2024-11-08 22:41:53.019727: train_loss -0.9585 
2024-11-08 22:41:53.027099: val_loss -0.8667 
2024-11-08 22:41:53.029456: Pseudo dice [np.float32(0.949), np.float32(0.8638)] 
2024-11-08 22:41:53.031981: Epoch time: 39.84 s 
2024-11-08 22:41:54.219250:  
2024-11-08 22:41:54.221690: Epoch 987 
2024-11-08 22:41:54.223923: Current learning rate: 0.0002 
2024-11-08 22:42:34.065025: train_loss -0.9599 
2024-11-08 22:42:34.071143: val_loss -0.8815 
2024-11-08 22:42:34.073655: Pseudo dice [np.float32(0.9511), np.float32(0.8692)] 
2024-11-08 22:42:34.076944: Epoch time: 39.85 s 
2024-11-08 22:42:35.273844:  
2024-11-08 22:42:35.276536: Epoch 988 
2024-11-08 22:42:35.279088: Current learning rate: 0.00019 
2024-11-08 22:43:15.106196: train_loss -0.9615 
2024-11-08 22:43:15.112803: val_loss -0.8769 
2024-11-08 22:43:15.115154: Pseudo dice [np.float32(0.9493), np.float32(0.8727)] 
2024-11-08 22:43:15.117524: Epoch time: 39.83 s 
2024-11-08 22:43:16.315953:  
2024-11-08 22:43:16.321893: Epoch 989 
2024-11-08 22:43:16.324248: Current learning rate: 0.00017 
2024-11-08 22:43:56.154330: train_loss -0.959 
2024-11-08 22:43:56.168748: val_loss -0.8794 
2024-11-08 22:43:56.171191: Pseudo dice [np.float32(0.9526), np.float32(0.8939)] 
2024-11-08 22:43:56.173725: Epoch time: 39.84 s 
2024-11-08 22:43:57.365283:  
2024-11-08 22:43:57.367808: Epoch 990 
2024-11-08 22:43:57.370179: Current learning rate: 0.00016 
2024-11-08 22:44:37.188631: train_loss -0.9604 
2024-11-08 22:44:37.195196: val_loss -0.8567 
2024-11-08 22:44:37.197827: Pseudo dice [np.float32(0.9458), np.float32(0.8666)] 
2024-11-08 22:44:37.200183: Epoch time: 39.82 s 
2024-11-08 22:44:38.391983:  
2024-11-08 22:44:38.394520: Epoch 991 
2024-11-08 22:44:38.397148: Current learning rate: 0.00014 
2024-11-08 22:45:18.213064: train_loss -0.9559 
2024-11-08 22:45:18.218810: val_loss -0.873 
2024-11-08 22:45:18.221297: Pseudo dice [np.float32(0.9521), np.float32(0.8796)] 
2024-11-08 22:45:18.223565: Epoch time: 39.82 s 
2024-11-08 22:45:19.418250:  
2024-11-08 22:45:19.420601: Epoch 992 
2024-11-08 22:45:19.422767: Current learning rate: 0.00013 
2024-11-08 22:45:59.243596: train_loss -0.9631 
2024-11-08 22:45:59.255451: val_loss -0.8553 
2024-11-08 22:45:59.257916: Pseudo dice [np.float32(0.9481), np.float32(0.855)] 
2024-11-08 22:45:59.260350: Epoch time: 39.83 s 
2024-11-08 22:46:00.455175:  
2024-11-08 22:46:00.457612: Epoch 993 
2024-11-08 22:46:00.459769: Current learning rate: 0.00011 
2024-11-08 22:46:40.276427: train_loss -0.9564 
2024-11-08 22:46:40.282413: val_loss -0.8688 
2024-11-08 22:46:40.284787: Pseudo dice [np.float32(0.9505), np.float32(0.8699)] 
2024-11-08 22:46:40.287480: Epoch time: 39.82 s 
2024-11-08 22:46:41.476121:  
2024-11-08 22:46:41.478721: Epoch 994 
2024-11-08 22:46:41.481600: Current learning rate: 0.0001 
2024-11-08 22:47:21.308379: train_loss -0.9629 
2024-11-08 22:47:21.314458: val_loss -0.8669 
2024-11-08 22:47:21.316895: Pseudo dice [np.float32(0.9519), np.float32(0.876)] 
2024-11-08 22:47:21.319196: Epoch time: 39.83 s 
2024-11-08 22:47:22.513775:  
2024-11-08 22:47:22.516461: Epoch 995 
2024-11-08 22:47:22.519673: Current learning rate: 8e-05 
2024-11-08 22:48:02.349380: train_loss -0.9593 
2024-11-08 22:48:02.357553: val_loss -0.8745 
2024-11-08 22:48:02.359980: Pseudo dice [np.float32(0.9518), np.float32(0.8711)] 
2024-11-08 22:48:02.362314: Epoch time: 39.84 s 
2024-11-08 22:48:03.553873:  
2024-11-08 22:48:03.556285: Epoch 996 
2024-11-08 22:48:03.558690: Current learning rate: 7e-05 
2024-11-08 22:48:43.403386: train_loss -0.9591 
2024-11-08 22:48:43.409399: val_loss -0.8902 
2024-11-08 22:48:43.411858: Pseudo dice [np.float32(0.9526), np.float32(0.8885)] 
2024-11-08 22:48:43.414210: Epoch time: 39.85 s 
2024-11-08 22:48:44.603150:  
2024-11-08 22:48:44.606573: Epoch 997 
2024-11-08 22:48:44.608936: Current learning rate: 5e-05 
2024-11-08 22:49:24.435394: train_loss -0.9589 
2024-11-08 22:49:24.438395: val_loss -0.9005 
2024-11-08 22:49:24.440783: Pseudo dice [np.float32(0.9581), np.float32(0.8946)] 
2024-11-08 22:49:24.443345: Epoch time: 39.83 s 
2024-11-08 22:49:25.634197:  
2024-11-08 22:49:25.637840: Epoch 998 
2024-11-08 22:49:25.640577: Current learning rate: 4e-05 
2024-11-08 22:50:05.484450: train_loss -0.9586 
2024-11-08 22:50:05.493969: val_loss -0.8634 
2024-11-08 22:50:05.496441: Pseudo dice [np.float32(0.9512), np.float32(0.8562)] 
2024-11-08 22:50:05.498857: Epoch time: 39.85 s 
2024-11-08 22:50:06.691866:  
2024-11-08 22:50:06.694216: Epoch 999 
2024-11-08 22:50:06.696820: Current learning rate: 2e-05 
2024-11-08 22:50:46.543818: train_loss -0.9579 
2024-11-08 22:50:46.548768: val_loss -0.8754 
2024-11-08 22:50:46.551184: Pseudo dice [np.float32(0.951), np.float32(0.8867)] 
2024-11-08 22:50:46.553597: Epoch time: 39.85 s 
2024-11-08 22:50:49.130096: Training done. 
2024-11-08 22:50:49.362408: Using splits from existing split file: /srv/scratch/z5362216/kits19/nnUNet_db/nnUNet_preprocessed/Dataset001_Kits19/splits_final.json 
2024-11-08 22:50:49.366090: The split file contains 5 splits. 
2024-11-08 22:50:49.368427: Desired fold for training: 1 
2024-11-08 22:50:49.371234: This split has 80 training and 20 validation cases. 
2024-11-08 22:50:49.374101: predicting imaging_000 
2024-11-08 22:50:49.382755: imaging_000, shape torch.Size([1, 611, 593, 593]), rank 0 
2024-11-08 22:51:57.294445: predicting imaging_002 
2024-11-08 22:51:57.332698: imaging_002, shape torch.Size([1, 261, 606, 606]), rank 0 
2024-11-08 22:52:16.544715: predicting imaging_006 
2024-11-08 22:52:16.560466: imaging_006, shape torch.Size([1, 157, 479, 479]), rank 0 
2024-11-08 22:52:44.097843: predicting imaging_008 
2024-11-08 22:52:44.419742: imaging_008, shape torch.Size([1, 227, 526, 526]), rank 0 
2024-11-08 22:53:04.625265: predicting imaging_017 
2024-11-08 22:53:04.806165: imaging_017, shape torch.Size([1, 97, 428, 428]), rank 0 
2024-11-08 22:53:07.186737: predicting imaging_026 
2024-11-08 22:53:07.798281: imaging_026, shape torch.Size([1, 302, 564, 564]), rank 0 
2024-11-08 22:53:36.323850: predicting imaging_030 
2024-11-08 22:53:36.575621: imaging_030, shape torch.Size([1, 38, 471, 471]), rank 0 
2024-11-08 22:53:37.602026: predicting imaging_037 
2024-11-08 22:53:37.797545: imaging_037, shape torch.Size([1, 97, 605, 605]), rank 0 
2024-11-08 22:53:46.147829: predicting imaging_039 
2024-11-08 22:53:46.422777: imaging_039, shape torch.Size([1, 90, 453, 453]), rank 0 
2024-11-08 22:53:49.342834: predicting imaging_045 
2024-11-08 22:53:49.934666: imaging_045, shape torch.Size([1, 62, 478, 478]), rank 0 
2024-11-08 22:53:53.333809: predicting imaging_046 
2024-11-08 22:53:53.599972: imaging_046, shape torch.Size([1, 159, 630, 630]), rank 0 
2024-11-08 22:54:08.778747: predicting imaging_047 
2024-11-08 22:54:09.077034: imaging_047, shape torch.Size([1, 142, 552, 552]), rank 0 
2024-11-08 22:54:21.256516: predicting imaging_050 
2024-11-08 22:54:21.449183: imaging_050, shape torch.Size([1, 96, 445, 445]), rank 0 
2024-11-08 22:54:23.751296: predicting imaging_052 
2024-11-08 22:54:24.010544: imaging_052, shape torch.Size([1, 673, 617, 617]), rank 0 
2024-11-08 22:55:27.954827: predicting imaging_054 
2024-11-08 22:55:28.239979: imaging_054, shape torch.Size([1, 104, 630, 630]), rank 0 
2024-11-08 22:55:37.224360: predicting imaging_057 
2024-11-08 22:55:37.746336: imaging_057, shape torch.Size([1, 80, 530, 530]), rank 0 
2024-11-08 22:55:44.680999: predicting imaging_071 
2024-11-08 22:55:45.078055: imaging_071, shape torch.Size([1, 612, 453, 453]), rank 0 
2024-11-08 22:55:59.600857: predicting imaging_076 
2024-11-08 22:55:59.899056: imaging_076, shape torch.Size([1, 66, 437, 437]), rank 0 
2024-11-08 22:56:02.342844: predicting imaging_087 
2024-11-08 22:56:02.518596: imaging_087, shape torch.Size([1, 49, 446, 446]), rank 0 
2024-11-08 22:56:04.929845: predicting imaging_092 
2024-11-08 22:56:05.303886: imaging_092, shape torch.Size([1, 98, 453, 453]), rank 0 
2024-11-08 22:58:23.384785: Validation complete 
2024-11-08 22:58:23.387532: Mean Validation Dice:  0.8642466411310274 
