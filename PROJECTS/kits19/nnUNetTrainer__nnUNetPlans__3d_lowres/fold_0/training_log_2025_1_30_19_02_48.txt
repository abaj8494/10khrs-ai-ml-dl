
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-01-30 19:02:48.271561: do_dummy_2d_data_aug: False 
2025-01-30 19:02:48.275817: Using splits from existing split file: /srv/scratch/z5362216/kits19/nnUNet_db/nnUNet_preprocessed/Dataset001_Kits19/splits_final.json 
2025-01-30 19:02:48.278284: The split file contains 5 splits. 
2025-01-30 19:02:48.280360: Desired fold for training: 0 
2025-01-30 19:02:48.282437: This split has 80 training and 20 validation cases. 
2025-01-30 19:02:51.164300: Using torch.compile... 

This is the configuration used by this training:
Configuration name: 3d_lowres
 {'data_identifier': 'nnUNetPlans_3d_lowres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [128, 128, 128], 'median_image_size_in_voxels': [200, 205, 205], 'spacing': [1.9849520718478983, 1.9849270710444444, 1.9849270710444444], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False, 'next_stage': '3d_cascade_fullres'} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset001_Kits19', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [3.0, 0.7939453125, 0.7939453125], 'original_median_shape_after_transp': [104, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [2, 0, 1], 'transpose_backward': [1, 2, 0], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 2553.0, 'mean': 104.46720886230469, 'median': 104.0, 'min': -277.0, 'percentile_00_5': -73.0, 'percentile_99_5': 292.0, 'std': 74.68063354492188}}} 
 
2025-01-30 19:02:52.255714: unpacking dataset... 
2025-01-30 19:02:57.507005: unpacking done... 
2025-01-30 19:02:57.528223: 
printing the network instead:
 
2025-01-30 19:02:57.530692: OptimizedModule(
  (_orig_mod): PlainConvUNet(
    (encoder): PlainConvEncoder(
      (stages): Sequential(
        (0): Sequential(
          (0): StackedConvBlocks(
            (convs): Sequential(
              (0): ConvDropoutNormReLU(
                (conv): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (1): ConvDropoutNormReLU(
                (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
            )
          )
        )
        (1): Sequential(
          (0): StackedConvBlocks(
            (convs): Sequential(
              (0): ConvDropoutNormReLU(
                (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (1): ConvDropoutNormReLU(
                (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
            )
          )
        )
        (2): Sequential(
          (0): StackedConvBlocks(
            (convs): Sequential(
              (0): ConvDropoutNormReLU(
                (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (1): ConvDropoutNormReLU(
                (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
            )
          )
        )
        (3): Sequential(
          (0): StackedConvBlocks(
            (convs): Sequential(
              (0): ConvDropoutNormReLU(
                (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (1): ConvDropoutNormReLU(
                (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
            )
          )
        )
        (4): Sequential(
          (0): StackedConvBlocks(
            (convs): Sequential(
              (0): ConvDropoutNormReLU(
                (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (1): ConvDropoutNormReLU(
                (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
            )
          )
        )
        (5): Sequential(
          (0): StackedConvBlocks(
            (convs): Sequential(
              (0): ConvDropoutNormReLU(
                (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (1): ConvDropoutNormReLU(
                (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
            )
          )
        )
      )
    )
    (decoder): UNetDecoder(
      (encoder): PlainConvEncoder(
        (stages): Sequential(
          (0): Sequential(
            (0): StackedConvBlocks(
              (convs): Sequential(
                (0): ConvDropoutNormReLU(
                  (conv): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                  (all_modules): Sequential(
                    (0): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                    (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                    (2): LeakyReLU(negative_slope=0.01, inplace=True)
                  )
                )
                (1): ConvDropoutNormReLU(
                  (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                  (all_modules): Sequential(
                    (0): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                    (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                    (2): LeakyReLU(negative_slope=0.01, inplace=True)
                  )
                )
              )
            )
          )
          (1): Sequential(
            (0): StackedConvBlocks(
              (convs): Sequential(
                (0): ConvDropoutNormReLU(
                  (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                  (all_modules): Sequential(
                    (0): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                    (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                    (2): LeakyReLU(negative_slope=0.01, inplace=True)
                  )
                )
                (1): ConvDropoutNormReLU(
                  (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                  (all_modules): Sequential(
                    (0): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                    (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                    (2): LeakyReLU(negative_slope=0.01, inplace=True)
                  )
                )
              )
            )
          )
          (2): Sequential(
            (0): StackedConvBlocks(
              (convs): Sequential(
                (0): ConvDropoutNormReLU(
                  (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                  (all_modules): Sequential(
                    (0): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                    (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                    (2): LeakyReLU(negative_slope=0.01, inplace=True)
                  )
                )
                (1): ConvDropoutNormReLU(
                  (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                  (all_modules): Sequential(
                    (0): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                    (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                    (2): LeakyReLU(negative_slope=0.01, inplace=True)
                  )
                )
              )
            )
          )
          (3): Sequential(
            (0): StackedConvBlocks(
              (convs): Sequential(
                (0): ConvDropoutNormReLU(
                  (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                  (all_modules): Sequential(
                    (0): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                    (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                    (2): LeakyReLU(negative_slope=0.01, inplace=True)
                  )
                )
                (1): ConvDropoutNormReLU(
                  (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                  (all_modules): Sequential(
                    (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                    (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                    (2): LeakyReLU(negative_slope=0.01, inplace=True)
                  )
                )
              )
            )
          )
          (4): Sequential(
            (0): StackedConvBlocks(
              (convs): Sequential(
                (0): ConvDropoutNormReLU(
                  (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                  (all_modules): Sequential(
                    (0): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                    (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                    (2): LeakyReLU(negative_slope=0.01, inplace=True)
                  )
                )
                (1): ConvDropoutNormReLU(
                  (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                  (all_modules): Sequential(
                    (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                    (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                    (2): LeakyReLU(negative_slope=0.01, inplace=True)
                  )
                )
              )
            )
          )
          (5): Sequential(
            (0): StackedConvBlocks(
              (convs): Sequential(
                (0): ConvDropoutNormReLU(
                  (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                  (all_modules): Sequential(
                    (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                    (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                    (2): LeakyReLU(negative_slope=0.01, inplace=True)
                  )
                )
                (1): ConvDropoutNormReLU(
                  (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                  (all_modules): Sequential(
                    (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                    (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                    (2): LeakyReLU(negative_slope=0.01, inplace=True)
                  )
                )
              )
            )
          )
        )
      )
      (stages): ModuleList(
        (0): StackedConvBlocks(
          (convs): Sequential(
            (0): ConvDropoutNormReLU(
              (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
              (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (1): ConvDropoutNormReLU(
              (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
              (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
          )
        )
        (1): StackedConvBlocks(
          (convs): Sequential(
            (0): ConvDropoutNormReLU(
              (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
              (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (1): ConvDropoutNormReLU(
              (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
              (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
          )
        )
        (2): StackedConvBlocks(
          (convs): Sequential(
            (0): ConvDropoutNormReLU(
              (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (1): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
          )
        )
        (3): StackedConvBlocks(
          (convs): Sequential(
            (0): ConvDropoutNormReLU(
              (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (1): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
          )
        )
        (4): StackedConvBlocks(
          (convs): Sequential(
            (0): ConvDropoutNormReLU(
              (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (1): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
          )
        )
      )
      (transpconvs): ModuleList(
        (0): ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2))
        (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2))
        (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2))
        (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2))
        (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2))
      )
      (seg_layers): ModuleList(
        (0): Conv3d(320, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1))
        (1): Conv3d(256, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1))
        (2): Conv3d(128, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1))
        (3): Conv3d(64, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1))
        (4): Conv3d(32, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1))
      )
    )
  )
) 
2025-01-30 19:02:57.537875: 
 
2025-01-30 19:02:57.540299: Unable to plot network architecture: nnUNet_compile is enabled! 
2025-01-30 19:02:57.557799:  
2025-01-30 19:02:57.560402: Epoch 0 
2025-01-30 19:02:57.562617: Current learning rate: 0.01 
2025-01-30 19:04:45.210378: train_loss 0.085 
2025-01-30 19:04:45.216488: val_loss -0.0296 
2025-01-30 19:04:45.218903: Pseudo dice [np.float32(0.0), np.float32(0.0)] 
2025-01-30 19:04:45.221108: Epoch time: 107.65 s 
2025-01-30 19:04:45.223361: Yayy! New best EMA pseudo Dice: 0.0 
2025-01-30 19:04:47.121647:  
2025-01-30 19:04:47.124397: Epoch 1 
2025-01-30 19:04:47.127136: Current learning rate: 0.00999 
2025-01-30 19:05:35.716865: train_loss -0.23 
2025-01-30 19:05:35.720151: val_loss -0.2566 
2025-01-30 19:05:35.722380: Pseudo dice [np.float32(0.7769), np.float32(0.0)] 
2025-01-30 19:05:35.724866: Epoch time: 48.6 s 
2025-01-30 19:05:35.727115: Yayy! New best EMA pseudo Dice: 0.03880000114440918 
2025-01-30 19:05:37.394529:  
2025-01-30 19:05:37.397425: Epoch 2 
2025-01-30 19:05:37.400316: Current learning rate: 0.00998 
2025-01-30 19:06:25.452130: train_loss -0.3635 
2025-01-30 19:06:25.459316: val_loss -0.3623 
2025-01-30 19:06:25.461723: Pseudo dice [np.float32(0.8269), np.float32(0.2674)] 
2025-01-30 19:06:25.464210: Epoch time: 48.06 s 
2025-01-30 19:06:25.466935: Yayy! New best EMA pseudo Dice: 0.08969999849796295 
2025-01-30 19:06:27.133472:  
2025-01-30 19:06:27.135854: Epoch 3 
2025-01-30 19:06:27.138378: Current learning rate: 0.00997 
2025-01-30 19:07:15.058973: train_loss -0.417 
2025-01-30 19:07:15.062855: val_loss -0.4454 
2025-01-30 19:07:15.065610: Pseudo dice [np.float32(0.8621), np.float32(0.4643)] 
2025-01-30 19:07:15.068130: Epoch time: 47.93 s 
2025-01-30 19:07:15.070592: Yayy! New best EMA pseudo Dice: 0.1469999998807907 
2025-01-30 19:07:16.738729:  
2025-01-30 19:07:16.740962: Epoch 4 
2025-01-30 19:07:16.743393: Current learning rate: 0.00996 
2025-01-30 19:08:05.357701: train_loss -0.4389 
2025-01-30 19:08:05.363453: val_loss -0.4078 
2025-01-30 19:08:05.366053: Pseudo dice [np.float32(0.842), np.float32(0.3517)] 
2025-01-30 19:08:05.368677: Epoch time: 48.62 s 
2025-01-30 19:08:05.371053: Yayy! New best EMA pseudo Dice: 0.19200000166893005 
2025-01-30 19:08:07.083843:  
2025-01-30 19:08:07.086424: Epoch 5 
2025-01-30 19:08:07.088922: Current learning rate: 0.00995 
2025-01-30 19:08:55.138317: train_loss -0.4716 
2025-01-30 19:08:55.142575: val_loss -0.4781 
2025-01-30 19:08:55.145469: Pseudo dice [np.float32(0.865), np.float32(0.5607)] 
2025-01-30 19:08:55.148298: Epoch time: 48.06 s 
2025-01-30 19:08:55.150802: Yayy! New best EMA pseudo Dice: 0.24410000443458557 
2025-01-30 19:08:56.876565:  
2025-01-30 19:08:56.879045: Epoch 6 
2025-01-30 19:08:56.881721: Current learning rate: 0.00995 
2025-01-30 19:09:44.863161: train_loss -0.5185 
2025-01-30 19:09:44.869452: val_loss -0.4491 
2025-01-30 19:09:44.872265: Pseudo dice [np.float32(0.8632), np.float32(0.5034)] 
2025-01-30 19:09:44.874893: Epoch time: 47.99 s 
2025-01-30 19:09:44.877257: Yayy! New best EMA pseudo Dice: 0.2879999876022339 
2025-01-30 19:09:46.551920:  
2025-01-30 19:09:46.554833: Epoch 7 
2025-01-30 19:09:46.557601: Current learning rate: 0.00994 
2025-01-30 19:10:35.033699: train_loss -0.5336 
2025-01-30 19:10:35.037501: val_loss -0.4203 
2025-01-30 19:10:35.039896: Pseudo dice [np.float32(0.8473), np.float32(0.3711)] 
2025-01-30 19:10:35.042443: Epoch time: 48.48 s 
2025-01-30 19:10:35.044740: Yayy! New best EMA pseudo Dice: 0.32010000944137573 
2025-01-30 19:10:36.788928:  
2025-01-30 19:10:36.791404: Epoch 8 
2025-01-30 19:10:36.793846: Current learning rate: 0.00993 
2025-01-30 19:11:24.847840: train_loss -0.5122 
2025-01-30 19:11:24.853272: val_loss -0.4696 
2025-01-30 19:11:24.855832: Pseudo dice [np.float32(0.8765), np.float32(0.495)] 
2025-01-30 19:11:24.858107: Epoch time: 48.06 s 
2025-01-30 19:11:24.860645: Yayy! New best EMA pseudo Dice: 0.35670000314712524 
2025-01-30 19:11:26.562822:  
2025-01-30 19:11:26.565558: Epoch 9 
2025-01-30 19:11:26.568546: Current learning rate: 0.00992 
2025-01-30 19:12:14.655925: train_loss -0.5518 
2025-01-30 19:12:14.659414: val_loss -0.4852 
2025-01-30 19:12:14.661865: Pseudo dice [np.float32(0.8884), np.float32(0.4534)] 
2025-01-30 19:12:14.664216: Epoch time: 48.09 s 
2025-01-30 19:12:14.666565: Yayy! New best EMA pseudo Dice: 0.3880999982357025 
2025-01-30 19:12:16.383651:  
2025-01-30 19:12:16.385993: Epoch 10 
2025-01-30 19:12:16.388301: Current learning rate: 0.00991 
2025-01-30 19:13:04.728976: train_loss -0.5853 
2025-01-30 19:13:04.734183: val_loss -0.4918 
2025-01-30 19:13:04.736667: Pseudo dice [np.float32(0.8877), np.float32(0.5448)] 
2025-01-30 19:13:04.738957: Epoch time: 48.35 s 
2025-01-30 19:13:04.741301: Yayy! New best EMA pseudo Dice: 0.42089998722076416 
2025-01-30 19:13:06.417820:  
2025-01-30 19:13:06.420238: Epoch 11 
2025-01-30 19:13:06.422395: Current learning rate: 0.0099 
2025-01-30 19:13:54.286497: train_loss -0.6053 
2025-01-30 19:13:54.291250: val_loss -0.5131 
2025-01-30 19:13:54.294017: Pseudo dice [np.float32(0.8894), np.float32(0.6148)] 
2025-01-30 19:13:54.296613: Epoch time: 47.87 s 
2025-01-30 19:13:54.299081: Yayy! New best EMA pseudo Dice: 0.45399999618530273 
2025-01-30 19:13:55.941376:  
2025-01-30 19:13:55.944286: Epoch 12 
2025-01-30 19:13:55.946916: Current learning rate: 0.00989 
2025-01-30 19:14:44.148632: train_loss -0.6188 
2025-01-30 19:14:44.155133: val_loss -0.5714 
2025-01-30 19:14:44.157890: Pseudo dice [np.float32(0.8973), np.float32(0.6626)] 
2025-01-30 19:14:44.160494: Epoch time: 48.21 s 
2025-01-30 19:14:44.163477: Yayy! New best EMA pseudo Dice: 0.48660001158714294 
2025-01-30 19:14:45.868992:  
2025-01-30 19:14:45.872153: Epoch 13 
2025-01-30 19:14:45.875127: Current learning rate: 0.00988 
2025-01-30 19:15:33.962443: train_loss -0.5827 
2025-01-30 19:15:33.966082: val_loss -0.5029 
2025-01-30 19:15:33.968581: Pseudo dice [np.float32(0.8595), np.float32(0.6102)] 
2025-01-30 19:15:33.971138: Epoch time: 48.09 s 
2025-01-30 19:15:33.973501: Yayy! New best EMA pseudo Dice: 0.5115000009536743 
2025-01-30 19:15:35.632901:  
2025-01-30 19:15:35.635203: Epoch 14 
2025-01-30 19:15:35.637520: Current learning rate: 0.00987 
2025-01-30 19:16:23.655758: train_loss -0.6216 
2025-01-30 19:16:23.661554: val_loss -0.5764 
2025-01-30 19:16:23.664471: Pseudo dice [np.float32(0.9053), np.float32(0.6981)] 
2025-01-30 19:16:23.667149: Epoch time: 48.02 s 
2025-01-30 19:16:23.669567: Yayy! New best EMA pseudo Dice: 0.5404999852180481 
2025-01-30 19:16:25.338550:  
2025-01-30 19:16:25.341219: Epoch 15 
2025-01-30 19:16:25.343668: Current learning rate: 0.00986 
2025-01-30 19:17:13.373632: train_loss -0.6356 
2025-01-30 19:17:13.377869: val_loss -0.5672 
2025-01-30 19:17:13.380326: Pseudo dice [np.float32(0.8997), np.float32(0.6395)] 
2025-01-30 19:17:13.382785: Epoch time: 48.04 s 
2025-01-30 19:17:13.385247: Yayy! New best EMA pseudo Dice: 0.5633999705314636 
2025-01-30 19:17:15.074992:  
2025-01-30 19:17:15.078049: Epoch 16 
2025-01-30 19:17:15.080666: Current learning rate: 0.00986 
2025-01-30 19:18:03.016077: train_loss -0.6464 
2025-01-30 19:18:03.021851: val_loss -0.5497 
2025-01-30 19:18:03.024600: Pseudo dice [np.float32(0.9101), np.float32(0.5552)] 
2025-01-30 19:18:03.027051: Epoch time: 47.94 s 
2025-01-30 19:18:03.029438: Yayy! New best EMA pseudo Dice: 0.580299973487854 
2025-01-30 19:18:04.771522:  
2025-01-30 19:18:04.774154: Epoch 17 
2025-01-30 19:18:04.776514: Current learning rate: 0.00985 
2025-01-30 19:18:52.709958: train_loss -0.6562 
2025-01-30 19:18:52.713591: val_loss -0.4539 
2025-01-30 19:18:52.716009: Pseudo dice [np.float32(0.8976), np.float32(0.4356)] 
2025-01-30 19:18:52.718242: Epoch time: 47.94 s 
2025-01-30 19:18:52.720578: Yayy! New best EMA pseudo Dice: 0.5889000296592712 
2025-01-30 19:18:54.460330:  
2025-01-30 19:18:54.463459: Epoch 18 
2025-01-30 19:18:54.466339: Current learning rate: 0.00984 
2025-01-30 19:19:42.857530: train_loss -0.6463 
2025-01-30 19:19:42.863980: val_loss -0.5626 
2025-01-30 19:19:42.867011: Pseudo dice [np.float32(0.9104), np.float32(0.6161)] 
2025-01-30 19:19:42.869684: Epoch time: 48.4 s 
2025-01-30 19:19:42.872345: Yayy! New best EMA pseudo Dice: 0.6064000129699707 
2025-01-30 19:19:45.128957:  
2025-01-30 19:19:45.131365: Epoch 19 
2025-01-30 19:19:45.133810: Current learning rate: 0.00983 
2025-01-30 19:20:33.035742: train_loss -0.6678 
2025-01-30 19:20:33.040097: val_loss -0.4978 
2025-01-30 19:20:33.042689: Pseudo dice [np.float32(0.8871), np.float32(0.4506)] 
2025-01-30 19:20:33.045398: Epoch time: 47.91 s 
2025-01-30 19:20:33.047941: Yayy! New best EMA pseudo Dice: 0.6126000285148621 
2025-01-30 19:20:34.778658:  
2025-01-30 19:20:34.781460: Epoch 20 
2025-01-30 19:20:34.784321: Current learning rate: 0.00982 
2025-01-30 19:21:23.052654: train_loss -0.6805 
2025-01-30 19:21:23.058098: val_loss -0.5033 
2025-01-30 19:21:23.060580: Pseudo dice [np.float32(0.8974), np.float32(0.4257)] 
2025-01-30 19:21:23.062838: Epoch time: 48.27 s 
2025-01-30 19:21:23.065071: Yayy! New best EMA pseudo Dice: 0.6175000071525574 
2025-01-30 19:21:24.802353:  
2025-01-30 19:21:24.804933: Epoch 21 
2025-01-30 19:21:24.807644: Current learning rate: 0.00981 
2025-01-30 19:22:12.970045: train_loss -0.6308 
2025-01-30 19:22:12.973674: val_loss -0.5547 
2025-01-30 19:22:12.975977: Pseudo dice [np.float32(0.9091), np.float32(0.5611)] 
2025-01-30 19:22:12.978484: Epoch time: 48.17 s 
2025-01-30 19:22:12.980856: Yayy! New best EMA pseudo Dice: 0.6292999982833862 
2025-01-30 19:22:14.636450:  
2025-01-30 19:22:14.638755: Epoch 22 
2025-01-30 19:22:14.641203: Current learning rate: 0.0098 
2025-01-30 19:23:02.932826: train_loss -0.6808 
2025-01-30 19:23:02.938776: val_loss -0.6091 
2025-01-30 19:23:02.941624: Pseudo dice [np.float32(0.9079), np.float32(0.757)] 
2025-01-30 19:23:02.944034: Epoch time: 48.3 s 
2025-01-30 19:23:02.946549: Yayy! New best EMA pseudo Dice: 0.6496000289916992 
2025-01-30 19:23:04.582960:  
2025-01-30 19:23:04.586090: Epoch 23 
2025-01-30 19:23:04.588916: Current learning rate: 0.00979 
2025-01-30 19:23:52.645818: train_loss -0.6684 
2025-01-30 19:23:52.649629: val_loss -0.6161 
2025-01-30 19:23:52.652143: Pseudo dice [np.float32(0.8949), np.float32(0.7325)] 
2025-01-30 19:23:52.654491: Epoch time: 48.06 s 
2025-01-30 19:23:52.656925: Yayy! New best EMA pseudo Dice: 0.6660000085830688 
2025-01-30 19:23:54.271493:  
2025-01-30 19:23:54.273920: Epoch 24 
2025-01-30 19:23:54.276465: Current learning rate: 0.00978 
2025-01-30 19:24:42.490555: train_loss -0.6815 
2025-01-30 19:24:42.495931: val_loss -0.6261 
2025-01-30 19:24:42.498255: Pseudo dice [np.float32(0.9144), np.float32(0.7123)] 
2025-01-30 19:24:42.500480: Epoch time: 48.22 s 
2025-01-30 19:24:42.502605: Yayy! New best EMA pseudo Dice: 0.6807000041007996 
2025-01-30 19:24:44.180998:  
2025-01-30 19:24:44.183609: Epoch 25 
2025-01-30 19:24:44.186098: Current learning rate: 0.00977 
2025-01-30 19:25:32.302501: train_loss -0.6679 
2025-01-30 19:25:32.307188: val_loss -0.5994 
2025-01-30 19:25:32.309972: Pseudo dice [np.float32(0.8986), np.float32(0.6564)] 
2025-01-30 19:25:32.312692: Epoch time: 48.12 s 
2025-01-30 19:25:32.315309: Yayy! New best EMA pseudo Dice: 0.6904000043869019 
2025-01-30 19:25:33.978470:  
2025-01-30 19:25:33.981506: Epoch 26 
2025-01-30 19:25:33.984292: Current learning rate: 0.00977 
2025-01-30 19:26:22.028053: train_loss -0.692 
2025-01-30 19:26:22.033854: val_loss -0.5129 
2025-01-30 19:26:22.036462: Pseudo dice [np.float32(0.9093), np.float32(0.4512)] 
2025-01-30 19:26:22.038974: Epoch time: 48.05 s 
2025-01-30 19:26:23.130014:  
2025-01-30 19:26:23.132599: Epoch 27 
2025-01-30 19:26:23.134878: Current learning rate: 0.00976 
2025-01-30 19:27:11.018306: train_loss -0.6931 
2025-01-30 19:27:11.022154: val_loss -0.6255 
2025-01-30 19:27:11.024628: Pseudo dice [np.float32(0.916), np.float32(0.769)] 
2025-01-30 19:27:11.026759: Epoch time: 47.89 s 
2025-01-30 19:27:11.029006: Yayy! New best EMA pseudo Dice: 0.7046999931335449 
2025-01-30 19:27:12.675829:  
2025-01-30 19:27:12.678107: Epoch 28 
2025-01-30 19:27:12.680680: Current learning rate: 0.00975 
2025-01-30 19:28:00.841235: train_loss -0.6951 
2025-01-30 19:28:00.847641: val_loss -0.5362 
2025-01-30 19:28:00.850247: Pseudo dice [np.float32(0.9018), np.float32(0.5256)] 
2025-01-30 19:28:00.852928: Epoch time: 48.17 s 
2025-01-30 19:28:00.855279: Yayy! New best EMA pseudo Dice: 0.7056000232696533 
2025-01-30 19:28:02.557164:  
2025-01-30 19:28:02.560347: Epoch 29 
2025-01-30 19:28:02.563232: Current learning rate: 0.00974 
2025-01-30 19:28:50.791385: train_loss -0.706 
2025-01-30 19:28:50.795286: val_loss -0.5277 
2025-01-30 19:28:50.797673: Pseudo dice [np.float32(0.9153), np.float32(0.5592)] 
2025-01-30 19:28:50.800277: Epoch time: 48.24 s 
2025-01-30 19:28:50.802838: Yayy! New best EMA pseudo Dice: 0.7088000178337097 
2025-01-30 19:28:52.510085:  
2025-01-30 19:28:52.513039: Epoch 30 
2025-01-30 19:28:52.515909: Current learning rate: 0.00973 
2025-01-30 19:29:40.560204: train_loss -0.6956 
2025-01-30 19:29:40.566231: val_loss -0.5357 
2025-01-30 19:29:40.569160: Pseudo dice [np.float32(0.9173), np.float32(0.457)] 
2025-01-30 19:29:40.571546: Epoch time: 48.05 s 
2025-01-30 19:29:41.679244:  
2025-01-30 19:29:41.681796: Epoch 31 
2025-01-30 19:29:41.684437: Current learning rate: 0.00972 
2025-01-30 19:30:29.958175: train_loss -0.6827 
2025-01-30 19:30:29.962146: val_loss -0.5329 
2025-01-30 19:30:29.964501: Pseudo dice [np.float32(0.9136), np.float32(0.4215)] 
2025-01-30 19:30:29.966993: Epoch time: 48.28 s 
2025-01-30 19:30:31.088813:  
2025-01-30 19:30:31.091541: Epoch 32 
2025-01-30 19:30:31.093987: Current learning rate: 0.00971 
2025-01-30 19:31:19.349072: train_loss -0.6903 
2025-01-30 19:31:19.354381: val_loss -0.5717 
2025-01-30 19:31:19.356755: Pseudo dice [np.float32(0.9166), np.float32(0.6671)] 
2025-01-30 19:31:19.358865: Epoch time: 48.26 s 
2025-01-30 19:31:19.361099: Yayy! New best EMA pseudo Dice: 0.7116000056266785 
2025-01-30 19:31:21.067069:  
2025-01-30 19:31:21.069679: Epoch 33 
2025-01-30 19:31:21.072403: Current learning rate: 0.0097 
2025-01-30 19:32:09.198030: train_loss -0.7198 
2025-01-30 19:32:09.201337: val_loss -0.6654 
2025-01-30 19:32:09.203750: Pseudo dice [np.float32(0.9112), np.float32(0.7634)] 
2025-01-30 19:32:09.205871: Epoch time: 48.13 s 
2025-01-30 19:32:09.208146: Yayy! New best EMA pseudo Dice: 0.7242000102996826 
2025-01-30 19:32:10.901364:  
2025-01-30 19:32:10.904035: Epoch 34 
2025-01-30 19:32:10.906590: Current learning rate: 0.00969 
2025-01-30 19:32:59.335903: train_loss -0.7042 
2025-01-30 19:32:59.340951: val_loss -0.5244 
2025-01-30 19:32:59.343290: Pseudo dice [np.float32(0.9287), np.float32(0.3912)] 
2025-01-30 19:32:59.345589: Epoch time: 48.44 s 
2025-01-30 19:33:00.481695:  
2025-01-30 19:33:00.484795: Epoch 35 
2025-01-30 19:33:00.487791: Current learning rate: 0.00968 
2025-01-30 19:33:48.472619: train_loss -0.6896 
2025-01-30 19:33:48.476639: val_loss -0.6346 
2025-01-30 19:33:48.479552: Pseudo dice [np.float32(0.9107), np.float32(0.7693)] 
2025-01-30 19:33:48.481826: Epoch time: 47.99 s 
2025-01-30 19:33:48.484433: Yayy! New best EMA pseudo Dice: 0.7300000190734863 
2025-01-30 19:33:50.221840:  
2025-01-30 19:33:50.226291: Epoch 36 
2025-01-30 19:33:50.229011: Current learning rate: 0.00968 
2025-01-30 19:34:38.464717: train_loss -0.7281 
2025-01-30 19:34:38.471109: val_loss -0.6006 
2025-01-30 19:34:38.473998: Pseudo dice [np.float32(0.908), np.float32(0.769)] 
2025-01-30 19:34:38.476700: Epoch time: 48.24 s 
2025-01-30 19:34:38.479164: Yayy! New best EMA pseudo Dice: 0.7408000230789185 
2025-01-30 19:34:40.710773:  
2025-01-30 19:34:40.714134: Epoch 37 
2025-01-30 19:34:40.717133: Current learning rate: 0.00967 
2025-01-30 19:35:28.552522: train_loss -0.7187 
2025-01-30 19:35:28.557081: val_loss -0.5842 
2025-01-30 19:35:28.559867: Pseudo dice [np.float32(0.9219), np.float32(0.5205)] 
2025-01-30 19:35:28.562773: Epoch time: 47.84 s 
2025-01-30 19:35:29.706319:  
2025-01-30 19:35:29.709207: Epoch 38 
2025-01-30 19:35:29.711937: Current learning rate: 0.00966 
2025-01-30 19:36:18.344831: train_loss -0.7284 
2025-01-30 19:36:18.350517: val_loss -0.666 
2025-01-30 19:36:18.352776: Pseudo dice [np.float32(0.9328), np.float32(0.8498)] 
2025-01-30 19:36:18.355162: Epoch time: 48.64 s 
2025-01-30 19:36:18.357425: Yayy! New best EMA pseudo Dice: 0.7541000247001648 
2025-01-30 19:36:20.039923:  
2025-01-30 19:36:20.042272: Epoch 39 
2025-01-30 19:36:20.044595: Current learning rate: 0.00965 
2025-01-30 19:37:08.320509: train_loss -0.7174 
2025-01-30 19:37:08.324804: val_loss -0.6331 
2025-01-30 19:37:08.327513: Pseudo dice [np.float32(0.9195), np.float32(0.7366)] 
2025-01-30 19:37:08.329996: Epoch time: 48.28 s 
2025-01-30 19:37:08.332640: Yayy! New best EMA pseudo Dice: 0.7615000009536743 
2025-01-30 19:37:10.058294:  
2025-01-30 19:37:10.061219: Epoch 40 
2025-01-30 19:37:10.064213: Current learning rate: 0.00964 
2025-01-30 19:37:58.428379: train_loss -0.7181 
2025-01-30 19:37:58.434096: val_loss -0.5377 
2025-01-30 19:37:58.436515: Pseudo dice [np.float32(0.9321), np.float32(0.476)] 
2025-01-30 19:37:58.438995: Epoch time: 48.37 s 
2025-01-30 19:37:59.637460:  
2025-01-30 19:37:59.640355: Epoch 41 
2025-01-30 19:37:59.642993: Current learning rate: 0.00963 
2025-01-30 19:38:48.017134: train_loss -0.7557 
2025-01-30 19:38:48.021224: val_loss -0.602 
2025-01-30 19:38:48.023853: Pseudo dice [np.float32(0.9199), np.float32(0.6373)] 
2025-01-30 19:38:48.026307: Epoch time: 48.38 s 
2025-01-30 19:38:49.118518:  
2025-01-30 19:38:49.121344: Epoch 42 
2025-01-30 19:38:49.124164: Current learning rate: 0.00962 
2025-01-30 19:39:37.702879: train_loss -0.7261 
2025-01-30 19:39:37.708432: val_loss -0.622 
2025-01-30 19:39:37.711043: Pseudo dice [np.float32(0.9283), np.float32(0.5855)] 
2025-01-30 19:39:37.713276: Epoch time: 48.59 s 
2025-01-30 19:39:38.832819:  
2025-01-30 19:39:38.836084: Epoch 43 
2025-01-30 19:39:38.838726: Current learning rate: 0.00961 
2025-01-30 19:40:27.012434: train_loss -0.7306 
2025-01-30 19:40:27.016977: val_loss -0.6477 
2025-01-30 19:40:27.019681: Pseudo dice [np.float32(0.9329), np.float32(0.7783)] 
2025-01-30 19:40:27.022202: Epoch time: 48.18 s 
2025-01-30 19:40:27.024731: Yayy! New best EMA pseudo Dice: 0.7677000164985657 
2025-01-30 19:40:28.640143:  
2025-01-30 19:40:28.643192: Epoch 44 
2025-01-30 19:40:28.646395: Current learning rate: 0.0096 
2025-01-30 19:41:16.668998: train_loss -0.7422 
2025-01-30 19:41:16.674989: val_loss -0.5955 
2025-01-30 19:41:16.677585: Pseudo dice [np.float32(0.9251), np.float32(0.6473)] 
2025-01-30 19:41:16.680194: Epoch time: 48.03 s 
2025-01-30 19:41:16.682994: Yayy! New best EMA pseudo Dice: 0.7695000171661377 
2025-01-30 19:41:18.366862:  
2025-01-30 19:41:18.369510: Epoch 45 
2025-01-30 19:41:18.372621: Current learning rate: 0.00959 
2025-01-30 19:42:06.483253: train_loss -0.7413 
2025-01-30 19:42:06.487014: val_loss -0.5652 
2025-01-30 19:42:06.489668: Pseudo dice [np.float32(0.9178), np.float32(0.5527)] 
2025-01-30 19:42:06.492052: Epoch time: 48.12 s 
2025-01-30 19:42:07.610065:  
2025-01-30 19:42:07.612400: Epoch 46 
2025-01-30 19:42:07.614781: Current learning rate: 0.00959 
2025-01-30 19:42:55.940495: train_loss -0.727 
2025-01-30 19:42:55.945915: val_loss -0.5926 
2025-01-30 19:42:55.948323: Pseudo dice [np.float32(0.9207), np.float32(0.6666)] 
2025-01-30 19:42:55.950676: Epoch time: 48.33 s 
2025-01-30 19:42:57.020361:  
2025-01-30 19:42:57.023268: Epoch 47 
2025-01-30 19:42:57.028421: Current learning rate: 0.00958 
2025-01-30 19:43:45.571191: train_loss -0.7189 
2025-01-30 19:43:45.574887: val_loss -0.6106 
2025-01-30 19:43:45.577342: Pseudo dice [np.float32(0.9317), np.float32(0.676)] 
2025-01-30 19:43:45.579618: Epoch time: 48.55 s 
2025-01-30 19:43:45.581905: Yayy! New best EMA pseudo Dice: 0.7724000215530396 
2025-01-30 19:43:47.227081:  
2025-01-30 19:43:47.229953: Epoch 48 
2025-01-30 19:43:47.232530: Current learning rate: 0.00957 
2025-01-30 19:44:35.159717: train_loss -0.7354 
2025-01-30 19:44:35.165545: val_loss -0.63 
2025-01-30 19:44:35.168139: Pseudo dice [np.float32(0.913), np.float32(0.7139)] 
2025-01-30 19:44:35.170604: Epoch time: 47.93 s 
2025-01-30 19:44:35.173149: Yayy! New best EMA pseudo Dice: 0.7764999866485596 
2025-01-30 19:44:36.819904:  
2025-01-30 19:44:36.822347: Epoch 49 
2025-01-30 19:44:36.824960: Current learning rate: 0.00956 
2025-01-30 19:45:24.902481: train_loss -0.74 
2025-01-30 19:45:24.907037: val_loss -0.6244 
2025-01-30 19:45:24.909270: Pseudo dice [np.float32(0.9127), np.float32(0.7972)] 
2025-01-30 19:45:24.911489: Epoch time: 48.08 s 
2025-01-30 19:45:25.430576: Yayy! New best EMA pseudo Dice: 0.7843000292778015 
2025-01-30 19:45:27.087604:  
2025-01-30 19:45:27.090200: Epoch 50 
2025-01-30 19:45:27.092767: Current learning rate: 0.00955 
2025-01-30 19:46:15.174737: train_loss -0.7315 
2025-01-30 19:46:15.180568: val_loss -0.5978 
2025-01-30 19:46:15.183038: Pseudo dice [np.float32(0.9224), np.float32(0.6898)] 
2025-01-30 19:46:15.185469: Epoch time: 48.09 s 
2025-01-30 19:46:15.187794: Yayy! New best EMA pseudo Dice: 0.7864999771118164 
2025-01-30 19:46:16.897846:  
2025-01-30 19:46:16.900560: Epoch 51 
2025-01-30 19:46:16.902943: Current learning rate: 0.00954 
2025-01-30 19:47:04.653545: train_loss -0.7305 
2025-01-30 19:47:04.657367: val_loss -0.6339 
2025-01-30 19:47:04.660243: Pseudo dice [np.float32(0.929), np.float32(0.7766)] 
2025-01-30 19:47:04.662906: Epoch time: 47.76 s 
2025-01-30 19:47:04.665562: Yayy! New best EMA pseudo Dice: 0.7930999994277954 
2025-01-30 19:47:06.360896:  
2025-01-30 19:47:06.363947: Epoch 52 
2025-01-30 19:47:06.366665: Current learning rate: 0.00953 
2025-01-30 19:47:54.444416: train_loss -0.7407 
2025-01-30 19:47:54.450829: val_loss -0.6294 
2025-01-30 19:47:54.453498: Pseudo dice [np.float32(0.9247), np.float32(0.7088)] 
2025-01-30 19:47:54.456055: Epoch time: 48.08 s 
2025-01-30 19:47:54.458557: Yayy! New best EMA pseudo Dice: 0.7954999804496765 
2025-01-30 19:47:56.125521:  
2025-01-30 19:47:56.128160: Epoch 53 
2025-01-30 19:47:56.130826: Current learning rate: 0.00952 
2025-01-30 19:48:44.141794: train_loss -0.7295 
2025-01-30 19:48:44.145764: val_loss -0.6052 
2025-01-30 19:48:44.148261: Pseudo dice [np.float32(0.9302), np.float32(0.4601)] 
2025-01-30 19:48:44.150736: Epoch time: 48.02 s 
2025-01-30 19:48:45.274762:  
2025-01-30 19:48:45.277084: Epoch 54 
2025-01-30 19:48:45.279622: Current learning rate: 0.00951 
2025-01-30 19:49:33.157410: train_loss -0.7367 
2025-01-30 19:49:33.163251: val_loss -0.6021 
2025-01-30 19:49:33.165803: Pseudo dice [np.float32(0.9269), np.float32(0.6143)] 
2025-01-30 19:49:33.168351: Epoch time: 47.88 s 
2025-01-30 19:49:34.779006:  
2025-01-30 19:49:34.781805: Epoch 55 
2025-01-30 19:49:34.784384: Current learning rate: 0.0095 
2025-01-30 19:50:22.620138: train_loss -0.7456 
2025-01-30 19:50:22.624132: val_loss -0.6045 
2025-01-30 19:50:22.626656: Pseudo dice [np.float32(0.9172), np.float32(0.6354)] 
2025-01-30 19:50:22.629212: Epoch time: 47.84 s 
2025-01-30 19:50:23.761179:  
2025-01-30 19:50:23.764037: Epoch 56 
2025-01-30 19:50:23.766845: Current learning rate: 0.00949 
2025-01-30 19:51:12.007371: train_loss -0.7396 
2025-01-30 19:51:12.013357: val_loss -0.6184 
2025-01-30 19:51:12.015666: Pseudo dice [np.float32(0.9109), np.float32(0.7633)] 
2025-01-30 19:51:12.018154: Epoch time: 48.25 s 
2025-01-30 19:51:13.106275:  
2025-01-30 19:51:13.108866: Epoch 57 
2025-01-30 19:51:13.111180: Current learning rate: 0.00949 
2025-01-30 19:52:01.255982: train_loss -0.7326 
2025-01-30 19:52:01.260380: val_loss -0.6266 
2025-01-30 19:52:01.263209: Pseudo dice [np.float32(0.9176), np.float32(0.6666)] 
2025-01-30 19:52:01.265757: Epoch time: 48.15 s 
2025-01-30 19:52:02.397606:  
2025-01-30 19:52:02.400454: Epoch 58 
2025-01-30 19:52:02.403189: Current learning rate: 0.00948 
2025-01-30 19:52:50.652659: train_loss -0.7308 
2025-01-30 19:52:50.657931: val_loss -0.6713 
2025-01-30 19:52:50.660382: Pseudo dice [np.float32(0.9234), np.float32(0.7322)] 
2025-01-30 19:52:50.662688: Epoch time: 48.26 s 
2025-01-30 19:52:51.759253:  
2025-01-30 19:52:51.764150: Epoch 59 
2025-01-30 19:52:51.766661: Current learning rate: 0.00947 
2025-01-30 19:53:39.542541: train_loss -0.7546 
2025-01-30 19:53:39.546041: val_loss -0.6206 
2025-01-30 19:53:39.548323: Pseudo dice [np.float32(0.9293), np.float32(0.6823)] 
2025-01-30 19:53:39.550401: Epoch time: 47.78 s 
2025-01-30 19:53:40.693116:  
2025-01-30 19:53:40.695507: Epoch 60 
2025-01-30 19:53:40.697821: Current learning rate: 0.00946 
2025-01-30 19:54:28.865906: train_loss -0.7506 
2025-01-30 19:54:28.872293: val_loss -0.6892 
2025-01-30 19:54:28.875329: Pseudo dice [np.float32(0.9283), np.float32(0.7789)] 
2025-01-30 19:54:28.878028: Epoch time: 48.17 s 
2025-01-30 19:54:28.880760: Yayy! New best EMA pseudo Dice: 0.8001000285148621 
2025-01-30 19:54:30.562482:  
2025-01-30 19:54:30.565654: Epoch 61 
2025-01-30 19:54:30.568786: Current learning rate: 0.00945 
2025-01-30 19:55:18.748766: train_loss -0.7542 
2025-01-30 19:55:18.753189: val_loss -0.6734 
2025-01-30 19:55:18.755977: Pseudo dice [np.float32(0.9212), np.float32(0.7552)] 
2025-01-30 19:55:18.758512: Epoch time: 48.19 s 
2025-01-30 19:55:18.761089: Yayy! New best EMA pseudo Dice: 0.8039000034332275 
2025-01-30 19:55:20.443383:  
2025-01-30 19:55:20.446292: Epoch 62 
2025-01-30 19:55:20.448877: Current learning rate: 0.00944 
2025-01-30 19:56:08.346925: train_loss -0.7692 
2025-01-30 19:56:08.352156: val_loss -0.6669 
2025-01-30 19:56:08.354415: Pseudo dice [np.float32(0.9292), np.float32(0.696)] 
2025-01-30 19:56:08.356650: Epoch time: 47.9 s 
2025-01-30 19:56:08.358755: Yayy! New best EMA pseudo Dice: 0.8047999739646912 
2025-01-30 19:56:10.040847:  
2025-01-30 19:56:10.043182: Epoch 63 
2025-01-30 19:56:10.045640: Current learning rate: 0.00943 
2025-01-30 19:56:58.375178: train_loss -0.7524 
2025-01-30 19:56:58.378728: val_loss -0.6382 
2025-01-30 19:56:58.380932: Pseudo dice [np.float32(0.9319), np.float32(0.7246)] 
2025-01-30 19:56:58.383070: Epoch time: 48.34 s 
2025-01-30 19:56:58.385176: Yayy! New best EMA pseudo Dice: 0.8070999979972839 
2025-01-30 19:57:00.056931:  
2025-01-30 19:57:00.059443: Epoch 64 
2025-01-30 19:57:00.061742: Current learning rate: 0.00942 
2025-01-30 19:57:48.173362: train_loss -0.7804 
2025-01-30 19:57:48.178972: val_loss -0.6489 
2025-01-30 19:57:48.181376: Pseudo dice [np.float32(0.9183), np.float32(0.6546)] 
2025-01-30 19:57:48.183900: Epoch time: 48.12 s 
2025-01-30 19:57:49.335637:  
2025-01-30 19:57:49.338665: Epoch 65 
2025-01-30 19:57:49.341617: Current learning rate: 0.00941 
2025-01-30 19:58:37.326830: train_loss -0.7714 
2025-01-30 19:58:37.331362: val_loss -0.6268 
2025-01-30 19:58:37.334253: Pseudo dice [np.float32(0.923), np.float32(0.5711)] 
2025-01-30 19:58:37.337029: Epoch time: 47.99 s 
2025-01-30 19:58:38.458924:  
2025-01-30 19:58:38.462013: Epoch 66 
2025-01-30 19:58:38.464660: Current learning rate: 0.0094 
2025-01-30 19:59:26.342569: train_loss -0.752 
2025-01-30 19:59:26.348102: val_loss -0.6041 
2025-01-30 19:59:26.350581: Pseudo dice [np.float32(0.9269), np.float32(0.5882)] 
2025-01-30 19:59:26.353181: Epoch time: 47.88 s 
2025-01-30 19:59:27.471363:  
2025-01-30 19:59:27.474050: Epoch 67 
2025-01-30 19:59:27.476537: Current learning rate: 0.00939 
2025-01-30 20:00:15.663651: train_loss -0.7526 
2025-01-30 20:00:15.667070: val_loss -0.6459 
2025-01-30 20:00:15.669367: Pseudo dice [np.float32(0.9117), np.float32(0.764)] 
2025-01-30 20:00:15.671582: Epoch time: 48.19 s 
2025-01-30 20:00:16.805230:  
2025-01-30 20:00:16.807758: Epoch 68 
2025-01-30 20:00:16.810193: Current learning rate: 0.00939 
2025-01-30 20:01:04.857557: train_loss -0.7604 
2025-01-30 20:01:04.863922: val_loss -0.6144 
2025-01-30 20:01:04.866458: Pseudo dice [np.float32(0.917), np.float32(0.5669)] 
2025-01-30 20:01:04.868994: Epoch time: 48.05 s 
2025-01-30 20:01:05.998923:  
2025-01-30 20:01:06.001559: Epoch 69 
2025-01-30 20:01:06.004080: Current learning rate: 0.00938 
2025-01-30 20:01:54.228239: train_loss -0.7661 
2025-01-30 20:01:54.231824: val_loss -0.7152 
2025-01-30 20:01:54.234323: Pseudo dice [np.float32(0.9333), np.float32(0.8389)] 
2025-01-30 20:01:54.236653: Epoch time: 48.23 s 
2025-01-30 20:01:55.370897:  
2025-01-30 20:01:55.374132: Epoch 70 
2025-01-30 20:01:55.377199: Current learning rate: 0.00937 
2025-01-30 20:02:43.638180: train_loss -0.7679 
2025-01-30 20:02:43.643762: val_loss -0.5841 
2025-01-30 20:02:43.646447: Pseudo dice [np.float32(0.9138), np.float32(0.5201)] 
2025-01-30 20:02:43.648981: Epoch time: 48.27 s 
2025-01-30 20:02:44.780787:  
2025-01-30 20:02:44.783522: Epoch 71 
2025-01-30 20:02:44.786175: Current learning rate: 0.00936 
2025-01-30 20:03:32.864366: train_loss -0.775 
2025-01-30 20:03:32.868098: val_loss -0.6856 
2025-01-30 20:03:32.870513: Pseudo dice [np.float32(0.9262), np.float32(0.758)] 
2025-01-30 20:03:32.872824: Epoch time: 48.08 s 
2025-01-30 20:03:33.996621:  
2025-01-30 20:03:33.998996: Epoch 72 
2025-01-30 20:03:34.001180: Current learning rate: 0.00935 
2025-01-30 20:04:22.252483: train_loss -0.7763 
2025-01-30 20:04:22.258353: val_loss -0.7023 
2025-01-30 20:04:22.262198: Pseudo dice [np.float32(0.9403), np.float32(0.7252)] 
2025-01-30 20:04:22.264743: Epoch time: 48.26 s 
2025-01-30 20:04:23.399444:  
2025-01-30 20:04:23.402075: Epoch 73 
2025-01-30 20:04:23.404956: Current learning rate: 0.00934 
2025-01-30 20:05:11.269457: train_loss -0.7898 
2025-01-30 20:05:11.273404: val_loss -0.6723 
2025-01-30 20:05:11.276016: Pseudo dice [np.float32(0.917), np.float32(0.6231)] 
2025-01-30 20:05:11.278397: Epoch time: 47.87 s 
2025-01-30 20:05:12.954143:  
2025-01-30 20:05:12.956840: Epoch 74 
2025-01-30 20:05:12.959517: Current learning rate: 0.00933 
2025-01-30 20:06:01.079308: train_loss -0.767 
2025-01-30 20:06:01.084461: val_loss -0.5812 
2025-01-30 20:06:01.086809: Pseudo dice [np.float32(0.9234), np.float32(0.5105)] 
2025-01-30 20:06:01.089150: Epoch time: 48.13 s 
2025-01-30 20:06:02.219950:  
2025-01-30 20:06:02.222392: Epoch 75 
2025-01-30 20:06:02.224773: Current learning rate: 0.00932 
2025-01-30 20:06:50.236121: train_loss -0.771 
2025-01-30 20:06:50.239758: val_loss -0.63 
2025-01-30 20:06:50.242186: Pseudo dice [np.float32(0.9222), np.float32(0.5714)] 
2025-01-30 20:06:50.244562: Epoch time: 48.02 s 
2025-01-30 20:06:51.381738:  
2025-01-30 20:06:51.384608: Epoch 76 
2025-01-30 20:06:51.387632: Current learning rate: 0.00931 
2025-01-30 20:07:39.480500: train_loss -0.7626 
2025-01-30 20:07:39.488857: val_loss -0.5868 
2025-01-30 20:07:39.491631: Pseudo dice [np.float32(0.9368), np.float32(0.5394)] 
2025-01-30 20:07:39.494195: Epoch time: 48.1 s 
2025-01-30 20:07:40.627485:  
2025-01-30 20:07:40.630062: Epoch 77 
2025-01-30 20:07:40.632465: Current learning rate: 0.0093 
2025-01-30 20:08:28.885775: train_loss -0.7864 
2025-01-30 20:08:28.889447: val_loss -0.6201 
2025-01-30 20:08:28.891991: Pseudo dice [np.float32(0.9147), np.float32(0.6832)] 
2025-01-30 20:08:28.894317: Epoch time: 48.26 s 
2025-01-30 20:08:30.038730:  
2025-01-30 20:08:30.041504: Epoch 78 
2025-01-30 20:08:30.044179: Current learning rate: 0.0093 
2025-01-30 20:09:18.522358: train_loss -0.7864 
2025-01-30 20:09:18.527853: val_loss -0.6405 
2025-01-30 20:09:18.530286: Pseudo dice [np.float32(0.9231), np.float32(0.668)] 
2025-01-30 20:09:18.532503: Epoch time: 48.48 s 
2025-01-30 20:09:19.675174:  
2025-01-30 20:09:19.677667: Epoch 79 
2025-01-30 20:09:19.680005: Current learning rate: 0.00929 
2025-01-30 20:10:07.632245: train_loss -0.7745 
2025-01-30 20:10:07.636351: val_loss -0.656 
2025-01-30 20:10:07.638998: Pseudo dice [np.float32(0.9247), np.float32(0.7246)] 
2025-01-30 20:10:07.641569: Epoch time: 47.96 s 
2025-01-30 20:10:08.791722:  
2025-01-30 20:10:08.794746: Epoch 80 
2025-01-30 20:10:08.797384: Current learning rate: 0.00928 
2025-01-30 20:10:57.234016: train_loss -0.7605 
2025-01-30 20:10:57.240242: val_loss -0.7129 
2025-01-30 20:10:57.242833: Pseudo dice [np.float32(0.9365), np.float32(0.7784)] 
2025-01-30 20:10:57.245368: Epoch time: 48.44 s 
2025-01-30 20:10:58.442649:  
2025-01-30 20:10:58.445893: Epoch 81 
2025-01-30 20:10:58.448800: Current learning rate: 0.00927 
2025-01-30 20:11:46.697397: train_loss -0.7827 
2025-01-30 20:11:46.701524: val_loss -0.6076 
2025-01-30 20:11:46.704312: Pseudo dice [np.float32(0.902), np.float32(0.7293)] 
2025-01-30 20:11:46.707028: Epoch time: 48.26 s 
2025-01-30 20:11:47.855115:  
2025-01-30 20:11:47.857919: Epoch 82 
2025-01-30 20:11:47.860636: Current learning rate: 0.00926 
2025-01-30 20:12:35.997958: train_loss -0.7764 
2025-01-30 20:12:36.003732: val_loss -0.5279 
2025-01-30 20:12:36.006238: Pseudo dice [np.float32(0.914), np.float32(0.6047)] 
2025-01-30 20:12:36.008924: Epoch time: 48.14 s 
2025-01-30 20:12:37.090267:  
2025-01-30 20:12:37.093232: Epoch 83 
2025-01-30 20:12:37.096098: Current learning rate: 0.00925 
2025-01-30 20:13:25.347895: train_loss -0.7418 
2025-01-30 20:13:25.351995: val_loss -0.571 
2025-01-30 20:13:25.354757: Pseudo dice [np.float32(0.9231), np.float32(0.6065)] 
2025-01-30 20:13:25.357036: Epoch time: 48.26 s 
2025-01-30 20:13:26.443205:  
2025-01-30 20:13:26.445951: Epoch 84 
2025-01-30 20:13:26.448337: Current learning rate: 0.00924 
2025-01-30 20:14:14.457633: train_loss -0.7716 
2025-01-30 20:14:14.463362: val_loss -0.643 
2025-01-30 20:14:14.466161: Pseudo dice [np.float32(0.9259), np.float32(0.7409)] 
2025-01-30 20:14:14.468616: Epoch time: 48.02 s 
2025-01-30 20:14:15.595168:  
2025-01-30 20:14:15.598512: Epoch 85 
2025-01-30 20:14:15.601178: Current learning rate: 0.00923 
2025-01-30 20:15:03.406856: train_loss -0.7446 
2025-01-30 20:15:03.410885: val_loss -0.6683 
2025-01-30 20:15:03.413677: Pseudo dice [np.float32(0.9054), np.float32(0.634)] 
2025-01-30 20:15:03.416171: Epoch time: 47.81 s 
2025-01-30 20:15:04.507077:  
2025-01-30 20:15:04.509753: Epoch 86 
2025-01-30 20:15:04.512359: Current learning rate: 0.00922 
2025-01-30 20:15:52.742281: train_loss -0.7471 
2025-01-30 20:15:52.749823: val_loss -0.6401 
2025-01-30 20:15:52.753011: Pseudo dice [np.float32(0.931), np.float32(0.6994)] 
2025-01-30 20:15:52.756166: Epoch time: 48.24 s 
2025-01-30 20:15:53.848407:  
2025-01-30 20:15:53.851409: Epoch 87 
2025-01-30 20:15:53.854056: Current learning rate: 0.00921 
2025-01-30 20:16:42.222455: train_loss -0.7632 
2025-01-30 20:16:42.226536: val_loss -0.6493 
2025-01-30 20:16:42.229473: Pseudo dice [np.float32(0.9284), np.float32(0.6588)] 
2025-01-30 20:16:42.231900: Epoch time: 48.37 s 
2025-01-30 20:16:43.358867:  
2025-01-30 20:16:43.361764: Epoch 88 
2025-01-30 20:16:43.364508: Current learning rate: 0.0092 
2025-01-30 20:17:31.444694: train_loss -0.7773 
2025-01-30 20:17:31.450704: val_loss -0.7112 
2025-01-30 20:17:31.453400: Pseudo dice [np.float32(0.9355), np.float32(0.8158)] 
2025-01-30 20:17:31.456064: Epoch time: 48.09 s 
2025-01-30 20:17:32.540774:  
2025-01-30 20:17:32.543640: Epoch 89 
2025-01-30 20:17:32.546398: Current learning rate: 0.0092 
2025-01-30 20:18:20.694367: train_loss -0.7463 
2025-01-30 20:18:20.698444: val_loss -0.6167 
2025-01-30 20:18:20.701000: Pseudo dice [np.float32(0.9243), np.float32(0.7028)] 
2025-01-30 20:18:20.703402: Epoch time: 48.15 s 
2025-01-30 20:18:21.828878:  
2025-01-30 20:18:21.831681: Epoch 90 
2025-01-30 20:18:21.834497: Current learning rate: 0.00919 
2025-01-30 20:19:10.189636: train_loss -0.7529 
2025-01-30 20:19:10.196855: val_loss -0.6447 
2025-01-30 20:19:10.199744: Pseudo dice [np.float32(0.9312), np.float32(0.6072)] 
2025-01-30 20:19:10.202502: Epoch time: 48.36 s 
2025-01-30 20:19:11.331828:  
2025-01-30 20:19:11.334755: Epoch 91 
2025-01-30 20:19:11.337461: Current learning rate: 0.00918 
2025-01-30 20:19:59.319927: train_loss -0.7784 
2025-01-30 20:19:59.323713: val_loss -0.5905 
2025-01-30 20:19:59.325973: Pseudo dice [np.float32(0.9284), np.float32(0.5857)] 
2025-01-30 20:19:59.328262: Epoch time: 47.99 s 
2025-01-30 20:20:00.402631:  
2025-01-30 20:20:00.405212: Epoch 92 
2025-01-30 20:20:00.407629: Current learning rate: 0.00917 
2025-01-30 20:20:48.330534: train_loss -0.7755 
2025-01-30 20:20:48.336653: val_loss -0.6586 
2025-01-30 20:20:48.339348: Pseudo dice [np.float32(0.9319), np.float32(0.7053)] 
2025-01-30 20:20:48.341920: Epoch time: 47.93 s 
2025-01-30 20:20:49.953873:  
2025-01-30 20:20:49.956614: Epoch 93 
2025-01-30 20:20:49.959045: Current learning rate: 0.00916 
2025-01-30 20:21:37.737840: train_loss -0.7603 
2025-01-30 20:21:37.741659: val_loss -0.7584 
2025-01-30 20:21:37.744041: Pseudo dice [np.float32(0.9382), np.float32(0.8606)] 
2025-01-30 20:21:37.746412: Epoch time: 47.78 s 
2025-01-30 20:21:37.748294: Yayy! New best EMA pseudo Dice: 0.8083999752998352 
2025-01-30 20:21:39.358867:  
2025-01-30 20:21:39.361460: Epoch 94 
2025-01-30 20:21:39.363930: Current learning rate: 0.00915 
2025-01-30 20:22:27.699550: train_loss -0.7843 
2025-01-30 20:22:27.706239: val_loss -0.6594 
2025-01-30 20:22:27.709001: Pseudo dice [np.float32(0.9183), np.float32(0.7184)] 
2025-01-30 20:22:27.711511: Epoch time: 48.34 s 
2025-01-30 20:22:27.714037: Yayy! New best EMA pseudo Dice: 0.8094000220298767 
2025-01-30 20:22:29.319443:  
2025-01-30 20:22:29.322150: Epoch 95 
2025-01-30 20:22:29.325154: Current learning rate: 0.00914 
2025-01-30 20:23:17.181603: train_loss -0.7608 
2025-01-30 20:23:17.186376: val_loss -0.5997 
2025-01-30 20:23:17.188907: Pseudo dice [np.float32(0.9183), np.float32(0.771)] 
2025-01-30 20:23:17.191391: Epoch time: 47.86 s 
2025-01-30 20:23:17.193919: Yayy! New best EMA pseudo Dice: 0.8129000067710876 
2025-01-30 20:23:18.797486:  
2025-01-30 20:23:18.800067: Epoch 96 
2025-01-30 20:23:18.802389: Current learning rate: 0.00913 
2025-01-30 20:24:06.793563: train_loss -0.7524 
2025-01-30 20:24:06.798986: val_loss -0.6125 
2025-01-30 20:24:06.801613: Pseudo dice [np.float32(0.9309), np.float32(0.5627)] 
2025-01-30 20:24:06.804255: Epoch time: 48.0 s 
2025-01-30 20:24:07.937631:  
2025-01-30 20:24:07.940498: Epoch 97 
2025-01-30 20:24:07.943379: Current learning rate: 0.00912 
2025-01-30 20:24:56.122280: train_loss -0.7404 
2025-01-30 20:24:56.126316: val_loss -0.6193 
2025-01-30 20:24:56.129253: Pseudo dice [np.float32(0.9368), np.float32(0.5091)] 
2025-01-30 20:24:56.131954: Epoch time: 48.19 s 
2025-01-30 20:24:57.267987:  
2025-01-30 20:24:57.271009: Epoch 98 
2025-01-30 20:24:57.274016: Current learning rate: 0.00911 
2025-01-30 20:25:45.272362: train_loss -0.7628 
2025-01-30 20:25:45.277723: val_loss -0.64 
2025-01-30 20:25:45.280224: Pseudo dice [np.float32(0.9415), np.float32(0.6936)] 
2025-01-30 20:25:45.282383: Epoch time: 48.01 s 
2025-01-30 20:25:46.378315:  
2025-01-30 20:25:46.380859: Epoch 99 
2025-01-30 20:25:46.383307: Current learning rate: 0.0091 
2025-01-30 20:26:34.214589: train_loss -0.7772 
2025-01-30 20:26:34.218581: val_loss -0.6614 
2025-01-30 20:26:34.221184: Pseudo dice [np.float32(0.9359), np.float32(0.7567)] 
2025-01-30 20:26:34.223627: Epoch time: 47.84 s 
2025-01-30 20:26:35.922098:  
2025-01-30 20:26:35.926150: Epoch 100 
2025-01-30 20:26:35.928728: Current learning rate: 0.0091 
2025-01-30 20:27:24.027892: train_loss -0.7748 
2025-01-30 20:27:24.033070: val_loss -0.673 
2025-01-30 20:27:24.035568: Pseudo dice [np.float32(0.9465), np.float32(0.699)] 
2025-01-30 20:27:24.037830: Epoch time: 48.11 s 
2025-01-30 20:27:25.133970:  
2025-01-30 20:27:25.136308: Epoch 101 
2025-01-30 20:27:25.138475: Current learning rate: 0.00909 
2025-01-30 20:28:13.064761: train_loss -0.7917 
2025-01-30 20:28:13.069183: val_loss -0.752 
2025-01-30 20:28:13.072117: Pseudo dice [np.float32(0.9386), np.float32(0.8714)] 
2025-01-30 20:28:13.075011: Epoch time: 47.93 s 
2025-01-30 20:28:13.077580: Yayy! New best EMA pseudo Dice: 0.8162999749183655 
2025-01-30 20:28:14.704984:  
2025-01-30 20:28:14.708034: Epoch 102 
2025-01-30 20:28:14.711053: Current learning rate: 0.00908 
2025-01-30 20:29:02.830375: train_loss -0.7835 
2025-01-30 20:29:02.836317: val_loss -0.669 
2025-01-30 20:29:02.838944: Pseudo dice [np.float32(0.9363), np.float32(0.7256)] 
2025-01-30 20:29:02.841680: Epoch time: 48.13 s 
2025-01-30 20:29:02.844005: Yayy! New best EMA pseudo Dice: 0.8177000284194946 
2025-01-30 20:29:04.503051:  
2025-01-30 20:29:04.506016: Epoch 103 
2025-01-30 20:29:04.509498: Current learning rate: 0.00907 
2025-01-30 20:29:52.501720: train_loss -0.7773 
2025-01-30 20:29:52.505974: val_loss -0.6542 
2025-01-30 20:29:52.508621: Pseudo dice [np.float32(0.9423), np.float32(0.6965)] 
2025-01-30 20:29:52.511307: Epoch time: 48.0 s 
2025-01-30 20:29:52.513990: Yayy! New best EMA pseudo Dice: 0.8179000020027161 
2025-01-30 20:29:54.173380:  
2025-01-30 20:29:54.175600: Epoch 104 
2025-01-30 20:29:54.177942: Current learning rate: 0.00906 
2025-01-30 20:30:42.216043: train_loss -0.7943 
2025-01-30 20:30:42.221484: val_loss -0.6713 
2025-01-30 20:30:42.224000: Pseudo dice [np.float32(0.9272), np.float32(0.7359)] 
2025-01-30 20:30:42.226437: Epoch time: 48.04 s 
2025-01-30 20:30:42.228702: Yayy! New best EMA pseudo Dice: 0.8192999958992004 
2025-01-30 20:30:43.903164:  
2025-01-30 20:30:43.906193: Epoch 105 
2025-01-30 20:30:43.908856: Current learning rate: 0.00905 
2025-01-30 20:31:32.142296: train_loss -0.7932 
2025-01-30 20:31:32.146520: val_loss -0.6775 
2025-01-30 20:31:32.149357: Pseudo dice [np.float32(0.9442), np.float32(0.7513)] 
2025-01-30 20:31:32.152482: Epoch time: 48.24 s 
2025-01-30 20:31:32.155068: Yayy! New best EMA pseudo Dice: 0.8220999836921692 
2025-01-30 20:31:33.850373:  
2025-01-30 20:31:33.853027: Epoch 106 
2025-01-30 20:31:33.855717: Current learning rate: 0.00904 
2025-01-30 20:32:22.309888: train_loss -0.8066 
2025-01-30 20:32:22.315717: val_loss -0.7115 
2025-01-30 20:32:22.318353: Pseudo dice [np.float32(0.9264), np.float32(0.8109)] 
2025-01-30 20:32:22.321058: Epoch time: 48.46 s 
2025-01-30 20:32:22.323449: Yayy! New best EMA pseudo Dice: 0.8267999887466431 
2025-01-30 20:32:24.006709:  
2025-01-30 20:32:24.009921: Epoch 107 
2025-01-30 20:32:24.012790: Current learning rate: 0.00903 
2025-01-30 20:33:12.036760: train_loss -0.8023 
2025-01-30 20:33:12.040485: val_loss -0.656 
2025-01-30 20:33:12.042988: Pseudo dice [np.float32(0.9305), np.float32(0.8306)] 
2025-01-30 20:33:12.045427: Epoch time: 48.03 s 
2025-01-30 20:33:12.047784: Yayy! New best EMA pseudo Dice: 0.832099974155426 
2025-01-30 20:33:13.676841:  
2025-01-30 20:33:13.680180: Epoch 108 
2025-01-30 20:33:13.683342: Current learning rate: 0.00902 
2025-01-30 20:34:02.058395: train_loss -0.7806 
2025-01-30 20:34:02.065684: val_loss -0.6506 
2025-01-30 20:34:02.069000: Pseudo dice [np.float32(0.91), np.float32(0.768)] 
2025-01-30 20:34:02.071985: Epoch time: 48.38 s 
2025-01-30 20:34:02.074630: Yayy! New best EMA pseudo Dice: 0.8327999711036682 
2025-01-30 20:34:03.711026:  
2025-01-30 20:34:03.713609: Epoch 109 
2025-01-30 20:34:03.716478: Current learning rate: 0.00901 
2025-01-30 20:34:52.129056: train_loss -0.7551 
2025-01-30 20:34:52.133396: val_loss -0.5847 
2025-01-30 20:34:52.136460: Pseudo dice [np.float32(0.9143), np.float32(0.5497)] 
2025-01-30 20:34:52.139222: Epoch time: 48.42 s 
2025-01-30 20:34:53.254686:  
2025-01-30 20:34:53.257514: Epoch 110 
2025-01-30 20:34:53.260466: Current learning rate: 0.009 
2025-01-30 20:35:41.584294: train_loss -0.7659 
2025-01-30 20:35:41.590042: val_loss -0.5942 
2025-01-30 20:35:41.592610: Pseudo dice [np.float32(0.9117), np.float32(0.5303)] 
2025-01-30 20:35:41.595036: Epoch time: 48.33 s 
2025-01-30 20:35:42.712824:  
2025-01-30 20:35:42.715255: Epoch 111 
2025-01-30 20:35:42.717901: Current learning rate: 0.009 
2025-01-30 20:36:31.080132: train_loss -0.7432 
2025-01-30 20:36:31.083980: val_loss -0.6976 
2025-01-30 20:36:31.086706: Pseudo dice [np.float32(0.9336), np.float32(0.7666)] 
2025-01-30 20:36:31.089176: Epoch time: 48.37 s 
2025-01-30 20:36:32.718872:  
2025-01-30 20:36:32.721155: Epoch 112 
2025-01-30 20:36:32.723576: Current learning rate: 0.00899 
2025-01-30 20:37:20.957995: train_loss -0.776 
2025-01-30 20:37:20.963925: val_loss -0.6635 
2025-01-30 20:37:20.966656: Pseudo dice [np.float32(0.9318), np.float32(0.6563)] 
2025-01-30 20:37:20.969210: Epoch time: 48.24 s 
2025-01-30 20:37:22.100245:  
2025-01-30 20:37:22.103358: Epoch 113 
2025-01-30 20:37:22.106146: Current learning rate: 0.00898 
2025-01-30 20:38:10.482219: train_loss -0.7852 
2025-01-30 20:38:10.485772: val_loss -0.6669 
2025-01-30 20:38:10.488111: Pseudo dice [np.float32(0.949), np.float32(0.7634)] 
2025-01-30 20:38:10.490152: Epoch time: 48.38 s 
2025-01-30 20:38:11.588110:  
2025-01-30 20:38:11.591632: Epoch 114 
2025-01-30 20:38:11.594301: Current learning rate: 0.00897 
2025-01-30 20:39:00.081137: train_loss -0.7695 
2025-01-30 20:39:00.086470: val_loss -0.6626 
2025-01-30 20:39:00.089148: Pseudo dice [np.float32(0.9326), np.float32(0.7086)] 
2025-01-30 20:39:00.091579: Epoch time: 48.49 s 
2025-01-30 20:39:01.189889:  
2025-01-30 20:39:01.192513: Epoch 115 
2025-01-30 20:39:01.195188: Current learning rate: 0.00896 
2025-01-30 20:39:49.349714: train_loss -0.7789 
2025-01-30 20:39:49.355708: val_loss -0.6511 
2025-01-30 20:39:49.358307: Pseudo dice [np.float32(0.9345), np.float32(0.6859)] 
2025-01-30 20:39:49.361071: Epoch time: 48.16 s 
2025-01-30 20:39:50.502686:  
2025-01-30 20:39:50.505210: Epoch 116 
2025-01-30 20:39:50.507998: Current learning rate: 0.00895 
2025-01-30 20:40:38.736937: train_loss -0.7826 
2025-01-30 20:40:38.742237: val_loss -0.672 
2025-01-30 20:40:38.744735: Pseudo dice [np.float32(0.9334), np.float32(0.8009)] 
2025-01-30 20:40:38.746968: Epoch time: 48.24 s 
2025-01-30 20:40:39.891627:  
2025-01-30 20:40:39.893908: Epoch 117 
2025-01-30 20:40:39.896173: Current learning rate: 0.00894 
2025-01-30 20:41:28.047232: train_loss -0.7648 
2025-01-30 20:41:28.051539: val_loss -0.6925 
2025-01-30 20:41:28.054226: Pseudo dice [np.float32(0.9324), np.float32(0.8211)] 
2025-01-30 20:41:28.056945: Epoch time: 48.16 s 
2025-01-30 20:41:29.167621:  
2025-01-30 20:41:29.170372: Epoch 118 
2025-01-30 20:41:29.172748: Current learning rate: 0.00893 
2025-01-30 20:42:17.705355: train_loss -0.7662 
2025-01-30 20:42:17.711081: val_loss -0.637 
2025-01-30 20:42:17.713701: Pseudo dice [np.float32(0.9379), np.float32(0.6948)] 
2025-01-30 20:42:17.716201: Epoch time: 48.54 s 
2025-01-30 20:42:18.825234:  
2025-01-30 20:42:18.827935: Epoch 119 
2025-01-30 20:42:18.830595: Current learning rate: 0.00892 
2025-01-30 20:43:07.580616: train_loss -0.7603 
2025-01-30 20:43:07.584004: val_loss -0.5838 
2025-01-30 20:43:07.586400: Pseudo dice [np.float32(0.9407), np.float32(0.4519)] 
2025-01-30 20:43:07.588712: Epoch time: 48.76 s 
2025-01-30 20:43:08.695046:  
2025-01-30 20:43:08.697639: Epoch 120 
2025-01-30 20:43:08.700189: Current learning rate: 0.00891 
2025-01-30 20:43:56.978593: train_loss -0.7901 
2025-01-30 20:43:56.986009: val_loss -0.6969 
2025-01-30 20:43:56.989020: Pseudo dice [np.float32(0.9393), np.float32(0.7511)] 
2025-01-30 20:43:56.991752: Epoch time: 48.28 s 
2025-01-30 20:43:58.097434:  
2025-01-30 20:43:58.100382: Epoch 121 
2025-01-30 20:43:58.103381: Current learning rate: 0.0089 
2025-01-30 20:44:46.377188: train_loss -0.7771 
2025-01-30 20:44:46.382365: val_loss -0.7015 
2025-01-30 20:44:46.385265: Pseudo dice [np.float32(0.9337), np.float32(0.8673)] 
2025-01-30 20:44:46.388155: Epoch time: 48.28 s 
2025-01-30 20:44:47.539464:  
2025-01-30 20:44:47.542316: Epoch 122 
2025-01-30 20:44:47.545201: Current learning rate: 0.00889 
2025-01-30 20:45:35.769802: train_loss -0.7673 
2025-01-30 20:45:35.776869: val_loss -0.6424 
2025-01-30 20:45:35.779662: Pseudo dice [np.float32(0.9415), np.float32(0.7426)] 
2025-01-30 20:45:35.782725: Epoch time: 48.23 s 
2025-01-30 20:45:36.897871:  
2025-01-30 20:45:36.900717: Epoch 123 
2025-01-30 20:45:36.903332: Current learning rate: 0.00889 
2025-01-30 20:46:25.234112: train_loss -0.7847 
2025-01-30 20:46:25.238374: val_loss -0.6022 
2025-01-30 20:46:25.240869: Pseudo dice [np.float32(0.9311), np.float32(0.489)] 
2025-01-30 20:46:25.243582: Epoch time: 48.34 s 
2025-01-30 20:46:26.389283:  
2025-01-30 20:46:26.391971: Epoch 124 
2025-01-30 20:46:26.394596: Current learning rate: 0.00888 
2025-01-30 20:47:14.841141: train_loss -0.7772 
2025-01-30 20:47:14.846818: val_loss -0.683 
2025-01-30 20:47:14.849474: Pseudo dice [np.float32(0.9337), np.float32(0.7982)] 
2025-01-30 20:47:14.852068: Epoch time: 48.45 s 
2025-01-30 20:47:15.969286:  
2025-01-30 20:47:15.971762: Epoch 125 
2025-01-30 20:47:15.974148: Current learning rate: 0.00887 
2025-01-30 20:48:03.948230: train_loss -0.7939 
2025-01-30 20:48:03.953453: val_loss -0.7004 
2025-01-30 20:48:03.955813: Pseudo dice [np.float32(0.9416), np.float32(0.8262)] 
2025-01-30 20:48:03.957976: Epoch time: 47.98 s 
2025-01-30 20:48:05.099867:  
2025-01-30 20:48:05.102387: Epoch 126 
2025-01-30 20:48:05.104697: Current learning rate: 0.00886 
2025-01-30 20:48:53.439314: train_loss -0.7941 
2025-01-30 20:48:53.445503: val_loss -0.7383 
2025-01-30 20:48:53.448181: Pseudo dice [np.float32(0.9447), np.float32(0.7849)] 
2025-01-30 20:48:53.450888: Epoch time: 48.34 s 
2025-01-30 20:48:54.556852:  
2025-01-30 20:48:54.561871: Epoch 127 
2025-01-30 20:48:54.564731: Current learning rate: 0.00885 
2025-01-30 20:49:42.847966: train_loss -0.7853 
2025-01-30 20:49:42.852204: val_loss -0.6856 
2025-01-30 20:49:42.854582: Pseudo dice [np.float32(0.9394), np.float32(0.7278)] 
2025-01-30 20:49:42.857104: Epoch time: 48.29 s 
2025-01-30 20:49:43.972731:  
2025-01-30 20:49:43.975564: Epoch 128 
2025-01-30 20:49:43.978389: Current learning rate: 0.00884 
2025-01-30 20:50:31.993147: train_loss -0.7841 
2025-01-30 20:50:31.999212: val_loss -0.6019 
2025-01-30 20:50:32.001693: Pseudo dice [np.float32(0.9414), np.float32(0.3416)] 
2025-01-30 20:50:32.004311: Epoch time: 48.02 s 
2025-01-30 20:50:33.143413:  
2025-01-30 20:50:33.146601: Epoch 129 
2025-01-30 20:50:33.149619: Current learning rate: 0.00883 
2025-01-30 20:51:21.493044: train_loss -0.7857 
2025-01-30 20:51:21.499274: val_loss -0.6888 
2025-01-30 20:51:21.501712: Pseudo dice [np.float32(0.944), np.float32(0.58)] 
2025-01-30 20:51:21.504361: Epoch time: 48.35 s 
2025-01-30 20:51:22.624437:  
2025-01-30 20:51:22.627673: Epoch 130 
2025-01-30 20:51:22.630678: Current learning rate: 0.00882 
2025-01-30 20:52:10.643375: train_loss -0.7879 
2025-01-30 20:52:10.649410: val_loss -0.6359 
2025-01-30 20:52:10.652086: Pseudo dice [np.float32(0.9249), np.float32(0.8208)] 
2025-01-30 20:52:10.654428: Epoch time: 48.02 s 
2025-01-30 20:52:12.295885:  
2025-01-30 20:52:12.299783: Epoch 131 
2025-01-30 20:52:12.302221: Current learning rate: 0.00881 
2025-01-30 20:53:00.323662: train_loss -0.7818 
2025-01-30 20:53:00.327900: val_loss -0.6443 
2025-01-30 20:53:00.330667: Pseudo dice [np.float32(0.9273), np.float32(0.7484)] 
2025-01-30 20:53:00.333360: Epoch time: 48.03 s 
2025-01-30 20:53:01.441324:  
2025-01-30 20:53:01.444729: Epoch 132 
2025-01-30 20:53:01.447672: Current learning rate: 0.0088 
2025-01-30 20:53:49.596610: train_loss -0.78 
2025-01-30 20:53:49.603409: val_loss -0.6507 
2025-01-30 20:53:49.606175: Pseudo dice [np.float32(0.9262), np.float32(0.7219)] 
2025-01-30 20:53:49.608897: Epoch time: 48.16 s 
2025-01-30 20:53:50.722735:  
2025-01-30 20:53:50.725626: Epoch 133 
2025-01-30 20:53:50.728450: Current learning rate: 0.00879 
2025-01-30 20:54:39.254556: train_loss -0.7716 
2025-01-30 20:54:39.261085: val_loss -0.7008 
2025-01-30 20:54:39.263922: Pseudo dice [np.float32(0.9418), np.float32(0.6875)] 
2025-01-30 20:54:39.266729: Epoch time: 48.53 s 
2025-01-30 20:54:40.382703:  
2025-01-30 20:54:40.386164: Epoch 134 
2025-01-30 20:54:40.389270: Current learning rate: 0.00879 
2025-01-30 20:55:28.321194: train_loss -0.7879 
2025-01-30 20:55:28.327935: val_loss -0.7076 
2025-01-30 20:55:28.330757: Pseudo dice [np.float32(0.9313), np.float32(0.8071)] 
2025-01-30 20:55:28.333698: Epoch time: 47.94 s 
2025-01-30 20:55:29.461019:  
2025-01-30 20:55:29.463743: Epoch 135 
2025-01-30 20:55:29.466223: Current learning rate: 0.00878 
2025-01-30 20:56:17.417789: train_loss -0.7922 
2025-01-30 20:56:17.422501: val_loss -0.7 
2025-01-30 20:56:17.425301: Pseudo dice [np.float32(0.9431), np.float32(0.8202)] 
2025-01-30 20:56:17.428043: Epoch time: 47.96 s 
2025-01-30 20:56:18.554561:  
2025-01-30 20:56:18.557541: Epoch 136 
2025-01-30 20:56:18.560521: Current learning rate: 0.00877 
2025-01-30 20:57:06.582138: train_loss -0.7952 
2025-01-30 20:57:06.587721: val_loss -0.6683 
2025-01-30 20:57:06.590130: Pseudo dice [np.float32(0.9244), np.float32(0.8289)] 
2025-01-30 20:57:06.592396: Epoch time: 48.03 s 
2025-01-30 20:57:07.718685:  
2025-01-30 20:57:07.721466: Epoch 137 
2025-01-30 20:57:07.724299: Current learning rate: 0.00876 
2025-01-30 20:57:55.830832: train_loss -0.8024 
2025-01-30 20:57:55.834814: val_loss -0.7635 
2025-01-30 20:57:55.837324: Pseudo dice [np.float32(0.942), np.float32(0.823)] 
2025-01-30 20:57:55.839751: Epoch time: 48.11 s 
2025-01-30 20:57:55.842090: Yayy! New best EMA pseudo Dice: 0.8377000093460083 
2025-01-30 20:57:57.571172:  
2025-01-30 20:57:57.573802: Epoch 138 
2025-01-30 20:57:57.576604: Current learning rate: 0.00875 
2025-01-30 20:58:45.413026: train_loss -0.7874 
2025-01-30 20:58:45.418564: val_loss -0.6773 
2025-01-30 20:58:45.420793: Pseudo dice [np.float32(0.9403), np.float32(0.6343)] 
2025-01-30 20:58:45.423270: Epoch time: 47.84 s 
2025-01-30 20:58:46.553377:  
2025-01-30 20:58:46.555848: Epoch 139 
2025-01-30 20:58:46.558078: Current learning rate: 0.00874 
2025-01-30 20:59:34.359753: train_loss -0.8144 
2025-01-30 20:59:34.363357: val_loss -0.7119 
2025-01-30 20:59:34.365826: Pseudo dice [np.float32(0.9461), np.float32(0.7815)] 
2025-01-30 20:59:34.368192: Epoch time: 47.81 s 
2025-01-30 20:59:35.535177:  
2025-01-30 20:59:35.537765: Epoch 140 
2025-01-30 20:59:35.540423: Current learning rate: 0.00873 
2025-01-30 21:00:23.745190: train_loss -0.8011 
2025-01-30 21:00:23.750662: val_loss -0.6746 
2025-01-30 21:00:23.753086: Pseudo dice [np.float32(0.9293), np.float32(0.8772)] 
2025-01-30 21:00:23.755584: Epoch time: 48.21 s 
2025-01-30 21:00:23.757859: Yayy! New best EMA pseudo Dice: 0.8424999713897705 
2025-01-30 21:00:25.469734:  
2025-01-30 21:00:25.472242: Epoch 141 
2025-01-30 21:00:25.474660: Current learning rate: 0.00872 
2025-01-30 21:01:13.947868: train_loss -0.8065 
2025-01-30 21:01:13.951611: val_loss -0.7392 
2025-01-30 21:01:13.954231: Pseudo dice [np.float32(0.9504), np.float32(0.866)] 
2025-01-30 21:01:13.956737: Epoch time: 48.48 s 
2025-01-30 21:01:13.959123: Yayy! New best EMA pseudo Dice: 0.8490999937057495 
2025-01-30 21:01:15.664719:  
2025-01-30 21:01:15.667878: Epoch 142 
2025-01-30 21:01:15.670449: Current learning rate: 0.00871 
2025-01-30 21:02:03.568965: train_loss -0.787 
2025-01-30 21:02:03.575584: val_loss -0.7299 
2025-01-30 21:02:03.578428: Pseudo dice [np.float32(0.9395), np.float32(0.8638)] 
2025-01-30 21:02:03.581103: Epoch time: 47.91 s 
2025-01-30 21:02:03.583704: Yayy! New best EMA pseudo Dice: 0.8543000221252441 
2025-01-30 21:02:05.315701:  
2025-01-30 21:02:05.318623: Epoch 143 
2025-01-30 21:02:05.321287: Current learning rate: 0.0087 
2025-01-30 21:02:53.208948: train_loss -0.8022 
2025-01-30 21:02:53.214453: val_loss -0.6606 
2025-01-30 21:02:53.216948: Pseudo dice [np.float32(0.9409), np.float32(0.7695)] 
2025-01-30 21:02:53.219624: Epoch time: 47.89 s 
2025-01-30 21:02:53.221992: Yayy! New best EMA pseudo Dice: 0.8543999791145325 
2025-01-30 21:02:54.972756:  
2025-01-30 21:02:54.976079: Epoch 144 
2025-01-30 21:02:54.978867: Current learning rate: 0.00869 
2025-01-30 21:03:42.927406: train_loss -0.7868 
2025-01-30 21:03:42.933470: val_loss -0.7145 
2025-01-30 21:03:42.936187: Pseudo dice [np.float32(0.9416), np.float32(0.7347)] 
2025-01-30 21:03:42.938811: Epoch time: 47.96 s 
2025-01-30 21:03:44.067156:  
2025-01-30 21:03:44.069831: Epoch 145 
2025-01-30 21:03:44.072630: Current learning rate: 0.00868 
2025-01-30 21:04:32.163580: train_loss -0.7887 
2025-01-30 21:04:32.168016: val_loss -0.7076 
2025-01-30 21:04:32.170948: Pseudo dice [np.float32(0.932), np.float32(0.8084)] 
2025-01-30 21:04:32.173460: Epoch time: 48.1 s 
2025-01-30 21:04:32.175913: Yayy! New best EMA pseudo Dice: 0.8544999957084656 
2025-01-30 21:04:33.908760:  
2025-01-30 21:04:33.912240: Epoch 146 
2025-01-30 21:04:33.915234: Current learning rate: 0.00868 
2025-01-30 21:05:21.848994: train_loss -0.7815 
2025-01-30 21:05:21.855288: val_loss -0.7129 
2025-01-30 21:05:21.857978: Pseudo dice [np.float32(0.945), np.float32(0.8015)] 
2025-01-30 21:05:21.860720: Epoch time: 47.94 s 
2025-01-30 21:05:21.863018: Yayy! New best EMA pseudo Dice: 0.8564000129699707 
2025-01-30 21:05:23.577366:  
2025-01-30 21:05:23.579607: Epoch 147 
2025-01-30 21:05:23.582024: Current learning rate: 0.00867 
2025-01-30 21:06:11.882293: train_loss -0.8003 
2025-01-30 21:06:11.885991: val_loss -0.6764 
2025-01-30 21:06:11.888352: Pseudo dice [np.float32(0.9345), np.float32(0.7029)] 
2025-01-30 21:06:11.890674: Epoch time: 48.31 s 
2025-01-30 21:06:13.054983:  
2025-01-30 21:06:13.057602: Epoch 148 
2025-01-30 21:06:13.060118: Current learning rate: 0.00866 
2025-01-30 21:07:01.390205: train_loss -0.8016 
2025-01-30 21:07:01.396710: val_loss -0.6975 
2025-01-30 21:07:01.399456: Pseudo dice [np.float32(0.9359), np.float32(0.8408)] 
2025-01-30 21:07:01.402163: Epoch time: 48.34 s 
2025-01-30 21:07:03.141680:  
2025-01-30 21:07:03.144643: Epoch 149 
2025-01-30 21:07:03.147516: Current learning rate: 0.00865 
2025-01-30 21:07:51.196141: train_loss -0.8066 
2025-01-30 21:07:51.199903: val_loss -0.6956 
2025-01-30 21:07:51.202205: Pseudo dice [np.float32(0.9436), np.float32(0.7503)] 
2025-01-30 21:07:51.204520: Epoch time: 48.06 s 
2025-01-30 21:07:52.918286:  
2025-01-30 21:07:52.920695: Epoch 150 
2025-01-30 21:07:52.923145: Current learning rate: 0.00864 
2025-01-30 21:08:40.985454: train_loss -0.766 
2025-01-30 21:08:40.991827: val_loss -0.6489 
2025-01-30 21:08:40.994543: Pseudo dice [np.float32(0.9061), np.float32(0.7564)] 
2025-01-30 21:08:40.997035: Epoch time: 48.07 s 
2025-01-30 21:08:42.168937:  
2025-01-30 21:08:42.171571: Epoch 151 
2025-01-30 21:08:42.174073: Current learning rate: 0.00863 
2025-01-30 21:09:30.341934: train_loss -0.7872 
2025-01-30 21:09:30.346456: val_loss -0.6136 
2025-01-30 21:09:30.349176: Pseudo dice [np.float32(0.9387), np.float32(0.6143)] 
2025-01-30 21:09:30.351542: Epoch time: 48.17 s 
2025-01-30 21:09:31.486915:  
2025-01-30 21:09:31.489374: Epoch 152 
2025-01-30 21:09:31.491990: Current learning rate: 0.00862 
2025-01-30 21:10:19.683782: train_loss -0.7777 
2025-01-30 21:10:19.688948: val_loss -0.7071 
2025-01-30 21:10:19.691289: Pseudo dice [np.float32(0.9424), np.float32(0.8084)] 
2025-01-30 21:10:19.693622: Epoch time: 48.2 s 
2025-01-30 21:10:20.828443:  
2025-01-30 21:10:20.830864: Epoch 153 
2025-01-30 21:10:20.833222: Current learning rate: 0.00861 
2025-01-30 21:11:09.069087: train_loss -0.7699 
2025-01-30 21:11:09.073784: val_loss -0.5667 
2025-01-30 21:11:09.076895: Pseudo dice [np.float32(0.9305), np.float32(0.4998)] 
2025-01-30 21:11:09.079574: Epoch time: 48.24 s 
2025-01-30 21:11:10.232280:  
2025-01-30 21:11:10.235300: Epoch 154 
2025-01-30 21:11:10.237938: Current learning rate: 0.0086 
2025-01-30 21:11:58.440991: train_loss -0.758 
2025-01-30 21:11:58.446589: val_loss -0.6138 
2025-01-30 21:11:58.449178: Pseudo dice [np.float32(0.9329), np.float32(0.5641)] 
2025-01-30 21:11:58.451928: Epoch time: 48.21 s 
2025-01-30 21:11:59.617987:  
2025-01-30 21:11:59.620479: Epoch 155 
2025-01-30 21:11:59.623176: Current learning rate: 0.00859 
2025-01-30 21:12:47.709463: train_loss -0.7778 
2025-01-30 21:12:47.714029: val_loss -0.6826 
2025-01-30 21:12:47.716964: Pseudo dice [np.float32(0.9308), np.float32(0.7629)] 
2025-01-30 21:12:47.719776: Epoch time: 48.09 s 
2025-01-30 21:12:48.869032:  
2025-01-30 21:12:48.871837: Epoch 156 
2025-01-30 21:12:48.874787: Current learning rate: 0.00858 
2025-01-30 21:13:36.588154: train_loss -0.7992 
2025-01-30 21:13:36.594187: val_loss -0.6344 
2025-01-30 21:13:36.596835: Pseudo dice [np.float32(0.9275), np.float32(0.6372)] 
2025-01-30 21:13:36.599233: Epoch time: 47.72 s 
2025-01-30 21:13:37.743740:  
2025-01-30 21:13:37.746670: Epoch 157 
2025-01-30 21:13:37.749437: Current learning rate: 0.00858 
2025-01-30 21:14:25.766562: train_loss -0.7782 
2025-01-30 21:14:25.771088: val_loss -0.6625 
2025-01-30 21:14:25.773937: Pseudo dice [np.float32(0.9287), np.float32(0.7689)] 
2025-01-30 21:14:25.776625: Epoch time: 48.02 s 
2025-01-30 21:14:26.921568:  
2025-01-30 21:14:26.924154: Epoch 158 
2025-01-30 21:14:26.926736: Current learning rate: 0.00857 
2025-01-30 21:15:15.385001: train_loss -0.7938 
2025-01-30 21:15:15.390629: val_loss -0.6914 
2025-01-30 21:15:15.392861: Pseudo dice [np.float32(0.9437), np.float32(0.6087)] 
2025-01-30 21:15:15.395010: Epoch time: 48.46 s 
2025-01-30 21:15:16.579811:  
2025-01-30 21:15:16.582445: Epoch 159 
2025-01-30 21:15:16.584753: Current learning rate: 0.00856 
2025-01-30 21:16:05.013602: train_loss -0.7968 
2025-01-30 21:16:05.017998: val_loss -0.6802 
2025-01-30 21:16:05.020571: Pseudo dice [np.float32(0.9306), np.float32(0.7912)] 
2025-01-30 21:16:05.023190: Epoch time: 48.43 s 
2025-01-30 21:16:06.166203:  
2025-01-30 21:16:06.169083: Epoch 160 
2025-01-30 21:16:06.171873: Current learning rate: 0.00855 
2025-01-30 21:16:54.548211: train_loss -0.7556 
2025-01-30 21:16:54.553357: val_loss -0.6055 
2025-01-30 21:16:54.555423: Pseudo dice [np.float32(0.9204), np.float32(0.7087)] 
2025-01-30 21:16:54.557583: Epoch time: 48.38 s 
2025-01-30 21:16:55.695918:  
2025-01-30 21:16:55.698425: Epoch 161 
2025-01-30 21:16:55.700651: Current learning rate: 0.00854 
2025-01-30 21:17:43.869197: train_loss -0.7673 
2025-01-30 21:17:43.873428: val_loss -0.6788 
2025-01-30 21:17:43.875714: Pseudo dice [np.float32(0.9376), np.float32(0.793)] 
2025-01-30 21:17:43.878122: Epoch time: 48.17 s 
2025-01-30 21:17:45.013976:  
2025-01-30 21:17:45.016473: Epoch 162 
2025-01-30 21:17:45.018971: Current learning rate: 0.00853 
2025-01-30 21:18:33.217963: train_loss -0.8029 
2025-01-30 21:18:33.224392: val_loss -0.6289 
2025-01-30 21:18:33.226991: Pseudo dice [np.float32(0.9429), np.float32(0.6552)] 
2025-01-30 21:18:33.253754: Epoch time: 48.2 s 
2025-01-30 21:18:34.391555:  
2025-01-30 21:18:34.394131: Epoch 163 
2025-01-30 21:18:34.396537: Current learning rate: 0.00852 
2025-01-30 21:19:22.336224: train_loss -0.8113 
2025-01-30 21:19:22.340240: val_loss -0.7373 
2025-01-30 21:19:22.343128: Pseudo dice [np.float32(0.9455), np.float32(0.8729)] 
2025-01-30 21:19:22.345795: Epoch time: 47.95 s 
2025-01-30 21:19:23.487051:  
2025-01-30 21:19:23.489846: Epoch 164 
2025-01-30 21:19:23.492502: Current learning rate: 0.00851 
2025-01-30 21:20:11.721472: train_loss -0.8012 
2025-01-30 21:20:11.727007: val_loss -0.6464 
2025-01-30 21:20:11.729342: Pseudo dice [np.float32(0.9434), np.float32(0.7609)] 
2025-01-30 21:20:11.731524: Epoch time: 48.24 s 
2025-01-30 21:20:12.847349:  
2025-01-30 21:20:12.850021: Epoch 165 
2025-01-30 21:20:12.852772: Current learning rate: 0.0085 
2025-01-30 21:21:00.887565: train_loss -0.8168 
2025-01-30 21:21:00.893348: val_loss -0.7117 
2025-01-30 21:21:00.895883: Pseudo dice [np.float32(0.9407), np.float32(0.7888)] 
2025-01-30 21:21:00.898475: Epoch time: 48.04 s 
2025-01-30 21:21:02.052951:  
2025-01-30 21:21:02.055834: Epoch 166 
2025-01-30 21:21:02.058337: Current learning rate: 0.00849 
2025-01-30 21:21:50.052789: train_loss -0.81 
2025-01-30 21:21:50.058536: val_loss -0.7202 
2025-01-30 21:21:50.060964: Pseudo dice [np.float32(0.9299), np.float32(0.8553)] 
2025-01-30 21:21:50.063444: Epoch time: 48.0 s 
2025-01-30 21:21:51.735337:  
2025-01-30 21:21:51.737848: Epoch 167 
2025-01-30 21:21:51.740163: Current learning rate: 0.00848 
2025-01-30 21:22:39.730176: train_loss -0.7975 
2025-01-30 21:22:39.733814: val_loss -0.6104 
2025-01-30 21:22:39.736502: Pseudo dice [np.float32(0.9388), np.float32(0.654)] 
2025-01-30 21:22:39.739253: Epoch time: 48.0 s 
2025-01-30 21:22:40.912684:  
2025-01-30 21:22:40.915308: Epoch 168 
2025-01-30 21:22:40.918008: Current learning rate: 0.00847 
2025-01-30 21:23:28.795532: train_loss -0.8016 
2025-01-30 21:23:28.801553: val_loss -0.71 
2025-01-30 21:23:28.804373: Pseudo dice [np.float32(0.934), np.float32(0.7737)] 
2025-01-30 21:23:28.806875: Epoch time: 47.88 s 
2025-01-30 21:23:29.939959:  
2025-01-30 21:23:29.942968: Epoch 169 
2025-01-30 21:23:29.945714: Current learning rate: 0.00847 
2025-01-30 21:24:17.846872: train_loss -0.7979 
2025-01-30 21:24:17.852984: val_loss -0.6756 
2025-01-30 21:24:17.856199: Pseudo dice [np.float32(0.9507), np.float32(0.6713)] 
2025-01-30 21:24:17.859088: Epoch time: 47.91 s 
2025-01-30 21:24:19.003511:  
2025-01-30 21:24:19.006703: Epoch 170 
2025-01-30 21:24:19.009474: Current learning rate: 0.00846 
2025-01-30 21:25:07.171815: train_loss -0.7903 
2025-01-30 21:25:07.178342: val_loss -0.693 
2025-01-30 21:25:07.181052: Pseudo dice [np.float32(0.9418), np.float32(0.7276)] 
2025-01-30 21:25:07.183521: Epoch time: 48.17 s 
2025-01-30 21:25:08.358877:  
2025-01-30 21:25:08.361808: Epoch 171 
2025-01-30 21:25:08.364211: Current learning rate: 0.00845 
2025-01-30 21:25:56.531081: train_loss -0.798 
2025-01-30 21:25:56.536761: val_loss -0.6293 
2025-01-30 21:25:56.539170: Pseudo dice [np.float32(0.9316), np.float32(0.7577)] 
2025-01-30 21:25:56.541624: Epoch time: 48.17 s 
2025-01-30 21:25:57.691955:  
2025-01-30 21:25:57.694592: Epoch 172 
2025-01-30 21:25:57.697165: Current learning rate: 0.00844 
2025-01-30 21:26:45.906680: train_loss -0.7814 
2025-01-30 21:26:45.913683: val_loss -0.6804 
2025-01-30 21:26:45.916383: Pseudo dice [np.float32(0.9313), np.float32(0.7132)] 
2025-01-30 21:26:45.918841: Epoch time: 48.22 s 
2025-01-30 21:26:47.095799:  
2025-01-30 21:26:47.098893: Epoch 173 
2025-01-30 21:26:47.101650: Current learning rate: 0.00843 
2025-01-30 21:27:35.042828: train_loss -0.7726 
2025-01-30 21:27:35.046740: val_loss -0.6947 
2025-01-30 21:27:35.048986: Pseudo dice [np.float32(0.9324), np.float32(0.6678)] 
2025-01-30 21:27:35.051682: Epoch time: 47.95 s 
2025-01-30 21:27:36.223502:  
2025-01-30 21:27:36.226350: Epoch 174 
2025-01-30 21:27:36.229300: Current learning rate: 0.00842 
2025-01-30 21:28:23.984141: train_loss -0.8148 
2025-01-30 21:28:23.989736: val_loss -0.6465 
2025-01-30 21:28:23.992171: Pseudo dice [np.float32(0.931), np.float32(0.7344)] 
2025-01-30 21:28:23.994600: Epoch time: 47.76 s 
2025-01-30 21:28:25.125826:  
2025-01-30 21:28:25.128799: Epoch 175 
2025-01-30 21:28:25.131974: Current learning rate: 0.00841 
2025-01-30 21:29:12.966189: train_loss -0.7652 
2025-01-30 21:29:12.970516: val_loss -0.7072 
2025-01-30 21:29:12.973309: Pseudo dice [np.float32(0.9286), np.float32(0.8431)] 
2025-01-30 21:29:12.976316: Epoch time: 47.84 s 
2025-01-30 21:29:14.110877:  
2025-01-30 21:29:14.113660: Epoch 176 
2025-01-30 21:29:14.116462: Current learning rate: 0.0084 
2025-01-30 21:30:01.956418: train_loss -0.7814 
2025-01-30 21:30:01.963580: val_loss -0.6844 
2025-01-30 21:30:01.966183: Pseudo dice [np.float32(0.9502), np.float32(0.6301)] 
2025-01-30 21:30:01.968897: Epoch time: 47.85 s 
2025-01-30 21:30:03.146639:  
2025-01-30 21:30:03.149783: Epoch 177 
2025-01-30 21:30:03.152465: Current learning rate: 0.00839 
2025-01-30 21:30:51.051853: train_loss -0.7816 
2025-01-30 21:30:51.057034: val_loss -0.6299 
2025-01-30 21:30:51.059579: Pseudo dice [np.float32(0.9379), np.float32(0.5612)] 
2025-01-30 21:30:51.061829: Epoch time: 47.91 s 
2025-01-30 21:30:52.239945:  
2025-01-30 21:30:52.242667: Epoch 178 
2025-01-30 21:30:52.245595: Current learning rate: 0.00838 
2025-01-30 21:31:40.333552: train_loss -0.7837 
2025-01-30 21:31:40.339137: val_loss -0.7201 
2025-01-30 21:31:40.341727: Pseudo dice [np.float32(0.9444), np.float32(0.7911)] 
2025-01-30 21:31:40.343995: Epoch time: 48.09 s 
2025-01-30 21:31:41.488427:  
2025-01-30 21:31:41.490762: Epoch 179 
2025-01-30 21:31:41.493323: Current learning rate: 0.00837 
2025-01-30 21:32:29.699411: train_loss -0.7888 
2025-01-30 21:32:29.706254: val_loss -0.7227 
2025-01-30 21:32:29.709096: Pseudo dice [np.float32(0.9454), np.float32(0.7796)] 
2025-01-30 21:32:29.711633: Epoch time: 48.21 s 
2025-01-30 21:32:30.894636:  
2025-01-30 21:32:30.897811: Epoch 180 
2025-01-30 21:32:30.900585: Current learning rate: 0.00836 
2025-01-30 21:33:18.649958: train_loss -0.7986 
2025-01-30 21:33:18.654877: val_loss -0.7147 
2025-01-30 21:33:18.657127: Pseudo dice [np.float32(0.9408), np.float32(0.7868)] 
2025-01-30 21:33:18.659305: Epoch time: 47.76 s 
2025-01-30 21:33:19.790052:  
2025-01-30 21:33:19.792683: Epoch 181 
2025-01-30 21:33:19.795323: Current learning rate: 0.00836 
2025-01-30 21:34:07.996913: train_loss -0.811 
2025-01-30 21:34:08.002183: val_loss -0.7142 
2025-01-30 21:34:08.004541: Pseudo dice [np.float32(0.9347), np.float32(0.8262)] 
2025-01-30 21:34:08.006690: Epoch time: 48.21 s 
2025-01-30 21:34:09.132837:  
2025-01-30 21:34:09.135090: Epoch 182 
2025-01-30 21:34:09.137326: Current learning rate: 0.00835 
2025-01-30 21:34:57.412976: train_loss -0.7936 
2025-01-30 21:34:57.419396: val_loss -0.7399 
2025-01-30 21:34:57.422119: Pseudo dice [np.float32(0.9553), np.float32(0.8153)] 
2025-01-30 21:34:57.424731: Epoch time: 48.28 s 
2025-01-30 21:34:58.597059:  
2025-01-30 21:34:58.599992: Epoch 183 
2025-01-30 21:34:58.602990: Current learning rate: 0.00834 
2025-01-30 21:35:46.657432: train_loss -0.8096 
2025-01-30 21:35:46.661717: val_loss -0.7214 
2025-01-30 21:35:46.664505: Pseudo dice [np.float32(0.9433), np.float32(0.8982)] 
2025-01-30 21:35:46.666838: Epoch time: 48.06 s 
2025-01-30 21:35:47.849446:  
2025-01-30 21:35:47.852568: Epoch 184 
2025-01-30 21:35:47.855252: Current learning rate: 0.00833 
2025-01-30 21:36:36.143255: train_loss -0.7981 
2025-01-30 21:36:36.149458: val_loss -0.6645 
2025-01-30 21:36:36.152100: Pseudo dice [np.float32(0.9508), np.float32(0.6881)] 
2025-01-30 21:36:36.154575: Epoch time: 48.3 s 
2025-01-30 21:36:37.289057:  
2025-01-30 21:36:37.292096: Epoch 185 
2025-01-30 21:36:37.294897: Current learning rate: 0.00832 
2025-01-30 21:37:25.134646: train_loss -0.8144 
2025-01-30 21:37:25.138352: val_loss -0.7428 
2025-01-30 21:37:25.141075: Pseudo dice [np.float32(0.9456), np.float32(0.8309)] 
2025-01-30 21:37:25.143647: Epoch time: 47.85 s 
2025-01-30 21:37:26.809473:  
2025-01-30 21:37:26.811948: Epoch 186 
2025-01-30 21:37:26.814182: Current learning rate: 0.00831 
2025-01-30 21:38:14.800217: train_loss -0.7977 
2025-01-30 21:38:14.806403: val_loss -0.7089 
2025-01-30 21:38:14.809017: Pseudo dice [np.float32(0.9468), np.float32(0.8053)] 
2025-01-30 21:38:14.811708: Epoch time: 47.99 s 
2025-01-30 21:38:15.949143:  
2025-01-30 21:38:15.952225: Epoch 187 
2025-01-30 21:38:15.954910: Current learning rate: 0.0083 
2025-01-30 21:39:04.093589: train_loss -0.7949 
2025-01-30 21:39:04.097384: val_loss -0.6493 
2025-01-30 21:39:04.099938: Pseudo dice [np.float32(0.9398), np.float32(0.7234)] 
2025-01-30 21:39:04.102188: Epoch time: 48.15 s 
2025-01-30 21:39:05.246267:  
2025-01-30 21:39:05.249816: Epoch 188 
2025-01-30 21:39:05.252928: Current learning rate: 0.00829 
2025-01-30 21:39:53.417540: train_loss -0.799 
2025-01-30 21:39:53.423817: val_loss -0.702 
2025-01-30 21:39:53.426273: Pseudo dice [np.float32(0.9503), np.float32(0.7841)] 
2025-01-30 21:39:53.428806: Epoch time: 48.17 s 
2025-01-30 21:39:54.601713:  
2025-01-30 21:39:54.604463: Epoch 189 
2025-01-30 21:39:54.606923: Current learning rate: 0.00828 
2025-01-30 21:40:42.606824: train_loss -0.7824 
2025-01-30 21:40:42.612628: val_loss -0.6813 
2025-01-30 21:40:42.615280: Pseudo dice [np.float32(0.9366), np.float32(0.7312)] 
2025-01-30 21:40:42.617850: Epoch time: 48.01 s 
2025-01-30 21:40:43.753182:  
2025-01-30 21:40:43.756546: Epoch 190 
2025-01-30 21:40:43.759259: Current learning rate: 0.00827 
2025-01-30 21:41:31.818361: train_loss -0.7735 
2025-01-30 21:41:31.825136: val_loss -0.7347 
2025-01-30 21:41:31.827886: Pseudo dice [np.float32(0.9295), np.float32(0.8381)] 
2025-01-30 21:41:31.830587: Epoch time: 48.07 s 
2025-01-30 21:41:32.966141:  
2025-01-30 21:41:32.968924: Epoch 191 
2025-01-30 21:41:32.971845: Current learning rate: 0.00826 
2025-01-30 21:42:21.005929: train_loss -0.7919 
2025-01-30 21:42:21.009989: val_loss -0.7149 
2025-01-30 21:42:21.012497: Pseudo dice [np.float32(0.9423), np.float32(0.8052)] 
2025-01-30 21:42:21.015054: Epoch time: 48.04 s 
2025-01-30 21:42:21.017397: Yayy! New best EMA pseudo Dice: 0.857200026512146 
2025-01-30 21:42:22.715878:  
2025-01-30 21:42:22.718625: Epoch 192 
2025-01-30 21:42:22.721195: Current learning rate: 0.00825 
2025-01-30 21:43:10.671326: train_loss -0.8133 
2025-01-30 21:43:10.676784: val_loss -0.7588 
2025-01-30 21:43:10.679068: Pseudo dice [np.float32(0.9423), np.float32(0.8637)] 
2025-01-30 21:43:10.681131: Epoch time: 47.96 s 
2025-01-30 21:43:10.683250: Yayy! New best EMA pseudo Dice: 0.8618000149726868 
2025-01-30 21:43:12.443910:  
2025-01-30 21:43:12.446692: Epoch 193 
2025-01-30 21:43:12.448942: Current learning rate: 0.00824 
2025-01-30 21:44:00.582481: train_loss -0.7996 
2025-01-30 21:44:00.586240: val_loss -0.7037 
2025-01-30 21:44:00.588897: Pseudo dice [np.float32(0.9324), np.float32(0.8746)] 
2025-01-30 21:44:00.591250: Epoch time: 48.14 s 
2025-01-30 21:44:00.593410: Yayy! New best EMA pseudo Dice: 0.8659999966621399 
2025-01-30 21:44:02.329958:  
2025-01-30 21:44:02.332801: Epoch 194 
2025-01-30 21:44:02.335445: Current learning rate: 0.00824 
2025-01-30 21:44:50.187098: train_loss -0.7992 
2025-01-30 21:44:50.193857: val_loss -0.7312 
2025-01-30 21:44:50.196506: Pseudo dice [np.float32(0.9309), np.float32(0.8738)] 
2025-01-30 21:44:50.199567: Epoch time: 47.86 s 
2025-01-30 21:44:50.201889: Yayy! New best EMA pseudo Dice: 0.8695999979972839 
2025-01-30 21:44:51.911809:  
2025-01-30 21:44:51.914452: Epoch 195 
2025-01-30 21:44:51.917076: Current learning rate: 0.00823 
2025-01-30 21:45:39.697939: train_loss -0.8128 
2025-01-30 21:45:39.702230: val_loss -0.6714 
2025-01-30 21:45:39.705210: Pseudo dice [np.float32(0.9107), np.float32(0.8076)] 
2025-01-30 21:45:39.707860: Epoch time: 47.79 s 
2025-01-30 21:45:40.860006:  
2025-01-30 21:45:40.862784: Epoch 196 
2025-01-30 21:45:40.865351: Current learning rate: 0.00822 
2025-01-30 21:46:28.804476: train_loss -0.7984 
2025-01-30 21:46:28.811652: val_loss -0.6203 
2025-01-30 21:46:28.814704: Pseudo dice [np.float32(0.9196), np.float32(0.617)] 
2025-01-30 21:46:28.817624: Epoch time: 47.95 s 
2025-01-30 21:46:29.971078:  
2025-01-30 21:46:29.974268: Epoch 197 
2025-01-30 21:46:29.977018: Current learning rate: 0.00821 
2025-01-30 21:47:18.060496: train_loss -0.7668 
2025-01-30 21:47:18.064849: val_loss -0.5274 
2025-01-30 21:47:18.067414: Pseudo dice [np.float32(0.9209), np.float32(0.3717)] 
2025-01-30 21:47:18.074911: Epoch time: 48.09 s 
2025-01-30 21:47:19.231307:  
2025-01-30 21:47:19.234516: Epoch 198 
2025-01-30 21:47:19.237253: Current learning rate: 0.0082 
2025-01-30 21:48:07.294237: train_loss -0.7798 
2025-01-30 21:48:07.301326: val_loss -0.6614 
2025-01-30 21:48:07.304199: Pseudo dice [np.float32(0.9357), np.float32(0.7433)] 
2025-01-30 21:48:07.306784: Epoch time: 48.06 s 
2025-01-30 21:48:08.460356:  
2025-01-30 21:48:08.463034: Epoch 199 
2025-01-30 21:48:08.465549: Current learning rate: 0.00819 
2025-01-30 21:48:56.851482: train_loss -0.7678 
2025-01-30 21:48:56.857192: val_loss -0.7067 
2025-01-30 21:48:56.859935: Pseudo dice [np.float32(0.9411), np.float32(0.7333)] 
2025-01-30 21:48:56.862716: Epoch time: 48.39 s 
2025-01-30 21:48:58.642766:  
2025-01-30 21:48:58.645729: Epoch 200 
2025-01-30 21:48:58.648360: Current learning rate: 0.00818 
2025-01-30 21:49:46.598996: train_loss -0.8037 
2025-01-30 21:49:46.605279: val_loss -0.6404 
2025-01-30 21:49:46.608095: Pseudo dice [np.float32(0.9337), np.float32(0.7042)] 
2025-01-30 21:49:46.610908: Epoch time: 47.96 s 
2025-01-30 21:49:47.805604:  
2025-01-30 21:49:47.808645: Epoch 201 
2025-01-30 21:49:47.811349: Current learning rate: 0.00817 
2025-01-30 21:50:36.341887: train_loss -0.7933 
2025-01-30 21:50:36.346146: val_loss -0.6092 
2025-01-30 21:50:36.349241: Pseudo dice [np.float32(0.9304), np.float32(0.6079)] 
2025-01-30 21:50:36.351942: Epoch time: 48.54 s 
2025-01-30 21:50:37.544378:  
2025-01-30 21:50:37.547058: Epoch 202 
2025-01-30 21:50:37.549698: Current learning rate: 0.00816 
2025-01-30 21:51:25.575928: train_loss -0.7947 
2025-01-30 21:51:25.581818: val_loss -0.6884 
2025-01-30 21:51:25.584447: Pseudo dice [np.float32(0.9473), np.float32(0.6242)] 
2025-01-30 21:51:25.587056: Epoch time: 48.03 s 
2025-01-30 21:51:26.741239:  
2025-01-30 21:51:26.744206: Epoch 203 
2025-01-30 21:51:26.746815: Current learning rate: 0.00815 
2025-01-30 21:52:14.693114: train_loss -0.795 
2025-01-30 21:52:14.697279: val_loss -0.7133 
2025-01-30 21:52:14.699974: Pseudo dice [np.float32(0.9362), np.float32(0.7829)] 
2025-01-30 21:52:14.702708: Epoch time: 47.95 s 
2025-01-30 21:52:16.423182:  
2025-01-30 21:52:16.427414: Epoch 204 
2025-01-30 21:52:16.430131: Current learning rate: 0.00814 
2025-01-30 21:53:04.404495: train_loss -0.7896 
2025-01-30 21:53:04.410343: val_loss -0.7357 
2025-01-30 21:53:04.412925: Pseudo dice [np.float32(0.9474), np.float32(0.7033)] 
2025-01-30 21:53:04.415293: Epoch time: 47.98 s 
2025-01-30 21:53:05.568516:  
2025-01-30 21:53:05.571319: Epoch 205 
2025-01-30 21:53:05.573841: Current learning rate: 0.00813 
2025-01-30 21:53:53.711464: train_loss -0.7835 
2025-01-30 21:53:53.715023: val_loss -0.6382 
2025-01-30 21:53:53.717417: Pseudo dice [np.float32(0.9088), np.float32(0.7762)] 
2025-01-30 21:53:53.719674: Epoch time: 48.14 s 
2025-01-30 21:53:54.806679:  
2025-01-30 21:53:54.809351: Epoch 206 
2025-01-30 21:53:54.811886: Current learning rate: 0.00813 
2025-01-30 21:54:42.694389: train_loss -0.8 
2025-01-30 21:54:42.701760: val_loss -0.6601 
2025-01-30 21:54:42.704525: Pseudo dice [np.float32(0.9464), np.float32(0.6249)] 
2025-01-30 21:54:42.707220: Epoch time: 47.89 s 
2025-01-30 21:54:43.802689:  
2025-01-30 21:54:43.805807: Epoch 207 
2025-01-30 21:54:43.808693: Current learning rate: 0.00812 
2025-01-30 21:55:31.970150: train_loss -0.8216 
2025-01-30 21:55:31.977365: val_loss -0.7023 
2025-01-30 21:55:31.979902: Pseudo dice [np.float32(0.9439), np.float32(0.792)] 
2025-01-30 21:55:31.982508: Epoch time: 48.17 s 
2025-01-30 21:55:33.109299:  
2025-01-30 21:55:33.112000: Epoch 208 
2025-01-30 21:55:33.114381: Current learning rate: 0.00811 
2025-01-30 21:56:21.372567: train_loss -0.8007 
2025-01-30 21:56:21.378585: val_loss -0.5929 
2025-01-30 21:56:21.385414: Pseudo dice [np.float32(0.9307), np.float32(0.5222)] 
2025-01-30 21:56:21.388076: Epoch time: 48.26 s 
2025-01-30 21:56:22.476549:  
2025-01-30 21:56:22.479465: Epoch 209 
2025-01-30 21:56:22.482032: Current learning rate: 0.0081 
2025-01-30 21:57:10.826198: train_loss -0.7906 
2025-01-30 21:57:10.833579: val_loss -0.6648 
2025-01-30 21:57:10.836739: Pseudo dice [np.float32(0.9297), np.float32(0.6833)] 
2025-01-30 21:57:10.839247: Epoch time: 48.35 s 
2025-01-30 21:57:11.931624:  
2025-01-30 21:57:11.934692: Epoch 210 
2025-01-30 21:57:11.937411: Current learning rate: 0.00809 
2025-01-30 21:57:59.981258: train_loss -0.7939 
2025-01-30 21:57:59.988786: val_loss -0.6763 
2025-01-30 21:57:59.991499: Pseudo dice [np.float32(0.9308), np.float32(0.7025)] 
2025-01-30 21:57:59.994570: Epoch time: 48.05 s 
2025-01-30 21:58:01.122253:  
2025-01-30 21:58:01.125483: Epoch 211 
2025-01-30 21:58:01.128339: Current learning rate: 0.00808 
2025-01-30 21:58:49.531205: train_loss -0.7781 
2025-01-30 21:58:49.536326: val_loss -0.6853 
2025-01-30 21:58:49.539389: Pseudo dice [np.float32(0.9298), np.float32(0.7414)] 
2025-01-30 21:58:49.542296: Epoch time: 48.41 s 
2025-01-30 21:58:50.636915:  
2025-01-30 21:58:50.639467: Epoch 212 
2025-01-30 21:58:50.642026: Current learning rate: 0.00807 
2025-01-30 21:59:39.106889: train_loss -0.7758 
2025-01-30 21:59:39.112523: val_loss -0.5997 
2025-01-30 21:59:39.115135: Pseudo dice [np.float32(0.9372), np.float32(0.5498)] 
2025-01-30 21:59:39.117482: Epoch time: 48.47 s 
2025-01-30 21:59:40.214818:  
2025-01-30 21:59:40.218141: Epoch 213 
2025-01-30 21:59:40.221080: Current learning rate: 0.00806 
2025-01-30 22:00:28.417498: train_loss -0.7767 
2025-01-30 22:00:28.422259: val_loss -0.7383 
2025-01-30 22:00:28.425326: Pseudo dice [np.float32(0.9308), np.float32(0.8078)] 
2025-01-30 22:00:28.428109: Epoch time: 48.2 s 
2025-01-30 22:00:29.534945:  
2025-01-30 22:00:29.538462: Epoch 214 
2025-01-30 22:00:29.541428: Current learning rate: 0.00805 
2025-01-30 22:01:17.817463: train_loss -0.7867 
2025-01-30 22:01:17.824675: val_loss -0.718 
2025-01-30 22:01:17.827504: Pseudo dice [np.float32(0.9428), np.float32(0.7199)] 
2025-01-30 22:01:17.830184: Epoch time: 48.28 s 
2025-01-30 22:01:18.964819:  
2025-01-30 22:01:18.967577: Epoch 215 
2025-01-30 22:01:18.970076: Current learning rate: 0.00804 
2025-01-30 22:02:07.137773: train_loss -0.7992 
2025-01-30 22:02:07.145302: val_loss -0.6707 
2025-01-30 22:02:07.147948: Pseudo dice [np.float32(0.9343), np.float32(0.7055)] 
2025-01-30 22:02:07.150543: Epoch time: 48.17 s 
2025-01-30 22:02:08.256305:  
2025-01-30 22:02:08.259332: Epoch 216 
2025-01-30 22:02:08.261949: Current learning rate: 0.00803 
2025-01-30 22:02:56.154614: train_loss -0.7924 
2025-01-30 22:02:56.163331: val_loss -0.6922 
2025-01-30 22:02:56.166055: Pseudo dice [np.float32(0.9458), np.float32(0.7886)] 
2025-01-30 22:02:56.168804: Epoch time: 47.9 s 
2025-01-30 22:02:57.302991:  
2025-01-30 22:02:57.306247: Epoch 217 
2025-01-30 22:02:57.309427: Current learning rate: 0.00802 
2025-01-30 22:03:45.470562: train_loss -0.8071 
2025-01-30 22:03:45.478221: val_loss -0.6825 
2025-01-30 22:03:45.481271: Pseudo dice [np.float32(0.9447), np.float32(0.726)] 
2025-01-30 22:03:45.483943: Epoch time: 48.17 s 
2025-01-30 22:03:46.624878:  
2025-01-30 22:03:46.627588: Epoch 218 
2025-01-30 22:03:46.630283: Current learning rate: 0.00801 
2025-01-30 22:04:34.760674: train_loss -0.8179 
2025-01-30 22:04:34.767146: val_loss -0.6267 
2025-01-30 22:04:34.769815: Pseudo dice [np.float32(0.942), np.float32(0.5681)] 
2025-01-30 22:04:34.772439: Epoch time: 48.14 s 
2025-01-30 22:04:35.875998:  
2025-01-30 22:04:35.879272: Epoch 219 
2025-01-30 22:04:35.882303: Current learning rate: 0.00801 
2025-01-30 22:05:24.159255: train_loss -0.7872 
2025-01-30 22:05:24.163323: val_loss -0.6804 
2025-01-30 22:05:24.166441: Pseudo dice [np.float32(0.9429), np.float32(0.7147)] 
2025-01-30 22:05:24.168950: Epoch time: 48.28 s 
2025-01-30 22:05:25.299779:  
2025-01-30 22:05:25.302523: Epoch 220 
2025-01-30 22:05:25.305230: Current learning rate: 0.008 
2025-01-30 22:06:13.248883: train_loss -0.7928 
2025-01-30 22:06:13.258308: val_loss -0.6794 
2025-01-30 22:06:13.260986: Pseudo dice [np.float32(0.9414), np.float32(0.7796)] 
2025-01-30 22:06:13.263631: Epoch time: 47.95 s 
2025-01-30 22:06:14.362517:  
2025-01-30 22:06:14.365355: Epoch 221 
2025-01-30 22:06:14.368069: Current learning rate: 0.00799 
2025-01-30 22:07:02.533437: train_loss -0.7929 
2025-01-30 22:07:02.539824: val_loss -0.7173 
2025-01-30 22:07:02.542323: Pseudo dice [np.float32(0.9425), np.float32(0.7624)] 
2025-01-30 22:07:02.544929: Epoch time: 48.17 s 
2025-01-30 22:07:03.639282:  
2025-01-30 22:07:03.642168: Epoch 222 
2025-01-30 22:07:03.645050: Current learning rate: 0.00798 
2025-01-30 22:07:51.791429: train_loss -0.7976 
2025-01-30 22:07:51.798786: val_loss -0.6401 
2025-01-30 22:07:51.801281: Pseudo dice [np.float32(0.945), np.float32(0.6657)] 
2025-01-30 22:07:51.803634: Epoch time: 48.15 s 
2025-01-30 22:07:53.463914:  
2025-01-30 22:07:53.466757: Epoch 223 
2025-01-30 22:07:53.469372: Current learning rate: 0.00797 
2025-01-30 22:08:41.405196: train_loss -0.8094 
2025-01-30 22:08:41.411379: val_loss -0.7273 
2025-01-30 22:08:41.413981: Pseudo dice [np.float32(0.9433), np.float32(0.8496)] 
2025-01-30 22:08:41.416454: Epoch time: 47.94 s 
2025-01-30 22:08:42.518140:  
2025-01-30 22:08:42.521285: Epoch 224 
2025-01-30 22:08:42.524446: Current learning rate: 0.00796 
2025-01-30 22:09:30.578809: train_loss -0.795 
2025-01-30 22:09:30.585020: val_loss -0.6869 
2025-01-30 22:09:30.587714: Pseudo dice [np.float32(0.9455), np.float32(0.6916)] 
2025-01-30 22:09:30.590067: Epoch time: 48.06 s 
2025-01-30 22:09:31.684430:  
2025-01-30 22:09:31.687279: Epoch 225 
2025-01-30 22:09:31.689934: Current learning rate: 0.00795 
2025-01-30 22:10:19.790894: train_loss -0.82 
2025-01-30 22:10:19.796165: val_loss -0.6514 
2025-01-30 22:10:19.798923: Pseudo dice [np.float32(0.947), np.float32(0.5291)] 
2025-01-30 22:10:19.801533: Epoch time: 48.11 s 
2025-01-30 22:10:20.885355:  
2025-01-30 22:10:20.887734: Epoch 226 
2025-01-30 22:10:20.890145: Current learning rate: 0.00794 
2025-01-30 22:11:08.930498: train_loss -0.8131 
2025-01-30 22:11:08.936936: val_loss -0.694 
2025-01-30 22:11:08.939431: Pseudo dice [np.float32(0.9266), np.float32(0.7746)] 
2025-01-30 22:11:08.941780: Epoch time: 48.05 s 
2025-01-30 22:11:10.023616:  
2025-01-30 22:11:10.026246: Epoch 227 
2025-01-30 22:11:10.028625: Current learning rate: 0.00793 
2025-01-30 22:11:57.951846: train_loss -0.7778 
2025-01-30 22:11:57.957647: val_loss -0.6873 
2025-01-30 22:11:57.960215: Pseudo dice [np.float32(0.9551), np.float32(0.5643)] 
2025-01-30 22:11:57.962437: Epoch time: 47.93 s 
2025-01-30 22:11:59.078924:  
2025-01-30 22:11:59.083019: Epoch 228 
2025-01-30 22:11:59.085406: Current learning rate: 0.00792 
2025-01-30 22:12:47.043770: train_loss -0.8183 
2025-01-30 22:12:47.049932: val_loss -0.699 
2025-01-30 22:12:47.052487: Pseudo dice [np.float32(0.9474), np.float32(0.7865)] 
2025-01-30 22:12:47.054869: Epoch time: 47.97 s 
2025-01-30 22:12:48.140142:  
2025-01-30 22:12:48.142603: Epoch 229 
2025-01-30 22:12:48.144967: Current learning rate: 0.00791 
2025-01-30 22:13:36.224473: train_loss -0.8117 
2025-01-30 22:13:36.229156: val_loss -0.6326 
2025-01-30 22:13:36.231750: Pseudo dice [np.float32(0.9404), np.float32(0.8359)] 
2025-01-30 22:13:36.234352: Epoch time: 48.09 s 
2025-01-30 22:13:37.323655:  
2025-01-30 22:13:37.326328: Epoch 230 
2025-01-30 22:13:37.329017: Current learning rate: 0.0079 
2025-01-30 22:14:25.712159: train_loss -0.8019 
2025-01-30 22:14:25.718684: val_loss -0.6012 
2025-01-30 22:14:25.721710: Pseudo dice [np.float32(0.9343), np.float32(0.505)] 
2025-01-30 22:14:25.724654: Epoch time: 48.39 s 
2025-01-30 22:14:26.850730:  
2025-01-30 22:14:26.853292: Epoch 231 
2025-01-30 22:14:26.856041: Current learning rate: 0.00789 
2025-01-30 22:15:14.737809: train_loss -0.8102 
2025-01-30 22:15:14.741298: val_loss -0.6911 
2025-01-30 22:15:14.743690: Pseudo dice [np.float32(0.9383), np.float32(0.7956)] 
2025-01-30 22:15:14.746059: Epoch time: 47.89 s 
2025-01-30 22:15:15.834902:  
2025-01-30 22:15:15.837597: Epoch 232 
2025-01-30 22:15:15.840492: Current learning rate: 0.00789 
2025-01-30 22:16:04.314378: train_loss -0.8011 
2025-01-30 22:16:04.320103: val_loss -0.5966 
2025-01-30 22:16:04.322431: Pseudo dice [np.float32(0.9288), np.float32(0.6144)] 
2025-01-30 22:16:04.325126: Epoch time: 48.48 s 
2025-01-30 22:16:05.454139:  
2025-01-30 22:16:05.457834: Epoch 233 
2025-01-30 22:16:05.462337: Current learning rate: 0.00788 
2025-01-30 22:16:53.316624: train_loss -0.8059 
2025-01-30 22:16:53.320392: val_loss -0.638 
2025-01-30 22:16:53.323184: Pseudo dice [np.float32(0.943), np.float32(0.5429)] 
2025-01-30 22:16:53.325631: Epoch time: 47.86 s 
2025-01-30 22:16:54.403609:  
2025-01-30 22:16:54.406163: Epoch 234 
2025-01-30 22:16:54.408734: Current learning rate: 0.00787 
2025-01-30 22:17:42.339974: train_loss -0.803 
2025-01-30 22:17:42.345679: val_loss -0.6774 
2025-01-30 22:17:42.348270: Pseudo dice [np.float32(0.9498), np.float32(0.6098)] 
2025-01-30 22:17:42.350796: Epoch time: 47.94 s 
2025-01-30 22:17:43.431110:  
2025-01-30 22:17:43.434011: Epoch 235 
2025-01-30 22:17:43.436718: Current learning rate: 0.00786 
2025-01-30 22:18:31.511909: train_loss -0.8004 
2025-01-30 22:18:31.515597: val_loss -0.6853 
2025-01-30 22:18:31.517977: Pseudo dice [np.float32(0.9314), np.float32(0.8017)] 
2025-01-30 22:18:31.520479: Epoch time: 48.08 s 
2025-01-30 22:18:32.637427:  
2025-01-30 22:18:32.640145: Epoch 236 
2025-01-30 22:18:32.642540: Current learning rate: 0.00785 
2025-01-30 22:19:20.836563: train_loss -0.8047 
2025-01-30 22:19:20.842176: val_loss -0.6263 
2025-01-30 22:19:20.844790: Pseudo dice [np.float32(0.9435), np.float32(0.4663)] 
2025-01-30 22:19:20.847209: Epoch time: 48.2 s 
2025-01-30 22:19:21.926311:  
2025-01-30 22:19:21.929071: Epoch 237 
2025-01-30 22:19:21.931745: Current learning rate: 0.00784 
2025-01-30 22:20:10.130689: train_loss -0.808 
2025-01-30 22:20:10.135356: val_loss -0.6851 
2025-01-30 22:20:10.138124: Pseudo dice [np.float32(0.934), np.float32(0.7865)] 
2025-01-30 22:20:10.140615: Epoch time: 48.21 s 
2025-01-30 22:20:11.253576:  
2025-01-30 22:20:11.256413: Epoch 238 
2025-01-30 22:20:11.259040: Current learning rate: 0.00783 
2025-01-30 22:20:59.468110: train_loss -0.8199 
2025-01-30 22:20:59.474266: val_loss -0.7224 
2025-01-30 22:20:59.476756: Pseudo dice [np.float32(0.9411), np.float32(0.7134)] 
2025-01-30 22:20:59.478988: Epoch time: 48.22 s 
2025-01-30 22:21:00.572502:  
2025-01-30 22:21:00.575566: Epoch 239 
2025-01-30 22:21:00.578090: Current learning rate: 0.00782 
2025-01-30 22:21:48.865829: train_loss -0.8306 
2025-01-30 22:21:48.869488: val_loss -0.6598 
2025-01-30 22:21:48.871968: Pseudo dice [np.float32(0.9498), np.float32(0.5604)] 
2025-01-30 22:21:48.874455: Epoch time: 48.29 s 
2025-01-30 22:21:49.993323:  
2025-01-30 22:21:49.996163: Epoch 240 
2025-01-30 22:21:49.998587: Current learning rate: 0.00781 
2025-01-30 22:22:37.742296: train_loss -0.8426 
2025-01-30 22:22:37.747499: val_loss -0.7387 
2025-01-30 22:22:37.749951: Pseudo dice [np.float32(0.952), np.float32(0.8014)] 
2025-01-30 22:22:37.752209: Epoch time: 47.75 s 
2025-01-30 22:22:38.854287:  
2025-01-30 22:22:38.857132: Epoch 241 
2025-01-30 22:22:38.859724: Current learning rate: 0.0078 
2025-01-30 22:23:26.969839: train_loss -0.8069 
2025-01-30 22:23:26.973863: val_loss -0.6422 
2025-01-30 22:23:26.976338: Pseudo dice [np.float32(0.9355), np.float32(0.6208)] 
2025-01-30 22:23:26.979031: Epoch time: 48.12 s 
2025-01-30 22:23:28.592812:  
2025-01-30 22:23:28.595353: Epoch 242 
2025-01-30 22:23:28.597837: Current learning rate: 0.00779 
2025-01-30 22:24:16.422810: train_loss -0.8094 
2025-01-30 22:24:16.428186: val_loss -0.6953 
2025-01-30 22:24:16.430926: Pseudo dice [np.float32(0.9383), np.float32(0.7761)] 
2025-01-30 22:24:16.433454: Epoch time: 47.83 s 
2025-01-30 22:24:17.535034:  
2025-01-30 22:24:17.537319: Epoch 243 
2025-01-30 22:24:17.539703: Current learning rate: 0.00778 
2025-01-30 22:25:05.614506: train_loss -0.7926 
2025-01-30 22:25:05.618705: val_loss -0.66 
2025-01-30 22:25:05.621584: Pseudo dice [np.float32(0.9398), np.float32(0.5754)] 
2025-01-30 22:25:05.624193: Epoch time: 48.08 s 
2025-01-30 22:25:06.731261:  
2025-01-30 22:25:06.734353: Epoch 244 
2025-01-30 22:25:06.737235: Current learning rate: 0.00777 
2025-01-30 22:25:54.704443: train_loss -0.7929 
2025-01-30 22:25:54.711005: val_loss -0.6444 
2025-01-30 22:25:54.713442: Pseudo dice [np.float32(0.9327), np.float32(0.5623)] 
2025-01-30 22:25:54.715711: Epoch time: 47.97 s 
2025-01-30 22:25:55.820595:  
2025-01-30 22:25:55.823447: Epoch 245 
2025-01-30 22:25:55.826103: Current learning rate: 0.00777 
2025-01-30 22:26:43.846654: train_loss -0.7975 
2025-01-30 22:26:43.850841: val_loss -0.6272 
2025-01-30 22:26:43.853523: Pseudo dice [np.float32(0.9432), np.float32(0.6923)] 
2025-01-30 22:26:43.856170: Epoch time: 48.03 s 
2025-01-30 22:26:44.985502:  
2025-01-30 22:26:44.988478: Epoch 246 
2025-01-30 22:26:44.991117: Current learning rate: 0.00776 
2025-01-30 22:27:32.930236: train_loss -0.7992 
2025-01-30 22:27:32.936495: val_loss -0.5733 
2025-01-30 22:27:32.939098: Pseudo dice [np.float32(0.9305), np.float32(0.6489)] 
2025-01-30 22:27:32.941963: Epoch time: 47.95 s 
2025-01-30 22:27:34.078241:  
2025-01-30 22:27:34.081308: Epoch 247 
2025-01-30 22:27:34.084413: Current learning rate: 0.00775 
2025-01-30 22:28:22.025022: train_loss -0.7889 
2025-01-30 22:28:22.028745: val_loss -0.6078 
2025-01-30 22:28:22.031378: Pseudo dice [np.float32(0.9406), np.float32(0.612)] 
2025-01-30 22:28:22.033694: Epoch time: 47.95 s 
2025-01-30 22:28:23.161927:  
2025-01-30 22:28:23.164791: Epoch 248 
2025-01-30 22:28:23.167391: Current learning rate: 0.00774 
2025-01-30 22:29:11.440435: train_loss -0.8082 
2025-01-30 22:29:11.445616: val_loss -0.6849 
2025-01-30 22:29:11.448225: Pseudo dice [np.float32(0.948), np.float32(0.662)] 
2025-01-30 22:29:11.450717: Epoch time: 48.28 s 
2025-01-30 22:29:12.556654:  
2025-01-30 22:29:12.559447: Epoch 249 
2025-01-30 22:29:12.562190: Current learning rate: 0.00773 
2025-01-30 22:30:00.986829: train_loss -0.7991 
2025-01-30 22:30:00.990260: val_loss -0.7008 
2025-01-30 22:30:00.992513: Pseudo dice [np.float32(0.9323), np.float32(0.7953)] 
2025-01-30 22:30:00.994868: Epoch time: 48.43 s 
2025-01-30 22:30:02.649449:  
2025-01-30 22:30:02.652186: Epoch 250 
2025-01-30 22:30:02.654892: Current learning rate: 0.00772 
2025-01-30 22:30:50.712606: train_loss -0.8199 
2025-01-30 22:30:50.717760: val_loss -0.7206 
2025-01-30 22:30:50.720204: Pseudo dice [np.float32(0.9393), np.float32(0.8555)] 
2025-01-30 22:30:50.722610: Epoch time: 48.06 s 
2025-01-30 22:30:51.832313:  
2025-01-30 22:30:51.834806: Epoch 251 
2025-01-30 22:30:51.837265: Current learning rate: 0.00771 
2025-01-30 22:31:39.597881: train_loss -0.8049 
2025-01-30 22:31:39.602076: val_loss -0.6802 
2025-01-30 22:31:39.605101: Pseudo dice [np.float32(0.9422), np.float32(0.8307)] 
2025-01-30 22:31:39.607656: Epoch time: 47.77 s 
2025-01-30 22:31:40.712370:  
2025-01-30 22:31:40.714946: Epoch 252 
2025-01-30 22:31:40.717685: Current learning rate: 0.0077 
2025-01-30 22:32:28.623316: train_loss -0.8182 
2025-01-30 22:32:28.628683: val_loss -0.7024 
2025-01-30 22:32:28.630885: Pseudo dice [np.float32(0.9479), np.float32(0.8277)] 
2025-01-30 22:32:28.633485: Epoch time: 47.91 s 
2025-01-30 22:32:29.737070:  
2025-01-30 22:32:29.739260: Epoch 253 
2025-01-30 22:32:29.741460: Current learning rate: 0.00769 
2025-01-30 22:33:17.837634: train_loss -0.8075 
2025-01-30 22:33:17.841231: val_loss -0.6789 
2025-01-30 22:33:17.843866: Pseudo dice [np.float32(0.9426), np.float32(0.6279)] 
2025-01-30 22:33:17.846061: Epoch time: 48.1 s 
2025-01-30 22:33:18.985808:  
2025-01-30 22:33:18.989213: Epoch 254 
2025-01-30 22:33:18.991713: Current learning rate: 0.00768 
2025-01-30 22:34:07.138982: train_loss -0.7909 
2025-01-30 22:34:07.144223: val_loss -0.7162 
2025-01-30 22:34:07.146704: Pseudo dice [np.float32(0.9469), np.float32(0.8036)] 
2025-01-30 22:34:07.148999: Epoch time: 48.15 s 
2025-01-30 22:34:08.250585:  
2025-01-30 22:34:08.253466: Epoch 255 
2025-01-30 22:34:08.256187: Current learning rate: 0.00767 
2025-01-30 22:34:55.977266: train_loss -0.7939 
2025-01-30 22:34:55.981233: val_loss -0.572 
2025-01-30 22:34:55.984061: Pseudo dice [np.float32(0.9272), np.float32(0.4466)] 
2025-01-30 22:34:55.986547: Epoch time: 47.73 s 
2025-01-30 22:34:57.088397:  
2025-01-30 22:34:57.091190: Epoch 256 
2025-01-30 22:34:57.094063: Current learning rate: 0.00766 
2025-01-30 22:35:45.085346: train_loss -0.7898 
2025-01-30 22:35:45.090640: val_loss -0.6265 
2025-01-30 22:35:45.093447: Pseudo dice [np.float32(0.936), np.float32(0.6183)] 
2025-01-30 22:35:45.095822: Epoch time: 48.0 s 
2025-01-30 22:35:46.208828:  
2025-01-30 22:35:46.211548: Epoch 257 
2025-01-30 22:35:46.214161: Current learning rate: 0.00765 
2025-01-30 22:36:34.013889: train_loss -0.7813 
2025-01-30 22:36:34.018644: val_loss -0.6738 
2025-01-30 22:36:34.021473: Pseudo dice [np.float32(0.9417), np.float32(0.6308)] 
2025-01-30 22:36:34.024201: Epoch time: 47.81 s 
2025-01-30 22:36:35.124264:  
2025-01-30 22:36:35.126910: Epoch 258 
2025-01-30 22:36:35.129318: Current learning rate: 0.00764 
2025-01-30 22:37:23.402910: train_loss -0.8082 
2025-01-30 22:37:23.408606: val_loss -0.5883 
2025-01-30 22:37:23.411260: Pseudo dice [np.float32(0.9249), np.float32(0.5784)] 
2025-01-30 22:37:23.413792: Epoch time: 48.28 s 
2025-01-30 22:37:24.520717:  
2025-01-30 22:37:24.524079: Epoch 259 
2025-01-30 22:37:24.526944: Current learning rate: 0.00764 
2025-01-30 22:38:12.747335: train_loss -0.8008 
2025-01-30 22:38:12.751839: val_loss -0.6733 
2025-01-30 22:38:12.754767: Pseudo dice [np.float32(0.9423), np.float32(0.6104)] 
2025-01-30 22:38:12.757385: Epoch time: 48.23 s 
2025-01-30 22:38:13.894632:  
2025-01-30 22:38:13.897221: Epoch 260 
2025-01-30 22:38:13.899938: Current learning rate: 0.00763 
2025-01-30 22:39:01.737621: train_loss -0.8003 
2025-01-30 22:39:01.743709: val_loss -0.6503 
2025-01-30 22:39:01.746354: Pseudo dice [np.float32(0.9459), np.float32(0.5556)] 
2025-01-30 22:39:01.748744: Epoch time: 47.84 s 
2025-01-30 22:39:02.887359:  
2025-01-30 22:39:02.890089: Epoch 261 
2025-01-30 22:39:02.892719: Current learning rate: 0.00762 
2025-01-30 22:39:51.107268: train_loss -0.801 
2025-01-30 22:39:51.111280: val_loss -0.7148 
2025-01-30 22:39:51.113769: Pseudo dice [np.float32(0.9358), np.float32(0.7533)] 
2025-01-30 22:39:51.116338: Epoch time: 48.22 s 
2025-01-30 22:39:52.800616:  
2025-01-30 22:39:52.803336: Epoch 262 
2025-01-30 22:39:52.805936: Current learning rate: 0.00761 
2025-01-30 22:40:41.070916: train_loss -0.7878 
2025-01-30 22:40:41.076777: val_loss -0.6962 
2025-01-30 22:40:41.079564: Pseudo dice [np.float32(0.9474), np.float32(0.689)] 
2025-01-30 22:40:41.082211: Epoch time: 48.27 s 
2025-01-30 22:40:42.229192:  
2025-01-30 22:40:42.232111: Epoch 263 
2025-01-30 22:40:42.234666: Current learning rate: 0.0076 
2025-01-30 22:41:30.462347: train_loss -0.8019 
2025-01-30 22:41:30.466803: val_loss -0.6794 
2025-01-30 22:41:30.469668: Pseudo dice [np.float32(0.9369), np.float32(0.7504)] 
2025-01-30 22:41:30.472162: Epoch time: 48.23 s 
2025-01-30 22:41:31.579516:  
2025-01-30 22:41:31.582156: Epoch 264 
2025-01-30 22:41:31.584613: Current learning rate: 0.00759 
2025-01-30 22:42:20.162634: train_loss -0.7704 
2025-01-30 22:42:20.168335: val_loss -0.6542 
2025-01-30 22:42:20.170889: Pseudo dice [np.float32(0.9393), np.float32(0.6763)] 
2025-01-30 22:42:20.173168: Epoch time: 48.58 s 
2025-01-30 22:42:21.313800:  
2025-01-30 22:42:21.316823: Epoch 265 
2025-01-30 22:42:21.319593: Current learning rate: 0.00758 
2025-01-30 22:43:09.238388: train_loss -0.8028 
2025-01-30 22:43:09.242861: val_loss -0.6575 
2025-01-30 22:43:09.245677: Pseudo dice [np.float32(0.9406), np.float32(0.7362)] 
2025-01-30 22:43:09.248583: Epoch time: 47.93 s 
2025-01-30 22:43:10.355743:  
2025-01-30 22:43:10.358876: Epoch 266 
2025-01-30 22:43:10.361400: Current learning rate: 0.00757 
2025-01-30 22:43:58.456851: train_loss -0.7877 
2025-01-30 22:43:58.463359: val_loss -0.6939 
2025-01-30 22:43:58.465950: Pseudo dice [np.float32(0.943), np.float32(0.7654)] 
2025-01-30 22:43:58.468622: Epoch time: 48.1 s 
2025-01-30 22:43:59.577200:  
2025-01-30 22:43:59.579862: Epoch 267 
2025-01-30 22:43:59.582519: Current learning rate: 0.00756 
2025-01-30 22:44:47.711928: train_loss -0.8013 
2025-01-30 22:44:47.716029: val_loss -0.6183 
2025-01-30 22:44:47.718581: Pseudo dice [np.float32(0.9347), np.float32(0.6789)] 
2025-01-30 22:44:47.721343: Epoch time: 48.14 s 
2025-01-30 22:44:48.825586:  
2025-01-30 22:44:48.828736: Epoch 268 
2025-01-30 22:44:48.831449: Current learning rate: 0.00755 
2025-01-30 22:45:36.958275: train_loss -0.8318 
2025-01-30 22:45:36.965739: val_loss -0.649 
2025-01-30 22:45:36.968571: Pseudo dice [np.float32(0.9333), np.float32(0.6805)] 
2025-01-30 22:45:36.971377: Epoch time: 48.13 s 
2025-01-30 22:45:38.074255:  
2025-01-30 22:45:38.077040: Epoch 269 
2025-01-30 22:45:38.079599: Current learning rate: 0.00754 
2025-01-30 22:46:26.027041: train_loss -0.8258 
2025-01-30 22:46:26.031134: val_loss -0.7166 
2025-01-30 22:46:26.034048: Pseudo dice [np.float32(0.9325), np.float32(0.8665)] 
2025-01-30 22:46:26.036721: Epoch time: 47.95 s 
2025-01-30 22:46:27.186686:  
2025-01-30 22:46:27.189607: Epoch 270 
2025-01-30 22:46:27.192634: Current learning rate: 0.00753 
2025-01-30 22:47:15.241812: train_loss -0.8055 
2025-01-30 22:47:15.248648: val_loss -0.6881 
2025-01-30 22:47:15.251721: Pseudo dice [np.float32(0.9471), np.float32(0.68)] 
2025-01-30 22:47:15.254496: Epoch time: 48.06 s 
2025-01-30 22:47:16.402375:  
2025-01-30 22:47:16.405074: Epoch 271 
2025-01-30 22:47:16.407943: Current learning rate: 0.00752 
2025-01-30 22:48:04.506023: train_loss -0.8218 
2025-01-30 22:48:04.510683: val_loss -0.7113 
2025-01-30 22:48:04.513571: Pseudo dice [np.float32(0.9464), np.float32(0.8165)] 
2025-01-30 22:48:04.516515: Epoch time: 48.1 s 
2025-01-30 22:48:05.659838:  
2025-01-30 22:48:05.662701: Epoch 272 
2025-01-30 22:48:05.665390: Current learning rate: 0.00751 
2025-01-30 22:48:53.800227: train_loss -0.8062 
2025-01-30 22:48:53.806686: val_loss -0.6727 
2025-01-30 22:48:53.809677: Pseudo dice [np.float32(0.9324), np.float32(0.809)] 
2025-01-30 22:48:53.812214: Epoch time: 48.14 s 
2025-01-30 22:48:54.915900:  
2025-01-30 22:48:54.918463: Epoch 273 
2025-01-30 22:48:54.921303: Current learning rate: 0.00751 
2025-01-30 22:49:43.041203: train_loss -0.7996 
2025-01-30 22:49:43.044852: val_loss -0.6815 
2025-01-30 22:49:43.047417: Pseudo dice [np.float32(0.9489), np.float32(0.6167)] 
2025-01-30 22:49:43.049597: Epoch time: 48.13 s 
2025-01-30 22:49:44.154036:  
2025-01-30 22:49:44.156574: Epoch 274 
2025-01-30 22:49:44.158901: Current learning rate: 0.0075 
2025-01-30 22:50:31.969091: train_loss -0.791 
2025-01-30 22:50:31.974402: val_loss -0.7124 
2025-01-30 22:50:31.976876: Pseudo dice [np.float32(0.9397), np.float32(0.8377)] 
2025-01-30 22:50:31.979070: Epoch time: 47.82 s 
2025-01-30 22:50:33.094618:  
2025-01-30 22:50:33.097322: Epoch 275 
2025-01-30 22:50:33.099809: Current learning rate: 0.00749 
2025-01-30 22:51:21.242079: train_loss -0.7976 
2025-01-30 22:51:21.246271: val_loss -0.6837 
2025-01-30 22:51:21.248795: Pseudo dice [np.float32(0.9312), np.float32(0.6706)] 
2025-01-30 22:51:21.251360: Epoch time: 48.15 s 
2025-01-30 22:51:22.390270:  
2025-01-30 22:51:22.393239: Epoch 276 
2025-01-30 22:51:22.395955: Current learning rate: 0.00748 
2025-01-30 22:52:10.444694: train_loss -0.7761 
2025-01-30 22:52:10.450276: val_loss -0.6653 
2025-01-30 22:52:10.452772: Pseudo dice [np.float32(0.9514), np.float32(0.8408)] 
2025-01-30 22:52:10.455170: Epoch time: 48.06 s 
2025-01-30 22:52:11.560212:  
2025-01-30 22:52:11.562515: Epoch 277 
2025-01-30 22:52:11.564767: Current learning rate: 0.00747 
2025-01-30 22:52:59.788303: train_loss -0.8015 
2025-01-30 22:52:59.792783: val_loss -0.7055 
2025-01-30 22:52:59.795705: Pseudo dice [np.float32(0.9429), np.float32(0.768)] 
2025-01-30 22:52:59.798346: Epoch time: 48.23 s 
2025-01-30 22:53:00.901198:  
2025-01-30 22:53:00.906519: Epoch 278 
2025-01-30 22:53:00.909550: Current learning rate: 0.00746 
2025-01-30 22:53:48.950875: train_loss -0.8147 
2025-01-30 22:53:48.957472: val_loss -0.7323 
2025-01-30 22:53:48.960348: Pseudo dice [np.float32(0.9498), np.float32(0.8766)] 
2025-01-30 22:53:48.962878: Epoch time: 48.05 s 
2025-01-30 22:53:50.073855:  
2025-01-30 22:53:50.076622: Epoch 279 
2025-01-30 22:53:50.079441: Current learning rate: 0.00745 
2025-01-30 22:54:38.265224: train_loss -0.8031 
2025-01-30 22:54:38.268847: val_loss -0.7416 
2025-01-30 22:54:38.271080: Pseudo dice [np.float32(0.9461), np.float32(0.7273)] 
2025-01-30 22:54:38.273479: Epoch time: 48.19 s 
2025-01-30 22:54:39.413819:  
2025-01-30 22:54:39.416251: Epoch 280 
2025-01-30 22:54:39.418587: Current learning rate: 0.00744 
2025-01-30 22:55:27.560601: train_loss -0.8064 
2025-01-30 22:55:27.566491: val_loss -0.6958 
2025-01-30 22:55:27.569165: Pseudo dice [np.float32(0.9351), np.float32(0.7552)] 
2025-01-30 22:55:27.571999: Epoch time: 48.15 s 
2025-01-30 22:55:29.314706:  
2025-01-30 22:55:29.317734: Epoch 281 
2025-01-30 22:55:29.320513: Current learning rate: 0.00743 
2025-01-30 22:56:17.304962: train_loss -0.812 
2025-01-30 22:56:17.308968: val_loss -0.7211 
2025-01-30 22:56:17.311612: Pseudo dice [np.float32(0.9524), np.float32(0.6906)] 
2025-01-30 22:56:17.314244: Epoch time: 47.99 s 
2025-01-30 22:56:18.426679:  
2025-01-30 22:56:18.429478: Epoch 282 
2025-01-30 22:56:18.432724: Current learning rate: 0.00742 
2025-01-30 22:57:06.459406: train_loss -0.8029 
2025-01-30 22:57:06.465271: val_loss -0.6962 
2025-01-30 22:57:06.468083: Pseudo dice [np.float32(0.9476), np.float32(0.6768)] 
2025-01-30 22:57:06.470682: Epoch time: 48.03 s 
2025-01-30 22:57:07.607330:  
2025-01-30 22:57:07.610225: Epoch 283 
2025-01-30 22:57:07.612786: Current learning rate: 0.00741 
2025-01-30 22:57:55.636170: train_loss -0.8026 
2025-01-30 22:57:55.640214: val_loss -0.6638 
2025-01-30 22:57:55.643016: Pseudo dice [np.float32(0.9341), np.float32(0.6696)] 
2025-01-30 22:57:55.645486: Epoch time: 48.03 s 
2025-01-30 22:57:56.757078:  
2025-01-30 22:57:56.759740: Epoch 284 
2025-01-30 22:57:56.762378: Current learning rate: 0.0074 
2025-01-30 22:58:44.601561: train_loss -0.7975 
2025-01-30 22:58:44.607773: val_loss -0.6489 
2025-01-30 22:58:44.610571: Pseudo dice [np.float32(0.941), np.float32(0.7653)] 
2025-01-30 22:58:44.612925: Epoch time: 47.85 s 
2025-01-30 22:58:45.725446:  
2025-01-30 22:58:45.728371: Epoch 285 
2025-01-30 22:58:45.730958: Current learning rate: 0.00739 
2025-01-30 22:59:33.680999: train_loss -0.8082 
2025-01-30 22:59:33.684986: val_loss -0.7484 
2025-01-30 22:59:33.687359: Pseudo dice [np.float32(0.948), np.float32(0.8539)] 
2025-01-30 22:59:33.689815: Epoch time: 47.96 s 
2025-01-30 22:59:34.799744:  
2025-01-30 22:59:34.802411: Epoch 286 
2025-01-30 22:59:34.804880: Current learning rate: 0.00738 
2025-01-30 23:00:22.826321: train_loss -0.8184 
2025-01-30 23:00:22.838655: val_loss -0.7337 
2025-01-30 23:00:22.841124: Pseudo dice [np.float32(0.9563), np.float32(0.8622)] 
2025-01-30 23:00:22.843793: Epoch time: 48.03 s 
2025-01-30 23:00:23.968802:  
2025-01-30 23:00:23.971348: Epoch 287 
2025-01-30 23:00:23.973860: Current learning rate: 0.00738 
2025-01-30 23:01:11.869791: train_loss -0.8183 
2025-01-30 23:01:11.873892: val_loss -0.7443 
2025-01-30 23:01:11.876574: Pseudo dice [np.float32(0.9538), np.float32(0.8365)] 
2025-01-30 23:01:11.879053: Epoch time: 47.9 s 
2025-01-30 23:01:13.041690:  
2025-01-30 23:01:13.044781: Epoch 288 
2025-01-30 23:01:13.047565: Current learning rate: 0.00737 
2025-01-30 23:02:01.118606: train_loss -0.8052 
2025-01-30 23:02:01.124560: val_loss -0.7264 
2025-01-30 23:02:01.127052: Pseudo dice [np.float32(0.9458), np.float32(0.8623)] 
2025-01-30 23:02:01.129366: Epoch time: 48.08 s 
2025-01-30 23:02:02.258328:  
2025-01-30 23:02:02.262479: Epoch 289 
2025-01-30 23:02:02.265571: Current learning rate: 0.00736 
2025-01-30 23:02:50.351141: train_loss -0.8066 
2025-01-30 23:02:50.355237: val_loss -0.681 
2025-01-30 23:02:50.357801: Pseudo dice [np.float32(0.9369), np.float32(0.7154)] 
2025-01-30 23:02:50.360513: Epoch time: 48.09 s 
2025-01-30 23:02:51.489179:  
2025-01-30 23:02:51.491686: Epoch 290 
2025-01-30 23:02:51.494113: Current learning rate: 0.00735 
2025-01-30 23:03:39.481952: train_loss -0.8127 
2025-01-30 23:03:39.487562: val_loss -0.7136 
2025-01-30 23:03:39.490066: Pseudo dice [np.float32(0.9401), np.float32(0.8669)] 
2025-01-30 23:03:39.492271: Epoch time: 47.99 s 
2025-01-30 23:03:40.631338:  
2025-01-30 23:03:40.634549: Epoch 291 
2025-01-30 23:03:40.637667: Current learning rate: 0.00734 
2025-01-30 23:04:28.626609: train_loss -0.8269 
2025-01-30 23:04:28.630327: val_loss -0.6704 
2025-01-30 23:04:28.632845: Pseudo dice [np.float32(0.949), np.float32(0.6004)] 
2025-01-30 23:04:28.635332: Epoch time: 48.0 s 
2025-01-30 23:04:29.751890:  
2025-01-30 23:04:29.754422: Epoch 292 
2025-01-30 23:04:29.757145: Current learning rate: 0.00733 
2025-01-30 23:05:17.570013: train_loss -0.8151 
2025-01-30 23:05:17.580021: val_loss -0.7409 
2025-01-30 23:05:17.582763: Pseudo dice [np.float32(0.9421), np.float32(0.8401)] 
2025-01-30 23:05:17.585298: Epoch time: 47.82 s 
2025-01-30 23:05:18.757219:  
2025-01-30 23:05:18.759897: Epoch 293 
2025-01-30 23:05:18.762279: Current learning rate: 0.00732 
2025-01-30 23:06:06.643980: train_loss -0.7946 
2025-01-30 23:06:06.648391: val_loss -0.73 
2025-01-30 23:06:06.650992: Pseudo dice [np.float32(0.9442), np.float32(0.7787)] 
2025-01-30 23:06:06.653822: Epoch time: 47.89 s 
2025-01-30 23:06:07.769391:  
2025-01-30 23:06:07.772423: Epoch 294 
2025-01-30 23:06:07.775225: Current learning rate: 0.00731 
2025-01-30 23:06:55.909835: train_loss -0.8092 
2025-01-30 23:06:55.915272: val_loss -0.7418 
2025-01-30 23:06:55.918016: Pseudo dice [np.float32(0.9504), np.float32(0.8386)] 
2025-01-30 23:06:55.920593: Epoch time: 48.14 s 
2025-01-30 23:06:57.047707:  
2025-01-30 23:06:57.050678: Epoch 295 
2025-01-30 23:06:57.053326: Current learning rate: 0.0073 
2025-01-30 23:07:45.172661: train_loss -0.8223 
2025-01-30 23:07:45.177141: val_loss -0.7303 
2025-01-30 23:07:45.180008: Pseudo dice [np.float32(0.9317), np.float32(0.8785)] 
2025-01-30 23:07:45.182559: Epoch time: 48.13 s 
2025-01-30 23:07:46.298835:  
2025-01-30 23:07:46.301411: Epoch 296 
2025-01-30 23:07:46.303929: Current learning rate: 0.00729 
2025-01-30 23:08:34.300224: train_loss -0.8073 
2025-01-30 23:08:34.306000: val_loss -0.6968 
2025-01-30 23:08:34.308466: Pseudo dice [np.float32(0.9408), np.float32(0.8091)] 
2025-01-30 23:08:34.311049: Epoch time: 48.0 s 
2025-01-30 23:08:35.472634:  
2025-01-30 23:08:35.475238: Epoch 297 
2025-01-30 23:08:35.477787: Current learning rate: 0.00728 
2025-01-30 23:09:23.717906: train_loss -0.7976 
2025-01-30 23:09:23.722207: val_loss -0.6936 
2025-01-30 23:09:23.725099: Pseudo dice [np.float32(0.9476), np.float32(0.6051)] 
2025-01-30 23:09:23.727894: Epoch time: 48.25 s 
2025-01-30 23:09:24.871431:  
2025-01-30 23:09:24.874643: Epoch 298 
2025-01-30 23:09:24.877367: Current learning rate: 0.00727 
2025-01-30 23:10:12.899991: train_loss -0.8239 
2025-01-30 23:10:12.905518: val_loss -0.7047 
2025-01-30 23:10:12.907939: Pseudo dice [np.float32(0.95), np.float32(0.6283)] 
2025-01-30 23:10:12.910338: Epoch time: 48.03 s 
2025-01-30 23:10:14.025290:  
2025-01-30 23:10:14.028009: Epoch 299 
2025-01-30 23:10:14.030516: Current learning rate: 0.00726 
2025-01-30 23:11:02.375304: train_loss -0.799 
2025-01-30 23:11:02.379952: val_loss -0.7073 
2025-01-30 23:11:02.382631: Pseudo dice [np.float32(0.9444), np.float32(0.7053)] 
2025-01-30 23:11:02.385318: Epoch time: 48.35 s 
2025-01-30 23:11:04.610980:  
2025-01-30 23:11:04.614452: Epoch 300 
2025-01-30 23:11:04.617440: Current learning rate: 0.00725 
2025-01-30 23:11:52.732896: train_loss -0.8073 
2025-01-30 23:11:52.737900: val_loss -0.6925 
2025-01-30 23:11:52.740299: Pseudo dice [np.float32(0.9378), np.float32(0.6366)] 
2025-01-30 23:11:52.742695: Epoch time: 48.12 s 
2025-01-30 23:11:53.870235:  
2025-01-30 23:11:53.872791: Epoch 301 
2025-01-30 23:11:53.875148: Current learning rate: 0.00724 
2025-01-30 23:12:42.215421: train_loss -0.8045 
2025-01-30 23:12:42.219133: val_loss -0.6733 
2025-01-30 23:12:42.221710: Pseudo dice [np.float32(0.9462), np.float32(0.7101)] 
2025-01-30 23:12:42.224156: Epoch time: 48.35 s 
2025-01-30 23:12:43.352521:  
2025-01-30 23:12:43.355752: Epoch 302 
2025-01-30 23:12:43.358283: Current learning rate: 0.00724 
2025-01-30 23:13:31.292034: train_loss -0.7886 
2025-01-30 23:13:31.298373: val_loss -0.6935 
2025-01-30 23:13:31.300992: Pseudo dice [np.float32(0.937), np.float32(0.7156)] 
2025-01-30 23:13:31.303756: Epoch time: 47.94 s 
2025-01-30 23:13:32.425190:  
2025-01-30 23:13:32.428101: Epoch 303 
2025-01-30 23:13:32.430923: Current learning rate: 0.00723 
2025-01-30 23:14:20.521989: train_loss -0.8031 
2025-01-30 23:14:20.525818: val_loss -0.6904 
2025-01-30 23:14:20.528501: Pseudo dice [np.float32(0.9286), np.float32(0.7695)] 
2025-01-30 23:14:20.531472: Epoch time: 48.1 s 
2025-01-30 23:14:21.650909:  
2025-01-30 23:14:21.654766: Epoch 304 
2025-01-30 23:14:21.657362: Current learning rate: 0.00722 
2025-01-30 23:15:09.652203: train_loss -0.7831 
2025-01-30 23:15:09.658046: val_loss -0.6347 
2025-01-30 23:15:09.660630: Pseudo dice [np.float32(0.9184), np.float32(0.7747)] 
2025-01-30 23:15:09.663314: Epoch time: 48.0 s 
2025-01-30 23:15:10.783704:  
2025-01-30 23:15:10.786644: Epoch 305 
2025-01-30 23:15:10.789394: Current learning rate: 0.00721 
2025-01-30 23:15:58.620180: train_loss -0.7827 
2025-01-30 23:15:58.624075: val_loss -0.5853 
2025-01-30 23:15:58.626574: Pseudo dice [np.float32(0.9337), np.float32(0.6475)] 
2025-01-30 23:15:58.629090: Epoch time: 47.84 s 
2025-01-30 23:15:59.751778:  
2025-01-30 23:15:59.754334: Epoch 306 
2025-01-30 23:15:59.757070: Current learning rate: 0.0072 
2025-01-30 23:16:47.799115: train_loss -0.7849 
2025-01-30 23:16:47.805079: val_loss -0.6743 
2025-01-30 23:16:47.807674: Pseudo dice [np.float32(0.9345), np.float32(0.7871)] 
2025-01-30 23:16:47.810087: Epoch time: 48.05 s 
2025-01-30 23:16:48.972043:  
2025-01-30 23:16:48.974449: Epoch 307 
2025-01-30 23:16:48.976980: Current learning rate: 0.00719 
2025-01-30 23:17:37.504089: train_loss -0.7838 
2025-01-30 23:17:37.508747: val_loss -0.653 
2025-01-30 23:17:37.511674: Pseudo dice [np.float32(0.9169), np.float32(0.6884)] 
2025-01-30 23:17:37.514338: Epoch time: 48.53 s 
2025-01-30 23:17:38.680272:  
2025-01-30 23:17:38.682972: Epoch 308 
2025-01-30 23:17:38.685570: Current learning rate: 0.00718 
2025-01-30 23:18:26.638745: train_loss -0.7774 
2025-01-30 23:18:26.644237: val_loss -0.6475 
2025-01-30 23:18:26.646735: Pseudo dice [np.float32(0.9066), np.float32(0.8005)] 
2025-01-30 23:18:26.648831: Epoch time: 47.96 s 
2025-01-30 23:18:27.780424:  
2025-01-30 23:18:27.782923: Epoch 309 
2025-01-30 23:18:27.785386: Current learning rate: 0.00717 
2025-01-30 23:19:15.792882: train_loss -0.7955 
2025-01-30 23:19:15.796942: val_loss -0.6868 
2025-01-30 23:19:15.799367: Pseudo dice [np.float32(0.9498), np.float32(0.8143)] 
2025-01-30 23:19:15.802064: Epoch time: 48.01 s 
2025-01-30 23:19:16.931631:  
2025-01-30 23:19:16.934888: Epoch 310 
2025-01-30 23:19:16.937928: Current learning rate: 0.00716 
2025-01-30 23:20:05.079390: train_loss -0.7944 
2025-01-30 23:20:05.085898: val_loss -0.6862 
2025-01-30 23:20:05.088476: Pseudo dice [np.float32(0.9419), np.float32(0.6665)] 
2025-01-30 23:20:05.091107: Epoch time: 48.15 s 
2025-01-30 23:20:06.211421:  
2025-01-30 23:20:06.214120: Epoch 311 
2025-01-30 23:20:06.216854: Current learning rate: 0.00715 
2025-01-30 23:20:54.180583: train_loss -0.8029 
2025-01-30 23:20:54.184568: val_loss -0.7303 
2025-01-30 23:20:54.187326: Pseudo dice [np.float32(0.9376), np.float32(0.8376)] 
2025-01-30 23:20:54.189917: Epoch time: 47.97 s 
2025-01-30 23:20:55.313468:  
2025-01-30 23:20:55.316322: Epoch 312 
2025-01-30 23:20:55.319314: Current learning rate: 0.00714 
2025-01-30 23:21:43.223481: train_loss -0.7866 
2025-01-30 23:21:43.228982: val_loss -0.6982 
2025-01-30 23:21:43.231395: Pseudo dice [np.float32(0.9495), np.float32(0.8309)] 
2025-01-30 23:21:43.233786: Epoch time: 47.91 s 
2025-01-30 23:21:44.364022:  
2025-01-30 23:21:44.366884: Epoch 313 
2025-01-30 23:21:44.369644: Current learning rate: 0.00713 
2025-01-30 23:22:32.466255: train_loss -0.8203 
2025-01-30 23:22:32.470087: val_loss -0.7198 
2025-01-30 23:22:32.472495: Pseudo dice [np.float32(0.9463), np.float32(0.8418)] 
2025-01-30 23:22:32.474746: Epoch time: 48.1 s 
2025-01-30 23:22:33.599480:  
2025-01-30 23:22:33.602625: Epoch 314 
2025-01-30 23:22:33.605407: Current learning rate: 0.00712 
2025-01-30 23:23:21.622162: train_loss -0.8013 
2025-01-30 23:23:21.629484: val_loss -0.6569 
2025-01-30 23:23:21.632326: Pseudo dice [np.float32(0.9449), np.float32(0.6053)] 
2025-01-30 23:23:21.635335: Epoch time: 48.02 s 
2025-01-30 23:23:22.765390:  
2025-01-30 23:23:22.769463: Epoch 315 
2025-01-30 23:23:22.772239: Current learning rate: 0.00711 
2025-01-30 23:24:10.950597: train_loss -0.8022 
2025-01-30 23:24:10.954348: val_loss -0.7171 
2025-01-30 23:24:10.956775: Pseudo dice [np.float32(0.9395), np.float32(0.8271)] 
2025-01-30 23:24:10.959251: Epoch time: 48.19 s 
2025-01-30 23:24:12.080642:  
2025-01-30 23:24:12.083329: Epoch 316 
2025-01-30 23:24:12.086005: Current learning rate: 0.0071 
2025-01-30 23:25:00.271741: train_loss -0.7947 
2025-01-30 23:25:00.278296: val_loss -0.7294 
2025-01-30 23:25:00.281305: Pseudo dice [np.float32(0.9447), np.float32(0.8442)] 
2025-01-30 23:25:00.284189: Epoch time: 48.19 s 
2025-01-30 23:25:01.415186:  
2025-01-30 23:25:01.418534: Epoch 317 
2025-01-30 23:25:01.421222: Current learning rate: 0.0071 
2025-01-30 23:25:49.464592: train_loss -0.8155 
2025-01-30 23:25:49.468520: val_loss -0.6595 
2025-01-30 23:25:49.471187: Pseudo dice [np.float32(0.932), np.float32(0.7953)] 
2025-01-30 23:25:49.473837: Epoch time: 48.05 s 
2025-01-30 23:25:50.632757:  
2025-01-30 23:25:50.635685: Epoch 318 
2025-01-30 23:25:50.638451: Current learning rate: 0.00709 
2025-01-30 23:26:38.740968: train_loss -0.7915 
2025-01-30 23:26:38.746305: val_loss -0.658 
2025-01-30 23:26:38.748623: Pseudo dice [np.float32(0.9362), np.float32(0.617)] 
2025-01-30 23:26:38.751072: Epoch time: 48.11 s 
2025-01-30 23:26:40.451999:  
2025-01-30 23:26:40.454684: Epoch 319 
2025-01-30 23:26:40.457494: Current learning rate: 0.00708 
2025-01-30 23:27:28.441069: train_loss -0.7881 
2025-01-30 23:27:28.445046: val_loss -0.7158 
2025-01-30 23:27:28.447558: Pseudo dice [np.float32(0.9499), np.float32(0.8002)] 
2025-01-30 23:27:28.449868: Epoch time: 47.99 s 
2025-01-30 23:27:29.581398:  
2025-01-30 23:27:29.584999: Epoch 320 
2025-01-30 23:27:29.587625: Current learning rate: 0.00707 
2025-01-30 23:28:17.837894: train_loss -0.8 
2025-01-30 23:28:17.843292: val_loss -0.7363 
2025-01-30 23:28:17.845829: Pseudo dice [np.float32(0.9397), np.float32(0.8601)] 
2025-01-30 23:28:17.847964: Epoch time: 48.26 s 
2025-01-30 23:28:19.019011:  
2025-01-30 23:28:19.022362: Epoch 321 
2025-01-30 23:28:19.025164: Current learning rate: 0.00706 
2025-01-30 23:29:07.199392: train_loss -0.8044 
2025-01-30 23:29:07.203792: val_loss -0.7103 
2025-01-30 23:29:07.206500: Pseudo dice [np.float32(0.9465), np.float32(0.8317)] 
2025-01-30 23:29:07.209225: Epoch time: 48.18 s 
2025-01-30 23:29:08.338094:  
2025-01-30 23:29:08.341238: Epoch 322 
2025-01-30 23:29:08.344018: Current learning rate: 0.00705 
2025-01-30 23:29:56.377269: train_loss -0.8041 
2025-01-30 23:29:56.382641: val_loss -0.6852 
2025-01-30 23:29:56.385477: Pseudo dice [np.float32(0.9428), np.float32(0.7068)] 
2025-01-30 23:29:56.387959: Epoch time: 48.04 s 
2025-01-30 23:29:57.513576:  
2025-01-30 23:29:57.516263: Epoch 323 
2025-01-30 23:29:57.518722: Current learning rate: 0.00704 
2025-01-30 23:30:45.361450: train_loss -0.8149 
2025-01-30 23:30:45.365165: val_loss -0.7191 
2025-01-30 23:30:45.367835: Pseudo dice [np.float32(0.9499), np.float32(0.7113)] 
2025-01-30 23:30:45.370264: Epoch time: 47.85 s 
2025-01-30 23:30:46.530451:  
2025-01-30 23:30:46.533598: Epoch 324 
2025-01-30 23:30:46.536629: Current learning rate: 0.00703 
2025-01-30 23:31:34.500159: train_loss -0.8113 
2025-01-30 23:31:34.505461: val_loss -0.6908 
2025-01-30 23:31:34.507738: Pseudo dice [np.float32(0.9482), np.float32(0.7177)] 
2025-01-30 23:31:34.509864: Epoch time: 47.97 s 
2025-01-30 23:31:35.634317:  
2025-01-30 23:31:35.636964: Epoch 325 
2025-01-30 23:31:35.639436: Current learning rate: 0.00702 
2025-01-30 23:32:23.672776: train_loss -0.8199 
2025-01-30 23:32:23.677536: val_loss -0.7058 
2025-01-30 23:32:23.680257: Pseudo dice [np.float32(0.9453), np.float32(0.8178)] 
2025-01-30 23:32:23.683186: Epoch time: 48.04 s 
2025-01-30 23:32:24.850208:  
2025-01-30 23:32:24.853894: Epoch 326 
2025-01-30 23:32:24.856811: Current learning rate: 0.00701 
2025-01-30 23:33:12.889240: train_loss -0.8022 
2025-01-30 23:33:12.895725: val_loss -0.7389 
2025-01-30 23:33:12.898230: Pseudo dice [np.float32(0.9502), np.float32(0.8717)] 
2025-01-30 23:33:12.901005: Epoch time: 48.04 s 
2025-01-30 23:33:14.028650:  
2025-01-30 23:33:14.031518: Epoch 327 
2025-01-30 23:33:14.034150: Current learning rate: 0.007 
2025-01-30 23:34:02.053602: train_loss -0.8304 
2025-01-30 23:34:02.057207: val_loss -0.7493 
2025-01-30 23:34:02.059486: Pseudo dice [np.float32(0.9501), np.float32(0.8153)] 
2025-01-30 23:34:02.061841: Epoch time: 48.03 s 
2025-01-30 23:34:03.230092:  
2025-01-30 23:34:03.232609: Epoch 328 
2025-01-30 23:34:03.235109: Current learning rate: 0.00699 
2025-01-30 23:34:51.060232: train_loss -0.8218 
2025-01-30 23:34:51.066633: val_loss -0.6591 
2025-01-30 23:34:51.069342: Pseudo dice [np.float32(0.9447), np.float32(0.5828)] 
2025-01-30 23:34:51.071926: Epoch time: 47.83 s 
2025-01-30 23:34:52.234990:  
2025-01-30 23:34:52.237671: Epoch 329 
2025-01-30 23:34:52.240596: Current learning rate: 0.00698 
2025-01-30 23:35:40.413326: train_loss -0.8152 
2025-01-30 23:35:40.417429: val_loss -0.6124 
2025-01-30 23:35:40.420088: Pseudo dice [np.float32(0.9261), np.float32(0.5765)] 
2025-01-30 23:35:40.422569: Epoch time: 48.18 s 
2025-01-30 23:35:41.550262:  
2025-01-30 23:35:41.553333: Epoch 330 
2025-01-30 23:35:41.556679: Current learning rate: 0.00697 
2025-01-30 23:36:30.022815: train_loss -0.8224 
2025-01-30 23:36:30.028988: val_loss -0.7338 
2025-01-30 23:36:30.031620: Pseudo dice [np.float32(0.9488), np.float32(0.8209)] 
2025-01-30 23:36:30.034308: Epoch time: 48.47 s 
2025-01-30 23:36:31.151542:  
2025-01-30 23:36:31.154562: Epoch 331 
2025-01-30 23:36:31.157241: Current learning rate: 0.00696 
2025-01-30 23:37:19.458888: train_loss -0.8101 
2025-01-30 23:37:19.462739: val_loss -0.7082 
2025-01-30 23:37:19.465160: Pseudo dice [np.float32(0.9393), np.float32(0.81)] 
2025-01-30 23:37:19.467778: Epoch time: 48.31 s 
2025-01-30 23:37:20.590809:  
2025-01-30 23:37:20.593997: Epoch 332 
2025-01-30 23:37:20.596750: Current learning rate: 0.00696 
2025-01-30 23:38:08.636557: train_loss -0.7952 
2025-01-30 23:38:08.642275: val_loss -0.6685 
2025-01-30 23:38:08.645112: Pseudo dice [np.float32(0.945), np.float32(0.7133)] 
2025-01-30 23:38:08.647404: Epoch time: 48.05 s 
2025-01-30 23:38:09.770029:  
2025-01-30 23:38:09.773139: Epoch 333 
2025-01-30 23:38:09.776323: Current learning rate: 0.00695 
2025-01-30 23:38:57.853617: train_loss -0.7747 
2025-01-30 23:38:57.857478: val_loss -0.5987 
2025-01-30 23:38:57.859968: Pseudo dice [np.float32(0.9425), np.float32(0.5258)] 
2025-01-30 23:38:57.862643: Epoch time: 48.08 s 
2025-01-30 23:38:59.031662:  
2025-01-30 23:38:59.034423: Epoch 334 
2025-01-30 23:38:59.036982: Current learning rate: 0.00694 
2025-01-30 23:39:46.988347: train_loss -0.8085 
2025-01-30 23:39:46.994111: val_loss -0.679 
2025-01-30 23:39:46.996831: Pseudo dice [np.float32(0.9366), np.float32(0.8298)] 
2025-01-30 23:39:46.999392: Epoch time: 47.96 s 
2025-01-30 23:39:48.136693:  
2025-01-30 23:39:48.139800: Epoch 335 
2025-01-30 23:39:48.142592: Current learning rate: 0.00693 
2025-01-30 23:40:36.011987: train_loss -0.793 
2025-01-30 23:40:36.015949: val_loss -0.6458 
2025-01-30 23:40:36.018386: Pseudo dice [np.float32(0.9398), np.float32(0.6416)] 
2025-01-30 23:40:36.020846: Epoch time: 47.88 s 
2025-01-30 23:40:37.160068:  
2025-01-30 23:40:37.162658: Epoch 336 
2025-01-30 23:40:37.165218: Current learning rate: 0.00692 
2025-01-30 23:41:25.193617: train_loss -0.7994 
2025-01-30 23:41:25.200648: val_loss -0.723 
2025-01-30 23:41:25.203169: Pseudo dice [np.float32(0.9386), np.float32(0.8617)] 
2025-01-30 23:41:25.205586: Epoch time: 48.03 s 
2025-01-30 23:41:26.923832:  
2025-01-30 23:41:26.926656: Epoch 337 
2025-01-30 23:41:26.929467: Current learning rate: 0.00691 
2025-01-30 23:42:14.874935: train_loss -0.7962 
2025-01-30 23:42:14.878913: val_loss -0.727 
2025-01-30 23:42:14.881597: Pseudo dice [np.float32(0.9481), np.float32(0.7411)] 
2025-01-30 23:42:14.884314: Epoch time: 47.95 s 
2025-01-30 23:42:16.028095:  
2025-01-30 23:42:16.031022: Epoch 338 
2025-01-30 23:42:16.033647: Current learning rate: 0.0069 
2025-01-30 23:43:04.242417: train_loss -0.8194 
2025-01-30 23:43:04.248048: val_loss -0.7526 
2025-01-30 23:43:04.250560: Pseudo dice [np.float32(0.9481), np.float32(0.8726)] 
2025-01-30 23:43:04.253042: Epoch time: 48.22 s 
2025-01-30 23:43:05.398118:  
2025-01-30 23:43:05.401231: Epoch 339 
2025-01-30 23:43:05.403849: Current learning rate: 0.00689 
2025-01-30 23:43:53.571578: train_loss -0.7911 
2025-01-30 23:43:53.576055: val_loss -0.7239 
2025-01-30 23:43:53.578851: Pseudo dice [np.float32(0.941), np.float32(0.8341)] 
2025-01-30 23:43:53.581610: Epoch time: 48.17 s 
2025-01-30 23:43:54.721674:  
2025-01-30 23:43:54.724357: Epoch 340 
2025-01-30 23:43:54.727016: Current learning rate: 0.00688 
2025-01-30 23:44:42.882123: train_loss -0.8022 
2025-01-30 23:44:42.887927: val_loss -0.7017 
2025-01-30 23:44:42.890590: Pseudo dice [np.float32(0.9448), np.float32(0.7752)] 
2025-01-30 23:44:42.893255: Epoch time: 48.16 s 
2025-01-30 23:44:44.073808:  
2025-01-30 23:44:44.076899: Epoch 341 
2025-01-30 23:44:44.079649: Current learning rate: 0.00687 
2025-01-30 23:45:32.384067: train_loss -0.8185 
2025-01-30 23:45:32.388301: val_loss -0.7156 
2025-01-30 23:45:32.390633: Pseudo dice [np.float32(0.9491), np.float32(0.8657)] 
2025-01-30 23:45:32.393078: Epoch time: 48.31 s 
2025-01-30 23:45:33.536306:  
2025-01-30 23:45:33.538979: Epoch 342 
2025-01-30 23:45:33.541504: Current learning rate: 0.00686 
2025-01-30 23:46:21.842559: train_loss -0.8033 
2025-01-30 23:46:21.848320: val_loss -0.6901 
2025-01-30 23:46:21.850796: Pseudo dice [np.float32(0.932), np.float32(0.7746)] 
2025-01-30 23:46:21.853344: Epoch time: 48.31 s 
2025-01-30 23:46:22.991232:  
2025-01-30 23:46:22.994033: Epoch 343 
2025-01-30 23:46:22.997047: Current learning rate: 0.00685 
2025-01-30 23:47:10.807284: train_loss -0.8105 
2025-01-30 23:47:10.811445: val_loss -0.6456 
2025-01-30 23:47:10.814019: Pseudo dice [np.float32(0.945), np.float32(0.6061)] 
2025-01-30 23:47:10.816643: Epoch time: 47.82 s 
2025-01-30 23:47:11.958441:  
2025-01-30 23:47:11.961611: Epoch 344 
2025-01-30 23:47:11.964394: Current learning rate: 0.00684 
2025-01-30 23:47:59.890486: train_loss -0.8164 
2025-01-30 23:47:59.897036: val_loss -0.5756 
2025-01-30 23:47:59.900024: Pseudo dice [np.float32(0.9446), np.float32(0.3874)] 
2025-01-30 23:47:59.904566: Epoch time: 47.93 s 
2025-01-30 23:48:01.053143:  
2025-01-30 23:48:01.056080: Epoch 345 
2025-01-30 23:48:01.058771: Current learning rate: 0.00683 
2025-01-30 23:48:49.087263: train_loss -0.8337 
2025-01-30 23:48:49.091650: val_loss -0.6674 
2025-01-30 23:48:49.094311: Pseudo dice [np.float32(0.9545), np.float32(0.6576)] 
2025-01-30 23:48:49.096568: Epoch time: 48.04 s 
2025-01-30 23:48:50.237519:  
2025-01-30 23:48:50.240547: Epoch 346 
2025-01-30 23:48:50.243101: Current learning rate: 0.00682 
2025-01-30 23:49:38.392714: train_loss -0.8122 
2025-01-30 23:49:38.399621: val_loss -0.7224 
2025-01-30 23:49:38.402433: Pseudo dice [np.float32(0.9495), np.float32(0.8606)] 
2025-01-30 23:49:38.405279: Epoch time: 48.16 s 
2025-01-30 23:49:39.543101:  
2025-01-30 23:49:39.545586: Epoch 347 
2025-01-30 23:49:39.547929: Current learning rate: 0.00681 
2025-01-30 23:50:27.544098: train_loss -0.8412 
2025-01-30 23:50:27.547954: val_loss -0.6585 
2025-01-30 23:50:27.550325: Pseudo dice [np.float32(0.9479), np.float32(0.6463)] 
2025-01-30 23:50:27.552699: Epoch time: 48.0 s 
2025-01-30 23:50:28.744182:  
2025-01-30 23:50:28.746952: Epoch 348 
2025-01-30 23:50:28.749588: Current learning rate: 0.0068 
2025-01-30 23:51:16.591893: train_loss -0.8134 
2025-01-30 23:51:16.598928: val_loss -0.6614 
2025-01-30 23:51:16.601953: Pseudo dice [np.float32(0.9455), np.float32(0.6938)] 
2025-01-30 23:51:16.604794: Epoch time: 47.85 s 
2025-01-30 23:51:17.785757:  
2025-01-30 23:51:17.788530: Epoch 349 
2025-01-30 23:51:17.791052: Current learning rate: 0.0068 
2025-01-30 23:52:06.054499: train_loss -0.8122 
2025-01-30 23:52:06.058639: val_loss -0.6716 
2025-01-30 23:52:06.061372: Pseudo dice [np.float32(0.9376), np.float32(0.6317)] 
2025-01-30 23:52:06.063991: Epoch time: 48.27 s 
2025-01-30 23:52:07.822464:  
2025-01-30 23:52:07.825462: Epoch 350 
2025-01-30 23:52:07.828268: Current learning rate: 0.00679 
2025-01-30 23:52:55.910386: train_loss -0.8211 
2025-01-30 23:52:55.917073: val_loss -0.6947 
2025-01-30 23:52:55.920192: Pseudo dice [np.float32(0.9502), np.float32(0.8044)] 
2025-01-30 23:52:55.923377: Epoch time: 48.09 s 
2025-01-30 23:52:57.104539:  
2025-01-30 23:52:57.107383: Epoch 351 
2025-01-30 23:52:57.109965: Current learning rate: 0.00678 
2025-01-30 23:53:45.065593: train_loss -0.8252 
2025-01-30 23:53:45.069405: val_loss -0.7425 
2025-01-30 23:53:45.072160: Pseudo dice [np.float32(0.945), np.float32(0.7835)] 
2025-01-30 23:53:45.074700: Epoch time: 47.96 s 
2025-01-30 23:53:46.213034:  
2025-01-30 23:53:46.215956: Epoch 352 
2025-01-30 23:53:46.218401: Current learning rate: 0.00677 
2025-01-30 23:54:34.143934: train_loss -0.8173 
2025-01-30 23:54:34.150531: val_loss -0.6773 
2025-01-30 23:54:34.153464: Pseudo dice [np.float32(0.9436), np.float32(0.6609)] 
2025-01-30 23:54:34.156262: Epoch time: 47.93 s 
2025-01-30 23:54:35.297004:  
2025-01-30 23:54:35.299726: Epoch 353 
2025-01-30 23:54:35.302285: Current learning rate: 0.00676 
2025-01-30 23:55:23.197868: train_loss -0.8125 
2025-01-30 23:55:23.201961: val_loss -0.6972 
2025-01-30 23:55:23.204867: Pseudo dice [np.float32(0.9371), np.float32(0.7439)] 
2025-01-30 23:55:23.207553: Epoch time: 47.9 s 
2025-01-30 23:55:24.349549:  
2025-01-30 23:55:24.353137: Epoch 354 
2025-01-30 23:55:24.355818: Current learning rate: 0.00675 
2025-01-30 23:56:12.501243: train_loss -0.8086 
2025-01-30 23:56:12.510252: val_loss -0.6679 
2025-01-30 23:56:12.513087: Pseudo dice [np.float32(0.9466), np.float32(0.6243)] 
2025-01-30 23:56:12.515640: Epoch time: 48.15 s 
2025-01-30 23:56:13.664430:  
2025-01-30 23:56:13.667195: Epoch 355 
2025-01-30 23:56:13.670121: Current learning rate: 0.00674 
2025-01-30 23:57:01.553083: train_loss -0.8055 
2025-01-30 23:57:01.608372: val_loss -0.6615 
2025-01-30 23:57:01.611342: Pseudo dice [np.float32(0.9412), np.float32(0.7847)] 
2025-01-30 23:57:01.613895: Epoch time: 47.89 s 
2025-01-30 23:57:03.281323:  
2025-01-30 23:57:03.284126: Epoch 356 
2025-01-30 23:57:03.287153: Current learning rate: 0.00673 
2025-01-30 23:57:51.365702: train_loss -0.812 
2025-01-30 23:57:51.374535: val_loss -0.6745 
2025-01-30 23:57:51.377074: Pseudo dice [np.float32(0.9479), np.float32(0.7428)] 
2025-01-30 23:57:51.380195: Epoch time: 48.09 s 
2025-01-30 23:57:52.561203:  
2025-01-30 23:57:52.564188: Epoch 357 
2025-01-30 23:57:52.566762: Current learning rate: 0.00672 
2025-01-30 23:58:40.915329: train_loss -0.8158 
2025-01-30 23:58:40.922219: val_loss -0.7367 
2025-01-30 23:58:40.925007: Pseudo dice [np.float32(0.9409), np.float32(0.897)] 
2025-01-30 23:58:40.927617: Epoch time: 48.35 s 
2025-01-30 23:58:42.068870:  
2025-01-30 23:58:42.071743: Epoch 358 
2025-01-30 23:58:42.074574: Current learning rate: 0.00671 
2025-01-30 23:59:30.378071: train_loss -0.8137 
2025-01-30 23:59:30.384515: val_loss -0.705 
2025-01-30 23:59:30.387088: Pseudo dice [np.float32(0.9308), np.float32(0.85)] 
2025-01-30 23:59:30.389700: Epoch time: 48.31 s 
2025-01-30 23:59:31.535995:  
2025-01-30 23:59:31.538865: Epoch 359 
2025-01-30 23:59:31.541622: Current learning rate: 0.0067 
2025-01-31 00:00:19.622751: train_loss -0.8127 
2025-01-31 00:00:19.630379: val_loss -0.6827 
2025-01-31 00:00:19.633240: Pseudo dice [np.float32(0.9282), np.float32(0.7022)] 
2025-01-31 00:00:19.636476: Epoch time: 48.09 s 
2025-01-31 00:00:20.817064:  
2025-01-31 00:00:20.820351: Epoch 360 
2025-01-31 00:00:20.822988: Current learning rate: 0.00669 
2025-01-31 00:01:08.597904: train_loss -0.8213 
2025-01-31 00:01:08.606375: val_loss -0.7421 
2025-01-31 00:01:08.609297: Pseudo dice [np.float32(0.951), np.float32(0.8328)] 
2025-01-31 00:01:08.611869: Epoch time: 47.78 s 
2025-01-31 00:01:09.762245:  
2025-01-31 00:01:09.765630: Epoch 361 
2025-01-31 00:01:09.768622: Current learning rate: 0.00668 
2025-01-31 00:01:57.837664: train_loss -0.8084 
2025-01-31 00:01:57.844850: val_loss -0.7715 
2025-01-31 00:01:57.847861: Pseudo dice [np.float32(0.9484), np.float32(0.8339)] 
2025-01-31 00:01:57.851053: Epoch time: 48.08 s 
2025-01-31 00:01:59.004436:  
2025-01-31 00:01:59.007358: Epoch 362 
2025-01-31 00:01:59.010315: Current learning rate: 0.00667 
2025-01-31 00:02:46.948963: train_loss -0.8218 
2025-01-31 00:02:46.957171: val_loss -0.7292 
2025-01-31 00:02:46.960140: Pseudo dice [np.float32(0.9445), np.float32(0.84)] 
2025-01-31 00:02:46.962783: Epoch time: 47.95 s 
2025-01-31 00:02:48.101130:  
2025-01-31 00:02:48.104088: Epoch 363 
2025-01-31 00:02:48.106661: Current learning rate: 0.00666 
2025-01-31 00:03:35.820061: train_loss -0.8164 
2025-01-31 00:03:35.826021: val_loss -0.6154 
2025-01-31 00:03:35.828496: Pseudo dice [np.float32(0.9429), np.float32(0.4501)] 
2025-01-31 00:03:35.831069: Epoch time: 47.72 s 
2025-01-31 00:03:36.974507:  
2025-01-31 00:03:36.977376: Epoch 364 
2025-01-31 00:03:36.980323: Current learning rate: 0.00665 
2025-01-31 00:04:25.314350: train_loss -0.8044 
2025-01-31 00:04:25.320500: val_loss -0.7036 
2025-01-31 00:04:25.323275: Pseudo dice [np.float32(0.9487), np.float32(0.8421)] 
2025-01-31 00:04:25.325919: Epoch time: 48.34 s 
2025-01-31 00:04:26.487270:  
2025-01-31 00:04:26.489845: Epoch 365 
2025-01-31 00:04:26.492319: Current learning rate: 0.00665 
2025-01-31 00:05:14.452357: train_loss -0.7751 
2025-01-31 00:05:14.457346: val_loss -0.7158 
2025-01-31 00:05:14.460015: Pseudo dice [np.float32(0.9428), np.float32(0.6706)] 
2025-01-31 00:05:14.462780: Epoch time: 47.97 s 
2025-01-31 00:05:15.612400:  
2025-01-31 00:05:15.614813: Epoch 366 
2025-01-31 00:05:15.617631: Current learning rate: 0.00664 
2025-01-31 00:06:03.605957: train_loss -0.8119 
2025-01-31 00:06:03.611644: val_loss -0.6773 
2025-01-31 00:06:03.614558: Pseudo dice [np.float32(0.9473), np.float32(0.6249)] 
2025-01-31 00:06:03.617138: Epoch time: 47.99 s 
2025-01-31 00:06:04.765041:  
2025-01-31 00:06:04.767942: Epoch 367 
2025-01-31 00:06:04.770578: Current learning rate: 0.00663 
2025-01-31 00:06:52.891060: train_loss -0.8066 
2025-01-31 00:06:52.894756: val_loss -0.7274 
2025-01-31 00:06:52.897495: Pseudo dice [np.float32(0.9473), np.float32(0.7603)] 
2025-01-31 00:06:52.900053: Epoch time: 48.13 s 
2025-01-31 00:06:54.045008:  
2025-01-31 00:06:54.047528: Epoch 368 
2025-01-31 00:06:54.049993: Current learning rate: 0.00662 
2025-01-31 00:07:42.424549: train_loss -0.8167 
2025-01-31 00:07:42.429757: val_loss -0.6944 
2025-01-31 00:07:42.432142: Pseudo dice [np.float32(0.9473), np.float32(0.6692)] 
2025-01-31 00:07:42.434875: Epoch time: 48.38 s 
2025-01-31 00:07:43.614513:  
2025-01-31 00:07:43.617598: Epoch 369 
2025-01-31 00:07:43.620311: Current learning rate: 0.00661 
2025-01-31 00:08:32.063020: train_loss -0.8101 
2025-01-31 00:08:32.066843: val_loss -0.7027 
2025-01-31 00:08:32.069499: Pseudo dice [np.float32(0.9534), np.float32(0.7409)] 
2025-01-31 00:08:32.072076: Epoch time: 48.45 s 
2025-01-31 00:08:33.219910:  
2025-01-31 00:08:33.222706: Epoch 370 
2025-01-31 00:08:33.225433: Current learning rate: 0.0066 
2025-01-31 00:09:21.423665: train_loss -0.83 
2025-01-31 00:09:21.430294: val_loss -0.7246 
2025-01-31 00:09:21.433093: Pseudo dice [np.float32(0.9509), np.float32(0.6787)] 
2025-01-31 00:09:21.435692: Epoch time: 48.2 s 
2025-01-31 00:09:22.585752:  
2025-01-31 00:09:22.588706: Epoch 371 
2025-01-31 00:09:22.591649: Current learning rate: 0.00659 
2025-01-31 00:10:10.724231: train_loss -0.8069 
2025-01-31 00:10:10.728402: val_loss -0.6783 
2025-01-31 00:10:10.731383: Pseudo dice [np.float32(0.9363), np.float32(0.8076)] 
2025-01-31 00:10:10.733937: Epoch time: 48.14 s 
2025-01-31 00:10:11.923337:  
2025-01-31 00:10:11.926279: Epoch 372 
2025-01-31 00:10:11.928881: Current learning rate: 0.00658 
2025-01-31 00:10:59.932036: train_loss -0.8132 
2025-01-31 00:10:59.937679: val_loss -0.6616 
2025-01-31 00:10:59.940250: Pseudo dice [np.float32(0.9501), np.float32(0.6276)] 
2025-01-31 00:10:59.942967: Epoch time: 48.01 s 
2025-01-31 00:11:01.089726:  
2025-01-31 00:11:01.092406: Epoch 373 
2025-01-31 00:11:01.095215: Current learning rate: 0.00657 
2025-01-31 00:11:49.754854: train_loss -0.8296 
2025-01-31 00:11:49.758670: val_loss -0.6968 
2025-01-31 00:11:49.761181: Pseudo dice [np.float32(0.941), np.float32(0.8018)] 
2025-01-31 00:11:49.763783: Epoch time: 48.67 s 
2025-01-31 00:11:50.911452:  
2025-01-31 00:11:50.914083: Epoch 374 
2025-01-31 00:11:50.916672: Current learning rate: 0.00656 
2025-01-31 00:12:39.056663: train_loss -0.8325 
2025-01-31 00:12:39.061819: val_loss -0.6615 
2025-01-31 00:12:39.064395: Pseudo dice [np.float32(0.954), np.float32(0.604)] 
2025-01-31 00:12:39.066797: Epoch time: 48.15 s 
2025-01-31 00:12:40.220936:  
2025-01-31 00:12:40.224601: Epoch 375 
2025-01-31 00:12:40.227703: Current learning rate: 0.00655 
2025-01-31 00:13:28.389521: train_loss -0.8274 
2025-01-31 00:13:28.393736: val_loss -0.644 
2025-01-31 00:13:28.396962: Pseudo dice [np.float32(0.9466), np.float32(0.6703)] 
2025-01-31 00:13:28.399596: Epoch time: 48.17 s 
2025-01-31 00:13:29.548276:  
2025-01-31 00:13:29.554931: Epoch 376 
2025-01-31 00:13:29.560149: Current learning rate: 0.00654 
2025-01-31 00:14:17.749031: train_loss -0.8184 
2025-01-31 00:14:17.753864: val_loss -0.7336 
2025-01-31 00:14:17.756212: Pseudo dice [np.float32(0.9326), np.float32(0.8487)] 
2025-01-31 00:14:17.758538: Epoch time: 48.2 s 
2025-01-31 00:14:18.912791:  
2025-01-31 00:14:18.915838: Epoch 377 
2025-01-31 00:14:18.918500: Current learning rate: 0.00653 
2025-01-31 00:15:06.791976: train_loss -0.8234 
2025-01-31 00:15:06.795775: val_loss -0.6669 
2025-01-31 00:15:06.798203: Pseudo dice [np.float32(0.9347), np.float32(0.7358)] 
2025-01-31 00:15:06.800594: Epoch time: 47.88 s 
2025-01-31 00:15:07.995710:  
2025-01-31 00:15:07.998394: Epoch 378 
2025-01-31 00:15:08.001232: Current learning rate: 0.00652 
2025-01-31 00:15:56.029806: train_loss -0.8025 
2025-01-31 00:15:56.035984: val_loss -0.6603 
2025-01-31 00:15:56.038647: Pseudo dice [np.float32(0.9261), np.float32(0.6654)] 
2025-01-31 00:15:56.041323: Epoch time: 48.03 s 
2025-01-31 00:15:57.194255:  
2025-01-31 00:15:57.197289: Epoch 379 
2025-01-31 00:15:57.199979: Current learning rate: 0.00651 
2025-01-31 00:16:45.351765: train_loss -0.8121 
2025-01-31 00:16:45.355956: val_loss -0.6881 
2025-01-31 00:16:45.358469: Pseudo dice [np.float32(0.9382), np.float32(0.7538)] 
2025-01-31 00:16:45.360967: Epoch time: 48.16 s 
2025-01-31 00:16:46.513813:  
2025-01-31 00:16:46.516827: Epoch 380 
2025-01-31 00:16:46.519482: Current learning rate: 0.0065 
2025-01-31 00:17:34.469383: train_loss -0.7971 
2025-01-31 00:17:34.474697: val_loss -0.7008 
2025-01-31 00:17:34.477500: Pseudo dice [np.float32(0.9449), np.float32(0.8049)] 
2025-01-31 00:17:34.480109: Epoch time: 47.96 s 
2025-01-31 00:17:35.667892:  
2025-01-31 00:17:35.670668: Epoch 381 
2025-01-31 00:17:35.675511: Current learning rate: 0.00649 
2025-01-31 00:18:23.809793: train_loss -0.8104 
2025-01-31 00:18:23.817185: val_loss -0.7587 
2025-01-31 00:18:23.819914: Pseudo dice [np.float32(0.947), np.float32(0.8859)] 
2025-01-31 00:18:23.822619: Epoch time: 48.14 s 
2025-01-31 00:18:25.016397:  
2025-01-31 00:18:25.019178: Epoch 382 
2025-01-31 00:18:25.021794: Current learning rate: 0.00648 
2025-01-31 00:19:13.408587: train_loss -0.82 
2025-01-31 00:19:13.417806: val_loss -0.625 
2025-01-31 00:19:13.421037: Pseudo dice [np.float32(0.9395), np.float32(0.7038)] 
2025-01-31 00:19:13.424992: Epoch time: 48.39 s 
2025-01-31 00:19:14.589502:  
2025-01-31 00:19:14.592790: Epoch 383 
2025-01-31 00:19:14.596004: Current learning rate: 0.00648 
2025-01-31 00:20:02.539733: train_loss -0.8199 
2025-01-31 00:20:02.545699: val_loss -0.7485 
2025-01-31 00:20:02.548938: Pseudo dice [np.float32(0.9356), np.float32(0.8887)] 
2025-01-31 00:20:02.551885: Epoch time: 47.95 s 
2025-01-31 00:20:03.756910:  
2025-01-31 00:20:03.759816: Epoch 384 
2025-01-31 00:20:03.762558: Current learning rate: 0.00647 
2025-01-31 00:20:51.766766: train_loss -0.8179 
2025-01-31 00:20:51.772380: val_loss -0.6771 
2025-01-31 00:20:51.774919: Pseudo dice [np.float32(0.9376), np.float32(0.7669)] 
2025-01-31 00:20:51.777601: Epoch time: 48.01 s 
2025-01-31 00:20:52.985088:  
2025-01-31 00:20:52.987825: Epoch 385 
2025-01-31 00:20:52.990789: Current learning rate: 0.00646 
2025-01-31 00:21:40.873308: train_loss -0.8178 
2025-01-31 00:21:40.880025: val_loss -0.7357 
2025-01-31 00:21:40.882609: Pseudo dice [np.float32(0.9428), np.float32(0.8884)] 
2025-01-31 00:21:40.885247: Epoch time: 47.89 s 
2025-01-31 00:21:42.095097:  
2025-01-31 00:21:42.098744: Epoch 386 
2025-01-31 00:21:42.101623: Current learning rate: 0.00645 
2025-01-31 00:22:29.940117: train_loss -0.8233 
2025-01-31 00:22:29.948917: val_loss -0.7258 
2025-01-31 00:22:29.951853: Pseudo dice [np.float32(0.9464), np.float32(0.8822)] 
2025-01-31 00:22:29.954767: Epoch time: 47.85 s 
2025-01-31 00:22:31.116523:  
2025-01-31 00:22:31.119956: Epoch 387 
2025-01-31 00:22:31.122950: Current learning rate: 0.00644 
2025-01-31 00:23:19.056969: train_loss -0.8105 
2025-01-31 00:23:19.060914: val_loss -0.7487 
2025-01-31 00:23:19.064128: Pseudo dice [np.float32(0.9483), np.float32(0.8907)] 
2025-01-31 00:23:19.066452: Epoch time: 47.94 s 
2025-01-31 00:23:20.241171:  
2025-01-31 00:23:20.244308: Epoch 388 
2025-01-31 00:23:20.247064: Current learning rate: 0.00643 
2025-01-31 00:24:08.225271: train_loss -0.8059 
2025-01-31 00:24:08.230085: val_loss -0.7292 
2025-01-31 00:24:08.232398: Pseudo dice [np.float32(0.9515), np.float32(0.8258)] 
2025-01-31 00:24:08.234866: Epoch time: 47.99 s 
2025-01-31 00:24:08.237206: Yayy! New best EMA pseudo Dice: 0.8698999881744385 
2025-01-31 00:24:09.959161:  
2025-01-31 00:24:09.962077: Epoch 389 
2025-01-31 00:24:09.964944: Current learning rate: 0.00642 
2025-01-31 00:24:57.773637: train_loss -0.825 
2025-01-31 00:24:57.780938: val_loss -0.6765 
2025-01-31 00:24:57.783773: Pseudo dice [np.float32(0.9382), np.float32(0.8077)] 
2025-01-31 00:24:57.786634: Epoch time: 47.82 s 
2025-01-31 00:24:57.789295: Yayy! New best EMA pseudo Dice: 0.870199978351593 
2025-01-31 00:24:59.559824:  
2025-01-31 00:24:59.563045: Epoch 390 
2025-01-31 00:24:59.565863: Current learning rate: 0.00641 
2025-01-31 00:25:47.708787: train_loss -0.8002 
2025-01-31 00:25:47.713548: val_loss -0.7173 
2025-01-31 00:25:47.716030: Pseudo dice [np.float32(0.9407), np.float32(0.8232)] 
2025-01-31 00:25:47.718292: Epoch time: 48.15 s 
2025-01-31 00:25:47.720423: Yayy! New best EMA pseudo Dice: 0.871399998664856 
2025-01-31 00:25:49.991241:  
2025-01-31 00:25:49.994060: Epoch 391 
2025-01-31 00:25:49.997112: Current learning rate: 0.0064 
2025-01-31 00:26:38.066852: train_loss -0.826 
2025-01-31 00:26:38.070852: val_loss -0.7073 
2025-01-31 00:26:38.073281: Pseudo dice [np.float32(0.9482), np.float32(0.8667)] 
2025-01-31 00:26:38.075887: Epoch time: 48.08 s 
2025-01-31 00:26:38.078115: Yayy! New best EMA pseudo Dice: 0.875 
2025-01-31 00:26:39.816142:  
2025-01-31 00:26:39.818968: Epoch 392 
2025-01-31 00:26:39.821758: Current learning rate: 0.00639 
2025-01-31 00:27:27.533501: train_loss -0.8007 
2025-01-31 00:27:27.538345: val_loss -0.7604 
2025-01-31 00:27:27.540906: Pseudo dice [np.float32(0.9494), np.float32(0.7596)] 
2025-01-31 00:27:27.543454: Epoch time: 47.72 s 
2025-01-31 00:27:28.738849:  
2025-01-31 00:27:28.742776: Epoch 393 
2025-01-31 00:27:28.745835: Current learning rate: 0.00638 
2025-01-31 00:28:17.006650: train_loss -0.8094 
2025-01-31 00:28:17.011137: val_loss -0.6335 
2025-01-31 00:28:17.014074: Pseudo dice [np.float32(0.9441), np.float32(0.5763)] 
2025-01-31 00:28:17.016643: Epoch time: 48.27 s 
2025-01-31 00:28:18.232227:  
2025-01-31 00:28:18.235730: Epoch 394 
2025-01-31 00:28:18.239043: Current learning rate: 0.00637 
2025-01-31 00:29:06.697460: train_loss -0.8157 
2025-01-31 00:29:06.703306: val_loss -0.6687 
2025-01-31 00:29:06.706027: Pseudo dice [np.float32(0.9444), np.float32(0.5674)] 
2025-01-31 00:29:06.708812: Epoch time: 48.47 s 
2025-01-31 00:29:07.886075:  
2025-01-31 00:29:07.889417: Epoch 395 
2025-01-31 00:29:07.892307: Current learning rate: 0.00636 
2025-01-31 00:29:56.183969: train_loss -0.8254 
2025-01-31 00:29:56.187712: val_loss -0.7065 
2025-01-31 00:29:56.190259: Pseudo dice [np.float32(0.9481), np.float32(0.7325)] 
2025-01-31 00:29:56.192795: Epoch time: 48.3 s 
2025-01-31 00:29:57.351932:  
2025-01-31 00:29:57.355052: Epoch 396 
2025-01-31 00:29:57.358155: Current learning rate: 0.00635 
2025-01-31 00:30:45.495908: train_loss -0.8222 
2025-01-31 00:30:45.502079: val_loss -0.7041 
2025-01-31 00:30:45.505133: Pseudo dice [np.float32(0.9399), np.float32(0.8164)] 
2025-01-31 00:30:45.508121: Epoch time: 48.14 s 
2025-01-31 00:30:46.668970:  
2025-01-31 00:30:46.673122: Epoch 397 
2025-01-31 00:30:46.675985: Current learning rate: 0.00634 
2025-01-31 00:31:34.999914: train_loss -0.8066 
2025-01-31 00:31:35.004086: val_loss -0.6932 
2025-01-31 00:31:35.006948: Pseudo dice [np.float32(0.9501), np.float32(0.557)] 
2025-01-31 00:31:35.010082: Epoch time: 48.33 s 
2025-01-31 00:31:36.180824:  
2025-01-31 00:31:36.183722: Epoch 398 
2025-01-31 00:31:36.186522: Current learning rate: 0.00633 
2025-01-31 00:32:24.407169: train_loss -0.829 
2025-01-31 00:32:24.412372: val_loss -0.676 
2025-01-31 00:32:24.415191: Pseudo dice [np.float32(0.9364), np.float32(0.7444)] 
2025-01-31 00:32:24.417789: Epoch time: 48.23 s 
2025-01-31 00:32:25.581720:  
2025-01-31 00:32:25.584568: Epoch 399 
2025-01-31 00:32:25.587062: Current learning rate: 0.00632 
2025-01-31 00:33:13.504339: train_loss -0.8217 
2025-01-31 00:33:13.508305: val_loss -0.6799 
2025-01-31 00:33:13.510834: Pseudo dice [np.float32(0.9582), np.float32(0.5541)] 
2025-01-31 00:33:13.513330: Epoch time: 47.92 s 
2025-01-31 00:33:15.254848:  
2025-01-31 00:33:15.257531: Epoch 400 
2025-01-31 00:33:15.260073: Current learning rate: 0.00631 
2025-01-31 00:34:03.201303: train_loss -0.8271 
2025-01-31 00:34:03.207248: val_loss -0.677 
2025-01-31 00:34:03.209828: Pseudo dice [np.float32(0.9397), np.float32(0.7088)] 
2025-01-31 00:34:03.212547: Epoch time: 47.95 s 
2025-01-31 00:34:04.378171:  
2025-01-31 00:34:04.383705: Epoch 401 
2025-01-31 00:34:04.386552: Current learning rate: 0.0063 
2025-01-31 00:34:52.546045: train_loss -0.8074 
2025-01-31 00:34:52.551051: val_loss -0.7302 
2025-01-31 00:34:52.554211: Pseudo dice [np.float32(0.9415), np.float32(0.7464)] 
2025-01-31 00:34:52.557540: Epoch time: 48.17 s 
2025-01-31 00:34:53.764987:  
2025-01-31 00:34:53.768013: Epoch 402 
2025-01-31 00:34:53.770689: Current learning rate: 0.0063 
2025-01-31 00:35:41.825743: train_loss -0.8079 
2025-01-31 00:35:41.831614: val_loss -0.6976 
2025-01-31 00:35:41.834290: Pseudo dice [np.float32(0.9565), np.float32(0.6905)] 
2025-01-31 00:35:41.836839: Epoch time: 48.06 s 
2025-01-31 00:35:43.029838:  
2025-01-31 00:35:43.032673: Epoch 403 
2025-01-31 00:35:43.035301: Current learning rate: 0.00629 
2025-01-31 00:36:31.008730: train_loss -0.8414 
2025-01-31 00:36:31.012813: val_loss -0.7182 
2025-01-31 00:36:31.015357: Pseudo dice [np.float32(0.9474), np.float32(0.7094)] 
2025-01-31 00:36:31.017922: Epoch time: 47.98 s 
2025-01-31 00:36:32.219098:  
2025-01-31 00:36:32.222194: Epoch 404 
2025-01-31 00:36:32.224737: Current learning rate: 0.00628 
2025-01-31 00:37:20.221967: train_loss -0.8316 
2025-01-31 00:37:20.227903: val_loss -0.6129 
2025-01-31 00:37:20.230318: Pseudo dice [np.float32(0.9451), np.float32(0.5541)] 
2025-01-31 00:37:20.232947: Epoch time: 48.0 s 
2025-01-31 00:37:21.401772:  
2025-01-31 00:37:21.404770: Epoch 405 
2025-01-31 00:37:21.407235: Current learning rate: 0.00627 
2025-01-31 00:38:09.347368: train_loss -0.825 
2025-01-31 00:38:09.351598: val_loss -0.6061 
2025-01-31 00:38:09.354542: Pseudo dice [np.float32(0.9421), np.float32(0.6818)] 
2025-01-31 00:38:09.357152: Epoch time: 47.95 s 
2025-01-31 00:38:10.517999:  
2025-01-31 00:38:10.521147: Epoch 406 
2025-01-31 00:38:10.524561: Current learning rate: 0.00626 
2025-01-31 00:38:58.923007: train_loss -0.8313 
2025-01-31 00:38:58.929041: val_loss -0.7059 
2025-01-31 00:38:58.931855: Pseudo dice [np.float32(0.9524), np.float32(0.7913)] 
2025-01-31 00:38:58.934735: Epoch time: 48.41 s 
2025-01-31 00:39:00.101710:  
2025-01-31 00:39:00.104602: Epoch 407 
2025-01-31 00:39:00.107174: Current learning rate: 0.00625 
2025-01-31 00:39:48.121762: train_loss -0.837 
2025-01-31 00:39:48.126690: val_loss -0.6758 
2025-01-31 00:39:48.129249: Pseudo dice [np.float32(0.9379), np.float32(0.7775)] 
2025-01-31 00:39:48.132325: Epoch time: 48.02 s 
2025-01-31 00:39:49.295493:  
2025-01-31 00:39:49.298404: Epoch 408 
2025-01-31 00:39:49.301171: Current learning rate: 0.00624 
2025-01-31 00:40:37.219442: train_loss -0.8156 
2025-01-31 00:40:37.225034: val_loss -0.7176 
2025-01-31 00:40:37.227548: Pseudo dice [np.float32(0.9504), np.float32(0.7717)] 
2025-01-31 00:40:37.230019: Epoch time: 47.92 s 
2025-01-31 00:40:38.948594:  
2025-01-31 00:40:38.951766: Epoch 409 
2025-01-31 00:40:38.954534: Current learning rate: 0.00623 
2025-01-31 00:41:27.007669: train_loss -0.8257 
2025-01-31 00:41:27.011999: val_loss -0.7198 
2025-01-31 00:41:27.014676: Pseudo dice [np.float32(0.9371), np.float32(0.8174)] 
2025-01-31 00:41:27.017271: Epoch time: 48.06 s 
2025-01-31 00:41:28.220600:  
2025-01-31 00:41:28.224601: Epoch 410 
2025-01-31 00:41:28.227554: Current learning rate: 0.00622 
2025-01-31 00:42:16.309076: train_loss -0.8002 
2025-01-31 00:42:16.314702: val_loss -0.622 
2025-01-31 00:42:16.317437: Pseudo dice [np.float32(0.9458), np.float32(0.6083)] 
2025-01-31 00:42:16.319778: Epoch time: 48.09 s 
2025-01-31 00:42:17.462545:  
2025-01-31 00:42:17.465666: Epoch 411 
2025-01-31 00:42:17.468271: Current learning rate: 0.00621 
2025-01-31 00:43:05.930933: train_loss -0.8151 
2025-01-31 00:43:05.934783: val_loss -0.7148 
2025-01-31 00:43:05.937423: Pseudo dice [np.float32(0.9463), np.float32(0.8717)] 
2025-01-31 00:43:05.939785: Epoch time: 48.47 s 
2025-01-31 00:43:07.041632:  
2025-01-31 00:43:07.044314: Epoch 412 
2025-01-31 00:43:07.046922: Current learning rate: 0.0062 
2025-01-31 00:43:55.430578: train_loss -0.8162 
2025-01-31 00:43:55.436615: val_loss -0.682 
2025-01-31 00:43:55.439152: Pseudo dice [np.float32(0.943), np.float32(0.5603)] 
2025-01-31 00:43:55.441838: Epoch time: 48.39 s 
2025-01-31 00:43:56.548759:  
2025-01-31 00:43:56.551548: Epoch 413 
2025-01-31 00:43:56.554018: Current learning rate: 0.00619 
2025-01-31 00:44:44.751331: train_loss -0.8219 
2025-01-31 00:44:44.755521: val_loss -0.6999 
2025-01-31 00:44:44.758298: Pseudo dice [np.float32(0.9397), np.float32(0.6555)] 
2025-01-31 00:44:44.760684: Epoch time: 48.2 s 
2025-01-31 00:44:45.872143:  
2025-01-31 00:44:45.876769: Epoch 414 
2025-01-31 00:44:45.879440: Current learning rate: 0.00618 
2025-01-31 00:45:33.911919: train_loss -0.8103 
2025-01-31 00:45:33.917103: val_loss -0.6643 
2025-01-31 00:45:33.919797: Pseudo dice [np.float32(0.9409), np.float32(0.7614)] 
2025-01-31 00:45:33.922363: Epoch time: 48.04 s 
2025-01-31 00:45:35.071270:  
2025-01-31 00:45:35.074180: Epoch 415 
2025-01-31 00:45:35.076995: Current learning rate: 0.00617 
2025-01-31 00:46:23.168390: train_loss -0.8087 
2025-01-31 00:46:23.172544: val_loss -0.6821 
2025-01-31 00:46:23.174915: Pseudo dice [np.float32(0.9352), np.float32(0.6733)] 
2025-01-31 00:46:23.177468: Epoch time: 48.1 s 
2025-01-31 00:46:24.310289:  
2025-01-31 00:46:24.312865: Epoch 416 
2025-01-31 00:46:24.315466: Current learning rate: 0.00616 
2025-01-31 00:47:12.504562: train_loss -0.8064 
2025-01-31 00:47:12.509991: val_loss -0.7519 
2025-01-31 00:47:12.513125: Pseudo dice [np.float32(0.9497), np.float32(0.8801)] 
2025-01-31 00:47:12.515563: Epoch time: 48.2 s 
2025-01-31 00:47:13.630524:  
2025-01-31 00:47:13.633305: Epoch 417 
2025-01-31 00:47:13.635888: Current learning rate: 0.00615 
2025-01-31 00:48:02.034136: train_loss -0.8122 
2025-01-31 00:48:02.038536: val_loss -0.7287 
2025-01-31 00:48:02.041422: Pseudo dice [np.float32(0.9423), np.float32(0.8615)] 
2025-01-31 00:48:02.044288: Epoch time: 48.4 s 
2025-01-31 00:48:03.149258:  
2025-01-31 00:48:03.152711: Epoch 418 
2025-01-31 00:48:03.155821: Current learning rate: 0.00614 
2025-01-31 00:48:51.602989: train_loss -0.8158 
2025-01-31 00:48:51.608664: val_loss -0.7522 
2025-01-31 00:48:51.611181: Pseudo dice [np.float32(0.9468), np.float32(0.8497)] 
2025-01-31 00:48:51.613966: Epoch time: 48.45 s 
2025-01-31 00:48:52.724396:  
2025-01-31 00:48:52.727460: Epoch 419 
2025-01-31 00:48:52.730630: Current learning rate: 0.00613 
2025-01-31 00:49:40.849512: train_loss -0.8226 
2025-01-31 00:49:40.853929: val_loss -0.7134 
2025-01-31 00:49:40.856895: Pseudo dice [np.float32(0.954), np.float32(0.7901)] 
2025-01-31 00:49:40.859755: Epoch time: 48.13 s 
2025-01-31 00:49:41.970300:  
2025-01-31 00:49:41.972786: Epoch 420 
2025-01-31 00:49:41.975136: Current learning rate: 0.00612 
2025-01-31 00:50:30.291180: train_loss -0.8164 
2025-01-31 00:50:30.296376: val_loss -0.7274 
2025-01-31 00:50:30.298612: Pseudo dice [np.float32(0.9555), np.float32(0.8493)] 
2025-01-31 00:50:30.301125: Epoch time: 48.32 s 
2025-01-31 00:50:31.402799:  
2025-01-31 00:50:31.406947: Epoch 421 
2025-01-31 00:50:31.409449: Current learning rate: 0.00612 
2025-01-31 00:51:19.679383: train_loss -0.8133 
2025-01-31 00:51:19.683746: val_loss -0.7408 
2025-01-31 00:51:19.686691: Pseudo dice [np.float32(0.9536), np.float32(0.9049)] 
2025-01-31 00:51:19.689518: Epoch time: 48.28 s 
2025-01-31 00:51:20.828775:  
2025-01-31 00:51:20.832186: Epoch 422 
2025-01-31 00:51:20.835171: Current learning rate: 0.00611 
2025-01-31 00:52:08.959584: train_loss -0.8173 
2025-01-31 00:52:08.964697: val_loss -0.6719 
2025-01-31 00:52:08.967706: Pseudo dice [np.float32(0.9433), np.float32(0.645)] 
2025-01-31 00:52:08.970189: Epoch time: 48.13 s 
2025-01-31 00:52:10.118248:  
2025-01-31 00:52:10.120976: Epoch 423 
2025-01-31 00:52:10.123517: Current learning rate: 0.0061 
2025-01-31 00:52:58.366287: train_loss -0.8197 
2025-01-31 00:52:58.370269: val_loss -0.6755 
2025-01-31 00:52:58.373115: Pseudo dice [np.float32(0.9448), np.float32(0.7593)] 
2025-01-31 00:52:58.375802: Epoch time: 48.25 s 
2025-01-31 00:52:59.485173:  
2025-01-31 00:52:59.488160: Epoch 424 
2025-01-31 00:52:59.490962: Current learning rate: 0.00609 
2025-01-31 00:53:47.174739: train_loss -0.8127 
2025-01-31 00:53:47.180510: val_loss -0.6412 
2025-01-31 00:53:47.183382: Pseudo dice [np.float32(0.9471), np.float32(0.6806)] 
2025-01-31 00:53:47.186247: Epoch time: 47.69 s 
2025-01-31 00:53:48.293364:  
2025-01-31 00:53:48.297963: Epoch 425 
2025-01-31 00:53:48.300572: Current learning rate: 0.00608 
2025-01-31 00:54:36.545943: train_loss -0.8289 
2025-01-31 00:54:36.550135: val_loss -0.7216 
2025-01-31 00:54:36.553064: Pseudo dice [np.float32(0.9605), np.float32(0.6928)] 
2025-01-31 00:54:36.556221: Epoch time: 48.25 s 
2025-01-31 00:54:37.663006:  
2025-01-31 00:54:37.666896: Epoch 426 
2025-01-31 00:54:37.669709: Current learning rate: 0.00607 
2025-01-31 00:55:25.823913: train_loss -0.8149 
2025-01-31 00:55:25.829079: val_loss -0.7206 
2025-01-31 00:55:25.831641: Pseudo dice [np.float32(0.9376), np.float32(0.8838)] 
2025-01-31 00:55:25.834218: Epoch time: 48.16 s 
2025-01-31 00:55:26.980498:  
2025-01-31 00:55:26.983690: Epoch 427 
2025-01-31 00:55:26.986449: Current learning rate: 0.00606 
2025-01-31 00:56:14.987744: train_loss -0.8137 
2025-01-31 00:56:14.991666: val_loss -0.6806 
2025-01-31 00:56:14.994344: Pseudo dice [np.float32(0.9596), np.float32(0.7293)] 
2025-01-31 00:56:14.997160: Epoch time: 48.01 s 
2025-01-31 00:56:16.620009:  
2025-01-31 00:56:16.622618: Epoch 428 
2025-01-31 00:56:16.625304: Current learning rate: 0.00605 
2025-01-31 00:57:04.687763: train_loss -0.8235 
2025-01-31 00:57:04.692468: val_loss -0.7556 
2025-01-31 00:57:04.694781: Pseudo dice [np.float32(0.9473), np.float32(0.8401)] 
2025-01-31 00:57:04.697114: Epoch time: 48.07 s 
2025-01-31 00:57:05.813337:  
2025-01-31 00:57:05.816051: Epoch 429 
2025-01-31 00:57:05.818656: Current learning rate: 0.00604 
2025-01-31 00:57:54.025203: train_loss -0.8154 
2025-01-31 00:57:54.029015: val_loss -0.7107 
2025-01-31 00:57:54.031667: Pseudo dice [np.float32(0.9568), np.float32(0.7759)] 
2025-01-31 00:57:54.034014: Epoch time: 48.21 s 
2025-01-31 00:57:55.146579:  
2025-01-31 00:57:55.151086: Epoch 430 
2025-01-31 00:57:55.153637: Current learning rate: 0.00603 
2025-01-31 00:58:43.172927: train_loss -0.8246 
2025-01-31 00:58:43.178672: val_loss -0.7219 
2025-01-31 00:58:43.180996: Pseudo dice [np.float32(0.9572), np.float32(0.8215)] 
2025-01-31 00:58:43.183425: Epoch time: 48.03 s 
2025-01-31 00:58:44.293499:  
2025-01-31 00:58:44.296395: Epoch 431 
2025-01-31 00:58:44.299017: Current learning rate: 0.00602 
2025-01-31 00:59:32.223346: train_loss -0.8151 
2025-01-31 00:59:32.227627: val_loss -0.7456 
2025-01-31 00:59:32.230569: Pseudo dice [np.float32(0.9377), np.float32(0.8291)] 
2025-01-31 00:59:32.233357: Epoch time: 47.93 s 
2025-01-31 00:59:33.383595:  
2025-01-31 00:59:33.386502: Epoch 432 
2025-01-31 00:59:33.389164: Current learning rate: 0.00601 
2025-01-31 01:00:21.568583: train_loss -0.8279 
2025-01-31 01:00:21.573785: val_loss -0.6528 
2025-01-31 01:00:21.576250: Pseudo dice [np.float32(0.9177), np.float32(0.8222)] 
2025-01-31 01:00:21.578640: Epoch time: 48.19 s 
2025-01-31 01:00:22.694350:  
2025-01-31 01:00:22.697040: Epoch 433 
2025-01-31 01:00:22.699469: Current learning rate: 0.006 
2025-01-31 01:01:10.998184: train_loss -0.8256 
2025-01-31 01:01:11.002215: val_loss -0.5992 
2025-01-31 01:01:11.004955: Pseudo dice [np.float32(0.9534), np.float32(0.4961)] 
2025-01-31 01:01:11.007391: Epoch time: 48.3 s 
2025-01-31 01:01:12.144170:  
2025-01-31 01:01:12.147467: Epoch 434 
2025-01-31 01:01:12.150252: Current learning rate: 0.00599 
2025-01-31 01:02:00.079638: train_loss -0.8219 
2025-01-31 01:02:00.085364: val_loss -0.6751 
2025-01-31 01:02:00.088288: Pseudo dice [np.float32(0.9474), np.float32(0.6664)] 
2025-01-31 01:02:00.090952: Epoch time: 47.94 s 
2025-01-31 01:02:01.202671:  
2025-01-31 01:02:01.205690: Epoch 435 
2025-01-31 01:02:01.208440: Current learning rate: 0.00598 
2025-01-31 01:02:49.373266: train_loss -0.8137 
2025-01-31 01:02:49.377207: val_loss -0.7269 
2025-01-31 01:02:49.380166: Pseudo dice [np.float32(0.9325), np.float32(0.8153)] 
2025-01-31 01:02:49.382650: Epoch time: 48.17 s 
2025-01-31 01:02:50.493043:  
2025-01-31 01:02:50.495588: Epoch 436 
2025-01-31 01:02:50.498052: Current learning rate: 0.00597 
2025-01-31 01:03:38.427118: train_loss -0.8294 
2025-01-31 01:03:38.432178: val_loss -0.7016 
2025-01-31 01:03:38.434731: Pseudo dice [np.float32(0.9409), np.float32(0.7701)] 
2025-01-31 01:03:38.437033: Epoch time: 47.93 s 
2025-01-31 01:03:39.539400:  
2025-01-31 01:03:39.542314: Epoch 437 
2025-01-31 01:03:39.544824: Current learning rate: 0.00596 
2025-01-31 01:04:27.682716: train_loss -0.8173 
2025-01-31 01:04:27.686615: val_loss -0.588 
2025-01-31 01:04:27.689351: Pseudo dice [np.float32(0.9341), np.float32(0.5563)] 
2025-01-31 01:04:27.691625: Epoch time: 48.14 s 
2025-01-31 01:04:28.805685:  
2025-01-31 01:04:28.809216: Epoch 438 
2025-01-31 01:04:28.811723: Current learning rate: 0.00595 
2025-01-31 01:05:16.941389: train_loss -0.8311 
2025-01-31 01:05:16.946600: val_loss -0.7067 
2025-01-31 01:05:16.949233: Pseudo dice [np.float32(0.9549), np.float32(0.8299)] 
2025-01-31 01:05:16.951617: Epoch time: 48.14 s 
2025-01-31 01:05:18.071343:  
2025-01-31 01:05:18.073939: Epoch 439 
2025-01-31 01:05:18.076643: Current learning rate: 0.00594 
2025-01-31 01:06:05.794628: train_loss -0.8273 
2025-01-31 01:06:05.798713: val_loss -0.7083 
2025-01-31 01:06:05.801549: Pseudo dice [np.float32(0.9531), np.float32(0.8512)] 
2025-01-31 01:06:05.804262: Epoch time: 47.72 s 
2025-01-31 01:06:06.912401:  
2025-01-31 01:06:06.915591: Epoch 440 
2025-01-31 01:06:06.918364: Current learning rate: 0.00593 
2025-01-31 01:06:54.985330: train_loss -0.8356 
2025-01-31 01:06:54.991169: val_loss -0.7215 
2025-01-31 01:06:54.994028: Pseudo dice [np.float32(0.9374), np.float32(0.875)] 
2025-01-31 01:06:54.996656: Epoch time: 48.07 s 
2025-01-31 01:06:56.138469:  
2025-01-31 01:06:56.141438: Epoch 441 
2025-01-31 01:06:56.143983: Current learning rate: 0.00592 
2025-01-31 01:07:44.333261: train_loss -0.8273 
2025-01-31 01:07:44.337626: val_loss -0.7487 
2025-01-31 01:07:44.340409: Pseudo dice [np.float32(0.9544), np.float32(0.9081)] 
2025-01-31 01:07:44.343195: Epoch time: 48.2 s 
2025-01-31 01:07:45.452694:  
2025-01-31 01:07:45.455576: Epoch 442 
2025-01-31 01:07:45.458131: Current learning rate: 0.00592 
2025-01-31 01:08:33.599566: train_loss -0.8194 
2025-01-31 01:08:33.605981: val_loss -0.6895 
2025-01-31 01:08:33.608859: Pseudo dice [np.float32(0.9504), np.float32(0.8359)] 
2025-01-31 01:08:33.611705: Epoch time: 48.15 s 
2025-01-31 01:08:34.729588:  
2025-01-31 01:08:34.732599: Epoch 443 
2025-01-31 01:08:34.735540: Current learning rate: 0.00591 
2025-01-31 01:09:22.751050: train_loss -0.8094 
2025-01-31 01:09:22.755365: val_loss -0.6047 
2025-01-31 01:09:22.758157: Pseudo dice [np.float32(0.9313), np.float32(0.7302)] 
2025-01-31 01:09:22.761050: Epoch time: 48.02 s 
2025-01-31 01:09:23.863092:  
2025-01-31 01:09:23.865932: Epoch 444 
2025-01-31 01:09:23.868700: Current learning rate: 0.0059 
2025-01-31 01:10:12.157220: train_loss -0.8294 
2025-01-31 01:10:12.163000: val_loss -0.7263 
2025-01-31 01:10:12.166713: Pseudo dice [np.float32(0.9455), np.float32(0.8344)] 
2025-01-31 01:10:12.169510: Epoch time: 48.29 s 
2025-01-31 01:10:13.261915:  
2025-01-31 01:10:13.264890: Epoch 445 
2025-01-31 01:10:13.267796: Current learning rate: 0.00589 
2025-01-31 01:11:01.351736: train_loss -0.8182 
2025-01-31 01:11:01.355892: val_loss -0.7032 
2025-01-31 01:11:01.358592: Pseudo dice [np.float32(0.9358), np.float32(0.7209)] 
2025-01-31 01:11:01.361170: Epoch time: 48.09 s 
2025-01-31 01:11:02.463835:  
2025-01-31 01:11:02.466392: Epoch 446 
2025-01-31 01:11:02.468991: Current learning rate: 0.00588 
2025-01-31 01:11:50.662643: train_loss -0.8219 
2025-01-31 01:11:50.668004: val_loss -0.7306 
2025-01-31 01:11:50.670782: Pseudo dice [np.float32(0.9426), np.float32(0.7925)] 
2025-01-31 01:11:50.673271: Epoch time: 48.2 s 
2025-01-31 01:11:51.803335:  
2025-01-31 01:11:51.806572: Epoch 447 
2025-01-31 01:11:51.809434: Current learning rate: 0.00587 
2025-01-31 01:12:40.058413: train_loss -0.8201 
2025-01-31 01:12:40.063070: val_loss -0.6624 
2025-01-31 01:12:40.066104: Pseudo dice [np.float32(0.9435), np.float32(0.6133)] 
2025-01-31 01:12:40.068909: Epoch time: 48.26 s 
2025-01-31 01:12:41.777610:  
2025-01-31 01:12:41.780330: Epoch 448 
2025-01-31 01:12:41.782783: Current learning rate: 0.00586 
2025-01-31 01:13:30.215910: train_loss -0.8124 
2025-01-31 01:13:30.221720: val_loss -0.6928 
2025-01-31 01:13:30.224558: Pseudo dice [np.float32(0.9384), np.float32(0.7462)] 
2025-01-31 01:13:30.227042: Epoch time: 48.44 s 
2025-01-31 01:13:31.326840:  
2025-01-31 01:13:31.329537: Epoch 449 
2025-01-31 01:13:31.332185: Current learning rate: 0.00585 
2025-01-31 01:14:19.716918: train_loss -0.8016 
2025-01-31 01:14:19.720580: val_loss -0.6772 
2025-01-31 01:14:19.723812: Pseudo dice [np.float32(0.9396), np.float32(0.8147)] 
2025-01-31 01:14:19.726058: Epoch time: 48.39 s 
2025-01-31 01:14:21.451774:  
2025-01-31 01:14:21.456221: Epoch 450 
2025-01-31 01:14:21.459038: Current learning rate: 0.00584 
2025-01-31 01:15:09.324585: train_loss -0.8312 
2025-01-31 01:15:09.329937: val_loss -0.6795 
2025-01-31 01:15:09.332344: Pseudo dice [np.float32(0.9418), np.float32(0.6937)] 
2025-01-31 01:15:09.334675: Epoch time: 47.87 s 
2025-01-31 01:15:10.470021:  
2025-01-31 01:15:10.473295: Epoch 451 
2025-01-31 01:15:10.476230: Current learning rate: 0.00583 
2025-01-31 01:15:58.256351: train_loss -0.823 
2025-01-31 01:15:58.260226: val_loss -0.691 
2025-01-31 01:15:58.262997: Pseudo dice [np.float32(0.9396), np.float32(0.8137)] 
2025-01-31 01:15:58.265198: Epoch time: 47.79 s 
2025-01-31 01:15:59.369129:  
2025-01-31 01:15:59.372036: Epoch 452 
2025-01-31 01:15:59.376458: Current learning rate: 0.00582 
2025-01-31 01:16:47.073409: train_loss -0.8243 
2025-01-31 01:16:47.079552: val_loss -0.7052 
2025-01-31 01:16:47.082260: Pseudo dice [np.float32(0.9487), np.float32(0.7797)] 
2025-01-31 01:16:47.084709: Epoch time: 47.71 s 
2025-01-31 01:16:48.179292:  
2025-01-31 01:16:48.182449: Epoch 453 
2025-01-31 01:16:48.185197: Current learning rate: 0.00581 
2025-01-31 01:17:36.339644: train_loss -0.7948 
2025-01-31 01:17:36.344164: val_loss -0.6198 
2025-01-31 01:17:36.347118: Pseudo dice [np.float32(0.9404), np.float32(0.5203)] 
2025-01-31 01:17:36.349682: Epoch time: 48.16 s 
2025-01-31 01:17:37.447789:  
2025-01-31 01:17:37.450895: Epoch 454 
2025-01-31 01:17:37.453574: Current learning rate: 0.0058 
2025-01-31 01:18:25.359881: train_loss -0.822 
2025-01-31 01:18:25.365843: val_loss -0.7734 
2025-01-31 01:18:25.368264: Pseudo dice [np.float32(0.9456), np.float32(0.9006)] 
2025-01-31 01:18:25.370883: Epoch time: 47.91 s 
2025-01-31 01:18:26.474471:  
2025-01-31 01:18:26.477630: Epoch 455 
2025-01-31 01:18:26.480408: Current learning rate: 0.00579 
2025-01-31 01:19:14.880865: train_loss -0.8231 
2025-01-31 01:19:14.885024: val_loss -0.7425 
2025-01-31 01:19:14.887777: Pseudo dice [np.float32(0.9437), np.float32(0.8629)] 
2025-01-31 01:19:14.890330: Epoch time: 48.41 s 
2025-01-31 01:19:16.022770:  
2025-01-31 01:19:16.025746: Epoch 456 
2025-01-31 01:19:16.028559: Current learning rate: 0.00578 
2025-01-31 01:20:04.134152: train_loss -0.8107 
2025-01-31 01:20:04.140296: val_loss -0.7574 
2025-01-31 01:20:04.142999: Pseudo dice [np.float32(0.9386), np.float32(0.8816)] 
2025-01-31 01:20:04.145484: Epoch time: 48.11 s 
2025-01-31 01:20:05.246301:  
2025-01-31 01:20:05.249039: Epoch 457 
2025-01-31 01:20:05.251601: Current learning rate: 0.00577 
2025-01-31 01:20:53.127576: train_loss -0.817 
2025-01-31 01:20:53.136617: val_loss -0.7404 
2025-01-31 01:20:53.141555: Pseudo dice [np.float32(0.9397), np.float32(0.8634)] 
2025-01-31 01:20:53.145948: Epoch time: 47.88 s 
2025-01-31 01:20:54.287324:  
2025-01-31 01:20:54.290077: Epoch 458 
2025-01-31 01:20:54.292704: Current learning rate: 0.00576 
2025-01-31 01:21:42.264313: train_loss -0.8214 
2025-01-31 01:21:42.270046: val_loss -0.6807 
2025-01-31 01:21:42.272846: Pseudo dice [np.float32(0.9503), np.float32(0.5157)] 
2025-01-31 01:21:42.275113: Epoch time: 47.98 s 
2025-01-31 01:21:43.375613:  
2025-01-31 01:21:43.378376: Epoch 459 
2025-01-31 01:21:43.381167: Current learning rate: 0.00575 
2025-01-31 01:22:31.439965: train_loss -0.8238 
2025-01-31 01:22:31.444129: val_loss -0.6614 
2025-01-31 01:22:31.446947: Pseudo dice [np.float32(0.9516), np.float32(0.6807)] 
2025-01-31 01:22:31.449720: Epoch time: 48.07 s 
2025-01-31 01:22:32.549801:  
2025-01-31 01:22:32.552730: Epoch 460 
2025-01-31 01:22:32.556276: Current learning rate: 0.00574 
2025-01-31 01:23:20.975130: train_loss -0.835 
2025-01-31 01:23:20.981187: val_loss -0.6958 
2025-01-31 01:23:20.984035: Pseudo dice [np.float32(0.9405), np.float32(0.8319)] 
2025-01-31 01:23:20.986641: Epoch time: 48.43 s 
2025-01-31 01:23:22.118169:  
2025-01-31 01:23:22.120934: Epoch 461 
2025-01-31 01:23:22.123434: Current learning rate: 0.00573 
2025-01-31 01:24:10.174561: train_loss -0.8388 
2025-01-31 01:24:10.178749: val_loss -0.7059 
2025-01-31 01:24:10.181566: Pseudo dice [np.float32(0.9519), np.float32(0.8509)] 
2025-01-31 01:24:10.184398: Epoch time: 48.06 s 
2025-01-31 01:24:11.285707:  
2025-01-31 01:24:11.288933: Epoch 462 
2025-01-31 01:24:11.291635: Current learning rate: 0.00572 
2025-01-31 01:24:59.308000: train_loss -0.8214 
2025-01-31 01:24:59.326409: val_loss -0.7317 
2025-01-31 01:24:59.328758: Pseudo dice [np.float32(0.9377), np.float32(0.8753)] 
2025-01-31 01:24:59.331152: Epoch time: 48.02 s 
2025-01-31 01:25:00.428840:  
2025-01-31 01:25:00.431849: Epoch 463 
2025-01-31 01:25:00.434385: Current learning rate: 0.00571 
2025-01-31 01:25:48.769177: train_loss -0.8142 
2025-01-31 01:25:48.773517: val_loss -0.6813 
2025-01-31 01:25:48.776494: Pseudo dice [np.float32(0.9351), np.float32(0.7745)] 
2025-01-31 01:25:48.779166: Epoch time: 48.34 s 
2025-01-31 01:25:49.887157:  
2025-01-31 01:25:49.890073: Epoch 464 
2025-01-31 01:25:49.893149: Current learning rate: 0.0057 
2025-01-31 01:26:38.059994: train_loss -0.8358 
2025-01-31 01:26:38.065676: val_loss -0.7406 
2025-01-31 01:26:38.068561: Pseudo dice [np.float32(0.937), np.float32(0.8721)] 
2025-01-31 01:26:38.071572: Epoch time: 48.17 s 
2025-01-31 01:26:39.195832:  
2025-01-31 01:26:39.198906: Epoch 465 
2025-01-31 01:26:39.201584: Current learning rate: 0.0057 
2025-01-31 01:27:26.995632: train_loss -0.8255 
2025-01-31 01:27:26.999762: val_loss -0.6817 
2025-01-31 01:27:27.002401: Pseudo dice [np.float32(0.9374), np.float32(0.7416)] 
2025-01-31 01:27:27.004869: Epoch time: 47.8 s 
2025-01-31 01:27:28.105591:  
2025-01-31 01:27:28.108820: Epoch 466 
2025-01-31 01:27:28.111496: Current learning rate: 0.00569 
2025-01-31 01:28:16.052005: train_loss -0.8257 
2025-01-31 01:28:16.057974: val_loss -0.7306 
2025-01-31 01:28:16.060908: Pseudo dice [np.float32(0.9368), np.float32(0.8316)] 
2025-01-31 01:28:16.063700: Epoch time: 47.95 s 
2025-01-31 01:28:17.739073:  
2025-01-31 01:28:17.741898: Epoch 467 
2025-01-31 01:28:17.744703: Current learning rate: 0.00568 
2025-01-31 01:29:05.601703: train_loss -0.8184 
2025-01-31 01:29:05.605294: val_loss -0.6966 
2025-01-31 01:29:05.608271: Pseudo dice [np.float32(0.9415), np.float32(0.8217)] 
2025-01-31 01:29:05.610722: Epoch time: 47.86 s 
2025-01-31 01:29:06.706971:  
2025-01-31 01:29:06.709817: Epoch 468 
2025-01-31 01:29:06.713244: Current learning rate: 0.00567 
2025-01-31 01:29:54.610416: train_loss -0.7749 
2025-01-31 01:29:54.616385: val_loss -0.6079 
2025-01-31 01:29:54.619140: Pseudo dice [np.float32(0.9267), np.float32(0.5713)] 
2025-01-31 01:29:54.622145: Epoch time: 47.9 s 
2025-01-31 01:29:55.743150:  
2025-01-31 01:29:55.745771: Epoch 469 
2025-01-31 01:29:55.748339: Current learning rate: 0.00566 
2025-01-31 01:30:43.514200: train_loss -0.794 
2025-01-31 01:30:43.518816: val_loss -0.6661 
2025-01-31 01:30:43.521824: Pseudo dice [np.float32(0.9491), np.float32(0.6463)] 
2025-01-31 01:30:43.524409: Epoch time: 47.77 s 
2025-01-31 01:30:44.626094:  
2025-01-31 01:30:44.629203: Epoch 470 
2025-01-31 01:30:44.631734: Current learning rate: 0.00565 
2025-01-31 01:31:33.023035: train_loss -0.8152 
2025-01-31 01:31:33.029096: val_loss -0.7284 
2025-01-31 01:31:33.031996: Pseudo dice [np.float32(0.9416), np.float32(0.8108)] 
2025-01-31 01:31:33.034739: Epoch time: 48.4 s 
2025-01-31 01:31:34.136523:  
2025-01-31 01:31:34.139574: Epoch 471 
2025-01-31 01:31:34.142564: Current learning rate: 0.00564 
2025-01-31 01:32:22.396652: train_loss -0.8085 
2025-01-31 01:32:22.400399: val_loss -0.6821 
2025-01-31 01:32:22.403111: Pseudo dice [np.float32(0.9422), np.float32(0.8073)] 
2025-01-31 01:32:22.406021: Epoch time: 48.26 s 
2025-01-31 01:32:23.503595:  
2025-01-31 01:32:23.506315: Epoch 472 
2025-01-31 01:32:23.508854: Current learning rate: 0.00563 
2025-01-31 01:33:11.547235: train_loss -0.7909 
2025-01-31 01:33:11.553083: val_loss -0.6884 
2025-01-31 01:33:11.555900: Pseudo dice [np.float32(0.9357), np.float32(0.8353)] 
2025-01-31 01:33:11.558819: Epoch time: 48.04 s 
2025-01-31 01:33:12.660301:  
2025-01-31 01:33:12.663014: Epoch 473 
2025-01-31 01:33:12.665978: Current learning rate: 0.00562 
2025-01-31 01:34:01.006395: train_loss -0.7929 
2025-01-31 01:34:01.010364: val_loss -0.634 
2025-01-31 01:34:01.013678: Pseudo dice [np.float32(0.9388), np.float32(0.4943)] 
2025-01-31 01:34:01.015997: Epoch time: 48.35 s 
2025-01-31 01:34:02.118000:  
2025-01-31 01:34:02.122917: Epoch 474 
2025-01-31 01:34:02.125702: Current learning rate: 0.00561 
2025-01-31 01:34:50.069634: train_loss -0.8008 
2025-01-31 01:34:50.074665: val_loss -0.6782 
2025-01-31 01:34:50.077366: Pseudo dice [np.float32(0.9421), np.float32(0.7016)] 
2025-01-31 01:34:50.079655: Epoch time: 47.95 s 
2025-01-31 01:34:51.180974:  
2025-01-31 01:34:51.184192: Epoch 475 
2025-01-31 01:34:51.187202: Current learning rate: 0.0056 
2025-01-31 01:35:39.076915: train_loss -0.8076 
2025-01-31 01:35:39.081073: val_loss -0.7191 
2025-01-31 01:35:39.084220: Pseudo dice [np.float32(0.9319), np.float32(0.8381)] 
2025-01-31 01:35:39.087137: Epoch time: 47.9 s 
2025-01-31 01:35:40.222852:  
2025-01-31 01:35:40.225553: Epoch 476 
2025-01-31 01:35:40.228198: Current learning rate: 0.00559 
2025-01-31 01:36:28.440246: train_loss -0.791 
2025-01-31 01:36:28.448235: val_loss -0.6343 
2025-01-31 01:36:28.450982: Pseudo dice [np.float32(0.9338), np.float32(0.636)] 
2025-01-31 01:36:28.453771: Epoch time: 48.22 s 
2025-01-31 01:36:29.584882:  
2025-01-31 01:36:29.587980: Epoch 477 
2025-01-31 01:36:29.590628: Current learning rate: 0.00558 
2025-01-31 01:37:17.404067: train_loss -0.8087 
2025-01-31 01:37:17.408250: val_loss -0.6839 
2025-01-31 01:37:17.411485: Pseudo dice [np.float32(0.9385), np.float32(0.7316)] 
2025-01-31 01:37:17.414672: Epoch time: 47.82 s 
2025-01-31 01:37:18.565810:  
2025-01-31 01:37:18.574262: Epoch 478 
2025-01-31 01:37:18.577268: Current learning rate: 0.00557 
2025-01-31 01:38:06.492330: train_loss -0.8026 
2025-01-31 01:38:06.498995: val_loss -0.6199 
2025-01-31 01:38:06.501569: Pseudo dice [np.float32(0.9388), np.float32(0.5993)] 
2025-01-31 01:38:06.504407: Epoch time: 47.93 s 
2025-01-31 01:38:07.656104:  
2025-01-31 01:38:07.658791: Epoch 479 
2025-01-31 01:38:07.661400: Current learning rate: 0.00556 
2025-01-31 01:38:55.870615: train_loss -0.8088 
2025-01-31 01:38:55.875216: val_loss -0.7088 
2025-01-31 01:38:55.878086: Pseudo dice [np.float32(0.9437), np.float32(0.8606)] 
2025-01-31 01:38:55.880870: Epoch time: 48.22 s 
2025-01-31 01:38:57.004465:  
2025-01-31 01:38:57.008029: Epoch 480 
2025-01-31 01:38:57.011089: Current learning rate: 0.00555 
2025-01-31 01:39:45.048237: train_loss -0.8022 
2025-01-31 01:39:45.054247: val_loss -0.7095 
2025-01-31 01:39:45.056725: Pseudo dice [np.float32(0.9531), np.float32(0.7749)] 
2025-01-31 01:39:45.059456: Epoch time: 48.04 s 
2025-01-31 01:39:46.174417:  
2025-01-31 01:39:46.177348: Epoch 481 
2025-01-31 01:39:46.179904: Current learning rate: 0.00554 
2025-01-31 01:40:34.107407: train_loss -0.827 
2025-01-31 01:40:34.113326: val_loss -0.7229 
2025-01-31 01:40:34.115987: Pseudo dice [np.float32(0.944), np.float32(0.7593)] 
2025-01-31 01:40:34.118569: Epoch time: 47.93 s 
2025-01-31 01:40:35.238296:  
2025-01-31 01:40:35.241079: Epoch 482 
2025-01-31 01:40:35.243866: Current learning rate: 0.00553 
2025-01-31 01:41:23.315051: train_loss -0.8078 
2025-01-31 01:41:23.319899: val_loss -0.6135 
2025-01-31 01:41:23.322271: Pseudo dice [np.float32(0.9384), np.float32(0.5129)] 
2025-01-31 01:41:23.324552: Epoch time: 48.08 s 
2025-01-31 01:41:24.441887:  
2025-01-31 01:41:24.444729: Epoch 483 
2025-01-31 01:41:24.448061: Current learning rate: 0.00552 
2025-01-31 01:42:12.584441: train_loss -0.8098 
2025-01-31 01:42:12.588471: val_loss -0.7043 
2025-01-31 01:42:12.591167: Pseudo dice [np.float32(0.9371), np.float32(0.8365)] 
2025-01-31 01:42:12.593657: Epoch time: 48.14 s 
2025-01-31 01:42:13.709760:  
2025-01-31 01:42:13.713626: Epoch 484 
2025-01-31 01:42:13.716758: Current learning rate: 0.00551 
2025-01-31 01:43:01.590980: train_loss -0.8298 
2025-01-31 01:43:01.598870: val_loss -0.7144 
2025-01-31 01:43:01.601363: Pseudo dice [np.float32(0.947), np.float32(0.8224)] 
2025-01-31 01:43:01.604035: Epoch time: 47.88 s 
2025-01-31 01:43:02.760998:  
2025-01-31 01:43:02.763974: Epoch 485 
2025-01-31 01:43:02.766672: Current learning rate: 0.0055 
2025-01-31 01:43:50.869222: train_loss -0.8075 
2025-01-31 01:43:50.874989: val_loss -0.7615 
2025-01-31 01:43:50.877666: Pseudo dice [np.float32(0.9506), np.float32(0.8734)] 
2025-01-31 01:43:50.880297: Epoch time: 48.11 s 
2025-01-31 01:43:52.034253:  
2025-01-31 01:43:52.037560: Epoch 486 
2025-01-31 01:43:52.040195: Current learning rate: 0.00549 
2025-01-31 01:44:40.013990: train_loss -0.823 
2025-01-31 01:44:40.021274: val_loss -0.6987 
2025-01-31 01:44:40.023863: Pseudo dice [np.float32(0.9469), np.float32(0.8291)] 
2025-01-31 01:44:40.026218: Epoch time: 47.98 s 
2025-01-31 01:44:41.672153:  
2025-01-31 01:44:41.675715: Epoch 487 
2025-01-31 01:44:41.678561: Current learning rate: 0.00548 
2025-01-31 01:45:29.717510: train_loss -0.8145 
2025-01-31 01:45:29.724056: val_loss -0.72 
2025-01-31 01:45:29.726624: Pseudo dice [np.float32(0.9472), np.float32(0.8184)] 
2025-01-31 01:45:29.729404: Epoch time: 48.05 s 
2025-01-31 01:45:30.883266:  
2025-01-31 01:45:30.887641: Epoch 488 
2025-01-31 01:45:30.891727: Current learning rate: 0.00547 
2025-01-31 01:46:18.760569: train_loss -0.8204 
2025-01-31 01:46:18.767884: val_loss -0.7336 
2025-01-31 01:46:18.770436: Pseudo dice [np.float32(0.9456), np.float32(0.8961)] 
2025-01-31 01:46:18.772923: Epoch time: 47.88 s 
2025-01-31 01:46:19.895954:  
2025-01-31 01:46:19.898990: Epoch 489 
2025-01-31 01:46:19.901818: Current learning rate: 0.00546 
2025-01-31 01:47:07.882163: train_loss -0.8304 
2025-01-31 01:47:07.888550: val_loss -0.6396 
2025-01-31 01:47:07.891200: Pseudo dice [np.float32(0.954), np.float32(0.6438)] 
2025-01-31 01:47:07.894781: Epoch time: 47.99 s 
2025-01-31 01:47:09.010404:  
2025-01-31 01:47:09.013253: Epoch 490 
2025-01-31 01:47:09.016019: Current learning rate: 0.00546 
2025-01-31 01:47:57.052793: train_loss -0.8179 
2025-01-31 01:47:57.060874: val_loss -0.7233 
2025-01-31 01:47:57.063690: Pseudo dice [np.float32(0.9432), np.float32(0.7861)] 
2025-01-31 01:47:57.066277: Epoch time: 48.04 s 
2025-01-31 01:47:58.182852:  
2025-01-31 01:47:58.185741: Epoch 491 
2025-01-31 01:47:58.188256: Current learning rate: 0.00545 
2025-01-31 01:48:46.206093: train_loss -0.821 
2025-01-31 01:48:46.212865: val_loss -0.7083 
2025-01-31 01:48:46.215510: Pseudo dice [np.float32(0.9373), np.float32(0.9125)] 
2025-01-31 01:48:46.218040: Epoch time: 48.02 s 
2025-01-31 01:48:47.339001:  
2025-01-31 01:48:47.341867: Epoch 492 
2025-01-31 01:48:47.344468: Current learning rate: 0.00544 
2025-01-31 01:49:35.382009: train_loss -0.8099 
2025-01-31 01:49:35.387699: val_loss -0.6386 
2025-01-31 01:49:35.390383: Pseudo dice [np.float32(0.9519), np.float32(0.4599)] 
2025-01-31 01:49:35.392924: Epoch time: 48.04 s 
2025-01-31 01:49:36.509688:  
2025-01-31 01:49:36.513204: Epoch 493 
2025-01-31 01:49:36.516007: Current learning rate: 0.00543 
2025-01-31 01:50:24.296809: train_loss -0.829 
2025-01-31 01:50:24.303956: val_loss -0.6629 
2025-01-31 01:50:24.306731: Pseudo dice [np.float32(0.9439), np.float32(0.6021)] 
2025-01-31 01:50:24.309502: Epoch time: 47.79 s 
2025-01-31 01:50:25.463477:  
2025-01-31 01:50:25.466630: Epoch 494 
2025-01-31 01:50:25.471497: Current learning rate: 0.00542 
2025-01-31 01:51:13.269604: train_loss -0.8307 
2025-01-31 01:51:13.277715: val_loss -0.6942 
2025-01-31 01:51:13.280605: Pseudo dice [np.float32(0.9332), np.float32(0.7388)] 
2025-01-31 01:51:13.283207: Epoch time: 47.81 s 
2025-01-31 01:51:14.403071:  
2025-01-31 01:51:14.406158: Epoch 495 
2025-01-31 01:51:14.409507: Current learning rate: 0.00541 
2025-01-31 01:52:02.281662: train_loss -0.8249 
2025-01-31 01:52:02.288367: val_loss -0.7156 
2025-01-31 01:52:02.290927: Pseudo dice [np.float32(0.9426), np.float32(0.7537)] 
2025-01-31 01:52:02.293523: Epoch time: 47.88 s 
2025-01-31 01:52:03.417317:  
2025-01-31 01:52:03.420449: Epoch 496 
2025-01-31 01:52:03.423292: Current learning rate: 0.0054 
2025-01-31 01:52:51.900707: train_loss -0.8315 
2025-01-31 01:52:51.908039: val_loss -0.6532 
2025-01-31 01:52:51.910587: Pseudo dice [np.float32(0.9421), np.float32(0.6746)] 
2025-01-31 01:52:51.913169: Epoch time: 48.48 s 
2025-01-31 01:52:53.026664:  
2025-01-31 01:52:53.029458: Epoch 497 
2025-01-31 01:52:53.031786: Current learning rate: 0.00539 
2025-01-31 01:53:40.869736: train_loss -0.8261 
2025-01-31 01:53:40.875457: val_loss -0.6876 
2025-01-31 01:53:40.877887: Pseudo dice [np.float32(0.9496), np.float32(0.7059)] 
2025-01-31 01:53:40.880617: Epoch time: 47.84 s 
2025-01-31 01:53:41.993770:  
2025-01-31 01:53:41.996849: Epoch 498 
2025-01-31 01:53:42.000263: Current learning rate: 0.00538 
2025-01-31 01:54:30.462718: train_loss -0.8248 
2025-01-31 01:54:30.468704: val_loss -0.6918 
2025-01-31 01:54:30.472013: Pseudo dice [np.float32(0.9378), np.float32(0.8057)] 
2025-01-31 01:54:30.474668: Epoch time: 48.47 s 
2025-01-31 01:54:31.593296:  
2025-01-31 01:54:31.597067: Epoch 499 
2025-01-31 01:54:31.600002: Current learning rate: 0.00537 
2025-01-31 01:55:19.548695: train_loss -0.832 
2025-01-31 01:55:19.554972: val_loss -0.709 
2025-01-31 01:55:19.557571: Pseudo dice [np.float32(0.9525), np.float32(0.8017)] 
2025-01-31 01:55:19.560090: Epoch time: 47.96 s 
2025-01-31 01:55:21.247159:  
2025-01-31 01:55:21.250174: Epoch 500 
2025-01-31 01:55:21.253286: Current learning rate: 0.00536 
2025-01-31 01:56:09.622676: train_loss -0.8265 
2025-01-31 01:56:09.628444: val_loss -0.7277 
2025-01-31 01:56:09.631357: Pseudo dice [np.float32(0.9461), np.float32(0.8349)] 
2025-01-31 01:56:09.634002: Epoch time: 48.38 s 
2025-01-31 01:56:10.759923:  
2025-01-31 01:56:10.762967: Epoch 501 
2025-01-31 01:56:10.765909: Current learning rate: 0.00535 
2025-01-31 01:56:58.515975: train_loss -0.8255 
2025-01-31 01:56:58.520134: val_loss -0.6731 
2025-01-31 01:56:58.522819: Pseudo dice [np.float32(0.9255), np.float32(0.66)] 
2025-01-31 01:56:58.525444: Epoch time: 47.76 s 
2025-01-31 01:56:59.643749:  
2025-01-31 01:56:59.646460: Epoch 502 
2025-01-31 01:56:59.649024: Current learning rate: 0.00534 
2025-01-31 01:57:47.602789: train_loss -0.8155 
2025-01-31 01:57:47.608503: val_loss -0.7016 
2025-01-31 01:57:47.611327: Pseudo dice [np.float32(0.9487), np.float32(0.8347)] 
2025-01-31 01:57:47.614198: Epoch time: 47.96 s 
2025-01-31 01:57:48.728795:  
2025-01-31 01:57:48.731747: Epoch 503 
2025-01-31 01:57:48.734283: Current learning rate: 0.00533 
2025-01-31 01:58:36.765394: train_loss -0.8321 
2025-01-31 01:58:36.768945: val_loss -0.703 
2025-01-31 01:58:36.771427: Pseudo dice [np.float32(0.947), np.float32(0.7145)] 
2025-01-31 01:58:36.773555: Epoch time: 48.04 s 
2025-01-31 01:58:37.916926:  
2025-01-31 01:58:37.919817: Epoch 504 
2025-01-31 01:58:37.922616: Current learning rate: 0.00532 
2025-01-31 01:59:25.900602: train_loss -0.8222 
2025-01-31 01:59:25.906097: val_loss -0.6888 
2025-01-31 01:59:25.908649: Pseudo dice [np.float32(0.95), np.float32(0.7104)] 
2025-01-31 01:59:25.911391: Epoch time: 47.98 s 
2025-01-31 01:59:27.058451:  
2025-01-31 01:59:27.061624: Epoch 505 
2025-01-31 01:59:27.064442: Current learning rate: 0.00531 
2025-01-31 02:00:15.097172: train_loss -0.8198 
2025-01-31 02:00:15.100785: val_loss -0.7298 
2025-01-31 02:00:15.103165: Pseudo dice [np.float32(0.9278), np.float32(0.8494)] 
2025-01-31 02:00:15.105619: Epoch time: 48.04 s 
2025-01-31 02:00:16.745943:  
2025-01-31 02:00:16.748754: Epoch 506 
2025-01-31 02:00:16.751324: Current learning rate: 0.0053 
2025-01-31 02:01:04.932695: train_loss -0.8139 
2025-01-31 02:01:04.938565: val_loss -0.7257 
2025-01-31 02:01:04.941421: Pseudo dice [np.float32(0.9364), np.float32(0.8572)] 
2025-01-31 02:01:04.944225: Epoch time: 48.19 s 
2025-01-31 02:01:06.064266:  
2025-01-31 02:01:06.067385: Epoch 507 
2025-01-31 02:01:06.070231: Current learning rate: 0.00529 
2025-01-31 02:01:54.403657: train_loss -0.823 
2025-01-31 02:01:54.407851: val_loss -0.6867 
2025-01-31 02:01:54.410680: Pseudo dice [np.float32(0.9352), np.float32(0.8131)] 
2025-01-31 02:01:54.413181: Epoch time: 48.34 s 
2025-01-31 02:01:55.531101:  
2025-01-31 02:01:55.533981: Epoch 508 
2025-01-31 02:01:55.536704: Current learning rate: 0.00528 
2025-01-31 02:02:43.734174: train_loss -0.8215 
2025-01-31 02:02:43.740000: val_loss -0.7141 
2025-01-31 02:02:43.742730: Pseudo dice [np.float32(0.95), np.float32(0.8937)] 
2025-01-31 02:02:43.745380: Epoch time: 48.2 s 
2025-01-31 02:02:44.865924:  
2025-01-31 02:02:44.870271: Epoch 509 
2025-01-31 02:02:44.872975: Current learning rate: 0.00527 
2025-01-31 02:03:33.114105: train_loss -0.8152 
2025-01-31 02:03:33.118338: val_loss -0.706 
2025-01-31 02:03:33.120994: Pseudo dice [np.float32(0.9281), np.float32(0.8475)] 
2025-01-31 02:03:33.123456: Epoch time: 48.25 s 
2025-01-31 02:03:34.243807:  
2025-01-31 02:03:34.246645: Epoch 510 
2025-01-31 02:03:34.248966: Current learning rate: 0.00526 
2025-01-31 02:04:22.297214: train_loss -0.8242 
2025-01-31 02:04:22.303956: val_loss -0.6799 
2025-01-31 02:04:22.308257: Pseudo dice [np.float32(0.9289), np.float32(0.7632)] 
2025-01-31 02:04:22.311164: Epoch time: 48.05 s 
2025-01-31 02:04:23.462969:  
2025-01-31 02:04:23.465683: Epoch 511 
2025-01-31 02:04:23.468262: Current learning rate: 0.00525 
2025-01-31 02:05:11.485853: train_loss -0.8132 
2025-01-31 02:05:11.489925: val_loss -0.7306 
2025-01-31 02:05:11.492883: Pseudo dice [np.float32(0.9453), np.float32(0.8324)] 
2025-01-31 02:05:11.495393: Epoch time: 48.02 s 
2025-01-31 02:05:12.655208:  
2025-01-31 02:05:12.658201: Epoch 512 
2025-01-31 02:05:12.660967: Current learning rate: 0.00524 
2025-01-31 02:06:01.102299: train_loss -0.8368 
2025-01-31 02:06:01.108754: val_loss -0.7077 
2025-01-31 02:06:01.112124: Pseudo dice [np.float32(0.9348), np.float32(0.8908)] 
2025-01-31 02:06:01.115346: Epoch time: 48.45 s 
2025-01-31 02:06:02.241186:  
2025-01-31 02:06:02.244501: Epoch 513 
2025-01-31 02:06:02.248078: Current learning rate: 0.00523 
2025-01-31 02:06:50.422512: train_loss -0.8402 
2025-01-31 02:06:50.426580: val_loss -0.6297 
2025-01-31 02:06:50.429366: Pseudo dice [np.float32(0.9429), np.float32(0.6886)] 
2025-01-31 02:06:50.431900: Epoch time: 48.18 s 
2025-01-31 02:06:51.586142:  
2025-01-31 02:06:51.589224: Epoch 514 
2025-01-31 02:06:51.592184: Current learning rate: 0.00522 
2025-01-31 02:07:39.665077: train_loss -0.8315 
2025-01-31 02:07:39.670986: val_loss -0.7398 
2025-01-31 02:07:39.674116: Pseudo dice [np.float32(0.9526), np.float32(0.7884)] 
2025-01-31 02:07:39.676871: Epoch time: 48.08 s 
2025-01-31 02:07:40.804559:  
2025-01-31 02:07:40.807356: Epoch 515 
2025-01-31 02:07:40.810182: Current learning rate: 0.00521 
2025-01-31 02:08:28.746777: train_loss -0.8261 
2025-01-31 02:08:28.751065: val_loss -0.6652 
2025-01-31 02:08:28.753654: Pseudo dice [np.float32(0.9383), np.float32(0.6975)] 
2025-01-31 02:08:28.756151: Epoch time: 47.94 s 
2025-01-31 02:08:29.881385:  
2025-01-31 02:08:29.884528: Epoch 516 
2025-01-31 02:08:29.887330: Current learning rate: 0.0052 
2025-01-31 02:09:17.899800: train_loss -0.8317 
2025-01-31 02:09:17.904788: val_loss -0.7347 
2025-01-31 02:09:17.907257: Pseudo dice [np.float32(0.9511), np.float32(0.7794)] 
2025-01-31 02:09:17.909590: Epoch time: 48.02 s 
2025-01-31 02:09:19.032850:  
2025-01-31 02:09:19.036285: Epoch 517 
2025-01-31 02:09:19.039620: Current learning rate: 0.00519 
2025-01-31 02:10:07.157193: train_loss -0.8338 
2025-01-31 02:10:07.160976: val_loss -0.7059 
2025-01-31 02:10:07.163787: Pseudo dice [np.float32(0.9464), np.float32(0.8167)] 
2025-01-31 02:10:07.166479: Epoch time: 48.13 s 
2025-01-31 02:10:08.330086:  
2025-01-31 02:10:08.333344: Epoch 518 
2025-01-31 02:10:08.336045: Current learning rate: 0.00518 
2025-01-31 02:10:56.644408: train_loss -0.8254 
2025-01-31 02:10:56.651523: val_loss -0.7102 
2025-01-31 02:10:56.654439: Pseudo dice [np.float32(0.9549), np.float32(0.7897)] 
2025-01-31 02:10:56.656767: Epoch time: 48.32 s 
2025-01-31 02:10:57.825353:  
2025-01-31 02:10:57.828271: Epoch 519 
2025-01-31 02:10:57.830841: Current learning rate: 0.00518 
2025-01-31 02:11:45.801044: train_loss -0.8325 
2025-01-31 02:11:45.808489: val_loss -0.7134 
2025-01-31 02:11:45.811119: Pseudo dice [np.float32(0.9543), np.float32(0.8865)] 
2025-01-31 02:11:45.813659: Epoch time: 47.98 s 
2025-01-31 02:11:46.938262:  
2025-01-31 02:11:46.941045: Epoch 520 
2025-01-31 02:11:46.943789: Current learning rate: 0.00517 
2025-01-31 02:12:35.422102: train_loss -0.8281 
2025-01-31 02:12:35.428916: val_loss -0.7003 
2025-01-31 02:12:35.431410: Pseudo dice [np.float32(0.9338), np.float32(0.7212)] 
2025-01-31 02:12:35.433790: Epoch time: 48.49 s 
2025-01-31 02:12:36.599901:  
2025-01-31 02:12:36.602709: Epoch 521 
2025-01-31 02:12:36.605326: Current learning rate: 0.00516 
2025-01-31 02:13:24.635503: train_loss -0.8257 
2025-01-31 02:13:24.639602: val_loss -0.7289 
2025-01-31 02:13:24.642199: Pseudo dice [np.float32(0.926), np.float32(0.8372)] 
2025-01-31 02:13:24.644739: Epoch time: 48.04 s 
2025-01-31 02:13:25.762701:  
2025-01-31 02:13:25.765718: Epoch 522 
2025-01-31 02:13:25.768663: Current learning rate: 0.00515 
2025-01-31 02:14:13.688244: train_loss -0.824 
2025-01-31 02:14:13.693491: val_loss -0.7061 
2025-01-31 02:14:13.695863: Pseudo dice [np.float32(0.9498), np.float32(0.7187)] 
2025-01-31 02:14:13.698335: Epoch time: 47.93 s 
2025-01-31 02:14:14.827115:  
2025-01-31 02:14:14.830248: Epoch 523 
2025-01-31 02:14:14.833091: Current learning rate: 0.00514 
2025-01-31 02:15:02.954166: train_loss -0.8307 
2025-01-31 02:15:02.958884: val_loss -0.6902 
2025-01-31 02:15:02.961920: Pseudo dice [np.float32(0.9393), np.float32(0.8175)] 
2025-01-31 02:15:02.964884: Epoch time: 48.13 s 
2025-01-31 02:15:04.093632:  
2025-01-31 02:15:04.097014: Epoch 524 
2025-01-31 02:15:04.099685: Current learning rate: 0.00513 
2025-01-31 02:15:51.984847: train_loss -0.8321 
2025-01-31 02:15:51.990748: val_loss -0.6538 
2025-01-31 02:15:51.993820: Pseudo dice [np.float32(0.9451), np.float32(0.6229)] 
2025-01-31 02:15:51.996712: Epoch time: 47.89 s 
2025-01-31 02:15:53.706726:  
2025-01-31 02:15:53.710044: Epoch 525 
2025-01-31 02:15:53.712829: Current learning rate: 0.00512 
2025-01-31 02:16:41.818946: train_loss -0.8292 
2025-01-31 02:16:41.822995: val_loss -0.6722 
2025-01-31 02:16:41.825615: Pseudo dice [np.float32(0.9427), np.float32(0.6748)] 
2025-01-31 02:16:41.828033: Epoch time: 48.11 s 
2025-01-31 02:16:42.952919:  
2025-01-31 02:16:42.955692: Epoch 526 
2025-01-31 02:16:42.958794: Current learning rate: 0.00511 
2025-01-31 02:17:30.689539: train_loss -0.8144 
2025-01-31 02:17:30.695372: val_loss -0.7135 
2025-01-31 02:17:30.698365: Pseudo dice [np.float32(0.9496), np.float32(0.7202)] 
2025-01-31 02:17:30.701305: Epoch time: 47.74 s 
2025-01-31 02:17:31.862504:  
2025-01-31 02:17:31.865192: Epoch 527 
2025-01-31 02:17:31.867850: Current learning rate: 0.0051 
2025-01-31 02:18:19.737667: train_loss -0.82 
2025-01-31 02:18:19.742048: val_loss -0.7472 
2025-01-31 02:18:19.744628: Pseudo dice [np.float32(0.9502), np.float32(0.8332)] 
2025-01-31 02:18:19.747116: Epoch time: 47.88 s 
2025-01-31 02:18:20.878365:  
2025-01-31 02:18:20.881414: Epoch 528 
2025-01-31 02:18:20.883951: Current learning rate: 0.00509 
2025-01-31 02:19:08.700657: train_loss -0.821 
2025-01-31 02:19:08.706347: val_loss -0.693 
2025-01-31 02:19:08.709166: Pseudo dice [np.float32(0.9427), np.float32(0.8188)] 
2025-01-31 02:19:08.712090: Epoch time: 47.82 s 
2025-01-31 02:19:09.874943:  
2025-01-31 02:19:09.877971: Epoch 529 
2025-01-31 02:19:09.880914: Current learning rate: 0.00508 
2025-01-31 02:19:57.670705: train_loss -0.8276 
2025-01-31 02:19:57.674937: val_loss -0.6923 
2025-01-31 02:19:57.677634: Pseudo dice [np.float32(0.9452), np.float32(0.7866)] 
2025-01-31 02:19:57.680339: Epoch time: 47.8 s 
2025-01-31 02:19:58.802626:  
2025-01-31 02:19:58.805754: Epoch 530 
2025-01-31 02:19:58.809237: Current learning rate: 0.00507 
2025-01-31 02:20:46.860809: train_loss -0.8191 
2025-01-31 02:20:46.865852: val_loss -0.6945 
2025-01-31 02:20:46.868391: Pseudo dice [np.float32(0.9444), np.float32(0.8419)] 
2025-01-31 02:20:46.870896: Epoch time: 48.06 s 
2025-01-31 02:20:47.999794:  
2025-01-31 02:20:48.002285: Epoch 531 
2025-01-31 02:20:48.005070: Current learning rate: 0.00506 
2025-01-31 02:21:36.099720: train_loss -0.8061 
2025-01-31 02:21:36.103700: val_loss -0.7249 
2025-01-31 02:21:36.106304: Pseudo dice [np.float32(0.9514), np.float32(0.7973)] 
2025-01-31 02:21:36.109010: Epoch time: 48.1 s 
2025-01-31 02:21:37.239004:  
2025-01-31 02:21:37.241922: Epoch 532 
2025-01-31 02:21:37.244817: Current learning rate: 0.00505 
2025-01-31 02:22:25.405821: train_loss -0.7984 
2025-01-31 02:22:25.411434: val_loss -0.6962 
2025-01-31 02:22:25.413707: Pseudo dice [np.float32(0.9558), np.float32(0.7192)] 
2025-01-31 02:22:25.416073: Epoch time: 48.17 s 
2025-01-31 02:22:26.581807:  
2025-01-31 02:22:26.584887: Epoch 533 
2025-01-31 02:22:26.587803: Current learning rate: 0.00504 
2025-01-31 02:23:14.646562: train_loss -0.819 
2025-01-31 02:23:14.650449: val_loss -0.6843 
2025-01-31 02:23:14.652737: Pseudo dice [np.float32(0.9547), np.float32(0.6817)] 
2025-01-31 02:23:14.655406: Epoch time: 48.07 s 
2025-01-31 02:23:15.788959:  
2025-01-31 02:23:15.792170: Epoch 534 
2025-01-31 02:23:15.794918: Current learning rate: 0.00503 
2025-01-31 02:24:03.645128: train_loss -0.8236 
2025-01-31 02:24:03.650765: val_loss -0.6952 
2025-01-31 02:24:03.653736: Pseudo dice [np.float32(0.9522), np.float32(0.7592)] 
2025-01-31 02:24:03.656457: Epoch time: 47.86 s 
2025-01-31 02:24:04.788204:  
2025-01-31 02:24:04.791878: Epoch 535 
2025-01-31 02:24:04.794515: Current learning rate: 0.00502 
2025-01-31 02:24:53.118713: train_loss -0.8301 
2025-01-31 02:24:53.122864: val_loss -0.7323 
2025-01-31 02:24:53.125432: Pseudo dice [np.float32(0.9524), np.float32(0.7908)] 
2025-01-31 02:24:53.128137: Epoch time: 48.33 s 
2025-01-31 02:24:54.256785:  
2025-01-31 02:24:54.259827: Epoch 536 
2025-01-31 02:24:54.262702: Current learning rate: 0.00501 
2025-01-31 02:25:42.148540: train_loss -0.8368 
2025-01-31 02:25:42.155006: val_loss -0.758 
2025-01-31 02:25:42.157908: Pseudo dice [np.float32(0.9545), np.float32(0.7574)] 
2025-01-31 02:25:42.160450: Epoch time: 47.89 s 
2025-01-31 02:25:43.284570:  
2025-01-31 02:25:43.287572: Epoch 537 
2025-01-31 02:25:43.290361: Current learning rate: 0.005 
2025-01-31 02:26:31.316335: train_loss -0.8261 
2025-01-31 02:26:31.320799: val_loss -0.7619 
2025-01-31 02:26:31.323623: Pseudo dice [np.float32(0.9464), np.float32(0.7795)] 
2025-01-31 02:26:31.326335: Epoch time: 48.03 s 
2025-01-31 02:26:32.532278:  
2025-01-31 02:26:32.535406: Epoch 538 
2025-01-31 02:26:32.539044: Current learning rate: 0.00499 
2025-01-31 02:27:20.525222: train_loss -0.8393 
2025-01-31 02:27:20.529955: val_loss -0.6889 
2025-01-31 02:27:20.532663: Pseudo dice [np.float32(0.9492), np.float32(0.6908)] 
2025-01-31 02:27:20.534835: Epoch time: 47.99 s 
2025-01-31 02:27:21.656957:  
2025-01-31 02:27:21.660233: Epoch 539 
2025-01-31 02:27:21.662933: Current learning rate: 0.00498 
2025-01-31 02:28:09.863588: train_loss -0.8275 
2025-01-31 02:28:09.867934: val_loss -0.6888 
2025-01-31 02:28:09.870649: Pseudo dice [np.float32(0.9484), np.float32(0.7215)] 
2025-01-31 02:28:09.873322: Epoch time: 48.21 s 
2025-01-31 02:28:10.999888:  
2025-01-31 02:28:11.003032: Epoch 540 
2025-01-31 02:28:11.006179: Current learning rate: 0.00497 
2025-01-31 02:28:59.361892: train_loss -0.8291 
2025-01-31 02:28:59.367577: val_loss -0.7057 
2025-01-31 02:28:59.370295: Pseudo dice [np.float32(0.9424), np.float32(0.8144)] 
2025-01-31 02:28:59.372929: Epoch time: 48.36 s 
2025-01-31 02:29:00.531389:  
2025-01-31 02:29:00.533953: Epoch 541 
2025-01-31 02:29:00.536657: Current learning rate: 0.00496 
2025-01-31 02:29:48.387104: train_loss -0.8184 
2025-01-31 02:29:48.391568: val_loss -0.6358 
2025-01-31 02:29:48.394233: Pseudo dice [np.float32(0.945), np.float32(0.525)] 
2025-01-31 02:29:48.396870: Epoch time: 47.86 s 
2025-01-31 02:29:49.519115:  
2025-01-31 02:29:49.522064: Epoch 542 
2025-01-31 02:29:49.524748: Current learning rate: 0.00495 
2025-01-31 02:30:37.525752: train_loss -0.8146 
2025-01-31 02:30:37.531192: val_loss -0.6978 
2025-01-31 02:30:37.533850: Pseudo dice [np.float32(0.9458), np.float32(0.7282)] 
2025-01-31 02:30:37.536663: Epoch time: 48.01 s 
2025-01-31 02:30:38.696414:  
2025-01-31 02:30:38.699494: Epoch 543 
2025-01-31 02:30:38.702420: Current learning rate: 0.00494 
2025-01-31 02:31:26.765053: train_loss -0.8242 
2025-01-31 02:31:26.769449: val_loss -0.6506 
2025-01-31 02:31:26.771927: Pseudo dice [np.float32(0.9468), np.float32(0.5303)] 
2025-01-31 02:31:26.774645: Epoch time: 48.07 s 
2025-01-31 02:31:27.893620:  
2025-01-31 02:31:27.896416: Epoch 544 
2025-01-31 02:31:27.899324: Current learning rate: 0.00493 
2025-01-31 02:32:15.831129: train_loss -0.8322 
2025-01-31 02:32:15.836534: val_loss -0.6558 
2025-01-31 02:32:15.839109: Pseudo dice [np.float32(0.9411), np.float32(0.5958)] 
2025-01-31 02:32:15.841750: Epoch time: 47.94 s 
2025-01-31 02:32:17.506099:  
2025-01-31 02:32:17.509618: Epoch 545 
2025-01-31 02:32:17.512642: Current learning rate: 0.00492 
2025-01-31 02:33:05.651716: train_loss -0.8277 
2025-01-31 02:33:05.655495: val_loss -0.7076 
2025-01-31 02:33:05.658209: Pseudo dice [np.float32(0.9479), np.float32(0.7797)] 
2025-01-31 02:33:05.660844: Epoch time: 48.15 s 
2025-01-31 02:33:06.837895:  
2025-01-31 02:33:06.840651: Epoch 546 
2025-01-31 02:33:06.843014: Current learning rate: 0.00491 
2025-01-31 02:33:54.693970: train_loss -0.8249 
2025-01-31 02:33:54.699213: val_loss -0.674 
2025-01-31 02:33:54.701916: Pseudo dice [np.float32(0.9443), np.float32(0.5472)] 
2025-01-31 02:33:54.704364: Epoch time: 47.86 s 
2025-01-31 02:33:55.864344:  
2025-01-31 02:33:55.867383: Epoch 547 
2025-01-31 02:33:55.870441: Current learning rate: 0.0049 
2025-01-31 02:34:43.623412: train_loss -0.803 
2025-01-31 02:34:43.627678: val_loss -0.6775 
2025-01-31 02:34:43.630432: Pseudo dice [np.float32(0.9262), np.float32(0.7711)] 
2025-01-31 02:34:43.633168: Epoch time: 47.76 s 
2025-01-31 02:34:44.791567:  
2025-01-31 02:34:44.795427: Epoch 548 
2025-01-31 02:34:44.798322: Current learning rate: 0.00489 
2025-01-31 02:35:33.253145: train_loss -0.8321 
2025-01-31 02:35:33.258803: val_loss -0.7405 
2025-01-31 02:35:33.262396: Pseudo dice [np.float32(0.9334), np.float32(0.8447)] 
2025-01-31 02:35:33.265179: Epoch time: 48.46 s 
2025-01-31 02:35:34.425375:  
2025-01-31 02:35:34.428315: Epoch 549 
2025-01-31 02:35:34.430940: Current learning rate: 0.00488 
2025-01-31 02:36:22.518807: train_loss -0.8259 
2025-01-31 02:36:22.523463: val_loss -0.7196 
2025-01-31 02:36:22.526387: Pseudo dice [np.float32(0.9506), np.float32(0.8632)] 
2025-01-31 02:36:22.529183: Epoch time: 48.09 s 
2025-01-31 02:36:24.255317:  
2025-01-31 02:36:24.258339: Epoch 550 
2025-01-31 02:36:24.261436: Current learning rate: 0.00487 
2025-01-31 02:37:12.520266: train_loss -0.8463 
2025-01-31 02:37:12.526319: val_loss -0.7459 
2025-01-31 02:37:12.529436: Pseudo dice [np.float32(0.9464), np.float32(0.7818)] 
2025-01-31 02:37:12.532429: Epoch time: 48.27 s 
2025-01-31 02:37:13.654202:  
2025-01-31 02:37:13.657044: Epoch 551 
2025-01-31 02:37:13.659475: Current learning rate: 0.00486 
2025-01-31 02:38:01.746103: train_loss -0.8049 
2025-01-31 02:38:01.750591: val_loss -0.6805 
2025-01-31 02:38:01.753355: Pseudo dice [np.float32(0.9339), np.float32(0.7762)] 
2025-01-31 02:38:01.756067: Epoch time: 48.09 s 
2025-01-31 02:38:02.882664:  
2025-01-31 02:38:02.885463: Epoch 552 
2025-01-31 02:38:02.888260: Current learning rate: 0.00485 
2025-01-31 02:38:51.043180: train_loss -0.8249 
2025-01-31 02:38:51.049244: val_loss -0.7162 
2025-01-31 02:38:51.051920: Pseudo dice [np.float32(0.9397), np.float32(0.8733)] 
2025-01-31 02:38:51.054663: Epoch time: 48.16 s 
2025-01-31 02:38:52.211926:  
2025-01-31 02:38:52.214881: Epoch 553 
2025-01-31 02:38:52.217989: Current learning rate: 0.00484 
2025-01-31 02:39:40.416096: train_loss -0.8284 
2025-01-31 02:39:40.420672: val_loss -0.7087 
2025-01-31 02:39:40.423434: Pseudo dice [np.float32(0.938), np.float32(0.7605)] 
2025-01-31 02:39:40.425940: Epoch time: 48.21 s 
2025-01-31 02:39:41.549317:  
2025-01-31 02:39:41.552609: Epoch 554 
2025-01-31 02:39:41.555385: Current learning rate: 0.00484 
2025-01-31 02:40:29.536018: train_loss -0.8117 
2025-01-31 02:40:29.541462: val_loss -0.6785 
2025-01-31 02:40:29.543769: Pseudo dice [np.float32(0.9421), np.float32(0.6801)] 
2025-01-31 02:40:29.546355: Epoch time: 47.99 s 
2025-01-31 02:40:30.671757:  
2025-01-31 02:40:30.674634: Epoch 555 
2025-01-31 02:40:30.677478: Current learning rate: 0.00483 
2025-01-31 02:41:19.015017: train_loss -0.8374 
2025-01-31 02:41:19.018937: val_loss -0.7216 
2025-01-31 02:41:19.021724: Pseudo dice [np.float32(0.947), np.float32(0.8193)] 
2025-01-31 02:41:19.023835: Epoch time: 48.34 s 
2025-01-31 02:41:20.170085:  
2025-01-31 02:41:20.173337: Epoch 556 
2025-01-31 02:41:20.176327: Current learning rate: 0.00482 
2025-01-31 02:42:08.250641: train_loss -0.82 
2025-01-31 02:42:08.255741: val_loss -0.6909 
2025-01-31 02:42:08.258359: Pseudo dice [np.float32(0.9504), np.float32(0.6996)] 
2025-01-31 02:42:08.260993: Epoch time: 48.08 s 
2025-01-31 02:42:09.388258:  
2025-01-31 02:42:09.391060: Epoch 557 
2025-01-31 02:42:09.394864: Current learning rate: 0.00481 
2025-01-31 02:42:57.582676: train_loss -0.8304 
2025-01-31 02:42:57.586946: val_loss -0.618 
2025-01-31 02:42:57.589702: Pseudo dice [np.float32(0.9376), np.float32(0.5441)] 
2025-01-31 02:42:57.592409: Epoch time: 48.2 s 
2025-01-31 02:42:58.756517:  
2025-01-31 02:42:58.759514: Epoch 558 
2025-01-31 02:42:58.762244: Current learning rate: 0.0048 
2025-01-31 02:43:47.038734: train_loss -0.8379 
2025-01-31 02:43:47.044090: val_loss -0.7342 
2025-01-31 02:43:47.046983: Pseudo dice [np.float32(0.954), np.float32(0.8868)] 
2025-01-31 02:43:47.049611: Epoch time: 48.28 s 
2025-01-31 02:43:48.208538:  
2025-01-31 02:43:48.211553: Epoch 559 
2025-01-31 02:43:48.214366: Current learning rate: 0.00479 
2025-01-31 02:44:36.360092: train_loss -0.8283 
2025-01-31 02:44:36.364100: val_loss -0.764 
2025-01-31 02:44:36.366455: Pseudo dice [np.float32(0.9515), np.float32(0.8604)] 
2025-01-31 02:44:36.368989: Epoch time: 48.15 s 
2025-01-31 02:44:37.493149:  
2025-01-31 02:44:37.496255: Epoch 560 
2025-01-31 02:44:37.499695: Current learning rate: 0.00478 
2025-01-31 02:45:25.762866: train_loss -0.8369 
2025-01-31 02:45:25.768316: val_loss -0.7471 
2025-01-31 02:45:25.771032: Pseudo dice [np.float32(0.9473), np.float32(0.869)] 
2025-01-31 02:45:25.773467: Epoch time: 48.27 s 
2025-01-31 02:45:26.934059:  
2025-01-31 02:45:26.937087: Epoch 561 
2025-01-31 02:45:26.939955: Current learning rate: 0.00477 
2025-01-31 02:46:15.063237: train_loss -0.8231 
2025-01-31 02:46:15.067630: val_loss -0.7327 
2025-01-31 02:46:15.070393: Pseudo dice [np.float32(0.9456), np.float32(0.7748)] 
2025-01-31 02:46:15.072641: Epoch time: 48.13 s 
2025-01-31 02:46:16.201154:  
2025-01-31 02:46:16.204108: Epoch 562 
2025-01-31 02:46:16.206741: Current learning rate: 0.00476 
2025-01-31 02:47:04.119800: train_loss -0.8159 
2025-01-31 02:47:04.124790: val_loss -0.6713 
2025-01-31 02:47:04.127380: Pseudo dice [np.float32(0.9537), np.float32(0.6275)] 
2025-01-31 02:47:04.129640: Epoch time: 47.92 s 
2025-01-31 02:47:05.259479:  
2025-01-31 02:47:05.262578: Epoch 563 
2025-01-31 02:47:05.265285: Current learning rate: 0.00475 
2025-01-31 02:47:53.627303: train_loss -0.8228 
2025-01-31 02:47:53.631723: val_loss -0.7446 
2025-01-31 02:47:53.634716: Pseudo dice [np.float32(0.9489), np.float32(0.8344)] 
2025-01-31 02:47:53.637232: Epoch time: 48.37 s 
2025-01-31 02:47:54.816021:  
2025-01-31 02:47:54.818819: Epoch 564 
2025-01-31 02:47:54.821736: Current learning rate: 0.00474 
2025-01-31 02:48:42.708488: train_loss -0.8269 
2025-01-31 02:48:42.713175: val_loss -0.7057 
2025-01-31 02:48:42.715721: Pseudo dice [np.float32(0.9565), np.float32(0.6938)] 
2025-01-31 02:48:42.718099: Epoch time: 47.89 s 
2025-01-31 02:48:43.880318:  
2025-01-31 02:48:43.883250: Epoch 565 
2025-01-31 02:48:43.886210: Current learning rate: 0.00473 
2025-01-31 02:49:31.973561: train_loss -0.8355 
2025-01-31 02:49:31.977832: val_loss -0.6986 
2025-01-31 02:49:31.980212: Pseudo dice [np.float32(0.9525), np.float32(0.6236)] 
2025-01-31 02:49:31.982674: Epoch time: 48.09 s 
2025-01-31 02:49:33.142781:  
2025-01-31 02:49:33.145376: Epoch 566 
2025-01-31 02:49:33.148149: Current learning rate: 0.00472 
2025-01-31 02:50:21.354643: train_loss -0.838 
2025-01-31 02:50:21.359543: val_loss -0.7247 
2025-01-31 02:50:21.362239: Pseudo dice [np.float32(0.9449), np.float32(0.7433)] 
2025-01-31 02:50:21.364503: Epoch time: 48.21 s 
2025-01-31 02:50:22.488481:  
2025-01-31 02:50:22.491060: Epoch 567 
2025-01-31 02:50:22.493790: Current learning rate: 0.00471 
2025-01-31 02:51:10.467126: train_loss -0.8364 
2025-01-31 02:51:10.472329: val_loss -0.6769 
2025-01-31 02:51:10.475013: Pseudo dice [np.float32(0.9376), np.float32(0.6411)] 
2025-01-31 02:51:10.477458: Epoch time: 47.98 s 
2025-01-31 02:51:11.626015:  
2025-01-31 02:51:11.628907: Epoch 568 
2025-01-31 02:51:11.631819: Current learning rate: 0.0047 
2025-01-31 02:51:59.689973: train_loss -0.8348 
2025-01-31 02:51:59.936152: val_loss -0.7452 
2025-01-31 02:51:59.938813: Pseudo dice [np.float32(0.9533), np.float32(0.8616)] 
2025-01-31 02:51:59.941451: Epoch time: 48.06 s 
2025-01-31 02:52:01.079124:  
2025-01-31 02:52:01.082017: Epoch 569 
2025-01-31 02:52:01.084844: Current learning rate: 0.00469 
2025-01-31 02:52:49.167702: train_loss -0.8292 
2025-01-31 02:52:49.172727: val_loss -0.7061 
2025-01-31 02:52:49.175612: Pseudo dice [np.float32(0.9447), np.float32(0.7066)] 
2025-01-31 02:52:49.178251: Epoch time: 48.09 s 
2025-01-31 02:52:50.322019:  
2025-01-31 02:52:50.324827: Epoch 570 
2025-01-31 02:52:50.328842: Current learning rate: 0.00468 
2025-01-31 02:53:38.438713: train_loss -0.8365 
2025-01-31 02:53:38.444002: val_loss -0.6887 
2025-01-31 02:53:38.446570: Pseudo dice [np.float32(0.9536), np.float32(0.7975)] 
2025-01-31 02:53:38.449155: Epoch time: 48.12 s 
2025-01-31 02:53:39.589167:  
2025-01-31 02:53:39.591928: Epoch 571 
2025-01-31 02:53:39.594620: Current learning rate: 0.00467 
2025-01-31 02:54:27.726959: train_loss -0.8301 
2025-01-31 02:54:27.731303: val_loss -0.7187 
2025-01-31 02:54:27.734228: Pseudo dice [np.float32(0.9463), np.float32(0.6871)] 
2025-01-31 02:54:27.737017: Epoch time: 48.14 s 
2025-01-31 02:54:28.876124:  
2025-01-31 02:54:28.878852: Epoch 572 
2025-01-31 02:54:28.881764: Current learning rate: 0.00466 
2025-01-31 02:55:16.877596: train_loss -0.8369 
2025-01-31 02:55:16.898628: val_loss -0.7146 
2025-01-31 02:55:16.900942: Pseudo dice [np.float32(0.9485), np.float32(0.7369)] 
2025-01-31 02:55:16.903198: Epoch time: 48.0 s 
2025-01-31 02:55:18.051756:  
2025-01-31 02:55:18.054361: Epoch 573 
2025-01-31 02:55:18.056886: Current learning rate: 0.00465 
2025-01-31 02:56:05.876325: train_loss -0.8397 
2025-01-31 02:56:05.880016: val_loss -0.7138 
2025-01-31 02:56:05.882670: Pseudo dice [np.float32(0.9529), np.float32(0.7831)] 
2025-01-31 02:56:05.884892: Epoch time: 47.83 s 
2025-01-31 02:56:07.045435:  
2025-01-31 02:56:07.051490: Epoch 574 
2025-01-31 02:56:07.054376: Current learning rate: 0.00464 
2025-01-31 02:56:55.081224: train_loss -0.8363 
2025-01-31 02:56:55.086715: val_loss -0.6508 
2025-01-31 02:56:55.090060: Pseudo dice [np.float32(0.9488), np.float32(0.5964)] 
2025-01-31 02:56:55.092798: Epoch time: 48.04 s 
2025-01-31 02:56:56.242018:  
2025-01-31 02:56:56.244589: Epoch 575 
2025-01-31 02:56:56.247019: Current learning rate: 0.00463 
2025-01-31 02:57:44.297198: train_loss -0.8301 
2025-01-31 02:57:44.301217: val_loss -0.6988 
2025-01-31 02:57:44.303788: Pseudo dice [np.float32(0.9528), np.float32(0.7156)] 
2025-01-31 02:57:44.306324: Epoch time: 48.06 s 
2025-01-31 02:57:45.461579:  
2025-01-31 02:57:45.464457: Epoch 576 
2025-01-31 02:57:45.467254: Current learning rate: 0.00462 
2025-01-31 02:58:33.240195: train_loss -0.8272 
2025-01-31 02:58:33.246464: val_loss -0.7338 
2025-01-31 02:58:33.249298: Pseudo dice [np.float32(0.9499), np.float32(0.7475)] 
2025-01-31 02:58:33.252028: Epoch time: 47.78 s 
2025-01-31 02:58:34.399636:  
2025-01-31 02:58:34.402467: Epoch 577 
2025-01-31 02:58:34.405049: Current learning rate: 0.00461 
2025-01-31 02:59:22.530892: train_loss -0.8288 
2025-01-31 02:59:22.535163: val_loss -0.7152 
2025-01-31 02:59:22.537906: Pseudo dice [np.float32(0.949), np.float32(0.8299)] 
2025-01-31 02:59:22.540291: Epoch time: 48.13 s 
2025-01-31 02:59:23.707287:  
2025-01-31 02:59:23.709861: Epoch 578 
2025-01-31 02:59:23.712273: Current learning rate: 0.0046 
2025-01-31 03:00:11.863322: train_loss -0.8295 
2025-01-31 03:00:11.869319: val_loss -0.6717 
2025-01-31 03:00:11.872392: Pseudo dice [np.float32(0.944), np.float32(0.7562)] 
2025-01-31 03:00:11.875020: Epoch time: 48.16 s 
2025-01-31 03:00:13.027943:  
2025-01-31 03:00:13.030449: Epoch 579 
2025-01-31 03:00:13.033017: Current learning rate: 0.00459 
2025-01-31 03:01:01.466342: train_loss -0.8268 
2025-01-31 03:01:01.470234: val_loss -0.6686 
2025-01-31 03:01:01.474087: Pseudo dice [np.float32(0.9399), np.float32(0.7378)] 
2025-01-31 03:01:01.476616: Epoch time: 48.44 s 
2025-01-31 03:01:02.630853:  
2025-01-31 03:01:02.633524: Epoch 580 
2025-01-31 03:01:02.636355: Current learning rate: 0.00458 
2025-01-31 03:01:50.506340: train_loss -0.8214 
2025-01-31 03:01:50.511534: val_loss -0.664 
2025-01-31 03:01:50.514238: Pseudo dice [np.float32(0.946), np.float32(0.6936)] 
2025-01-31 03:01:50.516732: Epoch time: 47.88 s 
2025-01-31 03:01:51.673091:  
2025-01-31 03:01:51.676273: Epoch 581 
2025-01-31 03:01:51.680723: Current learning rate: 0.00457 
2025-01-31 03:02:40.029984: train_loss -0.8273 
2025-01-31 03:02:40.033786: val_loss -0.7209 
2025-01-31 03:02:40.036351: Pseudo dice [np.float32(0.9611), np.float32(0.7713)] 
2025-01-31 03:02:40.038611: Epoch time: 48.36 s 
2025-01-31 03:02:41.766522:  
2025-01-31 03:02:41.769474: Epoch 582 
2025-01-31 03:02:41.772243: Current learning rate: 0.00456 
2025-01-31 03:03:29.949350: train_loss -0.8442 
2025-01-31 03:03:29.954464: val_loss -0.6844 
2025-01-31 03:03:29.957265: Pseudo dice [np.float32(0.9468), np.float32(0.7731)] 
2025-01-31 03:03:29.959732: Epoch time: 48.18 s 
2025-01-31 03:03:31.113539:  
2025-01-31 03:03:31.116522: Epoch 583 
2025-01-31 03:03:31.119371: Current learning rate: 0.00455 
2025-01-31 03:04:19.177635: train_loss -0.8405 
2025-01-31 03:04:19.181581: val_loss -0.64 
2025-01-31 03:04:19.184403: Pseudo dice [np.float32(0.9416), np.float32(0.584)] 
2025-01-31 03:04:19.187003: Epoch time: 48.07 s 
2025-01-31 03:04:20.346138:  
2025-01-31 03:04:20.348816: Epoch 584 
2025-01-31 03:04:20.351477: Current learning rate: 0.00454 
2025-01-31 03:05:08.310547: train_loss -0.8356 
2025-01-31 03:05:08.315984: val_loss -0.7179 
2025-01-31 03:05:08.318387: Pseudo dice [np.float32(0.9557), np.float32(0.7978)] 
2025-01-31 03:05:08.320950: Epoch time: 47.97 s 
2025-01-31 03:05:09.471426:  
2025-01-31 03:05:09.475676: Epoch 585 
2025-01-31 03:05:09.478233: Current learning rate: 0.00453 
2025-01-31 03:05:57.630581: train_loss -0.8418 
2025-01-31 03:05:57.634757: val_loss -0.7106 
2025-01-31 03:05:57.637258: Pseudo dice [np.float32(0.9511), np.float32(0.6545)] 
2025-01-31 03:05:57.639746: Epoch time: 48.16 s 
2025-01-31 03:05:58.793767:  
2025-01-31 03:05:58.796612: Epoch 586 
2025-01-31 03:05:58.798852: Current learning rate: 0.00452 
2025-01-31 03:06:46.680324: train_loss -0.8429 
2025-01-31 03:06:46.686142: val_loss -0.737 
2025-01-31 03:06:46.689113: Pseudo dice [np.float32(0.9598), np.float32(0.8307)] 
2025-01-31 03:06:46.691653: Epoch time: 47.89 s 
2025-01-31 03:06:47.844929:  
2025-01-31 03:06:47.847932: Epoch 587 
2025-01-31 03:06:47.850687: Current learning rate: 0.00451 
2025-01-31 03:07:36.208957: train_loss -0.8212 
2025-01-31 03:07:36.213165: val_loss -0.6635 
2025-01-31 03:07:36.215945: Pseudo dice [np.float32(0.943), np.float32(0.6938)] 
2025-01-31 03:07:36.218182: Epoch time: 48.36 s 
2025-01-31 03:07:37.379114:  
2025-01-31 03:07:37.381828: Epoch 588 
2025-01-31 03:07:37.384247: Current learning rate: 0.0045 
2025-01-31 03:08:25.262096: train_loss -0.8239 
2025-01-31 03:08:25.267204: val_loss -0.6888 
2025-01-31 03:08:25.270040: Pseudo dice [np.float32(0.9502), np.float32(0.8671)] 
2025-01-31 03:08:25.272649: Epoch time: 47.88 s 
2025-01-31 03:08:26.421211:  
2025-01-31 03:08:26.424146: Epoch 589 
2025-01-31 03:08:26.427808: Current learning rate: 0.00449 
2025-01-31 03:09:14.475760: train_loss -0.8314 
2025-01-31 03:09:14.479539: val_loss -0.6939 
2025-01-31 03:09:14.482303: Pseudo dice [np.float32(0.9417), np.float32(0.7779)] 
2025-01-31 03:09:14.484793: Epoch time: 48.06 s 
2025-01-31 03:09:15.634835:  
2025-01-31 03:09:15.637889: Epoch 590 
2025-01-31 03:09:15.640876: Current learning rate: 0.00448 
2025-01-31 03:10:03.715376: train_loss -0.8529 
2025-01-31 03:10:03.735836: val_loss -0.7051 
2025-01-31 03:10:03.738740: Pseudo dice [np.float32(0.945), np.float32(0.7275)] 
2025-01-31 03:10:03.741321: Epoch time: 48.08 s 
2025-01-31 03:10:04.892475:  
2025-01-31 03:10:04.895171: Epoch 591 
2025-01-31 03:10:04.897831: Current learning rate: 0.00447 
2025-01-31 03:10:53.173253: train_loss -0.8463 
2025-01-31 03:10:53.177130: val_loss -0.6666 
2025-01-31 03:10:53.179678: Pseudo dice [np.float32(0.9305), np.float32(0.7117)] 
2025-01-31 03:10:53.182228: Epoch time: 48.28 s 
2025-01-31 03:10:54.333542:  
2025-01-31 03:10:54.337898: Epoch 592 
2025-01-31 03:10:54.340864: Current learning rate: 0.00446 
2025-01-31 03:11:42.325653: train_loss -0.8232 
2025-01-31 03:11:42.330607: val_loss -0.6779 
2025-01-31 03:11:42.333256: Pseudo dice [np.float32(0.9471), np.float32(0.6893)] 
2025-01-31 03:11:42.335728: Epoch time: 47.99 s 
2025-01-31 03:11:43.491006:  
2025-01-31 03:11:43.493507: Epoch 593 
2025-01-31 03:11:43.495922: Current learning rate: 0.00445 
2025-01-31 03:12:31.675328: train_loss -0.82 
2025-01-31 03:12:31.678826: val_loss -0.6932 
2025-01-31 03:12:31.681404: Pseudo dice [np.float32(0.9497), np.float32(0.6809)] 
2025-01-31 03:12:31.683793: Epoch time: 48.19 s 
2025-01-31 03:12:32.839248:  
2025-01-31 03:12:32.842086: Epoch 594 
2025-01-31 03:12:32.844798: Current learning rate: 0.00444 
2025-01-31 03:13:20.879280: train_loss -0.8283 
2025-01-31 03:13:20.884182: val_loss -0.7338 
2025-01-31 03:13:20.886620: Pseudo dice [np.float32(0.9481), np.float32(0.7381)] 
2025-01-31 03:13:20.889000: Epoch time: 48.04 s 
2025-01-31 03:13:22.039305:  
2025-01-31 03:13:22.041890: Epoch 595 
2025-01-31 03:13:22.044404: Current learning rate: 0.00443 
2025-01-31 03:14:10.005729: train_loss -0.7959 
2025-01-31 03:14:10.009468: val_loss -0.6954 
2025-01-31 03:14:10.012290: Pseudo dice [np.float32(0.9554), np.float32(0.6576)] 
2025-01-31 03:14:10.014560: Epoch time: 47.97 s 
2025-01-31 03:14:11.164859:  
2025-01-31 03:14:11.167709: Epoch 596 
2025-01-31 03:14:11.170241: Current learning rate: 0.00442 
2025-01-31 03:14:59.441989: train_loss -0.8303 
2025-01-31 03:14:59.446433: val_loss -0.7106 
2025-01-31 03:14:59.448870: Pseudo dice [np.float32(0.9463), np.float32(0.8209)] 
2025-01-31 03:14:59.451123: Epoch time: 48.28 s 
2025-01-31 03:15:00.604453:  
2025-01-31 03:15:00.606968: Epoch 597 
2025-01-31 03:15:00.609617: Current learning rate: 0.00441 
2025-01-31 03:15:48.822259: train_loss -0.8293 
2025-01-31 03:15:48.825921: val_loss -0.6473 
2025-01-31 03:15:48.828188: Pseudo dice [np.float32(0.9342), np.float32(0.7548)] 
2025-01-31 03:15:48.830663: Epoch time: 48.22 s 
2025-01-31 03:15:49.983610:  
2025-01-31 03:15:49.986068: Epoch 598 
2025-01-31 03:15:49.988672: Current learning rate: 0.0044 
2025-01-31 03:16:38.327848: train_loss -0.8295 
2025-01-31 03:16:38.332883: val_loss -0.7037 
2025-01-31 03:16:38.335213: Pseudo dice [np.float32(0.9444), np.float32(0.6945)] 
2025-01-31 03:16:38.337581: Epoch time: 48.35 s 
2025-01-31 03:16:39.493026:  
2025-01-31 03:16:39.495359: Epoch 599 
2025-01-31 03:16:39.497666: Current learning rate: 0.00439 
2025-01-31 03:17:27.469721: train_loss -0.8217 
2025-01-31 03:17:27.473368: val_loss -0.671 
2025-01-31 03:17:27.476037: Pseudo dice [np.float32(0.946), np.float32(0.6832)] 
2025-01-31 03:17:27.478403: Epoch time: 47.98 s 
2025-01-31 03:17:29.156206:  
2025-01-31 03:17:29.158847: Epoch 600 
2025-01-31 03:17:29.162273: Current learning rate: 0.00438 
2025-01-31 03:18:17.063118: train_loss -0.8326 
2025-01-31 03:18:17.068409: val_loss -0.7049 
2025-01-31 03:18:17.070934: Pseudo dice [np.float32(0.9456), np.float32(0.5752)] 
2025-01-31 03:18:17.073419: Epoch time: 47.91 s 
2025-01-31 03:18:18.762021:  
2025-01-31 03:18:18.764954: Epoch 601 
2025-01-31 03:18:18.767550: Current learning rate: 0.00437 
2025-01-31 03:19:06.876088: train_loss -0.8345 
2025-01-31 03:19:06.879637: val_loss -0.6928 
2025-01-31 03:19:06.881846: Pseudo dice [np.float32(0.9521), np.float32(0.7602)] 
2025-01-31 03:19:06.884259: Epoch time: 48.11 s 
2025-01-31 03:19:08.031061:  
2025-01-31 03:19:08.033659: Epoch 602 
2025-01-31 03:19:08.036535: Current learning rate: 0.00436 
2025-01-31 03:19:56.073516: train_loss -0.834 
2025-01-31 03:19:56.079065: val_loss -0.7248 
2025-01-31 03:19:56.081576: Pseudo dice [np.float32(0.9487), np.float32(0.781)] 
2025-01-31 03:19:56.084566: Epoch time: 48.04 s 
2025-01-31 03:19:57.236600:  
2025-01-31 03:19:57.239665: Epoch 603 
2025-01-31 03:19:57.242187: Current learning rate: 0.00435 
2025-01-31 03:20:45.633819: train_loss -0.8299 
2025-01-31 03:20:45.637797: val_loss -0.7035 
2025-01-31 03:20:45.640478: Pseudo dice [np.float32(0.9223), np.float32(0.8005)] 
2025-01-31 03:20:45.642841: Epoch time: 48.4 s 
2025-01-31 03:20:46.799406:  
2025-01-31 03:20:46.802503: Epoch 604 
2025-01-31 03:20:46.805771: Current learning rate: 0.00434 
2025-01-31 03:21:34.741054: train_loss -0.8276 
2025-01-31 03:21:34.746476: val_loss -0.6971 
2025-01-31 03:21:34.749178: Pseudo dice [np.float32(0.947), np.float32(0.6605)] 
2025-01-31 03:21:34.751793: Epoch time: 47.94 s 
2025-01-31 03:21:35.906016:  
2025-01-31 03:21:35.910584: Epoch 605 
2025-01-31 03:21:35.913054: Current learning rate: 0.00433 
2025-01-31 03:22:24.377754: train_loss -0.8262 
2025-01-31 03:22:24.382010: val_loss -0.6804 
2025-01-31 03:22:24.384835: Pseudo dice [np.float32(0.9437), np.float32(0.7674)] 
2025-01-31 03:22:24.387383: Epoch time: 48.47 s 
2025-01-31 03:22:25.544668:  
2025-01-31 03:22:25.547538: Epoch 606 
2025-01-31 03:22:25.550214: Current learning rate: 0.00432 
2025-01-31 03:23:13.560013: train_loss -0.8517 
2025-01-31 03:23:13.565805: val_loss -0.7644 
2025-01-31 03:23:13.568732: Pseudo dice [np.float32(0.954), np.float32(0.8718)] 
2025-01-31 03:23:13.571158: Epoch time: 48.02 s 
2025-01-31 03:23:14.729943:  
2025-01-31 03:23:14.734578: Epoch 607 
2025-01-31 03:23:14.737346: Current learning rate: 0.00431 
2025-01-31 03:24:02.751148: train_loss -0.8398 
2025-01-31 03:24:02.755374: val_loss -0.7352 
2025-01-31 03:24:02.758089: Pseudo dice [np.float32(0.9416), np.float32(0.7839)] 
2025-01-31 03:24:02.760888: Epoch time: 48.02 s 
2025-01-31 03:24:03.920344:  
2025-01-31 03:24:03.923206: Epoch 608 
2025-01-31 03:24:03.925818: Current learning rate: 0.0043 
2025-01-31 03:24:52.064166: train_loss -0.8361 
2025-01-31 03:24:52.070510: val_loss -0.7462 
2025-01-31 03:24:52.073129: Pseudo dice [np.float32(0.952), np.float32(0.7985)] 
2025-01-31 03:24:52.075548: Epoch time: 48.14 s 
2025-01-31 03:24:53.225490:  
2025-01-31 03:24:53.227939: Epoch 609 
2025-01-31 03:24:53.230623: Current learning rate: 0.00429 
2025-01-31 03:25:41.824650: train_loss -0.8346 
2025-01-31 03:25:41.828321: val_loss -0.7393 
2025-01-31 03:25:41.831137: Pseudo dice [np.float32(0.9463), np.float32(0.8229)] 
2025-01-31 03:25:41.833614: Epoch time: 48.6 s 
2025-01-31 03:25:42.988856:  
2025-01-31 03:25:42.991703: Epoch 610 
2025-01-31 03:25:42.994179: Current learning rate: 0.00429 
2025-01-31 03:26:31.415753: train_loss -0.8353 
2025-01-31 03:26:31.421350: val_loss -0.7031 
2025-01-31 03:26:31.423778: Pseudo dice [np.float32(0.9354), np.float32(0.7892)] 
2025-01-31 03:26:31.426348: Epoch time: 48.43 s 
2025-01-31 03:26:32.586250:  
2025-01-31 03:26:32.588960: Epoch 611 
2025-01-31 03:26:32.591549: Current learning rate: 0.00428 
2025-01-31 03:27:20.750490: train_loss -0.8441 
2025-01-31 03:27:20.754308: val_loss -0.7505 
2025-01-31 03:27:20.756856: Pseudo dice [np.float32(0.9551), np.float32(0.8787)] 
2025-01-31 03:27:20.759457: Epoch time: 48.17 s 
2025-01-31 03:27:21.917135:  
2025-01-31 03:27:21.919972: Epoch 612 
2025-01-31 03:27:21.923208: Current learning rate: 0.00427 
2025-01-31 03:28:09.879231: train_loss -0.8504 
2025-01-31 03:28:09.885173: val_loss -0.7016 
2025-01-31 03:28:09.888016: Pseudo dice [np.float32(0.9526), np.float32(0.711)] 
2025-01-31 03:28:09.890489: Epoch time: 47.96 s 
2025-01-31 03:28:11.047202:  
2025-01-31 03:28:11.049916: Epoch 613 
2025-01-31 03:28:11.052764: Current learning rate: 0.00426 
2025-01-31 03:28:59.322658: train_loss -0.8529 
2025-01-31 03:28:59.326134: val_loss -0.7462 
2025-01-31 03:28:59.328598: Pseudo dice [np.float32(0.9531), np.float32(0.8408)] 
2025-01-31 03:28:59.330673: Epoch time: 48.28 s 
2025-01-31 03:29:00.487196:  
2025-01-31 03:29:00.489896: Epoch 614 
2025-01-31 03:29:00.492812: Current learning rate: 0.00425 
2025-01-31 03:29:48.531976: train_loss -0.8377 
2025-01-31 03:29:48.539804: val_loss -0.7071 
2025-01-31 03:29:48.542640: Pseudo dice [np.float32(0.9417), np.float32(0.7431)] 
2025-01-31 03:29:48.545246: Epoch time: 48.05 s 
2025-01-31 03:29:49.708290:  
2025-01-31 03:29:49.711449: Epoch 615 
2025-01-31 03:29:49.714653: Current learning rate: 0.00424 
2025-01-31 03:30:37.867219: train_loss -0.8118 
2025-01-31 03:30:37.872318: val_loss -0.7057 
2025-01-31 03:30:37.874636: Pseudo dice [np.float32(0.9426), np.float32(0.7917)] 
2025-01-31 03:30:37.877215: Epoch time: 48.16 s 
2025-01-31 03:30:39.035705:  
2025-01-31 03:30:39.038726: Epoch 616 
2025-01-31 03:30:39.041648: Current learning rate: 0.00423 
2025-01-31 03:31:27.230628: train_loss -0.8358 
2025-01-31 03:31:27.237327: val_loss -0.7248 
2025-01-31 03:31:27.239949: Pseudo dice [np.float32(0.9303), np.float32(0.8861)] 
2025-01-31 03:31:27.242573: Epoch time: 48.2 s 
2025-01-31 03:31:28.396031:  
2025-01-31 03:31:28.398817: Epoch 617 
2025-01-31 03:31:28.401710: Current learning rate: 0.00422 
2025-01-31 03:32:16.268967: train_loss -0.8356 
2025-01-31 03:32:16.275075: val_loss -0.6494 
2025-01-31 03:32:16.278218: Pseudo dice [np.float32(0.9299), np.float32(0.602)] 
2025-01-31 03:32:16.281906: Epoch time: 47.87 s 
2025-01-31 03:32:17.437593:  
2025-01-31 03:32:17.440125: Epoch 618 
2025-01-31 03:32:17.443364: Current learning rate: 0.00421 
2025-01-31 03:33:05.576188: train_loss -0.8257 
2025-01-31 03:33:05.582487: val_loss -0.7413 
2025-01-31 03:33:05.585058: Pseudo dice [np.float32(0.9476), np.float32(0.8953)] 
2025-01-31 03:33:05.587609: Epoch time: 48.14 s 
2025-01-31 03:33:06.748409:  
2025-01-31 03:33:06.750997: Epoch 619 
2025-01-31 03:33:06.753611: Current learning rate: 0.0042 
2025-01-31 03:33:54.530474: train_loss -0.8225 
2025-01-31 03:33:54.536680: val_loss -0.6519 
2025-01-31 03:33:54.539054: Pseudo dice [np.float32(0.9474), np.float32(0.5704)] 
2025-01-31 03:33:54.541444: Epoch time: 47.78 s 
2025-01-31 03:33:56.261714:  
2025-01-31 03:33:56.264888: Epoch 620 
2025-01-31 03:33:56.267417: Current learning rate: 0.00419 
2025-01-31 03:34:44.477260: train_loss -0.8319 
2025-01-31 03:34:44.483217: val_loss -0.5879 
2025-01-31 03:34:44.486082: Pseudo dice [np.float32(0.9436), np.float32(0.4118)] 
2025-01-31 03:34:44.488456: Epoch time: 48.22 s 
2025-01-31 03:34:45.647093:  
2025-01-31 03:34:45.649893: Epoch 621 
2025-01-31 03:34:45.652645: Current learning rate: 0.00418 
2025-01-31 03:35:34.158441: train_loss -0.8098 
2025-01-31 03:35:34.165594: val_loss -0.7032 
2025-01-31 03:35:34.168248: Pseudo dice [np.float32(0.938), np.float32(0.7246)] 
2025-01-31 03:35:34.171027: Epoch time: 48.51 s 
2025-01-31 03:35:35.331656:  
2025-01-31 03:35:35.334457: Epoch 622 
2025-01-31 03:35:35.336917: Current learning rate: 0.00417 
2025-01-31 03:36:23.191033: train_loss -0.8127 
2025-01-31 03:36:23.198763: val_loss -0.6866 
2025-01-31 03:36:23.201410: Pseudo dice [np.float32(0.9461), np.float32(0.6963)] 
2025-01-31 03:36:23.204015: Epoch time: 47.86 s 
2025-01-31 03:36:24.363043:  
2025-01-31 03:36:24.365813: Epoch 623 
2025-01-31 03:36:24.368261: Current learning rate: 0.00416 
2025-01-31 03:37:12.629897: train_loss -0.8201 
2025-01-31 03:37:12.635045: val_loss -0.726 
2025-01-31 03:37:12.637481: Pseudo dice [np.float32(0.9541), np.float32(0.7385)] 
2025-01-31 03:37:12.639947: Epoch time: 48.27 s 
2025-01-31 03:37:13.804345:  
2025-01-31 03:37:13.807141: Epoch 624 
2025-01-31 03:37:13.809983: Current learning rate: 0.00415 
2025-01-31 03:38:02.078357: train_loss -0.8262 
2025-01-31 03:38:02.090427: val_loss -0.7645 
2025-01-31 03:38:02.093199: Pseudo dice [np.float32(0.9563), np.float32(0.7839)] 
2025-01-31 03:38:02.095976: Epoch time: 48.27 s 
2025-01-31 03:38:03.262277:  
2025-01-31 03:38:03.265128: Epoch 625 
2025-01-31 03:38:03.268159: Current learning rate: 0.00414 
2025-01-31 03:38:51.344801: train_loss -0.8399 
2025-01-31 03:38:51.350222: val_loss -0.7101 
2025-01-31 03:38:51.353088: Pseudo dice [np.float32(0.9398), np.float32(0.7639)] 
2025-01-31 03:38:51.355897: Epoch time: 48.08 s 
2025-01-31 03:38:52.520575:  
2025-01-31 03:38:52.523498: Epoch 626 
2025-01-31 03:38:52.526317: Current learning rate: 0.00413 
2025-01-31 03:39:40.681156: train_loss -0.8313 
2025-01-31 03:39:40.688104: val_loss -0.6813 
2025-01-31 03:39:40.690694: Pseudo dice [np.float32(0.9416), np.float32(0.7217)] 
2025-01-31 03:39:40.693241: Epoch time: 48.16 s 
2025-01-31 03:39:41.854816:  
2025-01-31 03:39:41.857784: Epoch 627 
2025-01-31 03:39:41.860349: Current learning rate: 0.00412 
2025-01-31 03:40:29.735855: train_loss -0.8256 
2025-01-31 03:40:29.740869: val_loss -0.7005 
2025-01-31 03:40:29.743337: Pseudo dice [np.float32(0.953), np.float32(0.8017)] 
2025-01-31 03:40:29.745748: Epoch time: 47.88 s 
2025-01-31 03:40:30.902437:  
2025-01-31 03:40:30.905221: Epoch 628 
2025-01-31 03:40:30.907975: Current learning rate: 0.00411 
2025-01-31 03:41:19.067780: train_loss -0.8319 
2025-01-31 03:41:19.073949: val_loss -0.6862 
2025-01-31 03:41:19.076340: Pseudo dice [np.float32(0.9517), np.float32(0.7829)] 
2025-01-31 03:41:19.078797: Epoch time: 48.17 s 
2025-01-31 03:41:20.238453:  
2025-01-31 03:41:20.241451: Epoch 629 
2025-01-31 03:41:20.243969: Current learning rate: 0.0041 
2025-01-31 03:42:08.499215: train_loss -0.8327 
2025-01-31 03:42:08.504215: val_loss -0.7566 
2025-01-31 03:42:08.506770: Pseudo dice [np.float32(0.954), np.float32(0.7736)] 
2025-01-31 03:42:08.509024: Epoch time: 48.26 s 
2025-01-31 03:42:09.674948:  
2025-01-31 03:42:09.677783: Epoch 630 
2025-01-31 03:42:09.680447: Current learning rate: 0.00409 
2025-01-31 03:42:58.350694: train_loss -0.8356 
2025-01-31 03:42:58.356590: val_loss -0.6755 
2025-01-31 03:42:58.359601: Pseudo dice [np.float32(0.9441), np.float32(0.6362)] 
2025-01-31 03:42:58.362440: Epoch time: 48.68 s 
2025-01-31 03:42:59.521775:  
2025-01-31 03:42:59.525038: Epoch 631 
2025-01-31 03:42:59.527827: Current learning rate: 0.00408 
2025-01-31 03:43:47.739765: train_loss -0.8369 
2025-01-31 03:43:47.743482: val_loss -0.674 
2025-01-31 03:43:47.745846: Pseudo dice [np.float32(0.9504), np.float32(0.7631)] 
2025-01-31 03:43:47.748540: Epoch time: 48.22 s 
2025-01-31 03:43:48.903749:  
2025-01-31 03:43:48.906331: Epoch 632 
2025-01-31 03:43:48.908706: Current learning rate: 0.00407 
2025-01-31 03:44:36.842204: train_loss -0.8335 
2025-01-31 03:44:36.847184: val_loss -0.7277 
2025-01-31 03:44:36.849409: Pseudo dice [np.float32(0.9477), np.float32(0.7544)] 
2025-01-31 03:44:36.851885: Epoch time: 47.94 s 
2025-01-31 03:44:38.005536:  
2025-01-31 03:44:38.009465: Epoch 633 
2025-01-31 03:44:38.012081: Current learning rate: 0.00406 
2025-01-31 03:45:25.982469: train_loss -0.8261 
2025-01-31 03:45:25.986720: val_loss -0.6342 
2025-01-31 03:45:25.989524: Pseudo dice [np.float32(0.939), np.float32(0.7294)] 
2025-01-31 03:45:25.991755: Epoch time: 47.98 s 
2025-01-31 03:45:27.148865:  
2025-01-31 03:45:27.151662: Epoch 634 
2025-01-31 03:45:27.154381: Current learning rate: 0.00405 
2025-01-31 03:46:15.049999: train_loss -0.851 
2025-01-31 03:46:15.055645: val_loss -0.7237 
2025-01-31 03:46:15.058079: Pseudo dice [np.float32(0.9445), np.float32(0.8139)] 
2025-01-31 03:46:15.060472: Epoch time: 47.9 s 
2025-01-31 03:46:16.217658:  
2025-01-31 03:46:16.221997: Epoch 635 
2025-01-31 03:46:16.224566: Current learning rate: 0.00404 
2025-01-31 03:47:04.514094: train_loss -0.8478 
2025-01-31 03:47:04.520476: val_loss -0.7676 
2025-01-31 03:47:04.523307: Pseudo dice [np.float32(0.9531), np.float32(0.8884)] 
2025-01-31 03:47:04.525726: Epoch time: 48.3 s 
2025-01-31 03:47:05.686386:  
2025-01-31 03:47:05.689353: Epoch 636 
2025-01-31 03:47:05.692040: Current learning rate: 0.00403 
2025-01-31 03:47:53.775359: train_loss -0.8317 
2025-01-31 03:47:53.782372: val_loss -0.7587 
2025-01-31 03:47:53.785273: Pseudo dice [np.float32(0.9634), np.float32(0.9276)] 
2025-01-31 03:47:53.787967: Epoch time: 48.09 s 
2025-01-31 03:47:54.949341:  
2025-01-31 03:47:54.953952: Epoch 637 
2025-01-31 03:47:54.956864: Current learning rate: 0.00402 
2025-01-31 03:48:43.338870: train_loss -0.8304 
2025-01-31 03:48:43.344246: val_loss -0.7636 
2025-01-31 03:48:43.346848: Pseudo dice [np.float32(0.9473), np.float32(0.9057)] 
2025-01-31 03:48:43.349489: Epoch time: 48.39 s 
2025-01-31 03:48:45.031765:  
2025-01-31 03:48:45.034820: Epoch 638 
2025-01-31 03:48:45.037496: Current learning rate: 0.00401 
2025-01-31 03:49:33.049038: train_loss -0.8386 
2025-01-31 03:49:33.055163: val_loss -0.6954 
2025-01-31 03:49:33.057868: Pseudo dice [np.float32(0.9463), np.float32(0.7296)] 
2025-01-31 03:49:33.060594: Epoch time: 48.02 s 
2025-01-31 03:49:34.224583:  
2025-01-31 03:49:34.227448: Epoch 639 
2025-01-31 03:49:34.230033: Current learning rate: 0.004 
2025-01-31 03:50:22.252247: train_loss -0.8257 
2025-01-31 03:50:22.256762: val_loss -0.7083 
2025-01-31 03:50:22.259340: Pseudo dice [np.float32(0.9425), np.float32(0.8219)] 
2025-01-31 03:50:22.261945: Epoch time: 48.03 s 
2025-01-31 03:50:23.421826:  
2025-01-31 03:50:23.424921: Epoch 640 
2025-01-31 03:50:23.427870: Current learning rate: 0.00399 
2025-01-31 03:51:11.362933: train_loss -0.8442 
2025-01-31 03:51:11.369108: val_loss -0.7052 
2025-01-31 03:51:11.372069: Pseudo dice [np.float32(0.9509), np.float32(0.7838)] 
2025-01-31 03:51:11.374867: Epoch time: 47.94 s 
2025-01-31 03:51:12.534432:  
2025-01-31 03:51:12.537608: Epoch 641 
2025-01-31 03:51:12.540432: Current learning rate: 0.00398 
2025-01-31 03:52:00.746083: train_loss -0.8381 
2025-01-31 03:52:00.749864: val_loss -0.6465 
2025-01-31 03:52:00.752517: Pseudo dice [np.float32(0.9528), np.float32(0.5468)] 
2025-01-31 03:52:00.754903: Epoch time: 48.21 s 
2025-01-31 03:52:01.911616:  
2025-01-31 03:52:01.914440: Epoch 642 
2025-01-31 03:52:01.917609: Current learning rate: 0.00397 
2025-01-31 03:52:50.113744: train_loss -0.8181 
2025-01-31 03:52:50.120137: val_loss -0.7295 
2025-01-31 03:52:50.123071: Pseudo dice [np.float32(0.9452), np.float32(0.7701)] 
2025-01-31 03:52:50.125405: Epoch time: 48.2 s 
2025-01-31 03:52:51.280586:  
2025-01-31 03:52:51.283597: Epoch 643 
2025-01-31 03:52:51.286164: Current learning rate: 0.00396 
2025-01-31 03:53:39.244402: train_loss -0.8376 
2025-01-31 03:53:39.250648: val_loss -0.7581 
2025-01-31 03:53:39.253166: Pseudo dice [np.float32(0.9415), np.float32(0.8847)] 
2025-01-31 03:53:39.255563: Epoch time: 47.96 s 
2025-01-31 03:53:40.419543:  
2025-01-31 03:53:40.422374: Epoch 644 
2025-01-31 03:53:40.424736: Current learning rate: 0.00395 
2025-01-31 03:54:28.322384: train_loss -0.8411 
2025-01-31 03:54:28.328237: val_loss -0.7311 
2025-01-31 03:54:28.330790: Pseudo dice [np.float32(0.9467), np.float32(0.9028)] 
2025-01-31 03:54:28.333039: Epoch time: 47.9 s 
2025-01-31 03:54:29.491116:  
2025-01-31 03:54:29.494002: Epoch 645 
2025-01-31 03:54:29.496495: Current learning rate: 0.00394 
2025-01-31 03:55:17.712087: train_loss -0.8279 
2025-01-31 03:55:17.717543: val_loss -0.7302 
2025-01-31 03:55:17.720043: Pseudo dice [np.float32(0.9526), np.float32(0.8424)] 
2025-01-31 03:55:17.722465: Epoch time: 48.22 s 
2025-01-31 03:55:18.879103:  
2025-01-31 03:55:18.882231: Epoch 646 
2025-01-31 03:55:18.885004: Current learning rate: 0.00393 
2025-01-31 03:56:07.143211: train_loss -0.848 
2025-01-31 03:56:07.150471: val_loss -0.7429 
2025-01-31 03:56:07.152860: Pseudo dice [np.float32(0.9496), np.float32(0.8607)] 
2025-01-31 03:56:07.155126: Epoch time: 48.27 s 
2025-01-31 03:56:08.311171:  
2025-01-31 03:56:08.314535: Epoch 647 
2025-01-31 03:56:08.317707: Current learning rate: 0.00392 
2025-01-31 03:56:56.622940: train_loss -0.8193 
2025-01-31 03:56:56.627099: val_loss -0.6951 
2025-01-31 03:56:56.629862: Pseudo dice [np.float32(0.9421), np.float32(0.7622)] 
2025-01-31 03:56:56.632628: Epoch time: 48.31 s 
2025-01-31 03:56:57.789741:  
2025-01-31 03:56:57.792584: Epoch 648 
2025-01-31 03:56:57.795303: Current learning rate: 0.00391 
2025-01-31 03:57:46.181755: train_loss -0.8158 
2025-01-31 03:57:46.188457: val_loss -0.7355 
2025-01-31 03:57:46.190925: Pseudo dice [np.float32(0.9438), np.float32(0.8568)] 
2025-01-31 03:57:46.193274: Epoch time: 48.39 s 
2025-01-31 03:57:47.347585:  
2025-01-31 03:57:47.352313: Epoch 649 
2025-01-31 03:57:47.354892: Current learning rate: 0.0039 
2025-01-31 03:58:35.504647: train_loss -0.8241 
2025-01-31 03:58:35.508521: val_loss -0.7163 
2025-01-31 03:58:35.510889: Pseudo dice [np.float32(0.9461), np.float32(0.748)] 
2025-01-31 03:58:35.513494: Epoch time: 48.16 s 
2025-01-31 03:58:37.199503:  
2025-01-31 03:58:37.202241: Epoch 650 
2025-01-31 03:58:37.205049: Current learning rate: 0.00389 
2025-01-31 03:59:25.031805: train_loss -0.8362 
2025-01-31 03:59:25.037095: val_loss -0.727 
2025-01-31 03:59:25.039675: Pseudo dice [np.float32(0.952), np.float32(0.8952)] 
2025-01-31 03:59:25.042111: Epoch time: 47.83 s 
2025-01-31 03:59:25.044586: Yayy! New best EMA pseudo Dice: 0.8773000240325928 
2025-01-31 03:59:26.771337:  
2025-01-31 03:59:26.776373: Epoch 651 
2025-01-31 03:59:26.779191: Current learning rate: 0.00388 
2025-01-31 04:00:15.188453: train_loss -0.8375 
2025-01-31 04:00:15.194278: val_loss -0.7126 
2025-01-31 04:00:15.196910: Pseudo dice [np.float32(0.9465), np.float32(0.8223)] 
2025-01-31 04:00:15.199255: Epoch time: 48.42 s 
2025-01-31 04:00:15.201662: Yayy! New best EMA pseudo Dice: 0.878000020980835 
2025-01-31 04:00:16.896182:  
2025-01-31 04:00:16.900777: Epoch 652 
2025-01-31 04:00:16.903768: Current learning rate: 0.00387 
2025-01-31 04:01:04.953795: train_loss -0.837 
2025-01-31 04:01:04.961462: val_loss -0.7455 
2025-01-31 04:01:04.963929: Pseudo dice [np.float32(0.9582), np.float32(0.9049)] 
2025-01-31 04:01:04.966541: Epoch time: 48.06 s 
2025-01-31 04:01:04.968918: Yayy! New best EMA pseudo Dice: 0.883400022983551 
2025-01-31 04:01:06.648767:  
2025-01-31 04:01:06.653401: Epoch 653 
2025-01-31 04:01:06.655999: Current learning rate: 0.00386 
2025-01-31 04:01:54.715641: train_loss -0.8378 
2025-01-31 04:01:54.721093: val_loss -0.7347 
2025-01-31 04:01:54.723554: Pseudo dice [np.float32(0.9515), np.float32(0.8161)] 
2025-01-31 04:01:54.726078: Epoch time: 48.07 s 
2025-01-31 04:01:54.728319: Yayy! New best EMA pseudo Dice: 0.883400022983551 
2025-01-31 04:01:56.389094:  
2025-01-31 04:01:56.391443: Epoch 654 
2025-01-31 04:01:56.394078: Current learning rate: 0.00385 
2025-01-31 04:02:44.358917: train_loss -0.8471 
2025-01-31 04:02:44.365760: val_loss -0.739 
2025-01-31 04:02:44.368373: Pseudo dice [np.float32(0.9553), np.float32(0.7948)] 
2025-01-31 04:02:44.370975: Epoch time: 47.97 s 
2025-01-31 04:02:45.520388:  
2025-01-31 04:02:45.522941: Epoch 655 
2025-01-31 04:02:45.525354: Current learning rate: 0.00384 
2025-01-31 04:03:33.900898: train_loss -0.8392 
2025-01-31 04:03:33.904670: val_loss -0.746 
2025-01-31 04:03:33.907406: Pseudo dice [np.float32(0.9529), np.float32(0.9137)] 
2025-01-31 04:03:33.909627: Epoch time: 48.38 s 
2025-01-31 04:03:33.911942: Yayy! New best EMA pseudo Dice: 0.8877000212669373 
2025-01-31 04:03:36.112351:  
2025-01-31 04:03:36.115357: Epoch 656 
2025-01-31 04:03:36.118036: Current learning rate: 0.00383 
2025-01-31 04:04:24.002471: train_loss -0.8474 
2025-01-31 04:04:24.008098: val_loss -0.7148 
2025-01-31 04:04:24.010676: Pseudo dice [np.float32(0.9526), np.float32(0.8048)] 
2025-01-31 04:04:24.013226: Epoch time: 47.89 s 
2025-01-31 04:04:25.170190:  
2025-01-31 04:04:25.172917: Epoch 657 
2025-01-31 04:04:25.175421: Current learning rate: 0.00382 
2025-01-31 04:05:13.144909: train_loss -0.8385 
2025-01-31 04:05:13.148452: val_loss -0.7424 
2025-01-31 04:05:13.150671: Pseudo dice [np.float32(0.9521), np.float32(0.9019)] 
2025-01-31 04:05:13.152947: Epoch time: 47.98 s 
2025-01-31 04:05:13.155138: Yayy! New best EMA pseudo Dice: 0.8907999992370605 
2025-01-31 04:05:14.877803:  
2025-01-31 04:05:14.881834: Epoch 658 
2025-01-31 04:05:14.884773: Current learning rate: 0.00381 
2025-01-31 04:06:03.139418: train_loss -0.8337 
2025-01-31 04:06:03.145494: val_loss -0.6924 
2025-01-31 04:06:03.148632: Pseudo dice [np.float32(0.9586), np.float32(0.8155)] 
2025-01-31 04:06:03.151589: Epoch time: 48.26 s 
2025-01-31 04:06:04.310915:  
2025-01-31 04:06:04.313875: Epoch 659 
2025-01-31 04:06:04.316632: Current learning rate: 0.0038 
2025-01-31 04:06:52.209834: train_loss -0.8553 
2025-01-31 04:06:52.213775: val_loss -0.7732 
2025-01-31 04:06:52.216390: Pseudo dice [np.float32(0.9516), np.float32(0.8992)] 
2025-01-31 04:06:52.218832: Epoch time: 47.9 s 
2025-01-31 04:06:52.220998: Yayy! New best EMA pseudo Dice: 0.8938999772071838 
2025-01-31 04:06:53.884794:  
2025-01-31 04:06:53.887812: Epoch 660 
2025-01-31 04:06:53.890385: Current learning rate: 0.00379 
2025-01-31 04:07:42.242767: train_loss -0.8373 
2025-01-31 04:07:42.248519: val_loss -0.7117 
2025-01-31 04:07:42.251275: Pseudo dice [np.float32(0.947), np.float32(0.7727)] 
2025-01-31 04:07:42.253773: Epoch time: 48.36 s 
2025-01-31 04:07:43.419151:  
2025-01-31 04:07:43.423902: Epoch 661 
2025-01-31 04:07:43.426994: Current learning rate: 0.00378 
2025-01-31 04:08:31.681924: train_loss -0.8326 
2025-01-31 04:08:31.685681: val_loss -0.6832 
2025-01-31 04:08:31.688296: Pseudo dice [np.float32(0.9529), np.float32(0.6294)] 
2025-01-31 04:08:31.690664: Epoch time: 48.26 s 
2025-01-31 04:08:32.847686:  
2025-01-31 04:08:32.850220: Epoch 662 
2025-01-31 04:08:32.853177: Current learning rate: 0.00377 
2025-01-31 04:09:21.045060: train_loss -0.8205 
2025-01-31 04:09:21.051161: val_loss -0.6692 
2025-01-31 04:09:21.053785: Pseudo dice [np.float32(0.9423), np.float32(0.7214)] 
2025-01-31 04:09:21.056537: Epoch time: 48.2 s 
2025-01-31 04:09:22.234364:  
2025-01-31 04:09:22.236909: Epoch 663 
2025-01-31 04:09:22.239479: Current learning rate: 0.00376 
2025-01-31 04:10:10.069257: train_loss -0.8233 
2025-01-31 04:10:10.073308: val_loss -0.6634 
2025-01-31 04:10:10.076004: Pseudo dice [np.float32(0.9342), np.float32(0.6673)] 
2025-01-31 04:10:10.078336: Epoch time: 47.84 s 
2025-01-31 04:10:11.241839:  
2025-01-31 04:10:11.244300: Epoch 664 
2025-01-31 04:10:11.246771: Current learning rate: 0.00375 
2025-01-31 04:10:59.099967: train_loss -0.8342 
2025-01-31 04:10:59.106230: val_loss -0.7168 
2025-01-31 04:10:59.108872: Pseudo dice [np.float32(0.9512), np.float32(0.7595)] 
2025-01-31 04:10:59.111487: Epoch time: 47.86 s 
2025-01-31 04:11:00.266073:  
2025-01-31 04:11:00.269031: Epoch 665 
2025-01-31 04:11:00.271491: Current learning rate: 0.00374 
2025-01-31 04:11:48.177572: train_loss -0.8193 
2025-01-31 04:11:48.181535: val_loss -0.7618 
2025-01-31 04:11:48.184274: Pseudo dice [np.float32(0.953), np.float32(0.8703)] 
2025-01-31 04:11:48.186645: Epoch time: 47.91 s 
2025-01-31 04:11:49.345427:  
2025-01-31 04:11:49.348245: Epoch 666 
2025-01-31 04:11:49.350558: Current learning rate: 0.00373 
2025-01-31 04:12:37.451406: train_loss -0.8096 
2025-01-31 04:12:37.456744: val_loss -0.7108 
2025-01-31 04:12:37.459233: Pseudo dice [np.float32(0.9554), np.float32(0.7682)] 
2025-01-31 04:12:37.461723: Epoch time: 48.11 s 
2025-01-31 04:12:38.616850:  
2025-01-31 04:12:38.620576: Epoch 667 
2025-01-31 04:12:38.623077: Current learning rate: 0.00372 
2025-01-31 04:13:26.897156: train_loss -0.8318 
2025-01-31 04:13:26.901383: val_loss -0.7307 
2025-01-31 04:13:26.903833: Pseudo dice [np.float32(0.9473), np.float32(0.7427)] 
2025-01-31 04:13:26.906249: Epoch time: 48.28 s 
2025-01-31 04:13:28.075517:  
2025-01-31 04:13:28.078518: Epoch 668 
2025-01-31 04:13:28.080984: Current learning rate: 0.00371 
2025-01-31 04:14:16.128172: train_loss -0.8271 
2025-01-31 04:14:16.134018: val_loss -0.676 
2025-01-31 04:14:16.136606: Pseudo dice [np.float32(0.9494), np.float32(0.6818)] 
2025-01-31 04:14:16.139657: Epoch time: 48.05 s 
2025-01-31 04:14:17.312701:  
2025-01-31 04:14:17.315714: Epoch 669 
2025-01-31 04:14:17.318388: Current learning rate: 0.0037 
2025-01-31 04:15:05.604349: train_loss -0.8177 
2025-01-31 04:15:05.608810: val_loss -0.6507 
2025-01-31 04:15:05.611648: Pseudo dice [np.float32(0.9449), np.float32(0.6587)] 
2025-01-31 04:15:05.614606: Epoch time: 48.29 s 
2025-01-31 04:15:06.794445:  
2025-01-31 04:15:06.797451: Epoch 670 
2025-01-31 04:15:06.799990: Current learning rate: 0.00369 
2025-01-31 04:15:55.055918: train_loss -0.8198 
2025-01-31 04:15:55.061358: val_loss -0.6908 
2025-01-31 04:15:55.064056: Pseudo dice [np.float32(0.9537), np.float32(0.5766)] 
2025-01-31 04:15:55.066470: Epoch time: 48.26 s 
2025-01-31 04:15:56.245281:  
2025-01-31 04:15:56.248091: Epoch 671 
2025-01-31 04:15:56.250598: Current learning rate: 0.00368 
2025-01-31 04:16:44.247175: train_loss -0.8414 
2025-01-31 04:16:44.252084: val_loss -0.6473 
2025-01-31 04:16:44.255064: Pseudo dice [np.float32(0.9427), np.float32(0.5047)] 
2025-01-31 04:16:44.257945: Epoch time: 48.0 s 
2025-01-31 04:16:45.436834:  
2025-01-31 04:16:45.439478: Epoch 672 
2025-01-31 04:16:45.442001: Current learning rate: 0.00367 
2025-01-31 04:17:33.736268: train_loss -0.8376 
2025-01-31 04:17:33.741596: val_loss -0.7136 
2025-01-31 04:17:33.744411: Pseudo dice [np.float32(0.9496), np.float32(0.6638)] 
2025-01-31 04:17:33.746825: Epoch time: 48.3 s 
2025-01-31 04:17:34.918030:  
2025-01-31 04:17:34.920686: Epoch 673 
2025-01-31 04:17:34.923237: Current learning rate: 0.00366 
2025-01-31 04:18:23.556572: train_loss -0.8407 
2025-01-31 04:18:23.560492: val_loss -0.7122 
2025-01-31 04:18:23.563054: Pseudo dice [np.float32(0.9463), np.float32(0.7981)] 
2025-01-31 04:18:23.565480: Epoch time: 48.64 s 
2025-01-31 04:18:24.742670:  
2025-01-31 04:18:24.745780: Epoch 674 
2025-01-31 04:18:24.748474: Current learning rate: 0.00365 
2025-01-31 04:19:12.655255: train_loss -0.8435 
2025-01-31 04:19:12.660658: val_loss -0.7105 
2025-01-31 04:19:12.663212: Pseudo dice [np.float32(0.9501), np.float32(0.6703)] 
2025-01-31 04:19:12.665843: Epoch time: 47.91 s 
2025-01-31 04:19:14.368309:  
2025-01-31 04:19:14.371037: Epoch 675 
2025-01-31 04:19:14.373583: Current learning rate: 0.00364 
2025-01-31 04:20:02.989392: train_loss -0.8245 
2025-01-31 04:20:02.994173: val_loss -0.7121 
2025-01-31 04:20:02.997188: Pseudo dice [np.float32(0.9381), np.float32(0.851)] 
2025-01-31 04:20:03.000080: Epoch time: 48.62 s 
2025-01-31 04:20:04.169092:  
2025-01-31 04:20:04.172063: Epoch 676 
2025-01-31 04:20:04.174986: Current learning rate: 0.00363 
2025-01-31 04:20:52.113795: train_loss -0.8475 
2025-01-31 04:20:52.118989: val_loss -0.7157 
2025-01-31 04:20:52.121251: Pseudo dice [np.float32(0.9513), np.float32(0.8038)] 
2025-01-31 04:20:52.123595: Epoch time: 47.95 s 
2025-01-31 04:20:53.293469:  
2025-01-31 04:20:53.296562: Epoch 677 
2025-01-31 04:20:53.299669: Current learning rate: 0.00362 
2025-01-31 04:21:41.725909: train_loss -0.8286 
2025-01-31 04:21:41.730562: val_loss -0.7532 
2025-01-31 04:21:41.733302: Pseudo dice [np.float32(0.9483), np.float32(0.8584)] 
2025-01-31 04:21:41.736211: Epoch time: 48.43 s 
2025-01-31 04:21:42.908864:  
2025-01-31 04:21:42.911125: Epoch 678 
2025-01-31 04:21:42.913611: Current learning rate: 0.00361 
2025-01-31 04:22:30.965565: train_loss -0.8381 
2025-01-31 04:22:30.971565: val_loss -0.7143 
2025-01-31 04:22:30.974309: Pseudo dice [np.float32(0.9301), np.float32(0.8603)] 
2025-01-31 04:22:30.977013: Epoch time: 48.06 s 
2025-01-31 04:22:32.152940:  
2025-01-31 04:22:32.155714: Epoch 679 
2025-01-31 04:22:32.158472: Current learning rate: 0.0036 
2025-01-31 04:23:20.567756: train_loss -0.8323 
2025-01-31 04:23:20.571284: val_loss -0.7041 
2025-01-31 04:23:20.573852: Pseudo dice [np.float32(0.9277), np.float32(0.8034)] 
2025-01-31 04:23:20.576084: Epoch time: 48.42 s 
2025-01-31 04:23:21.752974:  
2025-01-31 04:23:21.755596: Epoch 680 
2025-01-31 04:23:21.758403: Current learning rate: 0.00359 
2025-01-31 04:24:09.811077: train_loss -0.834 
2025-01-31 04:24:09.816922: val_loss -0.6746 
2025-01-31 04:24:09.819880: Pseudo dice [np.float32(0.9468), np.float32(0.721)] 
2025-01-31 04:24:09.822310: Epoch time: 48.06 s 
2025-01-31 04:24:10.996045:  
2025-01-31 04:24:10.998883: Epoch 681 
2025-01-31 04:24:11.001348: Current learning rate: 0.00358 
2025-01-31 04:24:58.947796: train_loss -0.829 
2025-01-31 04:24:58.952290: val_loss -0.7244 
2025-01-31 04:24:58.954901: Pseudo dice [np.float32(0.9542), np.float32(0.9284)] 
2025-01-31 04:24:58.957628: Epoch time: 47.95 s 
2025-01-31 04:25:00.126446:  
2025-01-31 04:25:00.129491: Epoch 682 
2025-01-31 04:25:00.132750: Current learning rate: 0.00357 
2025-01-31 04:25:48.349137: train_loss -0.8302 
2025-01-31 04:25:48.355366: val_loss -0.7146 
2025-01-31 04:25:48.358230: Pseudo dice [np.float32(0.9493), np.float32(0.8215)] 
2025-01-31 04:25:48.360842: Epoch time: 48.22 s 
2025-01-31 04:25:49.535403:  
2025-01-31 04:25:49.538322: Epoch 683 
2025-01-31 04:25:49.540780: Current learning rate: 0.00356 
2025-01-31 04:26:37.713502: train_loss -0.8233 
2025-01-31 04:26:37.717366: val_loss -0.7386 
2025-01-31 04:26:37.719999: Pseudo dice [np.float32(0.9416), np.float32(0.7903)] 
2025-01-31 04:26:37.722449: Epoch time: 48.18 s 
2025-01-31 04:26:38.890600:  
2025-01-31 04:26:38.893647: Epoch 684 
2025-01-31 04:26:38.896489: Current learning rate: 0.00355 
2025-01-31 04:27:27.512277: train_loss -0.8316 
2025-01-31 04:27:27.517743: val_loss -0.7337 
2025-01-31 04:27:27.520407: Pseudo dice [np.float32(0.9531), np.float32(0.8642)] 
2025-01-31 04:27:27.522768: Epoch time: 48.62 s 
2025-01-31 04:27:28.694912:  
2025-01-31 04:27:28.697868: Epoch 685 
2025-01-31 04:27:28.700488: Current learning rate: 0.00354 
2025-01-31 04:28:16.661233: train_loss -0.8116 
2025-01-31 04:28:16.665143: val_loss -0.6976 
2025-01-31 04:28:16.668031: Pseudo dice [np.float32(0.9399), np.float32(0.7072)] 
2025-01-31 04:28:16.670267: Epoch time: 47.97 s 
2025-01-31 04:28:17.842358:  
2025-01-31 04:28:17.845036: Epoch 686 
2025-01-31 04:28:17.847876: Current learning rate: 0.00353 
2025-01-31 04:29:06.076542: train_loss -0.8299 
2025-01-31 04:29:06.082088: val_loss -0.7185 
2025-01-31 04:29:06.084920: Pseudo dice [np.float32(0.9533), np.float32(0.8505)] 
2025-01-31 04:29:06.087799: Epoch time: 48.24 s 
2025-01-31 04:29:07.263616:  
2025-01-31 04:29:07.266281: Epoch 687 
2025-01-31 04:29:07.268748: Current learning rate: 0.00352 
2025-01-31 04:29:55.321095: train_loss -0.8387 
2025-01-31 04:29:55.324916: val_loss -0.654 
2025-01-31 04:29:55.327581: Pseudo dice [np.float32(0.9536), np.float32(0.5451)] 
2025-01-31 04:29:55.329952: Epoch time: 48.06 s 
2025-01-31 04:29:56.498835:  
2025-01-31 04:29:56.501482: Epoch 688 
2025-01-31 04:29:56.503639: Current learning rate: 0.00351 
2025-01-31 04:30:44.699500: train_loss -0.8293 
2025-01-31 04:30:44.705245: val_loss -0.67 
2025-01-31 04:30:44.707924: Pseudo dice [np.float32(0.9331), np.float32(0.7073)] 
2025-01-31 04:30:44.710397: Epoch time: 48.2 s 
2025-01-31 04:30:45.882303:  
2025-01-31 04:30:45.888595: Epoch 689 
2025-01-31 04:30:45.891417: Current learning rate: 0.0035 
2025-01-31 04:31:34.175184: train_loss -0.8268 
2025-01-31 04:31:34.179180: val_loss -0.6722 
2025-01-31 04:31:34.181972: Pseudo dice [np.float32(0.946), np.float32(0.5999)] 
2025-01-31 04:31:34.184700: Epoch time: 48.29 s 
2025-01-31 04:31:35.358272:  
2025-01-31 04:31:35.361122: Epoch 690 
2025-01-31 04:31:35.363717: Current learning rate: 0.00349 
2025-01-31 04:32:23.670377: train_loss -0.8278 
2025-01-31 04:32:23.675634: val_loss -0.6879 
2025-01-31 04:32:23.678250: Pseudo dice [np.float32(0.9418), np.float32(0.7494)] 
2025-01-31 04:32:23.680842: Epoch time: 48.31 s 
2025-01-31 04:32:24.858152:  
2025-01-31 04:32:24.860734: Epoch 691 
2025-01-31 04:32:24.863042: Current learning rate: 0.00348 
2025-01-31 04:33:12.928134: train_loss -0.8395 
2025-01-31 04:33:12.931512: val_loss -0.7034 
2025-01-31 04:33:12.933891: Pseudo dice [np.float32(0.9482), np.float32(0.7062)] 
2025-01-31 04:33:12.936315: Epoch time: 48.07 s 
2025-01-31 04:33:14.112856:  
2025-01-31 04:33:14.116166: Epoch 692 
2025-01-31 04:33:14.118856: Current learning rate: 0.00346 
2025-01-31 04:34:01.976136: train_loss -0.8322 
2025-01-31 04:34:01.981861: val_loss -0.7246 
2025-01-31 04:34:01.984224: Pseudo dice [np.float32(0.9544), np.float32(0.7833)] 
2025-01-31 04:34:01.986702: Epoch time: 47.86 s 
2025-01-31 04:34:03.684156:  
2025-01-31 04:34:03.686730: Epoch 693 
2025-01-31 04:34:03.689284: Current learning rate: 0.00345 
2025-01-31 04:34:51.543212: train_loss -0.8552 
2025-01-31 04:34:51.548882: val_loss -0.7369 
2025-01-31 04:34:51.551571: Pseudo dice [np.float32(0.9501), np.float32(0.8541)] 
2025-01-31 04:34:51.554064: Epoch time: 47.86 s 
2025-01-31 04:34:52.725295:  
2025-01-31 04:34:52.727868: Epoch 694 
2025-01-31 04:34:52.730132: Current learning rate: 0.00344 
2025-01-31 04:35:40.864194: train_loss -0.8494 
2025-01-31 04:35:40.870605: val_loss -0.7324 
2025-01-31 04:35:40.873486: Pseudo dice [np.float32(0.9417), np.float32(0.8322)] 
2025-01-31 04:35:40.876279: Epoch time: 48.14 s 
2025-01-31 04:35:42.057580:  
2025-01-31 04:35:42.060205: Epoch 695 
2025-01-31 04:35:42.062598: Current learning rate: 0.00343 
2025-01-31 04:36:30.117019: train_loss -0.8372 
2025-01-31 04:36:30.121562: val_loss -0.7289 
2025-01-31 04:36:30.124557: Pseudo dice [np.float32(0.9472), np.float32(0.8415)] 
2025-01-31 04:36:30.126954: Epoch time: 48.06 s 
2025-01-31 04:36:31.305802:  
2025-01-31 04:36:31.308562: Epoch 696 
2025-01-31 04:36:31.311217: Current learning rate: 0.00342 
2025-01-31 04:37:19.501927: train_loss -0.8314 
2025-01-31 04:37:19.507654: val_loss -0.6718 
2025-01-31 04:37:19.510446: Pseudo dice [np.float32(0.9472), np.float32(0.6798)] 
2025-01-31 04:37:19.513393: Epoch time: 48.2 s 
2025-01-31 04:37:20.685221:  
2025-01-31 04:37:20.688992: Epoch 697 
2025-01-31 04:37:20.691548: Current learning rate: 0.00341 
2025-01-31 04:38:08.719821: train_loss -0.8342 
2025-01-31 04:38:08.723735: val_loss -0.6438 
2025-01-31 04:38:08.726434: Pseudo dice [np.float32(0.9458), np.float32(0.6332)] 
2025-01-31 04:38:08.729016: Epoch time: 48.04 s 
2025-01-31 04:38:09.898883:  
2025-01-31 04:38:09.901558: Epoch 698 
2025-01-31 04:38:09.904266: Current learning rate: 0.0034 
2025-01-31 04:38:58.053187: train_loss -0.8165 
2025-01-31 04:38:58.059259: val_loss -0.7021 
2025-01-31 04:38:58.062000: Pseudo dice [np.float32(0.9466), np.float32(0.7955)] 
2025-01-31 04:38:58.064753: Epoch time: 48.16 s 
2025-01-31 04:38:59.232963:  
2025-01-31 04:38:59.235565: Epoch 699 
2025-01-31 04:38:59.238050: Current learning rate: 0.00339 
2025-01-31 04:39:47.112796: train_loss -0.8435 
2025-01-31 04:39:47.116799: val_loss -0.7404 
2025-01-31 04:39:47.119344: Pseudo dice [np.float32(0.9621), np.float32(0.9038)] 
2025-01-31 04:39:47.121698: Epoch time: 47.88 s 
2025-01-31 04:39:48.851504:  
2025-01-31 04:39:48.855900: Epoch 700 
2025-01-31 04:39:48.858607: Current learning rate: 0.00338 
2025-01-31 04:40:36.810345: train_loss -0.8435 
2025-01-31 04:40:36.815663: val_loss -0.7533 
2025-01-31 04:40:36.818243: Pseudo dice [np.float32(0.9579), np.float32(0.8929)] 
2025-01-31 04:40:36.820901: Epoch time: 47.96 s 
2025-01-31 04:40:38.000011:  
2025-01-31 04:40:38.003245: Epoch 701 
2025-01-31 04:40:38.005887: Current learning rate: 0.00337 
2025-01-31 04:41:26.538700: train_loss -0.8387 
2025-01-31 04:41:26.542491: val_loss -0.7416 
2025-01-31 04:41:26.545301: Pseudo dice [np.float32(0.9512), np.float32(0.8545)] 
2025-01-31 04:41:26.547469: Epoch time: 48.54 s 
2025-01-31 04:41:27.722969:  
2025-01-31 04:41:27.726115: Epoch 702 
2025-01-31 04:41:27.728644: Current learning rate: 0.00336 
2025-01-31 04:42:16.185032: train_loss -0.8306 
2025-01-31 04:42:16.190907: val_loss -0.6788 
2025-01-31 04:42:16.193706: Pseudo dice [np.float32(0.9359), np.float32(0.6737)] 
2025-01-31 04:42:16.196174: Epoch time: 48.46 s 
2025-01-31 04:42:17.377636:  
2025-01-31 04:42:17.380429: Epoch 703 
2025-01-31 04:42:17.382904: Current learning rate: 0.00335 
2025-01-31 04:43:05.989621: train_loss -0.8349 
2025-01-31 04:43:05.994204: val_loss -0.6924 
2025-01-31 04:43:05.996901: Pseudo dice [np.float32(0.9489), np.float32(0.7819)] 
2025-01-31 04:43:05.999285: Epoch time: 48.61 s 
2025-01-31 04:43:07.224879:  
2025-01-31 04:43:07.227985: Epoch 704 
2025-01-31 04:43:07.230353: Current learning rate: 0.00334 
2025-01-31 04:43:55.548107: train_loss -0.8383 
2025-01-31 04:43:55.553268: val_loss -0.717 
2025-01-31 04:43:55.556081: Pseudo dice [np.float32(0.9458), np.float32(0.8475)] 
2025-01-31 04:43:55.558633: Epoch time: 48.32 s 
2025-01-31 04:43:56.769744:  
2025-01-31 04:43:56.772908: Epoch 705 
2025-01-31 04:43:56.775637: Current learning rate: 0.00333 
2025-01-31 04:44:44.674217: train_loss -0.8448 
2025-01-31 04:44:44.678492: val_loss -0.7413 
2025-01-31 04:44:44.681397: Pseudo dice [np.float32(0.9519), np.float32(0.8567)] 
2025-01-31 04:44:44.684024: Epoch time: 47.91 s 
2025-01-31 04:44:45.853565:  
2025-01-31 04:44:45.859947: Epoch 706 
2025-01-31 04:44:45.862592: Current learning rate: 0.00332 
2025-01-31 04:45:33.826127: train_loss -0.8292 
2025-01-31 04:45:33.831532: val_loss -0.7262 
2025-01-31 04:45:33.833920: Pseudo dice [np.float32(0.9456), np.float32(0.8798)] 
2025-01-31 04:45:33.836201: Epoch time: 47.97 s 
2025-01-31 04:45:35.025452:  
2025-01-31 04:45:35.028261: Epoch 707 
2025-01-31 04:45:35.031018: Current learning rate: 0.00331 
2025-01-31 04:46:23.161135: train_loss -0.8455 
2025-01-31 04:46:23.165634: val_loss -0.7513 
2025-01-31 04:46:23.168245: Pseudo dice [np.float32(0.9474), np.float32(0.8988)] 
2025-01-31 04:46:23.171134: Epoch time: 48.14 s 
2025-01-31 04:46:24.346334:  
2025-01-31 04:46:24.350054: Epoch 708 
2025-01-31 04:46:24.352602: Current learning rate: 0.0033 
2025-01-31 04:47:12.303936: train_loss -0.8273 
2025-01-31 04:47:12.308936: val_loss -0.7431 
2025-01-31 04:47:12.311664: Pseudo dice [np.float32(0.9468), np.float32(0.8407)] 
2025-01-31 04:47:12.314312: Epoch time: 47.96 s 
2025-01-31 04:47:13.492542:  
2025-01-31 04:47:13.495651: Epoch 709 
2025-01-31 04:47:13.498103: Current learning rate: 0.00329 
2025-01-31 04:48:01.748630: train_loss -0.8376 
2025-01-31 04:48:01.753030: val_loss -0.7454 
2025-01-31 04:48:01.755778: Pseudo dice [np.float32(0.9536), np.float32(0.8851)] 
2025-01-31 04:48:01.758569: Epoch time: 48.26 s 
2025-01-31 04:48:02.929774:  
2025-01-31 04:48:02.932595: Epoch 710 
2025-01-31 04:48:02.935348: Current learning rate: 0.00328 
2025-01-31 04:48:50.863896: train_loss -0.8248 
2025-01-31 04:48:50.869109: val_loss -0.7065 
2025-01-31 04:48:50.871637: Pseudo dice [np.float32(0.9273), np.float32(0.8227)] 
2025-01-31 04:48:50.874017: Epoch time: 47.93 s 
2025-01-31 04:48:52.680151:  
2025-01-31 04:48:52.683017: Epoch 711 
2025-01-31 04:48:52.686282: Current learning rate: 0.00327 
2025-01-31 04:49:40.611683: train_loss -0.8407 
2025-01-31 04:49:40.616118: val_loss -0.7073 
2025-01-31 04:49:40.619086: Pseudo dice [np.float32(0.9411), np.float32(0.7395)] 
2025-01-31 04:49:40.621652: Epoch time: 47.93 s 
2025-01-31 04:49:41.789866:  
2025-01-31 04:49:41.792644: Epoch 712 
2025-01-31 04:49:41.795083: Current learning rate: 0.00326 
2025-01-31 04:50:29.692769: train_loss -0.8422 
2025-01-31 04:50:29.697939: val_loss -0.7031 
2025-01-31 04:50:29.700570: Pseudo dice [np.float32(0.9427), np.float32(0.7672)] 
2025-01-31 04:50:29.703012: Epoch time: 47.9 s 
2025-01-31 04:50:30.871166:  
2025-01-31 04:50:30.874462: Epoch 713 
2025-01-31 04:50:30.877534: Current learning rate: 0.00325 
2025-01-31 04:51:18.828151: train_loss -0.8418 
2025-01-31 04:51:18.832005: val_loss -0.6723 
2025-01-31 04:51:18.834469: Pseudo dice [np.float32(0.9514), np.float32(0.5989)] 
2025-01-31 04:51:18.837060: Epoch time: 47.96 s 
2025-01-31 04:51:20.054888:  
2025-01-31 04:51:20.059831: Epoch 714 
2025-01-31 04:51:20.062436: Current learning rate: 0.00324 
2025-01-31 04:52:08.703534: train_loss -0.8326 
2025-01-31 04:52:08.708686: val_loss -0.7208 
2025-01-31 04:52:08.711432: Pseudo dice [np.float32(0.9446), np.float32(0.8181)] 
2025-01-31 04:52:08.713872: Epoch time: 48.65 s 
2025-01-31 04:52:09.885511:  
2025-01-31 04:52:09.889501: Epoch 715 
2025-01-31 04:52:09.892104: Current learning rate: 0.00323 
2025-01-31 04:52:58.354753: train_loss -0.8459 
2025-01-31 04:52:58.358624: val_loss -0.7388 
2025-01-31 04:52:58.361129: Pseudo dice [np.float32(0.9473), np.float32(0.8403)] 
2025-01-31 04:52:58.363711: Epoch time: 48.47 s 
2025-01-31 04:52:59.546974:  
2025-01-31 04:52:59.550031: Epoch 716 
2025-01-31 04:52:59.552951: Current learning rate: 0.00322 
2025-01-31 04:53:47.733657: train_loss -0.8339 
2025-01-31 04:53:47.739402: val_loss -0.7206 
2025-01-31 04:53:47.742051: Pseudo dice [np.float32(0.9554), np.float32(0.8645)] 
2025-01-31 04:53:47.744876: Epoch time: 48.19 s 
2025-01-31 04:53:48.922305:  
2025-01-31 04:53:48.924937: Epoch 717 
2025-01-31 04:53:48.927418: Current learning rate: 0.00321 
2025-01-31 04:54:36.881206: train_loss -0.8436 
2025-01-31 04:54:36.885477: val_loss -0.7389 
2025-01-31 04:54:36.888367: Pseudo dice [np.float32(0.9508), np.float32(0.8268)] 
2025-01-31 04:54:36.891059: Epoch time: 47.96 s 
2025-01-31 04:54:38.064408:  
2025-01-31 04:54:38.067263: Epoch 718 
2025-01-31 04:54:38.069942: Current learning rate: 0.0032 
2025-01-31 04:55:25.964346: train_loss -0.8331 
2025-01-31 04:55:25.969934: val_loss -0.7603 
2025-01-31 04:55:25.972509: Pseudo dice [np.float32(0.9512), np.float32(0.8903)] 
2025-01-31 04:55:25.975109: Epoch time: 47.9 s 
2025-01-31 04:55:27.143952:  
2025-01-31 04:55:27.147049: Epoch 719 
2025-01-31 04:55:27.149977: Current learning rate: 0.00319 
2025-01-31 04:56:15.021997: train_loss -0.846 
2025-01-31 04:56:15.026368: val_loss -0.7439 
2025-01-31 04:56:15.029219: Pseudo dice [np.float32(0.9588), np.float32(0.899)] 
2025-01-31 04:56:15.032114: Epoch time: 47.88 s 
2025-01-31 04:56:16.203485:  
2025-01-31 04:56:16.206347: Epoch 720 
2025-01-31 04:56:16.209083: Current learning rate: 0.00318 
2025-01-31 04:57:05.039722: train_loss -0.8412 
2025-01-31 04:57:05.045108: val_loss -0.7191 
2025-01-31 04:57:05.047510: Pseudo dice [np.float32(0.9504), np.float32(0.7671)] 
2025-01-31 04:57:05.049710: Epoch time: 48.84 s 
2025-01-31 04:57:06.219859:  
2025-01-31 04:57:06.222541: Epoch 721 
2025-01-31 04:57:06.225204: Current learning rate: 0.00317 
2025-01-31 04:57:54.083062: train_loss -0.8294 
2025-01-31 04:57:54.087024: val_loss -0.7155 
2025-01-31 04:57:54.089516: Pseudo dice [np.float32(0.9537), np.float32(0.8732)] 
2025-01-31 04:57:54.092049: Epoch time: 47.86 s 
2025-01-31 04:57:55.272102:  
2025-01-31 04:57:55.275356: Epoch 722 
2025-01-31 04:57:55.277979: Current learning rate: 0.00316 
2025-01-31 04:58:43.693230: train_loss -0.8272 
2025-01-31 04:58:43.698971: val_loss -0.7332 
2025-01-31 04:58:43.701715: Pseudo dice [np.float32(0.9504), np.float32(0.7755)] 
2025-01-31 04:58:43.704261: Epoch time: 48.42 s 
2025-01-31 04:58:44.919955:  
2025-01-31 04:58:44.923112: Epoch 723 
2025-01-31 04:58:44.926021: Current learning rate: 0.00315 
2025-01-31 04:59:32.852986: train_loss -0.8442 
2025-01-31 04:59:32.856881: val_loss -0.741 
2025-01-31 04:59:32.859640: Pseudo dice [np.float32(0.9472), np.float32(0.8198)] 
2025-01-31 04:59:32.861884: Epoch time: 47.93 s 
2025-01-31 04:59:34.079044:  
2025-01-31 04:59:34.081901: Epoch 724 
2025-01-31 04:59:34.084871: Current learning rate: 0.00314 
2025-01-31 05:00:21.999892: train_loss -0.8538 
2025-01-31 05:00:22.005026: val_loss -0.7709 
2025-01-31 05:00:22.007570: Pseudo dice [np.float32(0.9458), np.float32(0.8784)] 
2025-01-31 05:00:22.010059: Epoch time: 47.92 s 
2025-01-31 05:00:23.177427:  
2025-01-31 05:00:23.180491: Epoch 725 
2025-01-31 05:00:23.183624: Current learning rate: 0.00313 
2025-01-31 05:01:11.132041: train_loss -0.8332 
2025-01-31 05:01:11.136457: val_loss -0.761 
2025-01-31 05:01:11.139276: Pseudo dice [np.float32(0.9529), np.float32(0.9001)] 
2025-01-31 05:01:11.141915: Epoch time: 47.96 s 
2025-01-31 05:01:12.317958:  
2025-01-31 05:01:12.321080: Epoch 726 
2025-01-31 05:01:12.324300: Current learning rate: 0.00312 
2025-01-31 05:02:00.354209: train_loss -0.8448 
2025-01-31 05:02:00.359519: val_loss -0.7133 
2025-01-31 05:02:00.362089: Pseudo dice [np.float32(0.9531), np.float32(0.7337)] 
2025-01-31 05:02:00.364621: Epoch time: 48.04 s 
2025-01-31 05:02:01.577827:  
2025-01-31 05:02:01.580888: Epoch 727 
2025-01-31 05:02:01.583513: Current learning rate: 0.00311 
2025-01-31 05:02:49.547011: train_loss -0.8361 
2025-01-31 05:02:49.551212: val_loss -0.7032 
2025-01-31 05:02:49.553728: Pseudo dice [np.float32(0.9496), np.float32(0.6924)] 
2025-01-31 05:02:49.556123: Epoch time: 47.97 s 
2025-01-31 05:02:50.730279:  
2025-01-31 05:02:50.736245: Epoch 728 
2025-01-31 05:02:50.739249: Current learning rate: 0.0031 
2025-01-31 05:03:38.940825: train_loss -0.8317 
2025-01-31 05:03:38.947042: val_loss -0.6336 
2025-01-31 05:03:38.949843: Pseudo dice [np.float32(0.9415), np.float32(0.4892)] 
2025-01-31 05:03:38.952551: Epoch time: 48.21 s 
2025-01-31 05:03:40.164112:  
2025-01-31 05:03:40.166666: Epoch 729 
2025-01-31 05:03:40.169441: Current learning rate: 0.00309 
2025-01-31 05:04:28.235717: train_loss -0.8111 
2025-01-31 05:04:28.240284: val_loss -0.658 
2025-01-31 05:04:28.242955: Pseudo dice [np.float32(0.9315), np.float32(0.6875)] 
2025-01-31 05:04:28.245627: Epoch time: 48.07 s 
2025-01-31 05:04:30.066534:  
2025-01-31 05:04:30.069591: Epoch 730 
2025-01-31 05:04:30.072286: Current learning rate: 0.00308 
2025-01-31 05:05:18.297441: train_loss -0.8358 
2025-01-31 05:05:18.303742: val_loss -0.7423 
2025-01-31 05:05:18.306457: Pseudo dice [np.float32(0.9496), np.float32(0.755)] 
2025-01-31 05:05:18.309120: Epoch time: 48.23 s 
2025-01-31 05:05:19.526721:  
2025-01-31 05:05:19.529428: Epoch 731 
2025-01-31 05:05:19.532308: Current learning rate: 0.00307 
2025-01-31 05:06:07.738823: train_loss -0.8313 
2025-01-31 05:06:07.742659: val_loss -0.7605 
2025-01-31 05:06:07.745633: Pseudo dice [np.float32(0.9538), np.float32(0.9075)] 
2025-01-31 05:06:07.748245: Epoch time: 48.21 s 
2025-01-31 05:06:08.919688:  
2025-01-31 05:06:08.922574: Epoch 732 
2025-01-31 05:06:08.925448: Current learning rate: 0.00306 
2025-01-31 05:06:57.026434: train_loss -0.8249 
2025-01-31 05:06:57.032321: val_loss -0.7177 
2025-01-31 05:06:57.035126: Pseudo dice [np.float32(0.9523), np.float32(0.8618)] 
2025-01-31 05:06:57.038007: Epoch time: 48.11 s 
2025-01-31 05:06:58.217626:  
2025-01-31 05:06:58.220749: Epoch 733 
2025-01-31 05:06:58.223547: Current learning rate: 0.00305 
2025-01-31 05:07:46.114062: train_loss -0.8364 
2025-01-31 05:07:46.119478: val_loss -0.7414 
2025-01-31 05:07:46.122394: Pseudo dice [np.float32(0.9592), np.float32(0.8812)] 
2025-01-31 05:07:46.124731: Epoch time: 47.9 s 
2025-01-31 05:07:47.299622:  
2025-01-31 05:07:47.302582: Epoch 734 
2025-01-31 05:07:47.305278: Current learning rate: 0.00304 
2025-01-31 05:08:35.230665: train_loss -0.8466 
2025-01-31 05:08:35.236073: val_loss -0.7202 
2025-01-31 05:08:35.238893: Pseudo dice [np.float32(0.9553), np.float32(0.7983)] 
2025-01-31 05:08:35.241312: Epoch time: 47.93 s 
2025-01-31 05:08:36.453568:  
2025-01-31 05:08:36.456580: Epoch 735 
2025-01-31 05:08:36.458996: Current learning rate: 0.00303 
2025-01-31 05:09:24.571997: train_loss -0.8386 
2025-01-31 05:09:24.575544: val_loss -0.7179 
2025-01-31 05:09:24.578236: Pseudo dice [np.float32(0.9537), np.float32(0.8464)] 
2025-01-31 05:09:24.580982: Epoch time: 48.12 s 
2025-01-31 05:09:25.783256:  
2025-01-31 05:09:25.786195: Epoch 736 
2025-01-31 05:09:25.788886: Current learning rate: 0.00302 
2025-01-31 05:10:14.082958: train_loss -0.8427 
2025-01-31 05:10:14.088681: val_loss -0.7626 
2025-01-31 05:10:14.091264: Pseudo dice [np.float32(0.962), np.float32(0.8447)] 
2025-01-31 05:10:14.093795: Epoch time: 48.3 s 
2025-01-31 05:10:15.267377:  
2025-01-31 05:10:15.270379: Epoch 737 
2025-01-31 05:10:15.273405: Current learning rate: 0.00301 
2025-01-31 05:11:03.296112: train_loss -0.8577 
2025-01-31 05:11:03.300721: val_loss -0.6877 
2025-01-31 05:11:03.303653: Pseudo dice [np.float32(0.9557), np.float32(0.6407)] 
2025-01-31 05:11:03.306558: Epoch time: 48.03 s 
2025-01-31 05:11:04.485493:  
2025-01-31 05:11:04.488191: Epoch 738 
2025-01-31 05:11:04.491152: Current learning rate: 0.003 
2025-01-31 05:11:52.596153: train_loss -0.8381 
2025-01-31 05:11:52.602230: val_loss -0.7577 
2025-01-31 05:11:52.605035: Pseudo dice [np.float32(0.9522), np.float32(0.8861)] 
2025-01-31 05:11:52.607730: Epoch time: 48.11 s 
2025-01-31 05:11:53.769659:  
2025-01-31 05:11:53.772563: Epoch 739 
2025-01-31 05:11:53.775378: Current learning rate: 0.00299 
2025-01-31 05:12:42.204533: train_loss -0.8389 
2025-01-31 05:12:42.209447: val_loss -0.635 
2025-01-31 05:12:42.212328: Pseudo dice [np.float32(0.9503), np.float32(0.579)] 
2025-01-31 05:12:42.215079: Epoch time: 48.44 s 
2025-01-31 05:12:43.385355:  
2025-01-31 05:12:43.388234: Epoch 740 
2025-01-31 05:12:43.390898: Current learning rate: 0.00297 
2025-01-31 05:13:31.410252: train_loss -0.8436 
2025-01-31 05:13:31.415870: val_loss -0.6931 
2025-01-31 05:13:31.418438: Pseudo dice [np.float32(0.9479), np.float32(0.6387)] 
2025-01-31 05:13:31.420816: Epoch time: 48.03 s 
2025-01-31 05:13:32.592341:  
2025-01-31 05:13:32.596303: Epoch 741 
2025-01-31 05:13:32.599394: Current learning rate: 0.00296 
2025-01-31 05:14:20.817273: train_loss -0.8514 
2025-01-31 05:14:20.822881: val_loss -0.7762 
2025-01-31 05:14:20.825536: Pseudo dice [np.float32(0.9574), np.float32(0.8462)] 
2025-01-31 05:14:20.828276: Epoch time: 48.23 s 
2025-01-31 05:14:22.041579:  
2025-01-31 05:14:22.044561: Epoch 742 
2025-01-31 05:14:22.047414: Current learning rate: 0.00295 
2025-01-31 05:15:09.875545: train_loss -0.8328 
2025-01-31 05:15:09.881819: val_loss -0.7701 
2025-01-31 05:15:09.884446: Pseudo dice [np.float32(0.9429), np.float32(0.8947)] 
2025-01-31 05:15:09.887035: Epoch time: 47.83 s 
2025-01-31 05:15:11.096854:  
2025-01-31 05:15:11.100331: Epoch 743 
2025-01-31 05:15:11.103188: Current learning rate: 0.00294 
2025-01-31 05:15:59.785712: train_loss -0.8275 
2025-01-31 05:15:59.791118: val_loss -0.7568 
2025-01-31 05:15:59.793870: Pseudo dice [np.float32(0.9533), np.float32(0.8914)] 
2025-01-31 05:15:59.796417: Epoch time: 48.69 s 
2025-01-31 05:16:00.971064:  
2025-01-31 05:16:00.973824: Epoch 744 
2025-01-31 05:16:00.976436: Current learning rate: 0.00293 
2025-01-31 05:16:49.035153: train_loss -0.827 
2025-01-31 05:16:49.040974: val_loss -0.7313 
2025-01-31 05:16:49.043626: Pseudo dice [np.float32(0.949), np.float32(0.8441)] 
2025-01-31 05:16:49.046026: Epoch time: 48.06 s 
2025-01-31 05:16:50.255480:  
2025-01-31 05:16:50.258509: Epoch 745 
2025-01-31 05:16:50.261311: Current learning rate: 0.00292 
2025-01-31 05:17:38.320605: train_loss -0.834 
2025-01-31 05:17:38.324684: val_loss -0.6961 
2025-01-31 05:17:38.327298: Pseudo dice [np.float32(0.9349), np.float32(0.7916)] 
2025-01-31 05:17:38.329995: Epoch time: 48.07 s 
2025-01-31 05:17:39.500364:  
2025-01-31 05:17:39.503167: Epoch 746 
2025-01-31 05:17:39.505898: Current learning rate: 0.00291 
2025-01-31 05:18:27.360578: train_loss -0.8462 
2025-01-31 05:18:27.366682: val_loss -0.735 
2025-01-31 05:18:27.369264: Pseudo dice [np.float32(0.9604), np.float32(0.8617)] 
2025-01-31 05:18:27.371888: Epoch time: 47.86 s 
2025-01-31 05:18:28.586393:  
2025-01-31 05:18:28.589443: Epoch 747 
2025-01-31 05:18:28.592452: Current learning rate: 0.0029 
2025-01-31 05:19:17.467959: train_loss -0.8204 
2025-01-31 05:19:17.471799: val_loss -0.676 
2025-01-31 05:19:17.474276: Pseudo dice [np.float32(0.9401), np.float32(0.7225)] 
2025-01-31 05:19:17.476757: Epoch time: 48.88 s 
2025-01-31 05:19:18.646733:  
2025-01-31 05:19:18.649694: Epoch 748 
2025-01-31 05:19:18.652524: Current learning rate: 0.00289 
2025-01-31 05:20:06.592514: train_loss -0.8471 
2025-01-31 05:20:06.597665: val_loss -0.7405 
2025-01-31 05:20:06.600306: Pseudo dice [np.float32(0.9566), np.float32(0.8475)] 
2025-01-31 05:20:06.602782: Epoch time: 47.95 s 
2025-01-31 05:20:07.775781:  
2025-01-31 05:20:07.778844: Epoch 749 
2025-01-31 05:20:07.781625: Current learning rate: 0.00288 
2025-01-31 05:20:55.981932: train_loss -0.8298 
2025-01-31 05:20:55.986158: val_loss -0.7837 
2025-01-31 05:20:55.988952: Pseudo dice [np.float32(0.957), np.float32(0.8058)] 
2025-01-31 05:20:55.991421: Epoch time: 48.21 s 
2025-01-31 05:20:57.748865:  
2025-01-31 05:20:57.753619: Epoch 750 
2025-01-31 05:20:57.756438: Current learning rate: 0.00287 
2025-01-31 05:21:45.792161: train_loss -0.8439 
2025-01-31 05:21:45.799834: val_loss -0.7603 
2025-01-31 05:21:45.802641: Pseudo dice [np.float32(0.9529), np.float32(0.7936)] 
2025-01-31 05:21:45.805370: Epoch time: 48.04 s 
2025-01-31 05:21:46.978042:  
2025-01-31 05:21:46.981136: Epoch 751 
2025-01-31 05:21:46.984038: Current learning rate: 0.00286 
2025-01-31 05:22:34.972096: train_loss -0.8445 
2025-01-31 05:22:34.979461: val_loss -0.7485 
2025-01-31 05:22:34.982341: Pseudo dice [np.float32(0.9531), np.float32(0.761)] 
2025-01-31 05:22:34.985316: Epoch time: 47.99 s 
2025-01-31 05:22:36.151699:  
2025-01-31 05:22:36.154344: Epoch 752 
2025-01-31 05:22:36.156753: Current learning rate: 0.00285 
2025-01-31 05:23:24.211151: train_loss -0.8443 
2025-01-31 05:23:24.217535: val_loss -0.7309 
2025-01-31 05:23:24.220535: Pseudo dice [np.float32(0.9523), np.float32(0.8265)] 
2025-01-31 05:23:24.223355: Epoch time: 48.06 s 
2025-01-31 05:23:25.427492:  
2025-01-31 05:23:25.430625: Epoch 753 
2025-01-31 05:23:25.433387: Current learning rate: 0.00284 
2025-01-31 05:24:13.180285: train_loss -0.8372 
2025-01-31 05:24:13.186563: val_loss -0.6656 
2025-01-31 05:24:13.189130: Pseudo dice [np.float32(0.9443), np.float32(0.5756)] 
2025-01-31 05:24:13.191688: Epoch time: 47.75 s 
2025-01-31 05:24:14.391633:  
2025-01-31 05:24:14.395051: Epoch 754 
2025-01-31 05:24:14.397884: Current learning rate: 0.00283 
2025-01-31 05:25:02.617079: train_loss -0.8122 
2025-01-31 05:25:02.624663: val_loss -0.7263 
2025-01-31 05:25:02.627484: Pseudo dice [np.float32(0.9512), np.float32(0.7442)] 
2025-01-31 05:25:02.630274: Epoch time: 48.23 s 
2025-01-31 05:25:03.831606:  
2025-01-31 05:25:03.835173: Epoch 755 
2025-01-31 05:25:03.837879: Current learning rate: 0.00282 
2025-01-31 05:25:51.824537: train_loss -0.8475 
2025-01-31 05:25:51.830365: val_loss -0.6016 
2025-01-31 05:25:51.833437: Pseudo dice [np.float32(0.9454), np.float32(0.508)] 
2025-01-31 05:25:51.836020: Epoch time: 47.99 s 
2025-01-31 05:25:53.046216:  
2025-01-31 05:25:53.049251: Epoch 756 
2025-01-31 05:25:53.052131: Current learning rate: 0.00281 
2025-01-31 05:26:40.834659: train_loss -0.8313 
2025-01-31 05:26:40.842668: val_loss -0.7541 
2025-01-31 05:26:40.845255: Pseudo dice [np.float32(0.9544), np.float32(0.8392)] 
2025-01-31 05:26:40.847681: Epoch time: 47.79 s 
2025-01-31 05:26:42.025668:  
2025-01-31 05:26:42.028513: Epoch 757 
2025-01-31 05:26:42.032402: Current learning rate: 0.0028 
2025-01-31 05:27:30.273685: train_loss -0.8278 
2025-01-31 05:27:30.280792: val_loss -0.6633 
2025-01-31 05:27:30.283789: Pseudo dice [np.float32(0.9525), np.float32(0.489)] 
2025-01-31 05:27:30.286300: Epoch time: 48.25 s 
2025-01-31 05:27:31.480525:  
2025-01-31 05:27:31.483572: Epoch 758 
2025-01-31 05:27:31.486324: Current learning rate: 0.00279 
2025-01-31 05:28:19.854803: train_loss -0.8281 
2025-01-31 05:28:19.861791: val_loss -0.6804 
2025-01-31 05:28:19.864516: Pseudo dice [np.float32(0.9479), np.float32(0.6259)] 
2025-01-31 05:28:19.866742: Epoch time: 48.38 s 
2025-01-31 05:28:21.078249:  
2025-01-31 05:28:21.082279: Epoch 759 
2025-01-31 05:28:21.084841: Current learning rate: 0.00278 
2025-01-31 05:29:09.698719: train_loss -0.8142 
2025-01-31 05:29:09.705106: val_loss -0.6981 
2025-01-31 05:29:09.707598: Pseudo dice [np.float32(0.9549), np.float32(0.6963)] 
2025-01-31 05:29:09.709961: Epoch time: 48.62 s 
2025-01-31 05:29:10.900299:  
2025-01-31 05:29:10.903549: Epoch 760 
2025-01-31 05:29:10.906516: Current learning rate: 0.00277 
2025-01-31 05:29:58.739704: train_loss -0.8349 
2025-01-31 05:29:58.747354: val_loss -0.7467 
2025-01-31 05:29:58.750123: Pseudo dice [np.float32(0.957), np.float32(0.8163)] 
2025-01-31 05:29:58.752533: Epoch time: 47.84 s 
2025-01-31 05:29:59.968099:  
2025-01-31 05:29:59.971406: Epoch 761 
2025-01-31 05:29:59.974001: Current learning rate: 0.00276 
2025-01-31 05:30:48.086119: train_loss -0.8357 
2025-01-31 05:30:48.094705: val_loss -0.723 
2025-01-31 05:30:48.097471: Pseudo dice [np.float32(0.9577), np.float32(0.7903)] 
2025-01-31 05:30:48.100394: Epoch time: 48.12 s 
2025-01-31 05:30:49.315964:  
2025-01-31 05:30:49.319228: Epoch 762 
2025-01-31 05:30:49.322066: Current learning rate: 0.00275 
2025-01-31 05:31:37.406387: train_loss -0.8508 
2025-01-31 05:31:37.412484: val_loss -0.643 
2025-01-31 05:31:37.415138: Pseudo dice [np.float32(0.9446), np.float32(0.3166)] 
2025-01-31 05:31:37.417781: Epoch time: 48.09 s 
2025-01-31 05:31:38.641964:  
2025-01-31 05:31:38.644768: Epoch 763 
2025-01-31 05:31:38.647352: Current learning rate: 0.00274 
2025-01-31 05:32:26.632888: train_loss -0.8391 
2025-01-31 05:32:26.636889: val_loss -0.7245 
2025-01-31 05:32:26.639334: Pseudo dice [np.float32(0.9466), np.float32(0.7595)] 
2025-01-31 05:32:26.641944: Epoch time: 47.99 s 
2025-01-31 05:32:27.871572:  
2025-01-31 05:32:27.874534: Epoch 764 
2025-01-31 05:32:27.877244: Current learning rate: 0.00273 
2025-01-31 05:33:15.842694: train_loss -0.8301 
2025-01-31 05:33:15.848414: val_loss -0.6609 
2025-01-31 05:33:15.851126: Pseudo dice [np.float32(0.9436), np.float32(0.6526)] 
2025-01-31 05:33:15.853745: Epoch time: 47.97 s 
2025-01-31 05:33:17.555740:  
2025-01-31 05:33:17.558591: Epoch 765 
2025-01-31 05:33:17.561503: Current learning rate: 0.00272 
2025-01-31 05:34:05.564316: train_loss -0.823 
2025-01-31 05:34:05.571388: val_loss -0.6557 
2025-01-31 05:34:05.574156: Pseudo dice [np.float32(0.9422), np.float32(0.6508)] 
2025-01-31 05:34:05.576761: Epoch time: 48.01 s 
2025-01-31 05:34:06.781381:  
2025-01-31 05:34:06.784550: Epoch 766 
2025-01-31 05:34:06.787409: Current learning rate: 0.00271 
2025-01-31 05:34:54.860812: train_loss -0.8532 
2025-01-31 05:34:54.866637: val_loss -0.6968 
2025-01-31 05:34:54.869557: Pseudo dice [np.float32(0.9554), np.float32(0.822)] 
2025-01-31 05:34:54.872569: Epoch time: 48.08 s 
2025-01-31 05:34:56.062399:  
2025-01-31 05:34:56.065644: Epoch 767 
2025-01-31 05:34:56.068373: Current learning rate: 0.0027 
2025-01-31 05:35:43.851107: train_loss -0.8396 
2025-01-31 05:35:43.855375: val_loss -0.688 
2025-01-31 05:35:43.858220: Pseudo dice [np.float32(0.9422), np.float32(0.693)] 
2025-01-31 05:35:43.860779: Epoch time: 47.79 s 
2025-01-31 05:35:45.045110:  
2025-01-31 05:35:45.047868: Epoch 768 
2025-01-31 05:35:45.051420: Current learning rate: 0.00268 
2025-01-31 05:36:32.854825: train_loss -0.8351 
2025-01-31 05:36:32.860622: val_loss -0.7572 
2025-01-31 05:36:32.863554: Pseudo dice [np.float32(0.9582), np.float32(0.7951)] 
2025-01-31 05:36:32.866120: Epoch time: 47.81 s 
2025-01-31 05:36:34.055444:  
2025-01-31 05:36:34.058300: Epoch 769 
2025-01-31 05:36:34.061104: Current learning rate: 0.00267 
2025-01-31 05:37:22.362956: train_loss -0.829 
2025-01-31 05:37:22.366931: val_loss -0.7682 
2025-01-31 05:37:22.369523: Pseudo dice [np.float32(0.9521), np.float32(0.9167)] 
2025-01-31 05:37:22.372037: Epoch time: 48.31 s 
2025-01-31 05:37:23.563187:  
2025-01-31 05:37:23.566144: Epoch 770 
2025-01-31 05:37:23.569074: Current learning rate: 0.00266 
2025-01-31 05:38:11.639213: train_loss -0.8392 
2025-01-31 05:38:11.645013: val_loss -0.6891 
2025-01-31 05:38:11.647626: Pseudo dice [np.float32(0.9455), np.float32(0.6342)] 
2025-01-31 05:38:11.650319: Epoch time: 48.08 s 
2025-01-31 05:38:12.837842:  
2025-01-31 05:38:12.841173: Epoch 771 
2025-01-31 05:38:12.844200: Current learning rate: 0.00265 
2025-01-31 05:39:01.063977: train_loss -0.8318 
2025-01-31 05:39:01.067728: val_loss -0.7063 
2025-01-31 05:39:01.070149: Pseudo dice [np.float32(0.9453), np.float32(0.7118)] 
2025-01-31 05:39:01.072563: Epoch time: 48.23 s 
2025-01-31 05:39:02.243247:  
2025-01-31 05:39:02.246081: Epoch 772 
2025-01-31 05:39:02.248785: Current learning rate: 0.00264 
2025-01-31 05:39:50.242895: train_loss -0.8404 
2025-01-31 05:39:50.248175: val_loss -0.7386 
2025-01-31 05:39:50.250998: Pseudo dice [np.float32(0.9575), np.float32(0.7608)] 
2025-01-31 05:39:50.253649: Epoch time: 48.0 s 
2025-01-31 05:39:51.436871:  
2025-01-31 05:39:51.439593: Epoch 773 
2025-01-31 05:39:51.442271: Current learning rate: 0.00263 
2025-01-31 05:40:39.422749: train_loss -0.839 
2025-01-31 05:40:39.426769: val_loss -0.7266 
2025-01-31 05:40:39.429186: Pseudo dice [np.float32(0.9407), np.float32(0.8218)] 
2025-01-31 05:40:39.431724: Epoch time: 47.99 s 
2025-01-31 05:40:40.615672:  
2025-01-31 05:40:40.618352: Epoch 774 
2025-01-31 05:40:40.621076: Current learning rate: 0.00262 
2025-01-31 05:41:28.647310: train_loss -0.839 
2025-01-31 05:41:28.653070: val_loss -0.7213 
2025-01-31 05:41:28.655678: Pseudo dice [np.float32(0.9507), np.float32(0.7645)] 
2025-01-31 05:41:28.658357: Epoch time: 48.03 s 
2025-01-31 05:41:29.890639:  
2025-01-31 05:41:29.893862: Epoch 775 
2025-01-31 05:41:29.896718: Current learning rate: 0.00261 
2025-01-31 05:42:17.906455: train_loss -0.8474 
2025-01-31 05:42:17.911088: val_loss -0.6466 
2025-01-31 05:42:17.913957: Pseudo dice [np.float32(0.9429), np.float32(0.5997)] 
2025-01-31 05:42:17.916511: Epoch time: 48.02 s 
2025-01-31 05:42:19.106497:  
2025-01-31 05:42:19.109355: Epoch 776 
2025-01-31 05:42:19.112152: Current learning rate: 0.0026 
2025-01-31 05:43:07.042778: train_loss -0.8428 
2025-01-31 05:43:07.048218: val_loss -0.6664 
2025-01-31 05:43:07.051033: Pseudo dice [np.float32(0.9554), np.float32(0.5306)] 
2025-01-31 05:43:07.053375: Epoch time: 47.94 s 
2025-01-31 05:43:08.243441:  
2025-01-31 05:43:08.246323: Epoch 777 
2025-01-31 05:43:08.248894: Current learning rate: 0.00259 
2025-01-31 05:43:56.842962: train_loss -0.8493 
2025-01-31 05:43:56.846873: val_loss -0.6981 
2025-01-31 05:43:56.849365: Pseudo dice [np.float32(0.9564), np.float32(0.7251)] 
2025-01-31 05:43:56.851966: Epoch time: 48.6 s 
2025-01-31 05:43:58.035849:  
2025-01-31 05:43:58.038661: Epoch 778 
2025-01-31 05:43:58.041198: Current learning rate: 0.00258 
2025-01-31 05:44:46.099650: train_loss -0.8313 
2025-01-31 05:44:46.105184: val_loss -0.7058 
2025-01-31 05:44:46.107840: Pseudo dice [np.float32(0.9444), np.float32(0.7933)] 
2025-01-31 05:44:46.110445: Epoch time: 48.06 s 
2025-01-31 05:44:47.340801:  
2025-01-31 05:44:47.343508: Epoch 779 
2025-01-31 05:44:47.346177: Current learning rate: 0.00257 
2025-01-31 05:45:35.436745: train_loss -0.8543 
2025-01-31 05:45:35.441418: val_loss -0.7095 
2025-01-31 05:45:35.444185: Pseudo dice [np.float32(0.9401), np.float32(0.7905)] 
2025-01-31 05:45:35.446790: Epoch time: 48.1 s 
2025-01-31 05:45:36.629446:  
2025-01-31 05:45:36.633347: Epoch 780 
2025-01-31 05:45:36.635931: Current learning rate: 0.00256 
2025-01-31 05:46:24.695654: train_loss -0.8507 
2025-01-31 05:46:24.700994: val_loss -0.6801 
2025-01-31 05:46:24.703703: Pseudo dice [np.float32(0.9459), np.float32(0.6185)] 
2025-01-31 05:46:24.706231: Epoch time: 48.07 s 
2025-01-31 05:46:25.935421:  
2025-01-31 05:46:25.938043: Epoch 781 
2025-01-31 05:46:25.940731: Current learning rate: 0.00255 
2025-01-31 05:47:13.913596: train_loss -0.8306 
2025-01-31 05:47:13.917438: val_loss -0.7368 
2025-01-31 05:47:13.920330: Pseudo dice [np.float32(0.9562), np.float32(0.8436)] 
2025-01-31 05:47:13.922960: Epoch time: 47.98 s 
2025-01-31 05:47:15.151732:  
2025-01-31 05:47:15.154333: Epoch 782 
2025-01-31 05:47:15.157001: Current learning rate: 0.00254 
2025-01-31 05:48:03.488358: train_loss -0.8266 
2025-01-31 05:48:03.493612: val_loss -0.7475 
2025-01-31 05:48:03.496241: Pseudo dice [np.float32(0.9559), np.float32(0.8154)] 
2025-01-31 05:48:03.498638: Epoch time: 48.34 s 
2025-01-31 05:48:05.231835:  
2025-01-31 05:48:05.234542: Epoch 783 
2025-01-31 05:48:05.237413: Current learning rate: 0.00253 
2025-01-31 05:48:53.362197: train_loss -0.8258 
2025-01-31 05:48:53.366091: val_loss -0.6866 
2025-01-31 05:48:53.368645: Pseudo dice [np.float32(0.9417), np.float32(0.8082)] 
2025-01-31 05:48:53.371217: Epoch time: 48.13 s 
2025-01-31 05:48:54.558369:  
2025-01-31 05:48:54.561472: Epoch 784 
2025-01-31 05:48:54.564600: Current learning rate: 0.00252 
2025-01-31 05:49:42.625855: train_loss -0.8398 
2025-01-31 05:49:42.632284: val_loss -0.6721 
2025-01-31 05:49:42.635191: Pseudo dice [np.float32(0.9425), np.float32(0.7491)] 
2025-01-31 05:49:42.637960: Epoch time: 48.07 s 
2025-01-31 05:49:43.826233:  
2025-01-31 05:49:43.831486: Epoch 785 
2025-01-31 05:49:43.834222: Current learning rate: 0.00251 
2025-01-31 05:50:31.670213: train_loss -0.8363 
2025-01-31 05:50:31.676847: val_loss -0.7235 
2025-01-31 05:50:31.679632: Pseudo dice [np.float32(0.9425), np.float32(0.681)] 
2025-01-31 05:50:31.682184: Epoch time: 47.84 s 
2025-01-31 05:50:32.872726:  
2025-01-31 05:50:32.875746: Epoch 786 
2025-01-31 05:50:32.878405: Current learning rate: 0.0025 
2025-01-31 05:51:21.164071: train_loss -0.8413 
2025-01-31 05:51:21.169278: val_loss -0.6783 
2025-01-31 05:51:21.171791: Pseudo dice [np.float32(0.9474), np.float32(0.6492)] 
2025-01-31 05:51:21.182174: Epoch time: 48.29 s 
2025-01-31 05:51:22.367685:  
2025-01-31 05:51:22.370301: Epoch 787 
2025-01-31 05:51:22.373071: Current learning rate: 0.00249 
2025-01-31 05:52:10.604130: train_loss -0.8214 
2025-01-31 05:52:10.608556: val_loss -0.6003 
2025-01-31 05:52:10.611584: Pseudo dice [np.float32(0.9441), np.float32(0.476)] 
2025-01-31 05:52:10.614106: Epoch time: 48.24 s 
2025-01-31 05:52:11.847495:  
2025-01-31 05:52:11.850964: Epoch 788 
2025-01-31 05:52:11.854049: Current learning rate: 0.00248 
2025-01-31 05:52:59.782325: train_loss -0.8325 
2025-01-31 05:52:59.788470: val_loss -0.7065 
2025-01-31 05:52:59.791126: Pseudo dice [np.float32(0.949), np.float32(0.7399)] 
2025-01-31 05:52:59.793852: Epoch time: 47.94 s 
2025-01-31 05:53:00.986901:  
2025-01-31 05:53:00.989410: Epoch 789 
2025-01-31 05:53:00.992135: Current learning rate: 0.00247 
2025-01-31 05:53:49.022065: train_loss -0.8292 
2025-01-31 05:53:49.026523: val_loss -0.7494 
2025-01-31 05:53:49.029057: Pseudo dice [np.float32(0.9529), np.float32(0.8612)] 
2025-01-31 05:53:49.031885: Epoch time: 48.04 s 
2025-01-31 05:53:50.227867:  
2025-01-31 05:53:50.231008: Epoch 790 
2025-01-31 05:53:50.234431: Current learning rate: 0.00245 
2025-01-31 05:54:38.220380: train_loss -0.8319 
2025-01-31 05:54:38.226257: val_loss -0.701 
2025-01-31 05:54:38.229267: Pseudo dice [np.float32(0.9563), np.float32(0.7341)] 
2025-01-31 05:54:38.232073: Epoch time: 47.99 s 
2025-01-31 05:54:39.419837:  
2025-01-31 05:54:39.422556: Epoch 791 
2025-01-31 05:54:39.425397: Current learning rate: 0.00244 
2025-01-31 05:55:27.663517: train_loss -0.8469 
2025-01-31 05:55:27.667677: val_loss -0.7236 
2025-01-31 05:55:27.670202: Pseudo dice [np.float32(0.9427), np.float32(0.753)] 
2025-01-31 05:55:27.672977: Epoch time: 48.24 s 
2025-01-31 05:55:28.909259:  
2025-01-31 05:55:28.912414: Epoch 792 
2025-01-31 05:55:28.915211: Current learning rate: 0.00243 
2025-01-31 05:56:16.873334: train_loss -0.8442 
2025-01-31 05:56:16.878929: val_loss -0.7364 
2025-01-31 05:56:16.881473: Pseudo dice [np.float32(0.9502), np.float32(0.8711)] 
2025-01-31 05:56:16.884093: Epoch time: 47.96 s 
2025-01-31 05:56:18.077212:  
2025-01-31 05:56:18.079790: Epoch 793 
2025-01-31 05:56:18.082340: Current learning rate: 0.00242 
2025-01-31 05:57:06.570550: train_loss -0.844 
2025-01-31 05:57:06.575343: val_loss -0.7509 
2025-01-31 05:57:06.578304: Pseudo dice [np.float32(0.9537), np.float32(0.7791)] 
2025-01-31 05:57:06.581211: Epoch time: 48.49 s 
2025-01-31 05:57:07.771230:  
2025-01-31 05:57:07.774255: Epoch 794 
2025-01-31 05:57:07.777381: Current learning rate: 0.00241 
2025-01-31 05:57:55.729801: train_loss -0.8428 
2025-01-31 05:57:55.737088: val_loss -0.7336 
2025-01-31 05:57:55.739854: Pseudo dice [np.float32(0.9544), np.float32(0.8029)] 
2025-01-31 05:57:55.742412: Epoch time: 47.96 s 
2025-01-31 05:57:56.926966:  
2025-01-31 05:57:56.929954: Epoch 795 
2025-01-31 05:57:56.932844: Current learning rate: 0.0024 
2025-01-31 05:58:44.994364: train_loss -0.8637 
2025-01-31 05:58:45.000818: val_loss -0.7315 
2025-01-31 05:58:45.003639: Pseudo dice [np.float32(0.9593), np.float32(0.8373)] 
2025-01-31 05:58:45.006199: Epoch time: 48.07 s 
2025-01-31 05:58:46.206321:  
2025-01-31 05:58:46.209239: Epoch 796 
2025-01-31 05:58:46.212358: Current learning rate: 0.00239 
2025-01-31 05:59:34.440199: train_loss -0.8415 
2025-01-31 05:59:34.445432: val_loss -0.6872 
2025-01-31 05:59:34.447936: Pseudo dice [np.float32(0.9495), np.float32(0.7036)] 
2025-01-31 05:59:34.450508: Epoch time: 48.23 s 
2025-01-31 05:59:35.682059:  
2025-01-31 05:59:35.684809: Epoch 797 
2025-01-31 05:59:35.687235: Current learning rate: 0.00238 
2025-01-31 06:00:23.675796: train_loss -0.8284 
2025-01-31 06:00:23.680284: val_loss -0.7167 
2025-01-31 06:00:23.683391: Pseudo dice [np.float32(0.9533), np.float32(0.8386)] 
2025-01-31 06:00:23.686017: Epoch time: 47.99 s 
2025-01-31 06:00:24.925081:  
2025-01-31 06:00:24.928899: Epoch 798 
2025-01-31 06:00:24.931823: Current learning rate: 0.00237 
2025-01-31 06:01:12.964753: train_loss -0.828 
2025-01-31 06:01:12.970390: val_loss -0.7439 
2025-01-31 06:01:12.973171: Pseudo dice [np.float32(0.9561), np.float32(0.7475)] 
2025-01-31 06:01:12.975552: Epoch time: 48.04 s 
2025-01-31 06:01:14.162746:  
2025-01-31 06:01:14.165863: Epoch 799 
2025-01-31 06:01:14.168924: Current learning rate: 0.00236 
2025-01-31 06:02:02.206115: train_loss -0.8493 
2025-01-31 06:02:02.211226: val_loss -0.7717 
2025-01-31 06:02:02.214468: Pseudo dice [np.float32(0.9518), np.float32(0.8811)] 
2025-01-31 06:02:02.217709: Epoch time: 48.04 s 
2025-01-31 06:02:04.004030:  
2025-01-31 06:02:04.006618: Epoch 800 
2025-01-31 06:02:04.009348: Current learning rate: 0.00235 
2025-01-31 06:02:52.270370: train_loss -0.8504 
2025-01-31 06:02:52.275921: val_loss -0.7231 
2025-01-31 06:02:52.278727: Pseudo dice [np.float32(0.9413), np.float32(0.8325)] 
2025-01-31 06:02:52.281309: Epoch time: 48.27 s 
2025-01-31 06:02:54.005609:  
2025-01-31 06:02:54.008609: Epoch 801 
2025-01-31 06:02:54.011367: Current learning rate: 0.00234 
2025-01-31 06:03:42.435972: train_loss -0.8416 
2025-01-31 06:03:42.440288: val_loss -0.7345 
2025-01-31 06:03:42.443050: Pseudo dice [np.float32(0.9613), np.float32(0.8384)] 
2025-01-31 06:03:42.445602: Epoch time: 48.43 s 
2025-01-31 06:03:43.687606:  
2025-01-31 06:03:43.690825: Epoch 802 
2025-01-31 06:03:43.694022: Current learning rate: 0.00233 
2025-01-31 06:04:31.966470: train_loss -0.8583 
2025-01-31 06:04:31.973248: val_loss -0.7578 
2025-01-31 06:04:31.976276: Pseudo dice [np.float32(0.9565), np.float32(0.8934)] 
2025-01-31 06:04:31.978927: Epoch time: 48.28 s 
2025-01-31 06:04:33.221485:  
2025-01-31 06:04:33.226134: Epoch 803 
2025-01-31 06:04:33.229106: Current learning rate: 0.00232 
2025-01-31 06:05:21.405845: train_loss -0.8502 
2025-01-31 06:05:21.410376: val_loss -0.7251 
2025-01-31 06:05:21.413271: Pseudo dice [np.float32(0.9431), np.float32(0.8662)] 
2025-01-31 06:05:21.415915: Epoch time: 48.19 s 
2025-01-31 06:05:22.608312:  
2025-01-31 06:05:22.611255: Epoch 804 
2025-01-31 06:05:22.614016: Current learning rate: 0.00231 
2025-01-31 06:06:11.081047: train_loss -0.8507 
2025-01-31 06:06:11.086594: val_loss -0.7675 
2025-01-31 06:06:11.089180: Pseudo dice [np.float32(0.9475), np.float32(0.8491)] 
2025-01-31 06:06:11.091836: Epoch time: 48.47 s 
2025-01-31 06:06:12.318522:  
2025-01-31 06:06:12.321296: Epoch 805 
2025-01-31 06:06:12.324123: Current learning rate: 0.0023 
2025-01-31 06:07:00.598948: train_loss -0.8612 
2025-01-31 06:07:00.603641: val_loss -0.7426 
2025-01-31 06:07:00.606191: Pseudo dice [np.float32(0.9421), np.float32(0.8364)] 
2025-01-31 06:07:00.608734: Epoch time: 48.28 s 
2025-01-31 06:07:01.811889:  
2025-01-31 06:07:01.815610: Epoch 806 
2025-01-31 06:07:01.818501: Current learning rate: 0.00229 
2025-01-31 06:07:49.876074: train_loss -0.8458 
2025-01-31 06:07:49.881956: val_loss -0.754 
2025-01-31 06:07:49.884581: Pseudo dice [np.float32(0.9575), np.float32(0.8911)] 
2025-01-31 06:07:49.887190: Epoch time: 48.07 s 
2025-01-31 06:07:51.091581:  
2025-01-31 06:07:51.094563: Epoch 807 
2025-01-31 06:07:51.097142: Current learning rate: 0.00228 
2025-01-31 06:08:39.333797: train_loss -0.8456 
2025-01-31 06:08:39.338345: val_loss -0.7546 
2025-01-31 06:08:39.341286: Pseudo dice [np.float32(0.9513), np.float32(0.8551)] 
2025-01-31 06:08:39.343794: Epoch time: 48.24 s 
2025-01-31 06:08:40.540360:  
2025-01-31 06:08:40.543001: Epoch 808 
2025-01-31 06:08:40.545684: Current learning rate: 0.00226 
2025-01-31 06:09:28.473534: train_loss -0.8331 
2025-01-31 06:09:28.479516: val_loss -0.7395 
2025-01-31 06:09:28.482416: Pseudo dice [np.float32(0.9562), np.float32(0.8889)] 
2025-01-31 06:09:28.485215: Epoch time: 47.93 s 
2025-01-31 06:09:29.725082:  
2025-01-31 06:09:29.727757: Epoch 809 
2025-01-31 06:09:29.730355: Current learning rate: 0.00225 
2025-01-31 06:10:17.794152: train_loss -0.8387 
2025-01-31 06:10:17.798110: val_loss -0.723 
2025-01-31 06:10:17.800814: Pseudo dice [np.float32(0.9487), np.float32(0.8576)] 
2025-01-31 06:10:17.803302: Epoch time: 48.07 s 
2025-01-31 06:10:18.992312:  
2025-01-31 06:10:18.995439: Epoch 810 
2025-01-31 06:10:18.998257: Current learning rate: 0.00224 
2025-01-31 06:11:07.080439: train_loss -0.8356 
2025-01-31 06:11:07.086695: val_loss -0.7518 
2025-01-31 06:11:07.089783: Pseudo dice [np.float32(0.9555), np.float32(0.8281)] 
2025-01-31 06:11:07.092633: Epoch time: 48.09 s 
2025-01-31 06:11:08.286196:  
2025-01-31 06:11:08.289013: Epoch 811 
2025-01-31 06:11:08.291916: Current learning rate: 0.00223 
2025-01-31 06:11:56.049498: train_loss -0.8478 
2025-01-31 06:11:56.053439: val_loss -0.725 
2025-01-31 06:11:56.056359: Pseudo dice [np.float32(0.961), np.float32(0.7908)] 
2025-01-31 06:11:56.058816: Epoch time: 47.76 s 
2025-01-31 06:11:57.250108:  
2025-01-31 06:11:57.252879: Epoch 812 
2025-01-31 06:11:57.255625: Current learning rate: 0.00222 
