
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-01-25 18:37:43.273964: do_dummy_2d_data_aug: False 
2025-01-25 18:37:43.330670: Using splits from existing split file: /srv/scratch/z5362216/kits19/nnUNet_db/nnUNet_preprocessed/Dataset001_Kits19/splits_final.json 
2025-01-25 18:37:43.333532: The split file contains 5 splits. 
2025-01-25 18:37:43.335851: Desired fold for training: 2 
2025-01-25 18:37:43.338371: This split has 80 training and 20 validation cases. 
2025-01-25 18:37:48.112780: Using torch.compile... 

This is the configuration used by this training:
Configuration name: 3d_lowres
 {'data_identifier': 'nnUNetPlans_3d_lowres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [128, 128, 128], 'median_image_size_in_voxels': [200, 205, 205], 'spacing': [1.9849520718478983, 1.9849270710444444, 1.9849270710444444], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False, 'next_stage': '3d_cascade_fullres'} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset001_Kits19', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [3.0, 0.7939453125, 0.7939453125], 'original_median_shape_after_transp': [104, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [2, 0, 1], 'transpose_backward': [1, 2, 0], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 2553.0, 'mean': 104.46720886230469, 'median': 104.0, 'min': -277.0, 'percentile_00_5': -73.0, 'percentile_99_5': 292.0, 'std': 74.68063354492188}}} 
 
2025-01-25 18:37:52.368741: unpacking dataset... 
2025-01-25 18:37:57.917197: unpacking done... 
2025-01-25 18:37:57.999424: 
printing the network instead:
 
2025-01-25 18:37:58.001520: OptimizedModule(
  (_orig_mod): PlainConvUNet(
    (encoder): PlainConvEncoder(
      (stages): Sequential(
        (0): Sequential(
          (0): StackedConvBlocks(
            (convs): Sequential(
              (0): ConvDropoutNormReLU(
                (conv): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (1): ConvDropoutNormReLU(
                (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
            )
          )
        )
        (1): Sequential(
          (0): StackedConvBlocks(
            (convs): Sequential(
              (0): ConvDropoutNormReLU(
                (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (1): ConvDropoutNormReLU(
                (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
            )
          )
        )
        (2): Sequential(
          (0): StackedConvBlocks(
            (convs): Sequential(
              (0): ConvDropoutNormReLU(
                (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (1): ConvDropoutNormReLU(
                (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
            )
          )
        )
        (3): Sequential(
          (0): StackedConvBlocks(
            (convs): Sequential(
              (0): ConvDropoutNormReLU(
                (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (1): ConvDropoutNormReLU(
                (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
            )
          )
        )
        (4): Sequential(
          (0): StackedConvBlocks(
            (convs): Sequential(
              (0): ConvDropoutNormReLU(
                (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (1): ConvDropoutNormReLU(
                (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
            )
          )
        )
        (5): Sequential(
          (0): StackedConvBlocks(
            (convs): Sequential(
              (0): ConvDropoutNormReLU(
                (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (1): ConvDropoutNormReLU(
                (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
            )
          )
        )
      )
    )
    (decoder): UNetDecoder(
      (encoder): PlainConvEncoder(
        (stages): Sequential(
          (0): Sequential(
            (0): StackedConvBlocks(
              (convs): Sequential(
                (0): ConvDropoutNormReLU(
                  (conv): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                  (all_modules): Sequential(
                    (0): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                    (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                    (2): LeakyReLU(negative_slope=0.01, inplace=True)
                  )
                )
                (1): ConvDropoutNormReLU(
                  (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                  (all_modules): Sequential(
                    (0): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                    (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                    (2): LeakyReLU(negative_slope=0.01, inplace=True)
                  )
                )
              )
            )
          )
          (1): Sequential(
            (0): StackedConvBlocks(
              (convs): Sequential(
                (0): ConvDropoutNormReLU(
                  (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                  (all_modules): Sequential(
                    (0): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                    (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                    (2): LeakyReLU(negative_slope=0.01, inplace=True)
                  )
                )
                (1): ConvDropoutNormReLU(
                  (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                  (all_modules): Sequential(
                    (0): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                    (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                    (2): LeakyReLU(negative_slope=0.01, inplace=True)
                  )
                )
              )
            )
          )
          (2): Sequential(
            (0): StackedConvBlocks(
              (convs): Sequential(
                (0): ConvDropoutNormReLU(
                  (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                  (all_modules): Sequential(
                    (0): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                    (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                    (2): LeakyReLU(negative_slope=0.01, inplace=True)
                  )
                )
                (1): ConvDropoutNormReLU(
                  (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                  (all_modules): Sequential(
                    (0): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                    (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                    (2): LeakyReLU(negative_slope=0.01, inplace=True)
                  )
                )
              )
            )
          )
          (3): Sequential(
            (0): StackedConvBlocks(
              (convs): Sequential(
                (0): ConvDropoutNormReLU(
                  (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                  (all_modules): Sequential(
                    (0): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                    (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                    (2): LeakyReLU(negative_slope=0.01, inplace=True)
                  )
                )
                (1): ConvDropoutNormReLU(
                  (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                  (all_modules): Sequential(
                    (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                    (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                    (2): LeakyReLU(negative_slope=0.01, inplace=True)
                  )
                )
              )
            )
          )
          (4): Sequential(
            (0): StackedConvBlocks(
              (convs): Sequential(
                (0): ConvDropoutNormReLU(
                  (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                  (all_modules): Sequential(
                    (0): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                    (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                    (2): LeakyReLU(negative_slope=0.01, inplace=True)
                  )
                )
                (1): ConvDropoutNormReLU(
                  (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                  (all_modules): Sequential(
                    (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                    (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                    (2): LeakyReLU(negative_slope=0.01, inplace=True)
                  )
                )
              )
            )
          )
          (5): Sequential(
            (0): StackedConvBlocks(
              (convs): Sequential(
                (0): ConvDropoutNormReLU(
                  (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                  (all_modules): Sequential(
                    (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                    (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                    (2): LeakyReLU(negative_slope=0.01, inplace=True)
                  )
                )
                (1): ConvDropoutNormReLU(
                  (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                  (all_modules): Sequential(
                    (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                    (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                    (2): LeakyReLU(negative_slope=0.01, inplace=True)
                  )
                )
              )
            )
          )
        )
      )
      (stages): ModuleList(
        (0): StackedConvBlocks(
          (convs): Sequential(
            (0): ConvDropoutNormReLU(
              (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
              (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (1): ConvDropoutNormReLU(
              (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
              (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
          )
        )
        (1): StackedConvBlocks(
          (convs): Sequential(
            (0): ConvDropoutNormReLU(
              (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
              (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (1): ConvDropoutNormReLU(
              (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
              (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
          )
        )
        (2): StackedConvBlocks(
          (convs): Sequential(
            (0): ConvDropoutNormReLU(
              (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (1): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
          )
        )
        (3): StackedConvBlocks(
          (convs): Sequential(
            (0): ConvDropoutNormReLU(
              (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (1): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
          )
        )
        (4): StackedConvBlocks(
          (convs): Sequential(
            (0): ConvDropoutNormReLU(
              (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (1): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
          )
        )
      )
      (transpconvs): ModuleList(
        (0): ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2))
        (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2))
        (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2))
        (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2))
        (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2))
      )
      (seg_layers): ModuleList(
        (0): Conv3d(320, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1))
        (1): Conv3d(256, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1))
        (2): Conv3d(128, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1))
        (3): Conv3d(64, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1))
        (4): Conv3d(32, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1))
      )
    )
  )
) 
2025-01-25 18:37:58.007778: 
 
2025-01-25 18:37:58.009915: Unable to plot network architecture: nnUNet_compile is enabled! 
2025-01-25 18:37:58.099002:  
2025-01-25 18:37:58.101314: Epoch 0 
2025-01-25 18:37:58.103739: Current learning rate: 0.01 
2025-01-25 18:39:51.216406: train_loss 0.0512 
2025-01-25 18:39:51.221915: val_loss -0.182 
2025-01-25 18:39:51.224265: Pseudo dice [np.float32(0.4842), np.float32(0.0)] 
2025-01-25 18:39:51.226432: Epoch time: 113.12 s 
2025-01-25 18:39:51.228555: Yayy! New best EMA pseudo Dice: 0.24210000038146973 
2025-01-25 18:39:52.873205:  
2025-01-25 18:39:52.876096: Epoch 1 
2025-01-25 18:39:52.878633: Current learning rate: 0.00999 
2025-01-25 18:40:21.658485: train_loss -0.2759 
2025-01-25 18:40:21.664371: val_loss -0.3799 
2025-01-25 18:40:21.667069: Pseudo dice [np.float32(0.8247), np.float32(0.0)] 
2025-01-25 18:40:21.669550: Epoch time: 28.79 s 
2025-01-25 18:40:21.672075: Yayy! New best EMA pseudo Dice: 0.2590999901294708 
2025-01-25 18:40:23.719209:  
2025-01-25 18:40:23.721574: Epoch 2 
2025-01-25 18:40:23.723866: Current learning rate: 0.00998 
2025-01-25 18:40:52.610447: train_loss -0.3588 
2025-01-25 18:40:52.618176: val_loss -0.3992 
2025-01-25 18:40:52.620671: Pseudo dice [np.float32(0.8167), np.float32(0.2408)] 
2025-01-25 18:40:52.622908: Epoch time: 28.89 s 
2025-01-25 18:40:52.625299: Yayy! New best EMA pseudo Dice: 0.28610000014305115 
2025-01-25 18:40:54.065185:  
2025-01-25 18:40:54.068078: Epoch 3 
2025-01-25 18:40:54.070552: Current learning rate: 0.00997 
2025-01-25 18:41:22.813349: train_loss -0.4174 
2025-01-25 18:41:22.818588: val_loss -0.4331 
2025-01-25 18:41:22.821165: Pseudo dice [np.float32(0.8232), np.float32(0.3618)] 
2025-01-25 18:41:22.823519: Epoch time: 28.75 s 
2025-01-25 18:41:22.825920: Yayy! New best EMA pseudo Dice: 0.3167000114917755 
2025-01-25 18:41:24.419911:  
2025-01-25 18:41:24.422537: Epoch 4 
2025-01-25 18:41:24.424876: Current learning rate: 0.00996 
2025-01-25 18:41:52.331627: train_loss -0.4565 
2025-01-25 18:41:52.336789: val_loss -0.4932 
2025-01-25 18:41:52.339176: Pseudo dice [np.float32(0.8609), np.float32(0.4559)] 
2025-01-25 18:41:52.341542: Epoch time: 27.91 s 
2025-01-25 18:41:52.344332: Yayy! New best EMA pseudo Dice: 0.35089999437332153 
2025-01-25 18:41:53.902929:  
2025-01-25 18:41:53.905483: Epoch 5 
2025-01-25 18:41:53.908277: Current learning rate: 0.00995 
2025-01-25 18:42:23.140826: train_loss -0.4581 
2025-01-25 18:42:23.148438: val_loss -0.4973 
2025-01-25 18:42:23.151881: Pseudo dice [np.float32(0.8929), np.float32(0.3403)] 
2025-01-25 18:42:23.154981: Epoch time: 29.24 s 
2025-01-25 18:42:23.158139: Yayy! New best EMA pseudo Dice: 0.3774999976158142 
2025-01-25 18:42:24.862885:  
2025-01-25 18:42:24.865430: Epoch 6 
2025-01-25 18:42:24.868141: Current learning rate: 0.00995 
2025-01-25 18:42:54.068425: train_loss -0.4956 
2025-01-25 18:42:54.075033: val_loss -0.5005 
2025-01-25 18:42:54.077568: Pseudo dice [np.float32(0.8755), np.float32(0.4983)] 
2025-01-25 18:42:54.079988: Epoch time: 29.21 s 
2025-01-25 18:42:54.082313: Yayy! New best EMA pseudo Dice: 0.4083999991416931 
2025-01-25 18:42:55.558241:  
2025-01-25 18:42:55.561034: Epoch 7 
2025-01-25 18:42:55.563727: Current learning rate: 0.00994 
2025-01-25 18:43:26.433609: train_loss -0.5261 
2025-01-25 18:43:26.442539: val_loss -0.5023 
2025-01-25 18:43:26.445027: Pseudo dice [np.float32(0.8491), np.float32(0.4843)] 
2025-01-25 18:43:26.447680: Epoch time: 30.88 s 
2025-01-25 18:43:26.449889: Yayy! New best EMA pseudo Dice: 0.4341999888420105 
2025-01-25 18:43:28.058383:  
2025-01-25 18:43:28.060725: Epoch 8 
2025-01-25 18:43:28.062946: Current learning rate: 0.00993 
2025-01-25 18:43:57.511623: train_loss -0.5481 
2025-01-25 18:43:57.518803: val_loss -0.5848 
2025-01-25 18:43:57.521374: Pseudo dice [np.float32(0.8925), np.float32(0.6786)] 
2025-01-25 18:43:57.524026: Epoch time: 29.45 s 
2025-01-25 18:43:57.526478: Yayy! New best EMA pseudo Dice: 0.46939998865127563 
2025-01-25 18:43:59.103922:  
2025-01-25 18:43:59.106334: Epoch 9 
2025-01-25 18:43:59.108645: Current learning rate: 0.00992 
2025-01-25 18:44:30.156673: train_loss -0.5211 
2025-01-25 18:44:30.163112: val_loss -0.504 
2025-01-25 18:44:30.166260: Pseudo dice [np.float32(0.8586), np.float32(0.4369)] 
2025-01-25 18:44:30.168750: Epoch time: 31.05 s 
2025-01-25 18:44:30.171810: Yayy! New best EMA pseudo Dice: 0.487199991941452 
2025-01-25 18:44:31.723356:  
2025-01-25 18:44:31.725610: Epoch 10 
2025-01-25 18:44:31.727763: Current learning rate: 0.00991 
2025-01-25 18:45:01.157758: train_loss -0.5592 
2025-01-25 18:45:01.163282: val_loss -0.5974 
2025-01-25 18:45:01.165926: Pseudo dice [np.float32(0.8964), np.float32(0.648)] 
2025-01-25 18:45:01.168583: Epoch time: 29.44 s 
2025-01-25 18:45:01.171288: Yayy! New best EMA pseudo Dice: 0.5156999826431274 
2025-01-25 18:45:02.772086:  
2025-01-25 18:45:02.774607: Epoch 11 
2025-01-25 18:45:02.777061: Current learning rate: 0.0099 
2025-01-25 18:45:31.426229: train_loss -0.5777 
2025-01-25 18:45:31.432253: val_loss -0.6 
2025-01-25 18:45:31.434937: Pseudo dice [np.float32(0.9045), np.float32(0.5566)] 
2025-01-25 18:45:31.437289: Epoch time: 28.66 s 
2025-01-25 18:45:31.439774: Yayy! New best EMA pseudo Dice: 0.5371999740600586 
2025-01-25 18:45:33.017802:  
2025-01-25 18:45:33.020620: Epoch 12 
2025-01-25 18:45:33.023183: Current learning rate: 0.00989 
2025-01-25 18:46:03.009025: train_loss -0.6022 
2025-01-25 18:46:03.016097: val_loss -0.621 
2025-01-25 18:46:03.018551: Pseudo dice [np.float32(0.913), np.float32(0.594)] 
2025-01-25 18:46:03.020993: Epoch time: 29.99 s 
2025-01-25 18:46:03.023750: Yayy! New best EMA pseudo Dice: 0.5587999820709229 
2025-01-25 18:46:04.526737:  
2025-01-25 18:46:04.529377: Epoch 13 
2025-01-25 18:46:04.531725: Current learning rate: 0.00988 
2025-01-25 18:46:35.676163: train_loss -0.5969 
2025-01-25 18:46:35.683085: val_loss -0.5894 
2025-01-25 18:46:35.685831: Pseudo dice [np.float32(0.8891), np.float32(0.6562)] 
2025-01-25 18:46:35.688410: Epoch time: 31.15 s 
2025-01-25 18:46:35.691010: Yayy! New best EMA pseudo Dice: 0.5802000164985657 
2025-01-25 18:46:37.251738:  
2025-01-25 18:46:37.254572: Epoch 14 
2025-01-25 18:46:37.257232: Current learning rate: 0.00987 
2025-01-25 18:47:06.519485: train_loss -0.6091 
2025-01-25 18:47:06.525580: val_loss -0.6344 
2025-01-25 18:47:06.528003: Pseudo dice [np.float32(0.9269), np.float32(0.6574)] 
2025-01-25 18:47:06.530352: Epoch time: 29.27 s 
2025-01-25 18:47:06.532575: Yayy! New best EMA pseudo Dice: 0.6014000177383423 
2025-01-25 18:47:08.067384:  
2025-01-25 18:47:08.069823: Epoch 15 
2025-01-25 18:47:08.072107: Current learning rate: 0.00986 
2025-01-25 18:47:37.872086: train_loss -0.6302 
2025-01-25 18:47:37.875716: val_loss -0.6311 
2025-01-25 18:47:37.878095: Pseudo dice [np.float32(0.9068), np.float32(0.6966)] 
2025-01-25 18:47:37.880427: Epoch time: 29.81 s 
2025-01-25 18:47:37.882770: Yayy! New best EMA pseudo Dice: 0.621399998664856 
2025-01-25 18:47:39.437956:  
2025-01-25 18:47:39.440567: Epoch 16 
2025-01-25 18:47:39.443148: Current learning rate: 0.00986 
2025-01-25 18:48:09.574269: train_loss -0.6297 
2025-01-25 18:48:09.579497: val_loss -0.5871 
2025-01-25 18:48:09.581978: Pseudo dice [np.float32(0.9084), np.float32(0.7068)] 
2025-01-25 18:48:09.584440: Epoch time: 30.14 s 
2025-01-25 18:48:09.586863: Yayy! New best EMA pseudo Dice: 0.6399999856948853 
2025-01-25 18:48:11.167511:  
2025-01-25 18:48:11.170101: Epoch 17 
2025-01-25 18:48:11.172657: Current learning rate: 0.00985 
2025-01-25 18:48:41.059939: train_loss -0.6233 
2025-01-25 18:48:41.065905: val_loss -0.6738 
2025-01-25 18:48:41.068654: Pseudo dice [np.float32(0.918), np.float32(0.7335)] 
2025-01-25 18:48:41.071277: Epoch time: 29.89 s 
2025-01-25 18:48:41.073871: Yayy! New best EMA pseudo Dice: 0.6585999727249146 
2025-01-25 18:48:42.626788:  
2025-01-25 18:48:42.629125: Epoch 18 
2025-01-25 18:48:42.631506: Current learning rate: 0.00984 
2025-01-25 18:49:13.381016: train_loss -0.6581 
2025-01-25 18:49:13.387549: val_loss -0.6296 
2025-01-25 18:49:13.389862: Pseudo dice [np.float32(0.9055), np.float32(0.6606)] 
2025-01-25 18:49:13.392259: Epoch time: 30.76 s 
2025-01-25 18:49:13.394501: Yayy! New best EMA pseudo Dice: 0.6711000204086304 
2025-01-25 18:49:15.005292:  
2025-01-25 18:49:15.008124: Epoch 19 
2025-01-25 18:49:15.010322: Current learning rate: 0.00983 
2025-01-25 18:49:43.825551: train_loss -0.6376 
2025-01-25 18:49:43.830815: val_loss -0.6436 
2025-01-25 18:49:43.833295: Pseudo dice [np.float32(0.9118), np.float32(0.7288)] 
2025-01-25 18:49:43.835794: Epoch time: 28.82 s 
2025-01-25 18:49:43.837989: Yayy! New best EMA pseudo Dice: 0.6859999895095825 
2025-01-25 18:49:45.840092:  
2025-01-25 18:49:45.842927: Epoch 20 
2025-01-25 18:49:45.845498: Current learning rate: 0.00982 
2025-01-25 18:50:15.160538: train_loss -0.6575 
2025-01-25 18:50:15.171046: val_loss -0.6574 
2025-01-25 18:50:15.173435: Pseudo dice [np.float32(0.9301), np.float32(0.784)] 
2025-01-25 18:50:15.175741: Epoch time: 29.32 s 
2025-01-25 18:50:15.177918: Yayy! New best EMA pseudo Dice: 0.7031000256538391 
2025-01-25 18:50:16.816098:  
2025-01-25 18:50:16.818435: Epoch 21 
2025-01-25 18:50:16.820682: Current learning rate: 0.00981 
2025-01-25 18:50:45.568541: train_loss -0.6729 
2025-01-25 18:50:45.573822: val_loss -0.6448 
2025-01-25 18:50:45.576379: Pseudo dice [np.float32(0.9272), np.float32(0.6921)] 
2025-01-25 18:50:45.578936: Epoch time: 28.75 s 
2025-01-25 18:50:45.581406: Yayy! New best EMA pseudo Dice: 0.713699996471405 
2025-01-25 18:50:47.110880:  
2025-01-25 18:50:47.113264: Epoch 22 
2025-01-25 18:50:47.115845: Current learning rate: 0.0098 
2025-01-25 18:51:16.507444: train_loss -0.6668 
2025-01-25 18:51:16.513583: val_loss -0.7019 
2025-01-25 18:51:16.516052: Pseudo dice [np.float32(0.9148), np.float32(0.7619)] 
2025-01-25 18:51:16.518303: Epoch time: 29.4 s 
2025-01-25 18:51:16.520630: Yayy! New best EMA pseudo Dice: 0.7261999845504761 
2025-01-25 18:51:18.013794:  
2025-01-25 18:51:18.016563: Epoch 23 
2025-01-25 18:51:18.019230: Current learning rate: 0.00979 
2025-01-25 18:51:47.530801: train_loss -0.6613 
2025-01-25 18:51:47.535901: val_loss -0.6623 
2025-01-25 18:51:47.538702: Pseudo dice [np.float32(0.9236), np.float32(0.6479)] 
2025-01-25 18:51:47.541502: Epoch time: 29.52 s 
2025-01-25 18:51:47.544106: Yayy! New best EMA pseudo Dice: 0.732200026512146 
2025-01-25 18:51:49.066343:  
2025-01-25 18:51:49.069070: Epoch 24 
2025-01-25 18:51:49.071560: Current learning rate: 0.00978 
2025-01-25 18:52:18.026345: train_loss -0.6692 
2025-01-25 18:52:18.032915: val_loss -0.6421 
2025-01-25 18:52:18.035458: Pseudo dice [np.float32(0.9216), np.float32(0.7734)] 
2025-01-25 18:52:18.037699: Epoch time: 28.96 s 
2025-01-25 18:52:18.040096: Yayy! New best EMA pseudo Dice: 0.7437000274658203 
2025-01-25 18:52:19.649560:  
2025-01-25 18:52:19.652184: Epoch 25 
2025-01-25 18:52:19.654667: Current learning rate: 0.00977 
2025-01-25 18:52:51.059323: train_loss -0.6663 
2025-01-25 18:52:51.064506: val_loss -0.6839 
2025-01-25 18:52:51.067469: Pseudo dice [np.float32(0.9343), np.float32(0.7689)] 
2025-01-25 18:52:51.070014: Epoch time: 31.41 s 
2025-01-25 18:52:51.072706: Yayy! New best EMA pseudo Dice: 0.7544999718666077 
2025-01-25 18:52:52.565141:  
2025-01-25 18:52:52.567904: Epoch 26 
2025-01-25 18:52:52.570317: Current learning rate: 0.00977 
2025-01-25 18:53:22.819439: train_loss -0.6783 
2025-01-25 18:53:22.824748: val_loss -0.6602 
2025-01-25 18:53:22.826845: Pseudo dice [np.float32(0.9268), np.float32(0.7975)] 
2025-01-25 18:53:22.828973: Epoch time: 30.26 s 
2025-01-25 18:53:22.832515: Yayy! New best EMA pseudo Dice: 0.7652000188827515 
2025-01-25 18:53:24.354318:  
2025-01-25 18:53:24.356828: Epoch 27 
2025-01-25 18:53:24.359301: Current learning rate: 0.00976 
2025-01-25 18:53:53.383013: train_loss -0.6665 
2025-01-25 18:53:53.391770: val_loss -0.6339 
2025-01-25 18:53:53.394123: Pseudo dice [np.float32(0.9313), np.float32(0.737)] 
2025-01-25 18:53:53.396551: Epoch time: 29.03 s 
2025-01-25 18:53:53.398785: Yayy! New best EMA pseudo Dice: 0.7720999717712402 
2025-01-25 18:53:55.045147:  
2025-01-25 18:53:55.047348: Epoch 28 
2025-01-25 18:53:55.049546: Current learning rate: 0.00975 
2025-01-25 18:54:24.116583: train_loss -0.7072 
2025-01-25 18:54:24.130535: val_loss -0.6944 
2025-01-25 18:54:24.132899: Pseudo dice [np.float32(0.9302), np.float32(0.7706)] 
2025-01-25 18:54:24.135235: Epoch time: 29.07 s 
2025-01-25 18:54:24.137423: Yayy! New best EMA pseudo Dice: 0.7799999713897705 
2025-01-25 18:54:25.705954:  
2025-01-25 18:54:25.708321: Epoch 29 
2025-01-25 18:54:25.710595: Current learning rate: 0.00974 
2025-01-25 18:54:54.607468: train_loss -0.6729 
2025-01-25 18:54:54.612314: val_loss -0.6544 
2025-01-25 18:54:54.614596: Pseudo dice [np.float32(0.9233), np.float32(0.7329)] 
2025-01-25 18:54:54.616883: Epoch time: 28.9 s 
2025-01-25 18:54:54.619307: Yayy! New best EMA pseudo Dice: 0.7847999930381775 
2025-01-25 18:54:56.210262:  
2025-01-25 18:54:56.213662: Epoch 30 
2025-01-25 18:54:56.216140: Current learning rate: 0.00973 
2025-01-25 18:55:26.095814: train_loss -0.6981 
2025-01-25 18:55:26.101615: val_loss -0.6734 
2025-01-25 18:55:26.103843: Pseudo dice [np.float32(0.9346), np.float32(0.7686)] 
2025-01-25 18:55:26.106193: Epoch time: 29.89 s 
2025-01-25 18:55:26.108642: Yayy! New best EMA pseudo Dice: 0.7914999723434448 
2025-01-25 18:55:27.661828:  
2025-01-25 18:55:27.664448: Epoch 31 
2025-01-25 18:55:27.666910: Current learning rate: 0.00972 
2025-01-25 18:55:57.213164: train_loss -0.7025 
2025-01-25 18:55:57.217813: val_loss -0.6695 
2025-01-25 18:55:57.220067: Pseudo dice [np.float32(0.9168), np.float32(0.7091)] 
2025-01-25 18:55:57.222422: Epoch time: 29.55 s 
2025-01-25 18:55:57.224763: Yayy! New best EMA pseudo Dice: 0.7936000227928162 
2025-01-25 18:55:58.768610:  
2025-01-25 18:55:58.770970: Epoch 32 
2025-01-25 18:55:58.773396: Current learning rate: 0.00971 
2025-01-25 18:56:28.351589: train_loss -0.7077 
2025-01-25 18:56:28.359714: val_loss -0.7005 
2025-01-25 18:56:28.362468: Pseudo dice [np.float32(0.932), np.float32(0.7148)] 
2025-01-25 18:56:28.364924: Epoch time: 29.58 s 
2025-01-25 18:56:28.367380: Yayy! New best EMA pseudo Dice: 0.7965999841690063 
2025-01-25 18:56:29.883588:  
2025-01-25 18:56:29.886227: Epoch 33 
2025-01-25 18:56:29.888531: Current learning rate: 0.0097 
2025-01-25 18:57:00.486895: train_loss -0.7104 
2025-01-25 18:57:00.491951: val_loss -0.7101 
2025-01-25 18:57:00.494502: Pseudo dice [np.float32(0.9375), np.float32(0.8045)] 
2025-01-25 18:57:00.497028: Epoch time: 30.6 s 
2025-01-25 18:57:00.499751: Yayy! New best EMA pseudo Dice: 0.8040000200271606 
2025-01-25 18:57:02.031962:  
2025-01-25 18:57:02.034893: Epoch 34 
2025-01-25 18:57:02.037669: Current learning rate: 0.00969 
2025-01-25 18:57:32.003762: train_loss -0.6971 
2025-01-25 18:57:32.010033: val_loss -0.6894 
2025-01-25 18:57:32.012396: Pseudo dice [np.float32(0.9373), np.float32(0.7788)] 
2025-01-25 18:57:32.014751: Epoch time: 29.97 s 
2025-01-25 18:57:32.016975: Yayy! New best EMA pseudo Dice: 0.8094000220298767 
2025-01-25 18:57:33.537274:  
2025-01-25 18:57:33.540019: Epoch 35 
2025-01-25 18:57:33.542530: Current learning rate: 0.00968 
2025-01-25 18:58:03.300884: train_loss -0.7117 
2025-01-25 18:58:03.307950: val_loss -0.6929 
2025-01-25 18:58:03.310366: Pseudo dice [np.float32(0.935), np.float32(0.7606)] 
2025-01-25 18:58:03.313051: Epoch time: 29.76 s 
2025-01-25 18:58:03.315371: Yayy! New best EMA pseudo Dice: 0.8133000135421753 
2025-01-25 18:58:05.103772:  
2025-01-25 18:58:05.106228: Epoch 36 
2025-01-25 18:58:05.108446: Current learning rate: 0.00968 
2025-01-25 18:58:34.509398: train_loss -0.7138 
2025-01-25 18:58:34.515795: val_loss -0.6429 
2025-01-25 18:58:34.518162: Pseudo dice [np.float32(0.9277), np.float32(0.7838)] 
2025-01-25 18:58:34.520413: Epoch time: 29.41 s 
2025-01-25 18:58:34.522691: Yayy! New best EMA pseudo Dice: 0.8174999952316284 
2025-01-25 18:58:36.505707:  
2025-01-25 18:58:36.509271: Epoch 37 
2025-01-25 18:58:36.511819: Current learning rate: 0.00967 
2025-01-25 18:59:07.150556: train_loss -0.7131 
2025-01-25 18:59:07.157785: val_loss -0.7177 
2025-01-25 18:59:07.160301: Pseudo dice [np.float32(0.9332), np.float32(0.8342)] 
2025-01-25 18:59:07.162644: Epoch time: 30.65 s 
2025-01-25 18:59:07.165428: Yayy! New best EMA pseudo Dice: 0.8241000175476074 
2025-01-25 18:59:08.781276:  
2025-01-25 18:59:08.783991: Epoch 38 
2025-01-25 18:59:08.786391: Current learning rate: 0.00966 
2025-01-25 18:59:38.439185: train_loss -0.724 
2025-01-25 18:59:38.445392: val_loss -0.6839 
2025-01-25 18:59:38.447652: Pseudo dice [np.float32(0.9288), np.float32(0.7465)] 
2025-01-25 18:59:38.449786: Epoch time: 29.66 s 
2025-01-25 18:59:38.452072: Yayy! New best EMA pseudo Dice: 0.8255000114440918 
2025-01-25 18:59:40.211650:  
2025-01-25 18:59:40.214612: Epoch 39 
2025-01-25 18:59:40.217044: Current learning rate: 0.00965 
2025-01-25 19:00:10.267786: train_loss -0.7256 
2025-01-25 19:00:10.274848: val_loss -0.6973 
2025-01-25 19:00:10.277449: Pseudo dice [np.float32(0.9344), np.float32(0.8206)] 
2025-01-25 19:00:10.279970: Epoch time: 30.06 s 
2025-01-25 19:00:10.282589: Yayy! New best EMA pseudo Dice: 0.8306999802589417 
2025-01-25 19:00:12.059127:  
2025-01-25 19:00:12.061553: Epoch 40 
2025-01-25 19:00:12.064281: Current learning rate: 0.00964 
2025-01-25 19:00:41.121921: train_loss -0.7494 
2025-01-25 19:00:41.128428: val_loss -0.7221 
2025-01-25 19:00:41.131027: Pseudo dice [np.float32(0.9469), np.float32(0.8139)] 
2025-01-25 19:00:41.133407: Epoch time: 29.06 s 
2025-01-25 19:00:41.135836: Yayy! New best EMA pseudo Dice: 0.8356999754905701 
2025-01-25 19:00:42.710090:  
2025-01-25 19:00:42.712571: Epoch 41 
2025-01-25 19:00:42.715085: Current learning rate: 0.00963 
2025-01-25 19:01:11.330294: train_loss -0.7372 
2025-01-25 19:01:11.336097: val_loss -0.7049 
2025-01-25 19:01:11.338697: Pseudo dice [np.float32(0.9465), np.float32(0.8365)] 
2025-01-25 19:01:11.341421: Epoch time: 28.62 s 
2025-01-25 19:01:11.344023: Yayy! New best EMA pseudo Dice: 0.8411999940872192 
2025-01-25 19:01:12.833284:  
2025-01-25 19:01:12.835785: Epoch 42 
2025-01-25 19:01:12.838248: Current learning rate: 0.00962 
2025-01-25 19:01:41.505674: train_loss -0.7306 
2025-01-25 19:01:41.512530: val_loss -0.737 
2025-01-25 19:01:41.515372: Pseudo dice [np.float32(0.9384), np.float32(0.843)] 
2025-01-25 19:01:41.517620: Epoch time: 28.67 s 
2025-01-25 19:01:41.519863: Yayy! New best EMA pseudo Dice: 0.8461999893188477 
2025-01-25 19:01:42.997945:  
2025-01-25 19:01:43.000796: Epoch 43 
2025-01-25 19:01:43.003384: Current learning rate: 0.00961 
2025-01-25 19:02:14.050611: train_loss -0.7136 
2025-01-25 19:02:14.055802: val_loss -0.6981 
2025-01-25 19:02:14.058311: Pseudo dice [np.float32(0.9333), np.float32(0.7905)] 
2025-01-25 19:02:14.061150: Epoch time: 31.05 s 
2025-01-25 19:02:14.063879: Yayy! New best EMA pseudo Dice: 0.8478000164031982 
2025-01-25 19:02:15.602593:  
2025-01-25 19:02:15.604918: Epoch 44 
2025-01-25 19:02:15.607215: Current learning rate: 0.0096 
2025-01-25 19:02:46.061142: train_loss -0.7358 
2025-01-25 19:02:46.067254: val_loss -0.6985 
2025-01-25 19:02:46.069534: Pseudo dice [np.float32(0.9276), np.float32(0.818)] 
2025-01-25 19:02:46.071764: Epoch time: 30.46 s 
2025-01-25 19:02:46.074103: Yayy! New best EMA pseudo Dice: 0.8503000140190125 
2025-01-25 19:02:47.670605:  
2025-01-25 19:02:47.673150: Epoch 45 
2025-01-25 19:02:47.675369: Current learning rate: 0.00959 
2025-01-25 19:03:16.558106: train_loss -0.7343 
2025-01-25 19:03:16.563154: val_loss -0.7212 
2025-01-25 19:03:16.565529: Pseudo dice [np.float32(0.9375), np.float32(0.8082)] 
2025-01-25 19:03:16.567986: Epoch time: 28.89 s 
2025-01-25 19:03:16.570047: Yayy! New best EMA pseudo Dice: 0.8525000214576721 
2025-01-25 19:03:18.097650:  
2025-01-25 19:03:18.100014: Epoch 46 
2025-01-25 19:03:18.102588: Current learning rate: 0.00959 
2025-01-25 19:03:47.881064: train_loss -0.7322 
2025-01-25 19:03:47.887486: val_loss -0.7165 
2025-01-25 19:03:47.889994: Pseudo dice [np.float32(0.9338), np.float32(0.7791)] 
2025-01-25 19:03:47.892578: Epoch time: 29.78 s 
2025-01-25 19:03:47.895176: Yayy! New best EMA pseudo Dice: 0.8529000282287598 
2025-01-25 19:03:49.492230:  
2025-01-25 19:03:49.494636: Epoch 47 
2025-01-25 19:03:49.496917: Current learning rate: 0.00958 
2025-01-25 19:04:18.591956: train_loss -0.7413 
2025-01-25 19:04:18.598760: val_loss -0.6692 
2025-01-25 19:04:18.601305: Pseudo dice [np.float32(0.9343), np.float32(0.8015)] 
2025-01-25 19:04:18.603555: Epoch time: 29.1 s 
2025-01-25 19:04:18.605739: Yayy! New best EMA pseudo Dice: 0.8543999791145325 
2025-01-25 19:04:20.139701:  
2025-01-25 19:04:20.141969: Epoch 48 
2025-01-25 19:04:20.144408: Current learning rate: 0.00957 
2025-01-25 19:04:49.384306: train_loss -0.7317 
2025-01-25 19:04:49.391404: val_loss -0.6993 
2025-01-25 19:04:49.393638: Pseudo dice [np.float32(0.9365), np.float32(0.811)] 
2025-01-25 19:04:49.395972: Epoch time: 29.25 s 
2025-01-25 19:04:49.398335: Yayy! New best EMA pseudo Dice: 0.8562999963760376 
2025-01-25 19:04:51.014378:  
2025-01-25 19:04:51.016731: Epoch 49 
2025-01-25 19:04:51.019138: Current learning rate: 0.00956 
2025-01-25 19:05:20.552053: train_loss -0.7112 
2025-01-25 19:05:20.556742: val_loss -0.6958 
2025-01-25 19:05:20.559041: Pseudo dice [np.float32(0.9367), np.float32(0.8466)] 
2025-01-25 19:05:20.561348: Epoch time: 29.54 s 
2025-01-25 19:05:20.991323: Yayy! New best EMA pseudo Dice: 0.8598999977111816 
2025-01-25 19:05:22.467505:  
2025-01-25 19:05:22.470222: Epoch 50 
2025-01-25 19:05:22.472658: Current learning rate: 0.00955 
2025-01-25 19:05:51.684363: train_loss -0.7217 
2025-01-25 19:05:51.689997: val_loss -0.7198 
2025-01-25 19:05:51.692672: Pseudo dice [np.float32(0.9337), np.float32(0.8138)] 
2025-01-25 19:05:51.695299: Epoch time: 29.22 s 
2025-01-25 19:05:51.697643: Yayy! New best EMA pseudo Dice: 0.861299991607666 
2025-01-25 19:05:53.200596:  
2025-01-25 19:05:53.203592: Epoch 51 
2025-01-25 19:05:53.205892: Current learning rate: 0.00954 
2025-01-25 19:06:23.007421: train_loss -0.73 
2025-01-25 19:06:23.011797: val_loss -0.7338 
2025-01-25 19:06:23.013916: Pseudo dice [np.float32(0.9371), np.float32(0.8158)] 
2025-01-25 19:06:23.016131: Epoch time: 29.81 s 
2025-01-25 19:06:23.018254: Yayy! New best EMA pseudo Dice: 0.8628000020980835 
2025-01-25 19:06:24.516409:  
2025-01-25 19:06:24.518939: Epoch 52 
2025-01-25 19:06:24.521400: Current learning rate: 0.00953 
2025-01-25 19:06:55.102946: train_loss -0.7546 
2025-01-25 19:06:55.108010: val_loss -0.7022 
2025-01-25 19:06:55.110311: Pseudo dice [np.float32(0.9442), np.float32(0.8333)] 
2025-01-25 19:06:55.112676: Epoch time: 30.59 s 
2025-01-25 19:06:55.115052: Yayy! New best EMA pseudo Dice: 0.8654000163078308 
2025-01-25 19:06:56.617126:  
2025-01-25 19:06:56.619506: Epoch 53 
2025-01-25 19:06:56.621610: Current learning rate: 0.00952 
2025-01-25 19:07:26.176467: train_loss -0.7532 
2025-01-25 19:07:26.183336: val_loss -0.7008 
2025-01-25 19:07:26.185841: Pseudo dice [np.float32(0.9466), np.float32(0.8078)] 
2025-01-25 19:07:26.188317: Epoch time: 29.56 s 
2025-01-25 19:07:26.190756: Yayy! New best EMA pseudo Dice: 0.866599977016449 
2025-01-25 19:07:27.779884:  
2025-01-25 19:07:27.782610: Epoch 54 
2025-01-25 19:07:27.785102: Current learning rate: 0.00951 
2025-01-25 19:08:00.360353: train_loss -0.7333 
2025-01-25 19:08:00.367816: val_loss -0.7105 
2025-01-25 19:08:00.370297: Pseudo dice [np.float32(0.94), np.float32(0.7752)] 
2025-01-25 19:08:00.372664: Epoch time: 32.58 s 
2025-01-25 19:08:02.087674:  
2025-01-25 19:08:02.089993: Epoch 55 
2025-01-25 19:08:02.092135: Current learning rate: 0.0095 
2025-01-25 19:08:32.446058: train_loss -0.7437 
2025-01-25 19:08:32.450629: val_loss -0.7314 
2025-01-25 19:08:32.452729: Pseudo dice [np.float32(0.9139), np.float32(0.7762)] 
2025-01-25 19:08:32.454825: Epoch time: 30.36 s 
2025-01-25 19:08:33.483039:  
2025-01-25 19:08:33.485450: Epoch 56 
2025-01-25 19:08:33.488019: Current learning rate: 0.00949 
2025-01-25 19:09:05.309147: train_loss -0.743 
2025-01-25 19:09:05.316447: val_loss -0.7254 
2025-01-25 19:09:05.318829: Pseudo dice [np.float32(0.9523), np.float32(0.7691)] 
2025-01-25 19:09:05.321005: Epoch time: 31.83 s 
2025-01-25 19:09:06.375620:  
2025-01-25 19:09:06.378524: Epoch 57 
2025-01-25 19:09:06.381057: Current learning rate: 0.00949 
2025-01-25 19:09:35.620236: train_loss -0.7355 
2025-01-25 19:09:35.625037: val_loss -0.7288 
2025-01-25 19:09:35.627445: Pseudo dice [np.float32(0.9475), np.float32(0.7754)] 
2025-01-25 19:09:35.629761: Epoch time: 29.25 s 
2025-01-25 19:09:36.649879:  
2025-01-25 19:09:36.652436: Epoch 58 
2025-01-25 19:09:36.654681: Current learning rate: 0.00948 
2025-01-25 19:10:07.040470: train_loss -0.761 
2025-01-25 19:10:07.045347: val_loss -0.7062 
2025-01-25 19:10:07.047526: Pseudo dice [np.float32(0.9377), np.float32(0.8197)] 
2025-01-25 19:10:07.049713: Epoch time: 30.39 s 
2025-01-25 19:10:08.091916:  
2025-01-25 19:10:08.094356: Epoch 59 
2025-01-25 19:10:08.096615: Current learning rate: 0.00947 
2025-01-25 19:10:37.617338: train_loss -0.7623 
2025-01-25 19:10:37.622269: val_loss -0.7358 
2025-01-25 19:10:37.624688: Pseudo dice [np.float32(0.9439), np.float32(0.7129)] 
2025-01-25 19:10:37.627185: Epoch time: 29.53 s 
2025-01-25 19:10:38.670744:  
2025-01-25 19:10:38.673665: Epoch 60 
2025-01-25 19:10:38.676402: Current learning rate: 0.00946 
2025-01-25 19:11:08.759581: train_loss -0.7555 
2025-01-25 19:11:08.765139: val_loss -0.7405 
2025-01-25 19:11:08.767442: Pseudo dice [np.float32(0.9526), np.float32(0.8033)] 
2025-01-25 19:11:08.769842: Epoch time: 30.09 s 
2025-01-25 19:11:09.814011:  
2025-01-25 19:11:09.816298: Epoch 61 
2025-01-25 19:11:09.818622: Current learning rate: 0.00945 
2025-01-25 19:11:39.231895: train_loss -0.7803 
2025-01-25 19:11:39.235363: val_loss -0.7169 
2025-01-25 19:11:39.237651: Pseudo dice [np.float32(0.9303), np.float32(0.8304)] 
2025-01-25 19:11:39.239985: Epoch time: 29.42 s 
2025-01-25 19:11:40.273059:  
2025-01-25 19:11:40.275781: Epoch 62 
2025-01-25 19:11:40.278382: Current learning rate: 0.00944 
2025-01-25 19:12:09.038318: train_loss -0.7729 
2025-01-25 19:12:09.043531: val_loss -0.733 
2025-01-25 19:12:09.045923: Pseudo dice [np.float32(0.9432), np.float32(0.8177)] 
2025-01-25 19:12:09.048594: Epoch time: 28.77 s 
2025-01-25 19:12:10.109278:  
2025-01-25 19:12:10.111889: Epoch 63 
2025-01-25 19:12:10.114388: Current learning rate: 0.00943 
2025-01-25 19:12:40.688018: train_loss -0.7739 
2025-01-25 19:12:40.694053: val_loss -0.7625 
2025-01-25 19:12:40.696546: Pseudo dice [np.float32(0.9446), np.float32(0.8121)] 
2025-01-25 19:12:40.699459: Epoch time: 30.58 s 
2025-01-25 19:12:40.701824: Yayy! New best EMA pseudo Dice: 0.8672999739646912 
2025-01-25 19:12:42.456686:  
2025-01-25 19:12:42.459029: Epoch 64 
2025-01-25 19:12:42.461141: Current learning rate: 0.00942 
2025-01-25 19:13:12.973994: train_loss -0.767 
2025-01-25 19:13:12.979672: val_loss -0.6905 
2025-01-25 19:13:12.981895: Pseudo dice [np.float32(0.9317), np.float32(0.7436)] 
2025-01-25 19:13:12.984402: Epoch time: 30.52 s 
2025-01-25 19:13:14.026253:  
2025-01-25 19:13:14.028702: Epoch 65 
2025-01-25 19:13:14.031255: Current learning rate: 0.00941 
2025-01-25 19:13:45.908051: train_loss -0.7515 
2025-01-25 19:13:45.916237: val_loss -0.7422 
2025-01-25 19:13:45.918712: Pseudo dice [np.float32(0.9411), np.float32(0.8595)] 
2025-01-25 19:13:45.921250: Epoch time: 31.88 s 
2025-01-25 19:13:45.923882: Yayy! New best EMA pseudo Dice: 0.8679999709129333 
2025-01-25 19:13:47.505729:  
2025-01-25 19:13:47.508071: Epoch 66 
2025-01-25 19:13:47.510445: Current learning rate: 0.0094 
2025-01-25 19:14:17.854912: train_loss -0.756 
2025-01-25 19:14:17.864207: val_loss -0.7708 
2025-01-25 19:14:17.866729: Pseudo dice [np.float32(0.9479), np.float32(0.8479)] 
2025-01-25 19:14:17.869120: Epoch time: 30.35 s 
2025-01-25 19:14:17.871563: Yayy! New best EMA pseudo Dice: 0.8708999752998352 
2025-01-25 19:14:19.679118:  
2025-01-25 19:14:19.681571: Epoch 67 
2025-01-25 19:14:19.684103: Current learning rate: 0.00939 
2025-01-25 19:14:48.881721: train_loss -0.7524 
2025-01-25 19:14:48.892278: val_loss -0.7576 
2025-01-25 19:14:48.894903: Pseudo dice [np.float32(0.936), np.float32(0.8197)] 
2025-01-25 19:14:48.897480: Epoch time: 29.2 s 
2025-01-25 19:14:48.899846: Yayy! New best EMA pseudo Dice: 0.8715999722480774 
2025-01-25 19:14:50.555709:  
2025-01-25 19:14:50.558028: Epoch 68 
2025-01-25 19:14:50.560214: Current learning rate: 0.00939 
2025-01-25 19:15:20.074405: train_loss -0.7565 
2025-01-25 19:15:20.079663: val_loss -0.7269 
2025-01-25 19:15:20.081929: Pseudo dice [np.float32(0.9479), np.float32(0.8548)] 
2025-01-25 19:15:20.084140: Epoch time: 29.52 s 
2025-01-25 19:15:20.086306: Yayy! New best EMA pseudo Dice: 0.8745999932289124 
2025-01-25 19:15:21.601356:  
2025-01-25 19:15:21.604485: Epoch 69 
2025-01-25 19:15:21.606980: Current learning rate: 0.00938 
2025-01-25 19:15:52.137098: train_loss -0.7867 
2025-01-25 19:15:52.142720: val_loss -0.7245 
2025-01-25 19:15:52.145321: Pseudo dice [np.float32(0.9425), np.float32(0.8592)] 
2025-01-25 19:15:52.147647: Epoch time: 30.54 s 
2025-01-25 19:15:52.149993: Yayy! New best EMA pseudo Dice: 0.8772000074386597 
2025-01-25 19:15:53.736446:  
2025-01-25 19:15:53.739182: Epoch 70 
2025-01-25 19:15:53.741698: Current learning rate: 0.00937 
2025-01-25 19:16:22.504657: train_loss -0.7645 
2025-01-25 19:16:22.510338: val_loss -0.7682 
2025-01-25 19:16:22.512848: Pseudo dice [np.float32(0.9319), np.float32(0.7847)] 
2025-01-25 19:16:22.515290: Epoch time: 28.77 s 
2025-01-25 19:16:23.565878:  
2025-01-25 19:16:23.568488: Epoch 71 
2025-01-25 19:16:23.570715: Current learning rate: 0.00936 
2025-01-25 19:16:52.323500: train_loss -0.7752 
2025-01-25 19:16:52.328387: val_loss -0.7421 
2025-01-25 19:16:52.330903: Pseudo dice [np.float32(0.9502), np.float32(0.8352)] 
2025-01-25 19:16:52.333331: Epoch time: 28.76 s 
2025-01-25 19:16:53.385979:  
2025-01-25 19:16:53.388830: Epoch 72 
2025-01-25 19:16:53.391264: Current learning rate: 0.00935 
2025-01-25 19:17:22.958806: train_loss -0.7805 
2025-01-25 19:17:22.964006: val_loss -0.7174 
2025-01-25 19:17:22.966489: Pseudo dice [np.float32(0.9436), np.float32(0.7753)] 
2025-01-25 19:17:22.968865: Epoch time: 29.57 s 
2025-01-25 19:17:24.469106:  
2025-01-25 19:17:24.471681: Epoch 73 
2025-01-25 19:17:24.473956: Current learning rate: 0.00934 
2025-01-25 19:17:53.338774: train_loss -0.7609 
2025-01-25 19:17:53.344678: val_loss -0.7334 
2025-01-25 19:17:53.347203: Pseudo dice [np.float32(0.9362), np.float32(0.7461)] 
2025-01-25 19:17:53.349493: Epoch time: 28.87 s 
2025-01-25 19:17:54.404650:  
2025-01-25 19:17:54.407159: Epoch 74 
2025-01-25 19:17:54.409370: Current learning rate: 0.00933 
2025-01-25 19:18:24.452998: train_loss -0.7663 
2025-01-25 19:18:24.458858: val_loss -0.7266 
2025-01-25 19:18:24.461486: Pseudo dice [np.float32(0.9371), np.float32(0.776)] 
2025-01-25 19:18:24.463965: Epoch time: 30.05 s 
2025-01-25 19:18:25.532552:  
2025-01-25 19:18:25.534974: Epoch 75 
2025-01-25 19:18:25.537126: Current learning rate: 0.00932 
2025-01-25 19:18:54.952501: train_loss -0.7863 
2025-01-25 19:18:54.957947: val_loss -0.7655 
2025-01-25 19:18:54.960437: Pseudo dice [np.float32(0.9494), np.float32(0.8685)] 
2025-01-25 19:18:54.962836: Epoch time: 29.42 s 
2025-01-25 19:18:56.027168:  
2025-01-25 19:18:56.029863: Epoch 76 
2025-01-25 19:18:56.032393: Current learning rate: 0.00931 
2025-01-25 19:19:25.842455: train_loss -0.7844 
2025-01-25 19:19:25.847084: val_loss -0.6862 
2025-01-25 19:19:25.849417: Pseudo dice [np.float32(0.9399), np.float32(0.7637)] 
2025-01-25 19:19:25.851646: Epoch time: 29.82 s 
2025-01-25 19:19:26.916250:  
2025-01-25 19:19:26.918692: Epoch 77 
2025-01-25 19:19:26.921040: Current learning rate: 0.0093 
2025-01-25 19:19:56.381701: train_loss -0.7398 
2025-01-25 19:19:56.388688: val_loss -0.7189 
2025-01-25 19:19:56.391227: Pseudo dice [np.float32(0.9476), np.float32(0.8507)] 
2025-01-25 19:19:56.393512: Epoch time: 29.47 s 
2025-01-25 19:19:57.604483:  
2025-01-25 19:19:57.606699: Epoch 78 
2025-01-25 19:19:57.609069: Current learning rate: 0.0093 
2025-01-25 19:20:26.170579: train_loss -0.7845 
2025-01-25 19:20:26.175538: val_loss -0.747 
2025-01-25 19:20:26.178064: Pseudo dice [np.float32(0.9461), np.float32(0.8431)] 
2025-01-25 19:20:26.180595: Epoch time: 28.57 s 
2025-01-25 19:20:27.272714:  
2025-01-25 19:20:27.275193: Epoch 79 
2025-01-25 19:20:27.277555: Current learning rate: 0.00929 
2025-01-25 19:20:55.351539: train_loss -0.7675 
2025-01-25 19:20:55.354473: val_loss -0.748 
2025-01-25 19:20:55.356687: Pseudo dice [np.float32(0.9507), np.float32(0.8288)] 
2025-01-25 19:20:55.359147: Epoch time: 28.08 s 
2025-01-25 19:20:55.361853: Yayy! New best EMA pseudo Dice: 0.878000020980835 
2025-01-25 19:20:56.951926:  
2025-01-25 19:20:56.955176: Epoch 80 
2025-01-25 19:20:56.957484: Current learning rate: 0.00928 
2025-01-25 19:21:27.111936: train_loss -0.7799 
2025-01-25 19:21:27.116347: val_loss -0.7449 
2025-01-25 19:21:27.118545: Pseudo dice [np.float32(0.9445), np.float32(0.8511)] 
2025-01-25 19:21:27.120695: Epoch time: 30.16 s 
2025-01-25 19:21:27.122946: Yayy! New best EMA pseudo Dice: 0.8799999952316284 
2025-01-25 19:21:28.734162:  
2025-01-25 19:21:28.736701: Epoch 81 
2025-01-25 19:21:28.738993: Current learning rate: 0.00927 
2025-01-25 19:21:59.531772: train_loss -0.7656 
2025-01-25 19:21:59.535270: val_loss -0.7802 
2025-01-25 19:21:59.537575: Pseudo dice [np.float32(0.9539), np.float32(0.8763)] 
2025-01-25 19:21:59.539836: Epoch time: 30.8 s 
2025-01-25 19:21:59.542082: Yayy! New best EMA pseudo Dice: 0.8834999799728394 
2025-01-25 19:22:01.134458:  
2025-01-25 19:22:01.136930: Epoch 82 
2025-01-25 19:22:01.139264: Current learning rate: 0.00926 
2025-01-25 19:22:32.736054: train_loss -0.7647 
2025-01-25 19:22:32.741037: val_loss -0.7412 
2025-01-25 19:22:32.743415: Pseudo dice [np.float32(0.95), np.float32(0.8336)] 
2025-01-25 19:22:32.745939: Epoch time: 31.6 s 
2025-01-25 19:22:32.748024: Yayy! New best EMA pseudo Dice: 0.8842999935150146 
2025-01-25 19:22:34.259388:  
2025-01-25 19:22:34.262131: Epoch 83 
2025-01-25 19:22:34.264598: Current learning rate: 0.00925 
2025-01-25 19:23:05.592032: train_loss -0.7644 
2025-01-25 19:23:05.597457: val_loss -0.7488 
2025-01-25 19:23:05.600058: Pseudo dice [np.float32(0.9451), np.float32(0.8678)] 
2025-01-25 19:23:05.602494: Epoch time: 31.33 s 
2025-01-25 19:23:05.604909: Yayy! New best EMA pseudo Dice: 0.8865000009536743 
2025-01-25 19:23:07.099745:  
2025-01-25 19:23:07.102390: Epoch 84 
2025-01-25 19:23:07.104835: Current learning rate: 0.00924 
2025-01-25 19:23:36.779320: train_loss -0.7825 
2025-01-25 19:23:36.784675: val_loss -0.7375 
2025-01-25 19:23:36.787507: Pseudo dice [np.float32(0.9428), np.float32(0.84)] 
2025-01-25 19:23:36.790140: Epoch time: 29.68 s 
2025-01-25 19:23:36.792441: Yayy! New best EMA pseudo Dice: 0.8870000243186951 
2025-01-25 19:23:38.359031:  
2025-01-25 19:23:38.361680: Epoch 85 
2025-01-25 19:23:38.364200: Current learning rate: 0.00923 
2025-01-25 19:24:07.230442: train_loss -0.7663 
2025-01-25 19:24:07.233963: val_loss -0.7444 
2025-01-25 19:24:07.236383: Pseudo dice [np.float32(0.9509), np.float32(0.8479)] 
2025-01-25 19:24:07.238987: Epoch time: 28.87 s 
2025-01-25 19:24:07.241733: Yayy! New best EMA pseudo Dice: 0.8883000016212463 
2025-01-25 19:24:08.769984:  
2025-01-25 19:24:08.772871: Epoch 86 
2025-01-25 19:24:08.775682: Current learning rate: 0.00922 
2025-01-25 19:24:38.574032: train_loss -0.7755 
2025-01-25 19:24:38.579036: val_loss -0.7059 
2025-01-25 19:24:38.581479: Pseudo dice [np.float32(0.9322), np.float32(0.7985)] 
2025-01-25 19:24:38.583901: Epoch time: 29.8 s 
2025-01-25 19:24:39.599044:  
2025-01-25 19:24:39.601294: Epoch 87 
2025-01-25 19:24:39.603631: Current learning rate: 0.00921 
2025-01-25 19:25:08.376351: train_loss -0.7828 
2025-01-25 19:25:08.379976: val_loss -0.7244 
2025-01-25 19:25:08.382441: Pseudo dice [np.float32(0.9369), np.float32(0.8318)] 
2025-01-25 19:25:08.384694: Epoch time: 28.78 s 
2025-01-25 19:25:09.401325:  
2025-01-25 19:25:09.403472: Epoch 88 
2025-01-25 19:25:09.405725: Current learning rate: 0.0092 
2025-01-25 19:25:38.977626: train_loss -0.7836 
2025-01-25 19:25:38.982801: val_loss -0.732 
2025-01-25 19:25:38.985134: Pseudo dice [np.float32(0.943), np.float32(0.7868)] 
2025-01-25 19:25:38.987421: Epoch time: 29.58 s 
2025-01-25 19:25:39.999439:  
2025-01-25 19:25:40.001672: Epoch 89 
2025-01-25 19:25:40.003693: Current learning rate: 0.0092 
2025-01-25 19:26:09.870103: train_loss -0.7822 
2025-01-25 19:26:09.875980: val_loss -0.771 
2025-01-25 19:26:09.878641: Pseudo dice [np.float32(0.9471), np.float32(0.8447)] 
2025-01-25 19:26:09.880989: Epoch time: 29.87 s 
2025-01-25 19:26:10.932771:  
2025-01-25 19:26:10.935288: Epoch 90 
2025-01-25 19:26:10.937631: Current learning rate: 0.00919 
2025-01-25 19:26:39.654145: train_loss -0.7854 
2025-01-25 19:26:39.659542: val_loss -0.7415 
2025-01-25 19:26:39.661682: Pseudo dice [np.float32(0.9488), np.float32(0.853)] 
2025-01-25 19:26:39.663979: Epoch time: 28.72 s 
2025-01-25 19:26:41.167521:  
2025-01-25 19:26:41.169869: Epoch 91 
2025-01-25 19:26:41.172201: Current learning rate: 0.00918 
2025-01-25 19:27:09.980590: train_loss -0.7845 
2025-01-25 19:27:09.985276: val_loss -0.7398 
2025-01-25 19:27:09.987742: Pseudo dice [np.float32(0.9513), np.float32(0.8075)] 
2025-01-25 19:27:09.990195: Epoch time: 28.81 s 
2025-01-25 19:27:10.998982:  
2025-01-25 19:27:11.001355: Epoch 92 
2025-01-25 19:27:11.003638: Current learning rate: 0.00917 
2025-01-25 19:27:40.361796: train_loss -0.7903 
2025-01-25 19:27:40.373048: val_loss -0.7182 
2025-01-25 19:27:40.375595: Pseudo dice [np.float32(0.9516), np.float32(0.8705)] 
2025-01-25 19:27:40.378002: Epoch time: 29.36 s 
2025-01-25 19:27:40.380279: Yayy! New best EMA pseudo Dice: 0.8883000016212463 
2025-01-25 19:27:41.875135:  
2025-01-25 19:27:41.877692: Epoch 93 
2025-01-25 19:27:41.880048: Current learning rate: 0.00916 
2025-01-25 19:28:10.881750: train_loss -0.7967 
2025-01-25 19:28:10.890110: val_loss -0.7467 
2025-01-25 19:28:10.892797: Pseudo dice [np.float32(0.9521), np.float32(0.8456)] 
2025-01-25 19:28:10.895364: Epoch time: 29.01 s 
2025-01-25 19:28:10.897727: Yayy! New best EMA pseudo Dice: 0.8894000053405762 
2025-01-25 19:28:12.392673:  
2025-01-25 19:28:12.395246: Epoch 94 
2025-01-25 19:28:12.397680: Current learning rate: 0.00915 
2025-01-25 19:28:42.191664: train_loss -0.7843 
2025-01-25 19:28:42.203028: val_loss -0.7546 
2025-01-25 19:28:42.206514: Pseudo dice [np.float32(0.9429), np.float32(0.8137)] 
2025-01-25 19:28:42.211051: Epoch time: 29.8 s 
2025-01-25 19:28:43.256490:  
2025-01-25 19:28:43.258959: Epoch 95 
2025-01-25 19:28:43.261405: Current learning rate: 0.00914 
2025-01-25 19:29:13.133837: train_loss -0.7867 
2025-01-25 19:29:13.137834: val_loss -0.7278 
2025-01-25 19:29:13.140321: Pseudo dice [np.float32(0.9496), np.float32(0.8607)] 
2025-01-25 19:29:13.142866: Epoch time: 29.88 s 
2025-01-25 19:29:13.145209: Yayy! New best EMA pseudo Dice: 0.8899999856948853 
2025-01-25 19:29:14.720480:  
2025-01-25 19:29:14.722871: Epoch 96 
2025-01-25 19:29:14.725679: Current learning rate: 0.00913 
2025-01-25 19:29:43.024689: train_loss -0.7729 
2025-01-25 19:29:43.030444: val_loss -0.7562 
2025-01-25 19:29:43.032889: Pseudo dice [np.float32(0.9506), np.float32(0.8188)] 
2025-01-25 19:29:43.035765: Epoch time: 28.31 s 
2025-01-25 19:29:44.048661:  
2025-01-25 19:29:44.051086: Epoch 97 
2025-01-25 19:29:44.053243: Current learning rate: 0.00912 
2025-01-25 19:30:12.850845: train_loss -0.7527 
2025-01-25 19:30:12.856218: val_loss -0.7283 
2025-01-25 19:30:12.858287: Pseudo dice [np.float32(0.9294), np.float32(0.8253)] 
2025-01-25 19:30:12.860656: Epoch time: 28.8 s 
2025-01-25 19:30:13.884081:  
2025-01-25 19:30:13.886310: Epoch 98 
2025-01-25 19:30:13.888449: Current learning rate: 0.00911 
2025-01-25 19:30:43.275815: train_loss -0.7342 
2025-01-25 19:30:43.283258: val_loss -0.7128 
2025-01-25 19:30:43.285640: Pseudo dice [np.float32(0.928), np.float32(0.8273)] 
2025-01-25 19:30:43.288032: Epoch time: 29.39 s 
2025-01-25 19:30:44.350382:  
2025-01-25 19:30:44.352621: Epoch 99 
2025-01-25 19:30:44.354938: Current learning rate: 0.0091 
2025-01-25 19:31:13.273480: train_loss -0.7561 
2025-01-25 19:31:13.277965: val_loss -0.749 
2025-01-25 19:31:13.280199: Pseudo dice [np.float32(0.9377), np.float32(0.8034)] 
2025-01-25 19:31:13.282085: Epoch time: 28.92 s 
2025-01-25 19:31:14.746960:  
2025-01-25 19:31:14.749513: Epoch 100 
2025-01-25 19:31:14.751995: Current learning rate: 0.0091 
2025-01-25 19:31:44.562291: train_loss -0.7641 
2025-01-25 19:31:44.569050: val_loss -0.7048 
2025-01-25 19:31:44.571518: Pseudo dice [np.float32(0.9511), np.float32(0.817)] 
2025-01-25 19:31:44.573823: Epoch time: 29.82 s 
2025-01-25 19:31:45.753661:  
2025-01-25 19:31:45.755988: Epoch 101 
2025-01-25 19:31:45.758286: Current learning rate: 0.00909 
2025-01-25 19:32:15.324147: train_loss -0.7852 
2025-01-25 19:32:15.331490: val_loss -0.7626 
2025-01-25 19:32:15.333859: Pseudo dice [np.float32(0.9436), np.float32(0.8536)] 
2025-01-25 19:32:15.336379: Epoch time: 29.57 s 
2025-01-25 19:32:16.368870:  
2025-01-25 19:32:16.371392: Epoch 102 
2025-01-25 19:32:16.373718: Current learning rate: 0.00908 
2025-01-25 19:32:45.839393: train_loss -0.7806 
2025-01-25 19:32:45.844595: val_loss -0.7482 
2025-01-25 19:32:45.846801: Pseudo dice [np.float32(0.951), np.float32(0.8803)] 
2025-01-25 19:32:45.848956: Epoch time: 29.47 s 
2025-01-25 19:32:46.866344:  
2025-01-25 19:32:46.869081: Epoch 103 
2025-01-25 19:32:46.872030: Current learning rate: 0.00907 
2025-01-25 19:33:16.542337: train_loss -0.7794 
2025-01-25 19:33:16.551151: val_loss -0.7756 
2025-01-25 19:33:16.553916: Pseudo dice [np.float32(0.9498), np.float32(0.8826)] 
2025-01-25 19:33:16.556715: Epoch time: 29.68 s 
2025-01-25 19:33:16.559217: Yayy! New best EMA pseudo Dice: 0.892300009727478 
2025-01-25 19:33:18.113313:  
2025-01-25 19:33:18.115690: Epoch 104 
2025-01-25 19:33:18.118024: Current learning rate: 0.00906 
2025-01-25 19:33:47.761625: train_loss -0.7848 
2025-01-25 19:33:47.766893: val_loss -0.7371 
2025-01-25 19:33:47.769205: Pseudo dice [np.float32(0.953), np.float32(0.8709)] 
2025-01-25 19:33:47.771408: Epoch time: 29.65 s 
2025-01-25 19:33:47.773633: Yayy! New best EMA pseudo Dice: 0.8942000269889832 
2025-01-25 19:33:49.316095:  
2025-01-25 19:33:49.318723: Epoch 105 
2025-01-25 19:33:49.321009: Current learning rate: 0.00905 
2025-01-25 19:34:19.280874: train_loss -0.7746 
2025-01-25 19:34:19.287822: val_loss -0.7452 
2025-01-25 19:34:19.290237: Pseudo dice [np.float32(0.9401), np.float32(0.7579)] 
2025-01-25 19:34:19.292675: Epoch time: 29.97 s 
2025-01-25 19:34:20.313871:  
2025-01-25 19:34:20.316896: Epoch 106 
2025-01-25 19:34:20.319587: Current learning rate: 0.00904 
2025-01-25 19:34:50.527420: train_loss -0.7686 
2025-01-25 19:34:50.536012: val_loss -0.7269 
2025-01-25 19:34:50.538733: Pseudo dice [np.float32(0.9424), np.float32(0.8599)] 
2025-01-25 19:34:50.541173: Epoch time: 30.21 s 
2025-01-25 19:34:51.579663:  
2025-01-25 19:34:51.582290: Epoch 107 
2025-01-25 19:34:51.584817: Current learning rate: 0.00903 
2025-01-25 19:35:21.294864: train_loss -0.7713 
2025-01-25 19:35:21.300727: val_loss -0.7722 
2025-01-25 19:35:21.303467: Pseudo dice [np.float32(0.9519), np.float32(0.8286)] 
2025-01-25 19:35:21.305853: Epoch time: 29.72 s 
2025-01-25 19:35:22.352728:  
2025-01-25 19:35:22.355412: Epoch 108 
2025-01-25 19:35:22.358163: Current learning rate: 0.00902 
2025-01-25 19:35:53.500233: train_loss -0.7721 
2025-01-25 19:35:53.506191: val_loss -0.7549 
2025-01-25 19:35:53.508741: Pseudo dice [np.float32(0.9491), np.float32(0.8077)] 
2025-01-25 19:35:53.511142: Epoch time: 31.15 s 
2025-01-25 19:35:54.537336:  
2025-01-25 19:35:54.539797: Epoch 109 
2025-01-25 19:35:54.542264: Current learning rate: 0.00901 
2025-01-25 19:36:23.639449: train_loss -0.7736 
2025-01-25 19:36:23.648521: val_loss -0.7265 
2025-01-25 19:36:23.651138: Pseudo dice [np.float32(0.9418), np.float32(0.8616)] 
2025-01-25 19:36:23.653511: Epoch time: 29.1 s 
2025-01-25 19:36:25.393749:  
2025-01-25 19:36:25.396628: Epoch 110 
2025-01-25 19:36:25.399166: Current learning rate: 0.009 
2025-01-25 19:36:55.238958: train_loss -0.7792 
2025-01-25 19:36:55.245752: val_loss -0.7436 
2025-01-25 19:36:55.248130: Pseudo dice [np.float32(0.9505), np.float32(0.8711)] 
2025-01-25 19:36:55.250512: Epoch time: 29.85 s 
2025-01-25 19:36:56.414680:  
2025-01-25 19:36:56.417321: Epoch 111 
2025-01-25 19:36:56.419814: Current learning rate: 0.009 
2025-01-25 19:37:27.723614: train_loss -0.7843 
2025-01-25 19:37:27.731755: val_loss -0.7356 
2025-01-25 19:37:27.734185: Pseudo dice [np.float32(0.9454), np.float32(0.8624)] 
2025-01-25 19:37:27.736840: Epoch time: 31.31 s 
2025-01-25 19:37:28.793759:  
2025-01-25 19:37:28.796380: Epoch 112 
2025-01-25 19:37:28.798835: Current learning rate: 0.00899 
2025-01-25 19:37:57.767307: train_loss -0.8116 
2025-01-25 19:37:57.773072: val_loss -0.7455 
2025-01-25 19:37:57.775306: Pseudo dice [np.float32(0.9531), np.float32(0.8688)] 
2025-01-25 19:37:57.777626: Epoch time: 28.97 s 
2025-01-25 19:37:57.779838: Yayy! New best EMA pseudo Dice: 0.8956000208854675 
2025-01-25 19:37:59.310251:  
2025-01-25 19:37:59.313433: Epoch 113 
2025-01-25 19:37:59.315680: Current learning rate: 0.00898 
2025-01-25 19:38:29.787828: train_loss -0.7956 
2025-01-25 19:38:29.794669: val_loss -0.7614 
2025-01-25 19:38:29.797296: Pseudo dice [np.float32(0.9541), np.float32(0.8919)] 
2025-01-25 19:38:29.799667: Epoch time: 30.48 s 
2025-01-25 19:38:29.802176: Yayy! New best EMA pseudo Dice: 0.8982999920845032 
2025-01-25 19:38:31.305568:  
2025-01-25 19:38:31.308137: Epoch 114 
2025-01-25 19:38:31.310253: Current learning rate: 0.00897 
2025-01-25 19:39:02.060104: train_loss -0.7743 
2025-01-25 19:39:02.065682: val_loss -0.7779 
2025-01-25 19:39:02.068311: Pseudo dice [np.float32(0.9493), np.float32(0.8911)] 
2025-01-25 19:39:02.070717: Epoch time: 30.76 s 
2025-01-25 19:39:02.073173: Yayy! New best EMA pseudo Dice: 0.9004999995231628 
2025-01-25 19:39:03.564527:  
2025-01-25 19:39:03.567286: Epoch 115 
2025-01-25 19:39:03.569822: Current learning rate: 0.00896 
2025-01-25 19:39:35.431482: train_loss -0.7941 
2025-01-25 19:39:35.437489: val_loss -0.7615 
2025-01-25 19:39:35.439959: Pseudo dice [np.float32(0.9531), np.float32(0.8778)] 
2025-01-25 19:39:35.442407: Epoch time: 31.87 s 
2025-01-25 19:39:35.444539: Yayy! New best EMA pseudo Dice: 0.9020000100135803 
2025-01-25 19:39:37.002797:  
2025-01-25 19:39:37.005451: Epoch 116 
2025-01-25 19:39:37.007961: Current learning rate: 0.00895 
2025-01-25 19:40:06.226750: train_loss -0.775 
2025-01-25 19:40:06.232564: val_loss -0.7303 
2025-01-25 19:40:06.234990: Pseudo dice [np.float32(0.9496), np.float32(0.8231)] 
2025-01-25 19:40:06.237516: Epoch time: 29.22 s 
2025-01-25 19:40:07.281014:  
2025-01-25 19:40:07.283835: Epoch 117 
2025-01-25 19:40:07.286181: Current learning rate: 0.00894 
2025-01-25 19:40:36.919853: train_loss -0.7775 
2025-01-25 19:40:36.925331: val_loss -0.7607 
2025-01-25 19:40:36.927782: Pseudo dice [np.float32(0.9473), np.float32(0.8485)] 
2025-01-25 19:40:36.929911: Epoch time: 29.64 s 
2025-01-25 19:40:37.965987:  
2025-01-25 19:40:37.968947: Epoch 118 
2025-01-25 19:40:37.971515: Current learning rate: 0.00893 
2025-01-25 19:41:07.889539: train_loss -0.7832 
2025-01-25 19:41:07.894988: val_loss -0.6999 
2025-01-25 19:41:07.897280: Pseudo dice [np.float32(0.9506), np.float32(0.8611)] 
2025-01-25 19:41:07.899700: Epoch time: 29.92 s 
2025-01-25 19:41:08.931860:  
2025-01-25 19:41:08.935961: Epoch 119 
2025-01-25 19:41:08.938440: Current learning rate: 0.00892 
2025-01-25 19:41:39.634869: train_loss -0.802 
2025-01-25 19:41:39.640977: val_loss -0.7248 
2025-01-25 19:41:39.643409: Pseudo dice [np.float32(0.9488), np.float32(0.8515)] 
2025-01-25 19:41:39.645687: Epoch time: 30.7 s 
2025-01-25 19:41:40.694502:  
2025-01-25 19:41:40.697065: Epoch 120 
2025-01-25 19:41:40.699356: Current learning rate: 0.00891 
2025-01-25 19:42:10.063502: train_loss -0.7775 
2025-01-25 19:42:10.069198: val_loss -0.7276 
2025-01-25 19:42:10.071338: Pseudo dice [np.float32(0.9513), np.float32(0.8453)] 
2025-01-25 19:42:10.073680: Epoch time: 29.37 s 
2025-01-25 19:42:11.102804:  
2025-01-25 19:42:11.105441: Epoch 121 
2025-01-25 19:42:11.107792: Current learning rate: 0.0089 
2025-01-25 19:42:39.908698: train_loss -0.7874 
2025-01-25 19:42:39.914869: val_loss -0.7422 
2025-01-25 19:42:39.917331: Pseudo dice [np.float32(0.9422), np.float32(0.8364)] 
2025-01-25 19:42:39.919616: Epoch time: 28.81 s 
2025-01-25 19:42:40.961111:  
2025-01-25 19:42:40.963643: Epoch 122 
2025-01-25 19:42:40.966152: Current learning rate: 0.00889 
2025-01-25 19:43:12.187777: train_loss -0.7913 
2025-01-25 19:43:12.192918: val_loss -0.7153 
2025-01-25 19:43:12.195364: Pseudo dice [np.float32(0.9423), np.float32(0.7968)] 
2025-01-25 19:43:12.197664: Epoch time: 31.23 s 
2025-01-25 19:43:13.227795:  
2025-01-25 19:43:13.229999: Epoch 123 
2025-01-25 19:43:13.232260: Current learning rate: 0.00889 
2025-01-25 19:43:42.598499: train_loss -0.7871 
2025-01-25 19:43:42.603924: val_loss -0.7535 
2025-01-25 19:43:42.606470: Pseudo dice [np.float32(0.9487), np.float32(0.8539)] 
2025-01-25 19:43:42.608566: Epoch time: 29.37 s 
2025-01-25 19:43:43.639825:  
2025-01-25 19:43:43.642322: Epoch 124 
2025-01-25 19:43:43.644582: Current learning rate: 0.00888 
2025-01-25 19:44:14.047750: train_loss -0.7774 
2025-01-25 19:44:14.054659: val_loss -0.7585 
2025-01-25 19:44:14.057108: Pseudo dice [np.float32(0.9546), np.float32(0.8621)] 
2025-01-25 19:44:14.059512: Epoch time: 30.41 s 
2025-01-25 19:44:15.120107:  
2025-01-25 19:44:15.122596: Epoch 125 
2025-01-25 19:44:15.124733: Current learning rate: 0.00887 
2025-01-25 19:44:44.366785: train_loss -0.7828 
2025-01-25 19:44:44.374608: val_loss -0.7649 
2025-01-25 19:44:44.376962: Pseudo dice [np.float32(0.9557), np.float32(0.8619)] 
2025-01-25 19:44:44.379471: Epoch time: 29.25 s 
2025-01-25 19:44:45.525826:  
2025-01-25 19:44:45.528348: Epoch 126 
2025-01-25 19:44:45.530878: Current learning rate: 0.00886 
2025-01-25 19:45:16.532474: train_loss -0.7805 
2025-01-25 19:45:16.538570: val_loss -0.779 
2025-01-25 19:45:16.540964: Pseudo dice [np.float32(0.9485), np.float32(0.8697)] 
2025-01-25 19:45:16.543484: Epoch time: 31.01 s 
2025-01-25 19:45:17.584838:  
2025-01-25 19:45:17.587238: Epoch 127 
2025-01-25 19:45:17.589507: Current learning rate: 0.00885 
2025-01-25 19:45:46.462092: train_loss -0.7897 
2025-01-25 19:45:46.468419: val_loss -0.7685 
2025-01-25 19:45:46.470981: Pseudo dice [np.float32(0.9531), np.float32(0.7613)] 
2025-01-25 19:45:46.473169: Epoch time: 28.88 s 
2025-01-25 19:45:47.966255:  
2025-01-25 19:45:47.968603: Epoch 128 
2025-01-25 19:45:47.970849: Current learning rate: 0.00884 
2025-01-25 19:46:17.566556: train_loss -0.756 
2025-01-25 19:46:17.574496: val_loss -0.7266 
2025-01-25 19:46:17.577002: Pseudo dice [np.float32(0.9327), np.float32(0.8139)] 
2025-01-25 19:46:17.579464: Epoch time: 29.6 s 
2025-01-25 19:46:18.630018:  
2025-01-25 19:46:18.632626: Epoch 129 
2025-01-25 19:46:18.635211: Current learning rate: 0.00883 
2025-01-25 19:46:48.265915: train_loss -0.7785 
2025-01-25 19:46:48.271773: val_loss -0.7667 
2025-01-25 19:46:48.274189: Pseudo dice [np.float32(0.9531), np.float32(0.8601)] 
2025-01-25 19:46:48.276532: Epoch time: 29.64 s 
2025-01-25 19:46:49.315173:  
2025-01-25 19:46:49.317890: Epoch 130 
2025-01-25 19:46:49.320136: Current learning rate: 0.00882 
2025-01-25 19:47:19.293683: train_loss -0.779 
2025-01-25 19:47:19.300328: val_loss -0.762 
2025-01-25 19:47:19.304656: Pseudo dice [np.float32(0.9453), np.float32(0.8563)] 
2025-01-25 19:47:19.307328: Epoch time: 29.98 s 
2025-01-25 19:47:20.361889:  
2025-01-25 19:47:20.364464: Epoch 131 
2025-01-25 19:47:20.367085: Current learning rate: 0.00881 
2025-01-25 19:47:50.067781: train_loss -0.7823 
2025-01-25 19:47:50.076394: val_loss -0.7279 
2025-01-25 19:47:50.078792: Pseudo dice [np.float32(0.9468), np.float32(0.7999)] 
2025-01-25 19:47:50.081172: Epoch time: 29.71 s 
2025-01-25 19:47:51.206365:  
2025-01-25 19:47:51.208845: Epoch 132 
2025-01-25 19:47:51.211579: Current learning rate: 0.0088 
2025-01-25 19:48:20.396142: train_loss -0.7625 
2025-01-25 19:48:20.402855: val_loss -0.7304 
2025-01-25 19:48:20.405276: Pseudo dice [np.float32(0.9494), np.float32(0.8673)] 
2025-01-25 19:48:20.407525: Epoch time: 29.19 s 
2025-01-25 19:48:21.445930:  
2025-01-25 19:48:21.448745: Epoch 133 
2025-01-25 19:48:21.451512: Current learning rate: 0.00879 
2025-01-25 19:48:52.412188: train_loss -0.7759 
2025-01-25 19:48:52.431973: val_loss -0.7228 
2025-01-25 19:48:52.434389: Pseudo dice [np.float32(0.9478), np.float32(0.7529)] 
2025-01-25 19:48:52.436701: Epoch time: 30.97 s 
2025-01-25 19:48:53.516316:  
2025-01-25 19:48:53.518582: Epoch 134 
2025-01-25 19:48:53.520988: Current learning rate: 0.00879 
2025-01-25 19:49:23.310288: train_loss -0.8024 
2025-01-25 19:49:23.318842: val_loss -0.7826 
2025-01-25 19:49:23.321250: Pseudo dice [np.float32(0.9489), np.float32(0.8807)] 
2025-01-25 19:49:23.323622: Epoch time: 29.79 s 
2025-01-25 19:49:24.494524:  
2025-01-25 19:49:24.497345: Epoch 135 
2025-01-25 19:49:24.499962: Current learning rate: 0.00878 
2025-01-25 19:49:54.364703: train_loss -0.798 
2025-01-25 19:49:54.370508: val_loss -0.7541 
2025-01-25 19:49:54.372696: Pseudo dice [np.float32(0.9527), np.float32(0.8758)] 
2025-01-25 19:49:54.374957: Epoch time: 29.87 s 
2025-01-25 19:49:55.427158:  
2025-01-25 19:49:55.429703: Epoch 136 
2025-01-25 19:49:55.431890: Current learning rate: 0.00877 
2025-01-25 19:50:24.892078: train_loss -0.7921 
2025-01-25 19:50:24.898207: val_loss -0.7447 
2025-01-25 19:50:24.900652: Pseudo dice [np.float32(0.9377), np.float32(0.8258)] 
2025-01-25 19:50:24.902972: Epoch time: 29.47 s 
2025-01-25 19:50:25.958226:  
2025-01-25 19:50:25.960639: Epoch 137 
2025-01-25 19:50:25.963145: Current learning rate: 0.00876 
2025-01-25 19:50:54.431955: train_loss -0.7873 
2025-01-25 19:50:54.437992: val_loss -0.7573 
2025-01-25 19:50:54.440324: Pseudo dice [np.float32(0.9565), np.float32(0.8091)] 
2025-01-25 19:50:54.442577: Epoch time: 28.47 s 
2025-01-25 19:50:55.498997:  
2025-01-25 19:50:55.501556: Epoch 138 
2025-01-25 19:50:55.504080: Current learning rate: 0.00875 
2025-01-25 19:51:24.955249: train_loss -0.8053 
2025-01-25 19:51:24.962646: val_loss -0.7307 
2025-01-25 19:51:24.965171: Pseudo dice [np.float32(0.9516), np.float32(0.8775)] 
2025-01-25 19:51:24.967559: Epoch time: 29.46 s 
2025-01-25 19:51:26.032047:  
2025-01-25 19:51:26.034635: Epoch 139 
2025-01-25 19:51:26.037151: Current learning rate: 0.00874 
2025-01-25 19:51:56.649536: train_loss -0.7974 
2025-01-25 19:51:56.656906: val_loss -0.7961 
2025-01-25 19:51:56.659295: Pseudo dice [np.float32(0.9515), np.float32(0.8864)] 
2025-01-25 19:51:56.661486: Epoch time: 30.62 s 
2025-01-25 19:51:57.710656:  
2025-01-25 19:51:57.713321: Epoch 140 
2025-01-25 19:51:57.715699: Current learning rate: 0.00873 
2025-01-25 19:52:26.954057: train_loss -0.7928 
2025-01-25 19:52:26.960427: val_loss -0.7623 
2025-01-25 19:52:26.962844: Pseudo dice [np.float32(0.9523), np.float32(0.832)] 
2025-01-25 19:52:26.965187: Epoch time: 29.24 s 
2025-01-25 19:52:28.016425:  
2025-01-25 19:52:28.018973: Epoch 141 
2025-01-25 19:52:28.021630: Current learning rate: 0.00872 
2025-01-25 19:52:57.331110: train_loss -0.811 
2025-01-25 19:52:57.337516: val_loss -0.7585 
2025-01-25 19:52:57.339929: Pseudo dice [np.float32(0.9465), np.float32(0.7788)] 
2025-01-25 19:52:57.342181: Epoch time: 29.32 s 
2025-01-25 19:52:58.388376:  
2025-01-25 19:52:58.391001: Epoch 142 
2025-01-25 19:52:58.393429: Current learning rate: 0.00871 
2025-01-25 19:53:27.786756: train_loss -0.7945 
2025-01-25 19:53:27.793145: val_loss -0.7799 
2025-01-25 19:53:27.795504: Pseudo dice [np.float32(0.9512), np.float32(0.8803)] 
2025-01-25 19:53:27.797937: Epoch time: 29.4 s 
2025-01-25 19:53:28.847107:  
2025-01-25 19:53:28.849736: Epoch 143 
2025-01-25 19:53:28.852103: Current learning rate: 0.0087 
2025-01-25 19:53:57.105767: train_loss -0.7996 
2025-01-25 19:53:57.112711: val_loss -0.7394 
2025-01-25 19:53:57.115566: Pseudo dice [np.float32(0.9465), np.float32(0.8638)] 
2025-01-25 19:53:57.118088: Epoch time: 28.26 s 
2025-01-25 19:53:58.172872:  
2025-01-25 19:53:58.175482: Epoch 144 
2025-01-25 19:53:58.178218: Current learning rate: 0.00869 
2025-01-25 19:54:29.121608: train_loss -0.7998 
2025-01-25 19:54:29.127685: val_loss -0.739 
2025-01-25 19:54:29.130242: Pseudo dice [np.float32(0.9534), np.float32(0.7674)] 
2025-01-25 19:54:29.132632: Epoch time: 30.95 s 
2025-01-25 19:54:30.177824:  
2025-01-25 19:54:30.180424: Epoch 145 
2025-01-25 19:54:30.182910: Current learning rate: 0.00868 
2025-01-25 19:54:59.817287: train_loss -0.7857 
2025-01-25 19:54:59.823991: val_loss -0.7177 
2025-01-25 19:54:59.826405: Pseudo dice [np.float32(0.9449), np.float32(0.7931)] 
2025-01-25 19:54:59.828716: Epoch time: 29.64 s 
2025-01-25 19:55:00.896941:  
2025-01-25 19:55:00.899883: Epoch 146 
2025-01-25 19:55:00.902357: Current learning rate: 0.00868 
2025-01-25 19:55:31.076098: train_loss -0.7913 
2025-01-25 19:55:31.082117: val_loss -0.7344 
2025-01-25 19:55:31.084349: Pseudo dice [np.float32(0.952), np.float32(0.8917)] 
2025-01-25 19:55:31.086471: Epoch time: 30.18 s 
2025-01-25 19:55:32.593466:  
2025-01-25 19:55:32.596233: Epoch 147 
2025-01-25 19:55:32.598684: Current learning rate: 0.00867 
2025-01-25 19:56:02.550407: train_loss -0.7816 
2025-01-25 19:56:02.556001: val_loss -0.7863 
2025-01-25 19:56:02.558412: Pseudo dice [np.float32(0.956), np.float32(0.9074)] 
2025-01-25 19:56:02.560635: Epoch time: 29.96 s 
2025-01-25 19:56:03.619909:  
2025-01-25 19:56:03.622266: Epoch 148 
2025-01-25 19:56:03.624501: Current learning rate: 0.00866 
2025-01-25 19:56:33.406211: train_loss -0.8166 
2025-01-25 19:56:33.411732: val_loss -0.7782 
2025-01-25 19:56:33.416651: Pseudo dice [np.float32(0.9562), np.float32(0.8557)] 
2025-01-25 19:56:33.419437: Epoch time: 29.79 s 
2025-01-25 19:56:34.479473:  
2025-01-25 19:56:34.481902: Epoch 149 
2025-01-25 19:56:34.484419: Current learning rate: 0.00865 
2025-01-25 19:57:04.000383: train_loss -0.795 
2025-01-25 19:57:04.011004: val_loss -0.7674 
2025-01-25 19:57:04.013516: Pseudo dice [np.float32(0.9454), np.float32(0.8534)] 
2025-01-25 19:57:04.017341: Epoch time: 29.52 s 
2025-01-25 19:57:05.556875:  
2025-01-25 19:57:05.559776: Epoch 150 
2025-01-25 19:57:05.562133: Current learning rate: 0.00864 
2025-01-25 19:57:35.561554: train_loss -0.8088 
2025-01-25 19:57:35.567973: val_loss -0.7496 
2025-01-25 19:57:35.570255: Pseudo dice [np.float32(0.9413), np.float32(0.8961)] 
2025-01-25 19:57:35.572536: Epoch time: 30.01 s 
2025-01-25 19:57:36.647259:  
2025-01-25 19:57:36.650103: Epoch 151 
2025-01-25 19:57:36.652769: Current learning rate: 0.00863 
2025-01-25 19:58:05.039545: train_loss -0.8083 
2025-01-25 19:58:05.046419: val_loss -0.7818 
2025-01-25 19:58:05.048987: Pseudo dice [np.float32(0.9421), np.float32(0.846)] 
2025-01-25 19:58:05.051282: Epoch time: 28.39 s 
2025-01-25 19:58:06.104637:  
2025-01-25 19:58:06.107291: Epoch 152 
2025-01-25 19:58:06.109683: Current learning rate: 0.00862 
2025-01-25 19:58:36.092714: train_loss -0.7983 
2025-01-25 19:58:36.099394: val_loss -0.7793 
2025-01-25 19:58:36.101727: Pseudo dice [np.float32(0.9519), np.float32(0.817)] 
2025-01-25 19:58:36.104146: Epoch time: 29.99 s 
2025-01-25 19:58:37.163692:  
2025-01-25 19:58:37.166270: Epoch 153 
2025-01-25 19:58:37.168999: Current learning rate: 0.00861 
2025-01-25 19:59:07.931780: train_loss -0.7861 
2025-01-25 19:59:07.939261: val_loss -0.7603 
2025-01-25 19:59:07.941608: Pseudo dice [np.float32(0.9494), np.float32(0.8533)] 
2025-01-25 19:59:07.943843: Epoch time: 30.77 s 
2025-01-25 19:59:09.020391:  
2025-01-25 19:59:09.022790: Epoch 154 
2025-01-25 19:59:09.024963: Current learning rate: 0.0086 
2025-01-25 19:59:39.606157: train_loss -0.7839 
2025-01-25 19:59:39.613019: val_loss -0.7698 
2025-01-25 19:59:39.615538: Pseudo dice [np.float32(0.9489), np.float32(0.8457)] 
2025-01-25 19:59:39.618209: Epoch time: 30.59 s 
2025-01-25 19:59:40.734662:  
2025-01-25 19:59:40.737067: Epoch 155 
2025-01-25 19:59:40.739391: Current learning rate: 0.00859 
2025-01-25 20:00:10.545238: train_loss -0.7787 
2025-01-25 20:00:10.552929: val_loss -0.7717 
2025-01-25 20:00:10.555495: Pseudo dice [np.float32(0.9492), np.float32(0.8784)] 
2025-01-25 20:00:10.558136: Epoch time: 29.81 s 
2025-01-25 20:00:11.626708:  
2025-01-25 20:00:11.629299: Epoch 156 
2025-01-25 20:00:11.631628: Current learning rate: 0.00858 
2025-01-25 20:00:40.915723: train_loss -0.7796 
2025-01-25 20:00:40.921243: val_loss -0.7387 
2025-01-25 20:00:40.923677: Pseudo dice [np.float32(0.9533), np.float32(0.8422)] 
2025-01-25 20:00:40.926255: Epoch time: 29.29 s 
2025-01-25 20:00:41.993254:  
2025-01-25 20:00:41.995839: Epoch 157 
2025-01-25 20:00:41.998164: Current learning rate: 0.00858 
2025-01-25 20:01:11.547095: train_loss -0.7753 
2025-01-25 20:01:11.552945: val_loss -0.7301 
2025-01-25 20:01:11.555531: Pseudo dice [np.float32(0.9427), np.float32(0.8403)] 
2025-01-25 20:01:11.558091: Epoch time: 29.55 s 
2025-01-25 20:01:12.622495:  
2025-01-25 20:01:12.624930: Epoch 158 
2025-01-25 20:01:12.627330: Current learning rate: 0.00857 
2025-01-25 20:01:42.063585: train_loss -0.8033 
2025-01-25 20:01:42.069472: val_loss -0.7276 
2025-01-25 20:01:42.071826: Pseudo dice [np.float32(0.9543), np.float32(0.8412)] 
2025-01-25 20:01:42.074006: Epoch time: 29.44 s 
2025-01-25 20:01:43.142225:  
2025-01-25 20:01:43.144555: Epoch 159 
2025-01-25 20:01:43.146984: Current learning rate: 0.00856 
2025-01-25 20:02:12.725331: train_loss -0.7859 
2025-01-25 20:02:12.731933: val_loss -0.7043 
2025-01-25 20:02:12.734490: Pseudo dice [np.float32(0.9379), np.float32(0.8303)] 
2025-01-25 20:02:12.736934: Epoch time: 29.58 s 
2025-01-25 20:02:13.803680:  
2025-01-25 20:02:13.806690: Epoch 160 
2025-01-25 20:02:13.809584: Current learning rate: 0.00855 
2025-01-25 20:02:43.225451: train_loss -0.79 
2025-01-25 20:02:43.230673: val_loss -0.7444 
2025-01-25 20:02:43.233407: Pseudo dice [np.float32(0.9527), np.float32(0.8602)] 
2025-01-25 20:02:43.235720: Epoch time: 29.42 s 
2025-01-25 20:02:44.309237:  
2025-01-25 20:02:44.311767: Epoch 161 
2025-01-25 20:02:44.314313: Current learning rate: 0.00854 
2025-01-25 20:03:13.995123: train_loss -0.7846 
2025-01-25 20:03:14.003132: val_loss -0.7493 
2025-01-25 20:03:14.005715: Pseudo dice [np.float32(0.9519), np.float32(0.8816)] 
2025-01-25 20:03:14.008224: Epoch time: 29.69 s 
2025-01-25 20:03:15.180927:  
2025-01-25 20:03:15.183170: Epoch 162 
2025-01-25 20:03:15.185318: Current learning rate: 0.00853 
2025-01-25 20:03:44.158342: train_loss -0.7994 
2025-01-25 20:03:44.163601: val_loss -0.7432 
2025-01-25 20:03:44.165786: Pseudo dice [np.float32(0.9484), np.float32(0.8256)] 
2025-01-25 20:03:44.168094: Epoch time: 28.98 s 
2025-01-25 20:03:45.237993:  
2025-01-25 20:03:45.240715: Epoch 163 
2025-01-25 20:03:45.243204: Current learning rate: 0.00852 
2025-01-25 20:04:15.363321: train_loss -0.7965 
2025-01-25 20:04:15.371176: val_loss -0.7497 
2025-01-25 20:04:15.373732: Pseudo dice [np.float32(0.9529), np.float32(0.8418)] 
2025-01-25 20:04:15.376404: Epoch time: 30.13 s 
2025-01-25 20:04:17.017518:  
2025-01-25 20:04:17.019840: Epoch 164 
2025-01-25 20:04:17.022126: Current learning rate: 0.00851 
2025-01-25 20:04:47.669493: train_loss -0.7985 
2025-01-25 20:04:47.677956: val_loss -0.758 
2025-01-25 20:04:47.680697: Pseudo dice [np.float32(0.9435), np.float32(0.8464)] 
2025-01-25 20:04:47.683585: Epoch time: 30.65 s 
2025-01-25 20:04:48.742574:  
2025-01-25 20:04:48.744982: Epoch 165 
2025-01-25 20:04:48.747426: Current learning rate: 0.0085 
2025-01-25 20:05:18.731487: train_loss -0.7984 
2025-01-25 20:05:18.737447: val_loss -0.7696 
2025-01-25 20:05:18.739842: Pseudo dice [np.float32(0.9471), np.float32(0.8904)] 
2025-01-25 20:05:18.742293: Epoch time: 29.99 s 
2025-01-25 20:05:19.785970:  
2025-01-25 20:05:19.788326: Epoch 166 
2025-01-25 20:05:19.790509: Current learning rate: 0.00849 
2025-01-25 20:05:49.222737: train_loss -0.8065 
2025-01-25 20:05:49.228648: val_loss -0.748 
2025-01-25 20:05:49.231084: Pseudo dice [np.float32(0.954), np.float32(0.8582)] 
2025-01-25 20:05:49.233391: Epoch time: 29.44 s 
2025-01-25 20:05:50.289165:  
2025-01-25 20:05:50.292587: Epoch 167 
2025-01-25 20:05:50.295059: Current learning rate: 0.00848 
2025-01-25 20:06:19.254251: train_loss -0.8066 
2025-01-25 20:06:19.259188: val_loss -0.7278 
2025-01-25 20:06:19.261422: Pseudo dice [np.float32(0.9357), np.float32(0.7636)] 
2025-01-25 20:06:19.263538: Epoch time: 28.97 s 
2025-01-25 20:06:20.315612:  
2025-01-25 20:06:20.318075: Epoch 168 
2025-01-25 20:06:20.320515: Current learning rate: 0.00847 
2025-01-25 20:06:50.276909: train_loss -0.7951 
2025-01-25 20:06:50.283217: val_loss -0.76 
2025-01-25 20:06:50.285840: Pseudo dice [np.float32(0.9492), np.float32(0.8643)] 
2025-01-25 20:06:50.288299: Epoch time: 29.96 s 
2025-01-25 20:06:51.355744:  
2025-01-25 20:06:51.358313: Epoch 169 
2025-01-25 20:06:51.360567: Current learning rate: 0.00847 
2025-01-25 20:07:21.220048: train_loss -0.7739 
2025-01-25 20:07:21.225884: val_loss -0.73 
2025-01-25 20:07:21.228132: Pseudo dice [np.float32(0.9408), np.float32(0.7886)] 
2025-01-25 20:07:21.230540: Epoch time: 29.87 s 
2025-01-25 20:07:22.333096:  
2025-01-25 20:07:22.335577: Epoch 170 
2025-01-25 20:07:22.337855: Current learning rate: 0.00846 
2025-01-25 20:07:51.762209: train_loss -0.7779 
2025-01-25 20:07:51.768782: val_loss -0.7146 
2025-01-25 20:07:51.772133: Pseudo dice [np.float32(0.9374), np.float32(0.7846)] 
2025-01-25 20:07:51.774557: Epoch time: 29.43 s 
2025-01-25 20:07:52.842156:  
2025-01-25 20:07:52.844892: Epoch 171 
2025-01-25 20:07:52.847517: Current learning rate: 0.00845 
2025-01-25 20:08:23.342366: train_loss -0.7843 
2025-01-25 20:08:23.348281: val_loss -0.722 
2025-01-25 20:08:23.350488: Pseudo dice [np.float32(0.9496), np.float32(0.8413)] 
2025-01-25 20:08:23.352913: Epoch time: 30.5 s 
2025-01-25 20:08:24.419502:  
2025-01-25 20:08:24.421793: Epoch 172 
2025-01-25 20:08:24.424031: Current learning rate: 0.00844 
2025-01-25 20:08:54.576262: train_loss -0.8104 
2025-01-25 20:08:54.584571: val_loss -0.7768 
2025-01-25 20:08:54.587252: Pseudo dice [np.float32(0.9501), np.float32(0.8742)] 
2025-01-25 20:08:54.589708: Epoch time: 30.16 s 
2025-01-25 20:08:55.674832:  
2025-01-25 20:08:55.677119: Epoch 173 
2025-01-25 20:08:55.679363: Current learning rate: 0.00843 
2025-01-25 20:09:24.293612: train_loss -0.8151 
2025-01-25 20:09:24.298414: val_loss -0.7967 
2025-01-25 20:09:24.300947: Pseudo dice [np.float32(0.9476), np.float32(0.8875)] 
2025-01-25 20:09:24.303369: Epoch time: 28.62 s 
2025-01-25 20:09:25.367808:  
2025-01-25 20:09:25.370403: Epoch 174 
2025-01-25 20:09:25.372798: Current learning rate: 0.00842 
2025-01-25 20:09:54.577735: train_loss -0.798 
2025-01-25 20:09:54.583777: val_loss -0.7781 
2025-01-25 20:09:54.586574: Pseudo dice [np.float32(0.9577), np.float32(0.884)] 
2025-01-25 20:09:54.589395: Epoch time: 29.21 s 
2025-01-25 20:09:55.651620:  
2025-01-25 20:09:55.654124: Epoch 175 
2025-01-25 20:09:55.656529: Current learning rate: 0.00841 
2025-01-25 20:10:24.776442: train_loss -0.8035 
2025-01-25 20:10:24.783158: val_loss -0.7604 
2025-01-25 20:10:24.785729: Pseudo dice [np.float32(0.9504), np.float32(0.8537)] 
2025-01-25 20:10:24.788219: Epoch time: 29.13 s 
2025-01-25 20:10:25.903534:  
2025-01-25 20:10:25.906250: Epoch 176 
2025-01-25 20:10:25.908851: Current learning rate: 0.0084 
2025-01-25 20:10:54.987089: train_loss -0.7944 
2025-01-25 20:10:54.992944: val_loss -0.7861 
2025-01-25 20:10:54.995426: Pseudo dice [np.float32(0.9487), np.float32(0.886)] 
2025-01-25 20:10:54.997899: Epoch time: 29.08 s 
2025-01-25 20:10:56.065151:  
2025-01-25 20:10:56.067773: Epoch 177 
2025-01-25 20:10:56.070466: Current learning rate: 0.00839 
2025-01-25 20:11:25.545684: train_loss -0.7851 
2025-01-25 20:11:25.551979: val_loss -0.7621 
2025-01-25 20:11:25.554454: Pseudo dice [np.float32(0.9555), np.float32(0.884)] 
2025-01-25 20:11:25.557187: Epoch time: 29.48 s 
2025-01-25 20:11:25.559568: Yayy! New best EMA pseudo Dice: 0.9021999835968018 
2025-01-25 20:11:27.129251:  
2025-01-25 20:11:27.131827: Epoch 178 
2025-01-25 20:11:27.134256: Current learning rate: 0.00838 
2025-01-25 20:11:57.560750: train_loss -0.7839 
2025-01-25 20:11:57.566936: val_loss -0.7831 
2025-01-25 20:11:57.569445: Pseudo dice [np.float32(0.9505), np.float32(0.8877)] 
2025-01-25 20:11:57.571828: Epoch time: 30.43 s 
2025-01-25 20:11:57.574319: Yayy! New best EMA pseudo Dice: 0.9039000272750854 
2025-01-25 20:11:59.415149:  
2025-01-25 20:11:59.417921: Epoch 179 
2025-01-25 20:11:59.420408: Current learning rate: 0.00837 
2025-01-25 20:12:29.450817: train_loss -0.7854 
2025-01-25 20:12:29.455624: val_loss -0.7622 
2025-01-25 20:12:29.457785: Pseudo dice [np.float32(0.9436), np.float32(0.885)] 
2025-01-25 20:12:29.459848: Epoch time: 30.04 s 
2025-01-25 20:12:29.461875: Yayy! New best EMA pseudo Dice: 0.9049999713897705 
2025-01-25 20:12:31.061308:  
2025-01-25 20:12:31.063878: Epoch 180 
2025-01-25 20:12:31.066387: Current learning rate: 0.00836 
2025-01-25 20:12:59.606473: train_loss -0.7897 
2025-01-25 20:12:59.612821: val_loss -0.7448 
2025-01-25 20:12:59.615212: Pseudo dice [np.float32(0.9404), np.float32(0.7699)] 
2025-01-25 20:12:59.617802: Epoch time: 28.55 s 
2025-01-25 20:13:00.695624:  
2025-01-25 20:13:00.697931: Epoch 181 
2025-01-25 20:13:00.700319: Current learning rate: 0.00836 
2025-01-25 20:13:30.177981: train_loss -0.8 
2025-01-25 20:13:30.184081: val_loss -0.7413 
2025-01-25 20:13:30.186451: Pseudo dice [np.float32(0.9489), np.float32(0.8767)] 
2025-01-25 20:13:30.189147: Epoch time: 29.48 s 
2025-01-25 20:13:31.924191:  
2025-01-25 20:13:31.926760: Epoch 182 
2025-01-25 20:13:31.929451: Current learning rate: 0.00835 
2025-01-25 20:14:01.206093: train_loss -0.7967 
2025-01-25 20:14:01.211685: val_loss -0.7308 
2025-01-25 20:14:01.214255: Pseudo dice [np.float32(0.9494), np.float32(0.8578)] 
2025-01-25 20:14:01.216815: Epoch time: 29.28 s 
2025-01-25 20:14:02.272702:  
2025-01-25 20:14:02.275163: Epoch 183 
2025-01-25 20:14:02.277567: Current learning rate: 0.00834 
2025-01-25 20:14:32.265648: train_loss -0.7963 
2025-01-25 20:14:32.274284: val_loss -0.741 
2025-01-25 20:14:32.277153: Pseudo dice [np.float32(0.9535), np.float32(0.8604)] 
2025-01-25 20:14:32.279729: Epoch time: 29.99 s 
2025-01-25 20:14:33.361946:  
2025-01-25 20:14:33.365466: Epoch 184 
2025-01-25 20:14:33.368432: Current learning rate: 0.00833 
2025-01-25 20:15:02.115632: train_loss -0.7867 
2025-01-25 20:15:02.122217: val_loss -0.7359 
2025-01-25 20:15:02.124768: Pseudo dice [np.float32(0.9418), np.float32(0.7935)] 
2025-01-25 20:15:02.127387: Epoch time: 28.75 s 
2025-01-25 20:15:03.192081:  
2025-01-25 20:15:03.194914: Epoch 185 
2025-01-25 20:15:03.197519: Current learning rate: 0.00832 
2025-01-25 20:15:31.032673: train_loss -0.8016 
2025-01-25 20:15:31.035580: val_loss -0.7859 
2025-01-25 20:15:31.037894: Pseudo dice [np.float32(0.9557), np.float32(0.88)] 
2025-01-25 20:15:31.040297: Epoch time: 27.84 s 
2025-01-25 20:15:32.100082:  
2025-01-25 20:15:32.102692: Epoch 186 
2025-01-25 20:15:32.105212: Current learning rate: 0.00831 
2025-01-25 20:16:02.103057: train_loss -0.807 
2025-01-25 20:16:02.110001: val_loss -0.7573 
2025-01-25 20:16:02.112990: Pseudo dice [np.float32(0.9459), np.float32(0.7547)] 
2025-01-25 20:16:02.115527: Epoch time: 30.0 s 
2025-01-25 20:16:03.195880:  
2025-01-25 20:16:03.198589: Epoch 187 
2025-01-25 20:16:03.201433: Current learning rate: 0.0083 
2025-01-25 20:16:34.766208: train_loss -0.7741 
2025-01-25 20:16:34.771338: val_loss -0.7029 
2025-01-25 20:16:34.773949: Pseudo dice [np.float32(0.9527), np.float32(0.8505)] 
2025-01-25 20:16:34.776344: Epoch time: 31.57 s 
2025-01-25 20:16:35.856329:  
2025-01-25 20:16:35.858998: Epoch 188 
2025-01-25 20:16:35.861394: Current learning rate: 0.00829 
2025-01-25 20:17:08.300746: train_loss -0.7923 
2025-01-25 20:17:08.306030: val_loss -0.7538 
2025-01-25 20:17:08.308504: Pseudo dice [np.float32(0.9391), np.float32(0.8444)] 
2025-01-25 20:17:08.310574: Epoch time: 32.45 s 
2025-01-25 20:17:09.379544:  
2025-01-25 20:17:09.382187: Epoch 189 
2025-01-25 20:17:09.384482: Current learning rate: 0.00828 
2025-01-25 20:17:39.132901: train_loss -0.8016 
2025-01-25 20:17:39.137923: val_loss -0.7638 
2025-01-25 20:17:39.141447: Pseudo dice [np.float32(0.9551), np.float32(0.8652)] 
2025-01-25 20:17:39.144183: Epoch time: 29.75 s 
2025-01-25 20:17:40.225486:  
2025-01-25 20:17:40.228161: Epoch 190 
2025-01-25 20:17:40.230841: Current learning rate: 0.00827 
2025-01-25 20:18:09.261384: train_loss -0.8075 
2025-01-25 20:18:09.266973: val_loss -0.7649 
2025-01-25 20:18:09.269276: Pseudo dice [np.float32(0.9278), np.float32(0.9001)] 
2025-01-25 20:18:09.271462: Epoch time: 29.04 s 
2025-01-25 20:18:10.337222:  
2025-01-25 20:18:10.340261: Epoch 191 
2025-01-25 20:18:10.343302: Current learning rate: 0.00826 
2025-01-25 20:18:38.907739: train_loss -0.7817 
2025-01-25 20:18:38.911164: val_loss -0.722 
2025-01-25 20:18:38.913966: Pseudo dice [np.float32(0.9494), np.float32(0.8197)] 
2025-01-25 20:18:38.916577: Epoch time: 28.57 s 
2025-01-25 20:18:39.992820:  
2025-01-25 20:18:39.995481: Epoch 192 
2025-01-25 20:18:39.997888: Current learning rate: 0.00825 
2025-01-25 20:19:09.440611: train_loss -0.7979 
2025-01-25 20:19:09.446608: val_loss -0.7467 
2025-01-25 20:19:09.448745: Pseudo dice [np.float32(0.9443), np.float32(0.8455)] 
2025-01-25 20:19:09.451000: Epoch time: 29.45 s 
2025-01-25 20:19:10.520217:  
2025-01-25 20:19:10.522605: Epoch 193 
2025-01-25 20:19:10.524985: Current learning rate: 0.00824 
2025-01-25 20:19:40.369831: train_loss -0.825 
2025-01-25 20:19:40.375841: val_loss -0.784 
2025-01-25 20:19:40.378339: Pseudo dice [np.float32(0.9546), np.float32(0.8727)] 
2025-01-25 20:19:40.380878: Epoch time: 29.85 s 
2025-01-25 20:19:41.469393:  
2025-01-25 20:19:41.471864: Epoch 194 
2025-01-25 20:19:41.474248: Current learning rate: 0.00824 
2025-01-25 20:20:12.289878: train_loss -0.805 
2025-01-25 20:20:12.298002: val_loss -0.7797 
2025-01-25 20:20:12.300440: Pseudo dice [np.float32(0.9415), np.float32(0.8625)] 
2025-01-25 20:20:12.302843: Epoch time: 30.82 s 
2025-01-25 20:20:13.380246:  
2025-01-25 20:20:13.383323: Epoch 195 
2025-01-25 20:20:13.385729: Current learning rate: 0.00823 
2025-01-25 20:20:41.860014: train_loss -0.7939 
2025-01-25 20:20:41.867890: val_loss -0.7783 
2025-01-25 20:20:41.870429: Pseudo dice [np.float32(0.9501), np.float32(0.8602)] 
2025-01-25 20:20:41.873080: Epoch time: 28.48 s 
2025-01-25 20:20:42.997553:  
2025-01-25 20:20:43.000010: Epoch 196 
2025-01-25 20:20:43.002710: Current learning rate: 0.00822 
2025-01-25 20:21:13.743829: train_loss -0.7933 
2025-01-25 20:21:13.751410: val_loss -0.7429 
2025-01-25 20:21:13.753831: Pseudo dice [np.float32(0.9529), np.float32(0.8837)] 
2025-01-25 20:21:13.756248: Epoch time: 30.75 s 
2025-01-25 20:21:14.832143:  
2025-01-25 20:21:14.834647: Epoch 197 
2025-01-25 20:21:14.837181: Current learning rate: 0.00821 
2025-01-25 20:21:44.577808: train_loss -0.7823 
2025-01-25 20:21:44.584685: val_loss -0.7632 
2025-01-25 20:21:44.587430: Pseudo dice [np.float32(0.9584), np.float32(0.873)] 
2025-01-25 20:21:44.589699: Epoch time: 29.75 s 
2025-01-25 20:21:45.780298:  
2025-01-25 20:21:45.782722: Epoch 198 
2025-01-25 20:21:45.785169: Current learning rate: 0.0082 
2025-01-25 20:22:14.557052: train_loss -0.7906 
2025-01-25 20:22:14.565231: val_loss -0.7322 
2025-01-25 20:22:14.567908: Pseudo dice [np.float32(0.9514), np.float32(0.8515)] 
2025-01-25 20:22:14.570329: Epoch time: 28.78 s 
2025-01-25 20:22:16.353820:  
2025-01-25 20:22:16.356387: Epoch 199 
2025-01-25 20:22:16.358849: Current learning rate: 0.00819 
2025-01-25 20:22:46.079269: train_loss -0.8041 
2025-01-25 20:22:46.084109: val_loss -0.7894 
2025-01-25 20:22:46.086614: Pseudo dice [np.float32(0.9501), np.float32(0.8711)] 
2025-01-25 20:22:46.088720: Epoch time: 29.73 s 
2025-01-25 20:22:47.684030:  
2025-01-25 20:22:47.686737: Epoch 200 
2025-01-25 20:22:47.689178: Current learning rate: 0.00818 
2025-01-25 20:23:16.732165: train_loss -0.803 
2025-01-25 20:23:16.738546: val_loss -0.7665 
2025-01-25 20:23:16.741073: Pseudo dice [np.float32(0.9508), np.float32(0.8489)] 
2025-01-25 20:23:16.743450: Epoch time: 29.05 s 
2025-01-25 20:23:17.814367:  
2025-01-25 20:23:17.816797: Epoch 201 
2025-01-25 20:23:17.819236: Current learning rate: 0.00817 
2025-01-25 20:23:47.290210: train_loss -0.8032 
2025-01-25 20:23:47.296516: val_loss -0.7475 
2025-01-25 20:23:47.298991: Pseudo dice [np.float32(0.9388), np.float32(0.8797)] 
2025-01-25 20:23:47.301484: Epoch time: 29.48 s 
2025-01-25 20:23:48.379644:  
2025-01-25 20:23:48.382422: Epoch 202 
2025-01-25 20:23:48.384816: Current learning rate: 0.00816 
2025-01-25 20:24:17.742086: train_loss -0.7872 
2025-01-25 20:24:17.747972: val_loss -0.7025 
2025-01-25 20:24:17.750103: Pseudo dice [np.float32(0.9436), np.float32(0.759)] 
2025-01-25 20:24:17.752192: Epoch time: 29.36 s 
2025-01-25 20:24:18.826539:  
2025-01-25 20:24:18.828790: Epoch 203 
2025-01-25 20:24:18.830810: Current learning rate: 0.00815 
2025-01-25 20:24:48.996908: train_loss -0.7773 
2025-01-25 20:24:49.002894: val_loss -0.7401 
2025-01-25 20:24:49.005225: Pseudo dice [np.float32(0.9439), np.float32(0.8211)] 
2025-01-25 20:24:49.007862: Epoch time: 30.17 s 
2025-01-25 20:24:50.099440:  
2025-01-25 20:24:50.102096: Epoch 204 
2025-01-25 20:24:50.104744: Current learning rate: 0.00814 
2025-01-25 20:25:19.435323: train_loss -0.801 
2025-01-25 20:25:19.441574: val_loss -0.7529 
2025-01-25 20:25:19.443937: Pseudo dice [np.float32(0.9488), np.float32(0.8485)] 
2025-01-25 20:25:19.446429: Epoch time: 29.34 s 
2025-01-25 20:25:20.530219:  
2025-01-25 20:25:20.532917: Epoch 205 
2025-01-25 20:25:20.535291: Current learning rate: 0.00813 
2025-01-25 20:25:50.494835: train_loss -0.8033 
2025-01-25 20:25:50.502160: val_loss -0.7704 
2025-01-25 20:25:50.504935: Pseudo dice [np.float32(0.9603), np.float32(0.8915)] 
2025-01-25 20:25:50.507596: Epoch time: 29.97 s 
2025-01-25 20:25:51.534852:  
2025-01-25 20:25:51.537513: Epoch 206 
2025-01-25 20:25:51.540456: Current learning rate: 0.00813 
2025-01-25 20:26:21.416586: train_loss -0.7963 
2025-01-25 20:26:21.424153: val_loss -0.7619 
2025-01-25 20:26:21.426517: Pseudo dice [np.float32(0.9501), np.float32(0.8632)] 
2025-01-25 20:26:21.428877: Epoch time: 29.88 s 
2025-01-25 20:26:22.506104:  
2025-01-25 20:26:22.508899: Epoch 207 
2025-01-25 20:26:22.511465: Current learning rate: 0.00812 
2025-01-25 20:26:52.589710: train_loss -0.793 
2025-01-25 20:26:52.596053: val_loss -0.742 
2025-01-25 20:26:52.598899: Pseudo dice [np.float32(0.9522), np.float32(0.8596)] 
2025-01-25 20:26:52.601186: Epoch time: 30.08 s 
2025-01-25 20:26:53.647545:  
2025-01-25 20:26:53.649895: Epoch 208 
2025-01-25 20:26:53.652223: Current learning rate: 0.00811 
2025-01-25 20:27:22.790287: train_loss -0.805 
2025-01-25 20:27:22.798266: val_loss -0.7442 
2025-01-25 20:27:22.800658: Pseudo dice [np.float32(0.956), np.float32(0.8784)] 
2025-01-25 20:27:22.803033: Epoch time: 29.14 s 
2025-01-25 20:27:23.821361:  
2025-01-25 20:27:23.823775: Epoch 209 
2025-01-25 20:27:23.826203: Current learning rate: 0.0081 
2025-01-25 20:27:54.036516: train_loss -0.7972 
2025-01-25 20:27:54.042137: val_loss -0.7198 
2025-01-25 20:27:54.044880: Pseudo dice [np.float32(0.9414), np.float32(0.7388)] 
2025-01-25 20:27:54.047349: Epoch time: 30.22 s 
2025-01-25 20:27:55.067121:  
2025-01-25 20:27:55.069512: Epoch 210 
2025-01-25 20:27:55.072029: Current learning rate: 0.00809 
2025-01-25 20:28:24.627655: train_loss -0.7966 
2025-01-25 20:28:24.634336: val_loss -0.7682 
2025-01-25 20:28:24.636801: Pseudo dice [np.float32(0.9582), np.float32(0.8756)] 
2025-01-25 20:28:24.639071: Epoch time: 29.56 s 
2025-01-25 20:28:25.662524:  
2025-01-25 20:28:25.665141: Epoch 211 
2025-01-25 20:28:25.667434: Current learning rate: 0.00808 
2025-01-25 20:28:55.535105: train_loss -0.7899 
2025-01-25 20:28:55.541937: val_loss -0.7422 
2025-01-25 20:28:55.544939: Pseudo dice [np.float32(0.9537), np.float32(0.7509)] 
2025-01-25 20:28:55.547640: Epoch time: 29.87 s 
2025-01-25 20:28:56.585902:  
2025-01-25 20:28:56.588433: Epoch 212 
2025-01-25 20:28:56.590747: Current learning rate: 0.00807 
2025-01-25 20:29:25.177237: train_loss -0.8061 
2025-01-25 20:29:25.183669: val_loss -0.7414 
2025-01-25 20:29:25.186322: Pseudo dice [np.float32(0.9467), np.float32(0.8126)] 
2025-01-25 20:29:25.188793: Epoch time: 28.59 s 
2025-01-25 20:29:26.217643:  
2025-01-25 20:29:26.219887: Epoch 213 
2025-01-25 20:29:26.222327: Current learning rate: 0.00806 
2025-01-25 20:29:55.384579: train_loss -0.8083 
2025-01-25 20:29:55.392317: val_loss -0.7092 
2025-01-25 20:29:55.395298: Pseudo dice [np.float32(0.9454), np.float32(0.8068)] 
2025-01-25 20:29:55.398188: Epoch time: 29.17 s 
2025-01-25 20:29:56.441936:  
2025-01-25 20:29:56.444692: Epoch 214 
2025-01-25 20:29:56.447569: Current learning rate: 0.00805 
2025-01-25 20:30:25.162005: train_loss -0.7784 
2025-01-25 20:30:25.168271: val_loss -0.7232 
2025-01-25 20:30:25.171044: Pseudo dice [np.float32(0.9384), np.float32(0.8897)] 
2025-01-25 20:30:25.173278: Epoch time: 28.72 s 
2025-01-25 20:30:26.191492:  
2025-01-25 20:30:26.194291: Epoch 215 
2025-01-25 20:30:26.196666: Current learning rate: 0.00804 
2025-01-25 20:30:57.545275: train_loss -0.786 
2025-01-25 20:30:57.554851: val_loss -0.7747 
2025-01-25 20:30:57.557273: Pseudo dice [np.float32(0.9537), np.float32(0.8928)] 
2025-01-25 20:30:57.559597: Epoch time: 31.35 s 
2025-01-25 20:30:58.579580:  
2025-01-25 20:30:58.582161: Epoch 216 
2025-01-25 20:30:58.584613: Current learning rate: 0.00803 
2025-01-25 20:31:27.091182: train_loss -0.807 
2025-01-25 20:31:27.097605: val_loss -0.7694 
2025-01-25 20:31:27.099984: Pseudo dice [np.float32(0.9526), np.float32(0.8698)] 
2025-01-25 20:31:27.102404: Epoch time: 28.51 s 
2025-01-25 20:31:28.592777:  
2025-01-25 20:31:28.595262: Epoch 217 
2025-01-25 20:31:28.597734: Current learning rate: 0.00802 
2025-01-25 20:31:58.116958: train_loss -0.8062 
2025-01-25 20:31:58.120917: val_loss -0.8061 
2025-01-25 20:31:58.123794: Pseudo dice [np.float32(0.9563), np.float32(0.8884)] 
2025-01-25 20:31:58.126145: Epoch time: 29.53 s 
2025-01-25 20:31:59.144861:  
2025-01-25 20:31:59.147552: Epoch 218 
2025-01-25 20:31:59.150097: Current learning rate: 0.00801 
2025-01-25 20:32:29.282587: train_loss -0.7998 
2025-01-25 20:32:29.291408: val_loss -0.7723 
2025-01-25 20:32:29.293774: Pseudo dice [np.float32(0.9466), np.float32(0.8868)] 
2025-01-25 20:32:29.296014: Epoch time: 30.14 s 
2025-01-25 20:32:30.487754:  
2025-01-25 20:32:30.490254: Epoch 219 
2025-01-25 20:32:30.492768: Current learning rate: 0.00801 
2025-01-25 20:32:59.116717: train_loss -0.8015 
2025-01-25 20:32:59.119881: val_loss -0.7672 
2025-01-25 20:32:59.122664: Pseudo dice [np.float32(0.949), np.float32(0.8787)] 
2025-01-25 20:32:59.125418: Epoch time: 28.63 s 
2025-01-25 20:33:00.160248:  
2025-01-25 20:33:00.163198: Epoch 220 
2025-01-25 20:33:00.165617: Current learning rate: 0.008 
2025-01-25 20:33:31.562027: train_loss -0.8074 
2025-01-25 20:33:31.568781: val_loss -0.7532 
2025-01-25 20:33:31.571764: Pseudo dice [np.float32(0.9573), np.float32(0.8676)] 
2025-01-25 20:33:31.574397: Epoch time: 31.4 s 
2025-01-25 20:33:32.607502:  
2025-01-25 20:33:32.610193: Epoch 221 
2025-01-25 20:33:32.612774: Current learning rate: 0.00799 
2025-01-25 20:34:01.492600: train_loss -0.7945 
2025-01-25 20:34:01.499110: val_loss -0.7627 
2025-01-25 20:34:01.501972: Pseudo dice [np.float32(0.9535), np.float32(0.8336)] 
2025-01-25 20:34:01.504400: Epoch time: 28.89 s 
2025-01-25 20:34:02.532820:  
2025-01-25 20:34:02.535369: Epoch 222 
2025-01-25 20:34:02.537851: Current learning rate: 0.00798 
2025-01-25 20:34:32.615002: train_loss -0.7975 
2025-01-25 20:34:32.623761: val_loss -0.7294 
2025-01-25 20:34:32.626596: Pseudo dice [np.float32(0.9588), np.float32(0.8741)] 
2025-01-25 20:34:32.629659: Epoch time: 30.08 s 
2025-01-25 20:34:33.661247:  
2025-01-25 20:34:33.664085: Epoch 223 
2025-01-25 20:34:33.666626: Current learning rate: 0.00797 
2025-01-25 20:35:02.631982: train_loss -0.8048 
2025-01-25 20:35:02.638745: val_loss -0.8018 
2025-01-25 20:35:02.641296: Pseudo dice [np.float32(0.96), np.float32(0.8972)] 
2025-01-25 20:35:02.643889: Epoch time: 28.97 s 
2025-01-25 20:35:02.646174: Yayy! New best EMA pseudo Dice: 0.9067000150680542 
2025-01-25 20:35:04.193449:  
2025-01-25 20:35:04.196038: Epoch 224 
2025-01-25 20:35:04.198483: Current learning rate: 0.00796 
2025-01-25 20:35:33.963134: train_loss -0.8024 
2025-01-25 20:35:33.970150: val_loss -0.779 
2025-01-25 20:35:33.972901: Pseudo dice [np.float32(0.9513), np.float32(0.8792)] 
2025-01-25 20:35:33.975369: Epoch time: 29.77 s 
2025-01-25 20:35:33.977945: Yayy! New best EMA pseudo Dice: 0.9075999855995178 
2025-01-25 20:35:35.602606:  
2025-01-25 20:35:35.605542: Epoch 225 
2025-01-25 20:35:35.608047: Current learning rate: 0.00795 
2025-01-25 20:36:05.757083: train_loss -0.8119 
2025-01-25 20:36:05.759912: val_loss -0.7556 
2025-01-25 20:36:05.762262: Pseudo dice [np.float32(0.9501), np.float32(0.8734)] 
2025-01-25 20:36:05.764748: Epoch time: 30.16 s 
2025-01-25 20:36:05.767174: Yayy! New best EMA pseudo Dice: 0.9079999923706055 
2025-01-25 20:36:07.269557:  
2025-01-25 20:36:07.272309: Epoch 226 
2025-01-25 20:36:07.274692: Current learning rate: 0.00794 
2025-01-25 20:36:38.177984: train_loss -0.7933 
2025-01-25 20:36:38.188052: val_loss -0.7684 
2025-01-25 20:36:38.190710: Pseudo dice [np.float32(0.9597), np.float32(0.8563)] 
2025-01-25 20:36:38.193276: Epoch time: 30.91 s 
2025-01-25 20:36:38.195495: Yayy! New best EMA pseudo Dice: 0.9079999923706055 
2025-01-25 20:36:39.850569:  
2025-01-25 20:36:39.853344: Epoch 227 
2025-01-25 20:36:39.856092: Current learning rate: 0.00793 
2025-01-25 20:37:10.830956: train_loss -0.793 
2025-01-25 20:37:10.837171: val_loss -0.768 
2025-01-25 20:37:10.839632: Pseudo dice [np.float32(0.9413), np.float32(0.8569)] 
2025-01-25 20:37:10.841811: Epoch time: 30.98 s 
2025-01-25 20:37:11.850052:  
2025-01-25 20:37:11.853665: Epoch 228 
2025-01-25 20:37:11.856143: Current learning rate: 0.00792 
2025-01-25 20:37:42.278343: train_loss -0.8099 
2025-01-25 20:37:42.285702: val_loss -0.7718 
2025-01-25 20:37:42.288513: Pseudo dice [np.float32(0.9583), np.float32(0.8914)] 
2025-01-25 20:37:42.291402: Epoch time: 30.43 s 
2025-01-25 20:37:42.294123: Yayy! New best EMA pseudo Dice: 0.9089000225067139 
2025-01-25 20:37:43.832667:  
2025-01-25 20:37:43.835208: Epoch 229 
2025-01-25 20:37:43.837329: Current learning rate: 0.00791 
2025-01-25 20:38:16.276659: train_loss -0.8152 
2025-01-25 20:38:16.280587: val_loss -0.7691 
2025-01-25 20:38:16.282819: Pseudo dice [np.float32(0.9507), np.float32(0.8778)] 
2025-01-25 20:38:16.285398: Epoch time: 32.44 s 
2025-01-25 20:38:16.287685: Yayy! New best EMA pseudo Dice: 0.9093999862670898 
2025-01-25 20:38:17.818526:  
2025-01-25 20:38:17.821196: Epoch 230 
2025-01-25 20:38:17.823412: Current learning rate: 0.0079 
2025-01-25 20:38:47.200269: train_loss -0.783 
2025-01-25 20:38:47.209497: val_loss -0.7802 
2025-01-25 20:38:47.212315: Pseudo dice [np.float32(0.9492), np.float32(0.8567)] 
2025-01-25 20:38:47.214904: Epoch time: 29.38 s 
2025-01-25 20:38:48.234558:  
2025-01-25 20:38:48.237165: Epoch 231 
2025-01-25 20:38:48.239455: Current learning rate: 0.00789 
2025-01-25 20:39:18.035920: train_loss -0.7729 
2025-01-25 20:39:18.041602: val_loss -0.6995 
2025-01-25 20:39:18.044075: Pseudo dice [np.float32(0.94), np.float32(0.7949)] 
2025-01-25 20:39:18.046379: Epoch time: 29.8 s 
2025-01-25 20:39:19.076024:  
2025-01-25 20:39:19.079010: Epoch 232 
2025-01-25 20:39:19.081688: Current learning rate: 0.00789 
2025-01-25 20:39:48.440971: train_loss -0.7679 
2025-01-25 20:39:48.446033: val_loss -0.7689 
2025-01-25 20:39:48.448408: Pseudo dice [np.float32(0.9573), np.float32(0.872)] 
2025-01-25 20:39:48.450644: Epoch time: 29.37 s 
2025-01-25 20:39:49.462878:  
2025-01-25 20:39:49.465337: Epoch 233 
2025-01-25 20:39:49.467755: Current learning rate: 0.00788 
2025-01-25 20:40:20.527445: train_loss -0.7685 
2025-01-25 20:40:20.532975: val_loss -0.7123 
2025-01-25 20:40:20.535510: Pseudo dice [np.float32(0.9501), np.float32(0.8344)] 
2025-01-25 20:40:20.538169: Epoch time: 31.07 s 
2025-01-25 20:40:21.555876:  
2025-01-25 20:40:21.558762: Epoch 234 
2025-01-25 20:40:21.561363: Current learning rate: 0.00787 
2025-01-25 20:40:51.592551: train_loss -0.774 
2025-01-25 20:40:51.599273: val_loss -0.7734 
2025-01-25 20:40:51.601542: Pseudo dice [np.float32(0.9518), np.float32(0.8694)] 
2025-01-25 20:40:51.603858: Epoch time: 30.04 s 
2025-01-25 20:40:52.618470:  
2025-01-25 20:40:52.620881: Epoch 235 
2025-01-25 20:40:52.623259: Current learning rate: 0.00786 
2025-01-25 20:41:23.404083: train_loss -0.7736 
2025-01-25 20:41:23.410283: val_loss -0.7636 
2025-01-25 20:41:23.412822: Pseudo dice [np.float32(0.9394), np.float32(0.8429)] 
2025-01-25 20:41:23.415080: Epoch time: 30.79 s 
2025-01-25 20:41:24.888702:  
2025-01-25 20:41:24.891574: Epoch 236 
2025-01-25 20:41:24.894172: Current learning rate: 0.00785 
2025-01-25 20:41:53.690626: train_loss -0.7784 
2025-01-25 20:41:53.696810: val_loss -0.733 
2025-01-25 20:41:53.699065: Pseudo dice [np.float32(0.9573), np.float32(0.8518)] 
2025-01-25 20:41:53.701330: Epoch time: 28.8 s 
2025-01-25 20:41:54.708955:  
2025-01-25 20:41:54.711418: Epoch 237 
2025-01-25 20:41:54.713889: Current learning rate: 0.00784 
2025-01-25 20:42:24.206063: train_loss -0.7919 
2025-01-25 20:42:24.211357: val_loss -0.755 
2025-01-25 20:42:24.213969: Pseudo dice [np.float32(0.9466), np.float32(0.8593)] 
2025-01-25 20:42:24.216314: Epoch time: 29.5 s 
2025-01-25 20:42:25.246290:  
2025-01-25 20:42:25.248878: Epoch 238 
2025-01-25 20:42:25.251104: Current learning rate: 0.00783 
2025-01-25 20:42:54.865278: train_loss -0.8034 
2025-01-25 20:42:54.871882: val_loss -0.7748 
2025-01-25 20:42:54.874474: Pseudo dice [np.float32(0.9542), np.float32(0.8637)] 
2025-01-25 20:42:54.876912: Epoch time: 29.62 s 
2025-01-25 20:42:55.900316:  
2025-01-25 20:42:55.902792: Epoch 239 
2025-01-25 20:42:55.905140: Current learning rate: 0.00782 
2025-01-25 20:43:27.061130: train_loss -0.8089 
2025-01-25 20:43:27.065902: val_loss -0.7365 
2025-01-25 20:43:27.068403: Pseudo dice [np.float32(0.9469), np.float32(0.8785)] 
2025-01-25 20:43:27.070862: Epoch time: 31.16 s 
2025-01-25 20:43:28.097543:  
2025-01-25 20:43:28.100202: Epoch 240 
2025-01-25 20:43:28.102469: Current learning rate: 0.00781 
2025-01-25 20:43:57.554888: train_loss -0.7916 
2025-01-25 20:43:57.563330: val_loss -0.7983 
2025-01-25 20:43:57.565744: Pseudo dice [np.float32(0.9613), np.float32(0.8506)] 
2025-01-25 20:43:57.568273: Epoch time: 29.46 s 
2025-01-25 20:43:58.799135:  
2025-01-25 20:43:58.802321: Epoch 241 
2025-01-25 20:43:58.805067: Current learning rate: 0.0078 
2025-01-25 20:44:29.543533: train_loss -0.7977 
2025-01-25 20:44:29.547917: val_loss -0.769 
2025-01-25 20:44:29.552078: Pseudo dice [np.float32(0.9525), np.float32(0.874)] 
2025-01-25 20:44:29.554384: Epoch time: 30.75 s 
2025-01-25 20:44:30.591902:  
2025-01-25 20:44:30.594551: Epoch 242 
2025-01-25 20:44:30.597191: Current learning rate: 0.00779 
2025-01-25 20:45:00.159262: train_loss -0.7961 
2025-01-25 20:45:00.168179: val_loss -0.7712 
2025-01-25 20:45:00.170552: Pseudo dice [np.float32(0.9542), np.float32(0.8837)] 
2025-01-25 20:45:00.172927: Epoch time: 29.57 s 
2025-01-25 20:45:01.455713:  
2025-01-25 20:45:01.458476: Epoch 243 
2025-01-25 20:45:01.461258: Current learning rate: 0.00778 
2025-01-25 20:45:31.714821: train_loss -0.7847 
2025-01-25 20:45:31.719502: val_loss -0.7712 
2025-01-25 20:45:31.722040: Pseudo dice [np.float32(0.952), np.float32(0.8495)] 
2025-01-25 20:45:31.724627: Epoch time: 30.26 s 
2025-01-25 20:45:32.775148:  
2025-01-25 20:45:32.777851: Epoch 244 
2025-01-25 20:45:32.780532: Current learning rate: 0.00777 
2025-01-25 20:46:02.108906: train_loss -0.7689 
2025-01-25 20:46:02.115683: val_loss -0.7068 
2025-01-25 20:46:02.118087: Pseudo dice [np.float32(0.942), np.float32(0.7827)] 
2025-01-25 20:46:02.120419: Epoch time: 29.33 s 
2025-01-25 20:46:03.145278:  
2025-01-25 20:46:03.147793: Epoch 245 
2025-01-25 20:46:03.150379: Current learning rate: 0.00777 
2025-01-25 20:46:32.702789: train_loss -0.7846 
2025-01-25 20:46:32.709016: val_loss -0.7327 
2025-01-25 20:46:32.711538: Pseudo dice [np.float32(0.9575), np.float32(0.8538)] 
2025-01-25 20:46:32.713763: Epoch time: 29.56 s 
2025-01-25 20:46:33.804112:  
2025-01-25 20:46:33.806591: Epoch 246 
2025-01-25 20:46:33.809198: Current learning rate: 0.00776 
2025-01-25 20:47:05.070301: train_loss -0.7948 
2025-01-25 20:47:05.078958: val_loss -0.7947 
2025-01-25 20:47:05.081264: Pseudo dice [np.float32(0.9481), np.float32(0.8557)] 
2025-01-25 20:47:05.083505: Epoch time: 31.27 s 
2025-01-25 20:47:06.141447:  
2025-01-25 20:47:06.143722: Epoch 247 
2025-01-25 20:47:06.146097: Current learning rate: 0.00775 
2025-01-25 20:47:36.255814: train_loss -0.7712 
2025-01-25 20:47:36.261665: val_loss -0.7151 
2025-01-25 20:47:36.264262: Pseudo dice [np.float32(0.9534), np.float32(0.8325)] 
2025-01-25 20:47:36.266691: Epoch time: 30.12 s 
2025-01-25 20:47:37.304778:  
2025-01-25 20:47:37.307399: Epoch 248 
2025-01-25 20:47:37.309697: Current learning rate: 0.00774 
2025-01-25 20:48:07.233603: train_loss -0.7948 
2025-01-25 20:48:07.239890: val_loss -0.7451 
2025-01-25 20:48:07.242042: Pseudo dice [np.float32(0.9546), np.float32(0.8545)] 
2025-01-25 20:48:07.244330: Epoch time: 29.93 s 
2025-01-25 20:48:08.267616:  
2025-01-25 20:48:08.270376: Epoch 249 
2025-01-25 20:48:08.272789: Current learning rate: 0.00773 
2025-01-25 20:48:36.929540: train_loss -0.7796 
2025-01-25 20:48:36.933775: val_loss -0.7421 
2025-01-25 20:48:36.936062: Pseudo dice [np.float32(0.9533), np.float32(0.8636)] 
2025-01-25 20:48:36.938674: Epoch time: 28.66 s 
2025-01-25 20:48:38.489274:  
2025-01-25 20:48:38.491565: Epoch 250 
2025-01-25 20:48:38.493665: Current learning rate: 0.00772 
2025-01-25 20:49:07.100571: train_loss -0.7961 
2025-01-25 20:49:07.103388: val_loss -0.8046 
2025-01-25 20:49:07.105690: Pseudo dice [np.float32(0.9507), np.float32(0.9119)] 
2025-01-25 20:49:07.108090: Epoch time: 28.61 s 
2025-01-25 20:49:08.136381:  
2025-01-25 20:49:08.138721: Epoch 251 
2025-01-25 20:49:08.141026: Current learning rate: 0.00771 
2025-01-25 20:49:38.257687: train_loss -0.7931 
2025-01-25 20:49:38.265015: val_loss -0.7261 
2025-01-25 20:49:38.267589: Pseudo dice [np.float32(0.9579), np.float32(0.8632)] 
2025-01-25 20:49:38.270049: Epoch time: 30.12 s 
2025-01-25 20:49:39.297791:  
2025-01-25 20:49:39.300197: Epoch 252 
2025-01-25 20:49:39.302552: Current learning rate: 0.0077 
2025-01-25 20:50:09.212259: train_loss -0.8125 
2025-01-25 20:50:09.218927: val_loss -0.7571 
2025-01-25 20:50:09.221590: Pseudo dice [np.float32(0.9579), np.float32(0.8914)] 
2025-01-25 20:50:09.224055: Epoch time: 29.92 s 
2025-01-25 20:50:10.251286:  
2025-01-25 20:50:10.254088: Epoch 253 
2025-01-25 20:50:10.256476: Current learning rate: 0.00769 
2025-01-25 20:50:39.650558: train_loss -0.7977 
2025-01-25 20:50:39.661181: val_loss -0.7685 
2025-01-25 20:50:39.665603: Pseudo dice [np.float32(0.957), np.float32(0.8533)] 
2025-01-25 20:50:39.668087: Epoch time: 29.4 s 
2025-01-25 20:50:40.850799:  
2025-01-25 20:50:40.853560: Epoch 254 
2025-01-25 20:50:40.856284: Current learning rate: 0.00768 
2025-01-25 20:51:09.697833: train_loss -0.7935 
2025-01-25 20:51:09.704920: val_loss -0.7805 
2025-01-25 20:51:09.707535: Pseudo dice [np.float32(0.9482), np.float32(0.8606)] 
2025-01-25 20:51:09.739567: Epoch time: 28.85 s 
2025-01-25 20:51:11.228879:  
2025-01-25 20:51:11.231606: Epoch 255 
2025-01-25 20:51:11.234242: Current learning rate: 0.00767 
2025-01-25 20:51:39.820861: train_loss -0.7883 
2025-01-25 20:51:39.826192: val_loss -0.7103 
2025-01-25 20:51:39.828912: Pseudo dice [np.float32(0.9508), np.float32(0.854)] 
2025-01-25 20:51:39.831514: Epoch time: 28.59 s 
2025-01-25 20:51:40.877545:  
2025-01-25 20:51:40.881098: Epoch 256 
2025-01-25 20:51:40.883650: Current learning rate: 0.00766 
2025-01-25 20:52:10.082851: train_loss -0.8212 
2025-01-25 20:52:10.089379: val_loss -0.7868 
2025-01-25 20:52:10.091848: Pseudo dice [np.float32(0.9512), np.float32(0.8795)] 
2025-01-25 20:52:10.094151: Epoch time: 29.21 s 
2025-01-25 20:52:11.115998:  
2025-01-25 20:52:11.118864: Epoch 257 
2025-01-25 20:52:11.121741: Current learning rate: 0.00765 
2025-01-25 20:52:41.157087: train_loss -0.7956 
2025-01-25 20:52:41.162753: val_loss -0.735 
2025-01-25 20:52:41.165117: Pseudo dice [np.float32(0.9455), np.float32(0.8178)] 
2025-01-25 20:52:41.167688: Epoch time: 30.04 s 
2025-01-25 20:52:42.418299:  
2025-01-25 20:52:42.420779: Epoch 258 
2025-01-25 20:52:42.423424: Current learning rate: 0.00764 
2025-01-25 20:53:11.768815: train_loss -0.8155 
2025-01-25 20:53:11.777700: val_loss -0.7655 
2025-01-25 20:53:11.780468: Pseudo dice [np.float32(0.958), np.float32(0.8753)] 
2025-01-25 20:53:11.782834: Epoch time: 29.35 s 
2025-01-25 20:53:12.883999:  
2025-01-25 20:53:12.886690: Epoch 259 
2025-01-25 20:53:12.889084: Current learning rate: 0.00764 
2025-01-25 20:53:41.857702: train_loss -0.804 
2025-01-25 20:53:41.863633: val_loss -0.7875 
2025-01-25 20:53:41.866385: Pseudo dice [np.float32(0.9573), np.float32(0.9018)] 
2025-01-25 20:53:41.868841: Epoch time: 28.97 s 
2025-01-25 20:53:42.890970:  
2025-01-25 20:53:42.893726: Epoch 260 
2025-01-25 20:53:42.896436: Current learning rate: 0.00763 
2025-01-25 20:54:12.440054: train_loss -0.8099 
2025-01-25 20:54:12.448384: val_loss -0.7415 
2025-01-25 20:54:12.451385: Pseudo dice [np.float32(0.9504), np.float32(0.8745)] 
2025-01-25 20:54:12.454037: Epoch time: 29.55 s 
2025-01-25 20:54:13.501339:  
2025-01-25 20:54:13.504625: Epoch 261 
2025-01-25 20:54:13.507011: Current learning rate: 0.00762 
2025-01-25 20:54:41.886353: train_loss -0.8049 
2025-01-25 20:54:41.892879: val_loss -0.7952 
2025-01-25 20:54:41.895025: Pseudo dice [np.float32(0.9568), np.float32(0.8957)] 
2025-01-25 20:54:41.897308: Epoch time: 28.39 s 
2025-01-25 20:54:41.899508: Yayy! New best EMA pseudo Dice: 0.9106000065803528 
2025-01-25 20:54:43.465925:  
2025-01-25 20:54:43.468719: Epoch 262 
2025-01-25 20:54:43.470919: Current learning rate: 0.00761 
2025-01-25 20:55:11.703606: train_loss -0.8092 
2025-01-25 20:55:11.707944: val_loss -0.7445 
2025-01-25 20:55:11.710464: Pseudo dice [np.float32(0.9512), np.float32(0.8467)] 
2025-01-25 20:55:11.712828: Epoch time: 28.24 s 
2025-01-25 20:55:12.796149:  
2025-01-25 20:55:12.800790: Epoch 263 
2025-01-25 20:55:12.803138: Current learning rate: 0.0076 
2025-01-25 20:55:41.528720: train_loss -0.7902 
2025-01-25 20:55:41.531435: val_loss -0.7504 
2025-01-25 20:55:41.533683: Pseudo dice [np.float32(0.958), np.float32(0.8771)] 
2025-01-25 20:55:41.535892: Epoch time: 28.73 s 
2025-01-25 20:55:42.555742:  
2025-01-25 20:55:42.558188: Epoch 264 
2025-01-25 20:55:42.560526: Current learning rate: 0.00759 
2025-01-25 20:56:12.320787: train_loss -0.8216 
2025-01-25 20:56:12.325276: val_loss -0.8005 
2025-01-25 20:56:12.327907: Pseudo dice [np.float32(0.9581), np.float32(0.8803)] 
2025-01-25 20:56:12.330519: Epoch time: 29.77 s 
2025-01-25 20:56:12.332980: Yayy! New best EMA pseudo Dice: 0.9111999869346619 
2025-01-25 20:56:13.819732:  
2025-01-25 20:56:13.823368: Epoch 265 
2025-01-25 20:56:13.825825: Current learning rate: 0.00758 
2025-01-25 20:56:44.037135: train_loss -0.8223 
2025-01-25 20:56:44.039888: val_loss -0.7291 
2025-01-25 20:56:44.042008: Pseudo dice [np.float32(0.949), np.float32(0.819)] 
2025-01-25 20:56:44.044300: Epoch time: 30.22 s 
2025-01-25 20:56:45.066914:  
2025-01-25 20:56:45.069273: Epoch 266 
2025-01-25 20:56:45.071660: Current learning rate: 0.00757 
2025-01-25 20:57:15.107469: train_loss -0.8065 
2025-01-25 20:57:15.112511: val_loss -0.7394 
2025-01-25 20:57:15.114876: Pseudo dice [np.float32(0.9541), np.float32(0.8939)] 
2025-01-25 20:57:15.117249: Epoch time: 30.04 s 
2025-01-25 20:57:16.164697:  
2025-01-25 20:57:16.167299: Epoch 267 
2025-01-25 20:57:16.169639: Current learning rate: 0.00756 
2025-01-25 20:57:45.336519: train_loss -0.8044 
2025-01-25 20:57:45.339322: val_loss -0.7443 
2025-01-25 20:57:45.341638: Pseudo dice [np.float32(0.9597), np.float32(0.8865)] 
2025-01-25 20:57:45.343819: Epoch time: 29.17 s 
2025-01-25 20:57:45.346247: Yayy! New best EMA pseudo Dice: 0.911300003528595 
2025-01-25 20:57:46.968673:  
2025-01-25 20:57:46.971558: Epoch 268 
2025-01-25 20:57:46.974055: Current learning rate: 0.00755 
2025-01-25 20:58:17.661039: train_loss -0.7964 
2025-01-25 20:58:17.670856: val_loss -0.7683 
2025-01-25 20:58:17.673014: Pseudo dice [np.float32(0.9458), np.float32(0.8668)] 
2025-01-25 20:58:17.675657: Epoch time: 30.69 s 
2025-01-25 20:58:18.780434:  
2025-01-25 20:58:18.783073: Epoch 269 
2025-01-25 20:58:18.785794: Current learning rate: 0.00754 
2025-01-25 20:58:49.739979: train_loss -0.8005 
2025-01-25 20:58:49.754571: val_loss -0.8001 
2025-01-25 20:58:49.757301: Pseudo dice [np.float32(0.9578), np.float32(0.8991)] 
2025-01-25 20:58:49.759703: Epoch time: 30.96 s 
2025-01-25 20:58:49.762103: Yayy! New best EMA pseudo Dice: 0.9125999808311462 
2025-01-25 20:58:51.431838:  
2025-01-25 20:58:51.434376: Epoch 270 
2025-01-25 20:58:51.437130: Current learning rate: 0.00753 
2025-01-25 20:59:20.145050: train_loss -0.7964 
2025-01-25 20:59:20.153619: val_loss -0.7664 
2025-01-25 20:59:20.156315: Pseudo dice [np.float32(0.9574), np.float32(0.8864)] 
2025-01-25 20:59:20.159033: Epoch time: 28.71 s 
2025-01-25 20:59:20.161498: Yayy! New best EMA pseudo Dice: 0.9135000109672546 
2025-01-25 20:59:21.874288:  
2025-01-25 20:59:21.876768: Epoch 271 
2025-01-25 20:59:21.878885: Current learning rate: 0.00752 
2025-01-25 20:59:50.979337: train_loss -0.8216 
2025-01-25 20:59:50.981989: val_loss -0.7378 
2025-01-25 20:59:50.984166: Pseudo dice [np.float32(0.9495), np.float32(0.8401)] 
2025-01-25 20:59:50.986392: Epoch time: 29.11 s 
2025-01-25 20:59:52.008937:  
2025-01-25 20:59:52.011544: Epoch 272 
2025-01-25 20:59:52.013938: Current learning rate: 0.00751 
2025-01-25 21:00:21.368523: train_loss -0.8129 
2025-01-25 21:00:21.373774: val_loss -0.7647 
2025-01-25 21:00:21.376398: Pseudo dice [np.float32(0.9478), np.float32(0.8909)] 
2025-01-25 21:00:21.378796: Epoch time: 29.36 s 
2025-01-25 21:00:22.420543:  
2025-01-25 21:00:22.423050: Epoch 273 
2025-01-25 21:00:22.425242: Current learning rate: 0.00751 
2025-01-25 21:00:51.968781: train_loss -0.8174 
2025-01-25 21:00:51.971713: val_loss -0.7295 
2025-01-25 21:00:51.974111: Pseudo dice [np.float32(0.951), np.float32(0.85)] 
2025-01-25 21:00:51.976570: Epoch time: 29.55 s 
2025-01-25 21:00:53.439094:  
2025-01-25 21:00:53.441605: Epoch 274 
2025-01-25 21:00:53.443979: Current learning rate: 0.0075 
2025-01-25 21:01:22.183327: train_loss -0.803 
2025-01-25 21:01:22.189499: val_loss -0.7649 
2025-01-25 21:01:22.192062: Pseudo dice [np.float32(0.9511), np.float32(0.8876)] 
2025-01-25 21:01:22.194368: Epoch time: 28.75 s 
2025-01-25 21:01:23.222884:  
2025-01-25 21:01:23.225590: Epoch 275 
2025-01-25 21:01:23.227773: Current learning rate: 0.00749 
2025-01-25 21:01:51.579151: train_loss -0.7975 
2025-01-25 21:01:51.583964: val_loss -0.7986 
2025-01-25 21:01:51.586087: Pseudo dice [np.float32(0.9544), np.float32(0.8949)] 
2025-01-25 21:01:51.588442: Epoch time: 28.36 s 
2025-01-25 21:01:52.621189:  
2025-01-25 21:01:52.623950: Epoch 276 
2025-01-25 21:01:52.626678: Current learning rate: 0.00748 
2025-01-25 21:02:21.652484: train_loss -0.8115 
2025-01-25 21:02:21.657120: val_loss -0.7279 
2025-01-25 21:02:21.660072: Pseudo dice [np.float32(0.9474), np.float32(0.8742)] 
2025-01-25 21:02:21.662960: Epoch time: 29.03 s 
2025-01-25 21:02:22.693057:  
2025-01-25 21:02:22.698289: Epoch 277 
2025-01-25 21:02:22.700754: Current learning rate: 0.00747 
2025-01-25 21:02:52.151939: train_loss -0.8052 
2025-01-25 21:02:52.159662: val_loss -0.7416 
2025-01-25 21:02:52.161976: Pseudo dice [np.float32(0.9455), np.float32(0.8123)] 
2025-01-25 21:02:52.164319: Epoch time: 29.46 s 
2025-01-25 21:02:53.215340:  
2025-01-25 21:02:53.218223: Epoch 278 
2025-01-25 21:02:53.220800: Current learning rate: 0.00746 
2025-01-25 21:03:21.951179: train_loss -0.7947 
2025-01-25 21:03:21.955752: val_loss -0.7647 
2025-01-25 21:03:21.959704: Pseudo dice [np.float32(0.9552), np.float32(0.8801)] 
2025-01-25 21:03:21.962261: Epoch time: 28.74 s 
2025-01-25 21:03:22.990473:  
2025-01-25 21:03:22.996156: Epoch 279 
2025-01-25 21:03:22.998800: Current learning rate: 0.00745 
2025-01-25 21:03:53.943261: train_loss -0.811 
2025-01-25 21:03:53.949937: val_loss -0.7982 
2025-01-25 21:03:53.952557: Pseudo dice [np.float32(0.9554), np.float32(0.8612)] 
2025-01-25 21:03:53.955071: Epoch time: 30.95 s 
2025-01-25 21:03:54.991548:  
2025-01-25 21:03:54.993955: Epoch 280 
2025-01-25 21:03:54.996308: Current learning rate: 0.00744 
2025-01-25 21:04:24.059935: train_loss -0.8039 
2025-01-25 21:04:24.065846: val_loss -0.7532 
2025-01-25 21:04:24.068435: Pseudo dice [np.float32(0.9518), np.float32(0.8569)] 
2025-01-25 21:04:24.070976: Epoch time: 29.07 s 
2025-01-25 21:04:25.097003:  
2025-01-25 21:04:25.099665: Epoch 281 
2025-01-25 21:04:25.102164: Current learning rate: 0.00743 
2025-01-25 21:04:54.551940: train_loss -0.8168 
2025-01-25 21:04:54.559057: val_loss -0.7609 
2025-01-25 21:04:54.561463: Pseudo dice [np.float32(0.963), np.float32(0.884)] 
2025-01-25 21:04:54.563930: Epoch time: 29.46 s 
2025-01-25 21:04:55.741379:  
2025-01-25 21:04:55.743837: Epoch 282 
2025-01-25 21:04:55.746323: Current learning rate: 0.00742 
2025-01-25 21:05:25.990274: train_loss -0.8226 
2025-01-25 21:05:25.996177: val_loss -0.7621 
2025-01-25 21:05:25.999050: Pseudo dice [np.float32(0.9614), np.float32(0.8916)] 
2025-01-25 21:05:26.001635: Epoch time: 30.25 s 
2025-01-25 21:05:27.035011:  
2025-01-25 21:05:27.037541: Epoch 283 
2025-01-25 21:05:27.039894: Current learning rate: 0.00741 
2025-01-25 21:05:58.120519: train_loss -0.8197 
2025-01-25 21:05:58.127674: val_loss -0.7688 
2025-01-25 21:05:58.130330: Pseudo dice [np.float32(0.958), np.float32(0.912)] 
2025-01-25 21:05:58.133060: Epoch time: 31.09 s 
2025-01-25 21:05:58.136042: Yayy! New best EMA pseudo Dice: 0.9147999882698059 
2025-01-25 21:06:00.049951:  
2025-01-25 21:06:00.052393: Epoch 284 
2025-01-25 21:06:00.054947: Current learning rate: 0.0074 
2025-01-25 21:06:30.450620: train_loss -0.8011 
2025-01-25 21:06:30.458064: val_loss -0.7518 
2025-01-25 21:06:30.460695: Pseudo dice [np.float32(0.9592), np.float32(0.9028)] 
2025-01-25 21:06:30.463340: Epoch time: 30.4 s 
2025-01-25 21:06:30.465695: Yayy! New best EMA pseudo Dice: 0.9164000153541565 
2025-01-25 21:06:32.067164:  
2025-01-25 21:06:32.069970: Epoch 285 
2025-01-25 21:06:32.073072: Current learning rate: 0.00739 
2025-01-25 21:07:00.765897: train_loss -0.8116 
2025-01-25 21:07:00.770712: val_loss -0.8041 
2025-01-25 21:07:00.773308: Pseudo dice [np.float32(0.9522), np.float32(0.8919)] 
2025-01-25 21:07:00.775821: Epoch time: 28.7 s 
2025-01-25 21:07:00.778356: Yayy! New best EMA pseudo Dice: 0.9169999957084656 
2025-01-25 21:07:02.302234:  
2025-01-25 21:07:02.304812: Epoch 286 
2025-01-25 21:07:02.307414: Current learning rate: 0.00738 
2025-01-25 21:07:32.390313: train_loss -0.8028 
2025-01-25 21:07:32.396739: val_loss -0.7705 
2025-01-25 21:07:32.399259: Pseudo dice [np.float32(0.9594), np.float32(0.8829)] 
2025-01-25 21:07:32.402067: Epoch time: 30.09 s 
2025-01-25 21:07:32.404410: Yayy! New best EMA pseudo Dice: 0.9174000024795532 
2025-01-25 21:07:33.939276:  
2025-01-25 21:07:33.941945: Epoch 287 
2025-01-25 21:07:33.944433: Current learning rate: 0.00738 
2025-01-25 21:08:02.918510: train_loss -0.8354 
2025-01-25 21:08:02.922292: val_loss -0.7867 
2025-01-25 21:08:02.924654: Pseudo dice [np.float32(0.9539), np.float32(0.8801)] 
2025-01-25 21:08:02.927043: Epoch time: 28.98 s 
2025-01-25 21:08:03.969278:  
2025-01-25 21:08:03.973148: Epoch 288 
2025-01-25 21:08:03.976231: Current learning rate: 0.00737 
2025-01-25 21:08:32.829231: train_loss -0.799 
2025-01-25 21:08:32.836162: val_loss -0.7652 
2025-01-25 21:08:32.838384: Pseudo dice [np.float32(0.9461), np.float32(0.8202)] 
2025-01-25 21:08:32.840978: Epoch time: 28.86 s 
2025-01-25 21:08:33.877343:  
2025-01-25 21:08:33.880486: Epoch 289 
2025-01-25 21:08:33.883149: Current learning rate: 0.00736 
2025-01-25 21:09:03.528040: train_loss -0.7991 
2025-01-25 21:09:03.533963: val_loss -0.7568 
2025-01-25 21:09:03.536393: Pseudo dice [np.float32(0.9458), np.float32(0.8481)] 
2025-01-25 21:09:03.538711: Epoch time: 29.65 s 
2025-01-25 21:09:04.596608:  
2025-01-25 21:09:04.600147: Epoch 290 
2025-01-25 21:09:04.602531: Current learning rate: 0.00735 
2025-01-25 21:09:34.266117: train_loss -0.8129 
2025-01-25 21:09:34.273807: val_loss -0.763 
2025-01-25 21:09:34.276660: Pseudo dice [np.float32(0.9593), np.float32(0.8925)] 
2025-01-25 21:09:34.279052: Epoch time: 29.67 s 
2025-01-25 21:09:35.334836:  
2025-01-25 21:09:35.337136: Epoch 291 
2025-01-25 21:09:35.339340: Current learning rate: 0.00734 
2025-01-25 21:10:04.331095: train_loss -0.8128 
2025-01-25 21:10:04.337171: val_loss -0.7675 
2025-01-25 21:10:04.339664: Pseudo dice [np.float32(0.9542), np.float32(0.8865)] 
2025-01-25 21:10:04.342006: Epoch time: 29.0 s 
2025-01-25 21:10:05.391804:  
2025-01-25 21:10:05.394789: Epoch 292 
2025-01-25 21:10:05.398059: Current learning rate: 0.00733 
2025-01-25 21:10:34.570672: train_loss -0.7921 
2025-01-25 21:10:34.576226: val_loss -0.7873 
2025-01-25 21:10:34.578410: Pseudo dice [np.float32(0.9589), np.float32(0.8979)] 
2025-01-25 21:10:34.580686: Epoch time: 29.18 s 
2025-01-25 21:10:36.044480:  
2025-01-25 21:10:36.046876: Epoch 293 
2025-01-25 21:10:36.049220: Current learning rate: 0.00732 
2025-01-25 21:11:05.552938: train_loss -0.778 
2025-01-25 21:11:05.556090: val_loss -0.7573 
2025-01-25 21:11:05.558508: Pseudo dice [np.float32(0.9553), np.float32(0.7914)] 
2025-01-25 21:11:05.560961: Epoch time: 29.51 s 
2025-01-25 21:11:06.600011:  
2025-01-25 21:11:06.603073: Epoch 294 
2025-01-25 21:11:06.605449: Current learning rate: 0.00731 
2025-01-25 21:11:36.408421: train_loss -0.7864 
2025-01-25 21:11:36.413898: val_loss -0.7648 
2025-01-25 21:11:36.416100: Pseudo dice [np.float32(0.9551), np.float32(0.8932)] 
2025-01-25 21:11:36.418259: Epoch time: 29.81 s 
2025-01-25 21:11:37.457245:  
2025-01-25 21:11:37.459992: Epoch 295 
2025-01-25 21:11:37.462247: Current learning rate: 0.0073 
2025-01-25 21:12:06.793262: train_loss -0.7895 
2025-01-25 21:12:06.796113: val_loss -0.7694 
2025-01-25 21:12:06.798473: Pseudo dice [np.float32(0.9455), np.float32(0.8749)] 
2025-01-25 21:12:06.800916: Epoch time: 29.34 s 
2025-01-25 21:12:07.840666:  
2025-01-25 21:12:07.843372: Epoch 296 
2025-01-25 21:12:07.845935: Current learning rate: 0.00729 
2025-01-25 21:12:38.558243: train_loss -0.8151 
2025-01-25 21:12:38.566476: val_loss -0.7922 
2025-01-25 21:12:38.569019: Pseudo dice [np.float32(0.9635), np.float32(0.8978)] 
2025-01-25 21:12:38.572588: Epoch time: 30.72 s 
2025-01-25 21:12:39.811911:  
2025-01-25 21:12:39.814952: Epoch 297 
2025-01-25 21:12:39.817992: Current learning rate: 0.00728 
2025-01-25 21:13:08.508497: train_loss -0.8106 
2025-01-25 21:13:08.511284: val_loss -0.7659 
2025-01-25 21:13:08.513773: Pseudo dice [np.float32(0.9458), np.float32(0.8915)] 
2025-01-25 21:13:08.516076: Epoch time: 28.7 s 
2025-01-25 21:13:09.553598:  
2025-01-25 21:13:09.556126: Epoch 298 
2025-01-25 21:13:09.558456: Current learning rate: 0.00727 
2025-01-25 21:13:40.451744: train_loss -0.7935 
2025-01-25 21:13:40.459023: val_loss -0.7985 
2025-01-25 21:13:40.461332: Pseudo dice [np.float32(0.9498), np.float32(0.8484)] 
2025-01-25 21:13:40.463862: Epoch time: 30.9 s 
2025-01-25 21:13:41.610204:  
2025-01-25 21:13:41.613377: Epoch 299 
2025-01-25 21:13:41.616153: Current learning rate: 0.00726 
2025-01-25 21:14:13.311897: train_loss -0.8089 
2025-01-25 21:14:13.314964: val_loss -0.8043 
2025-01-25 21:14:13.317647: Pseudo dice [np.float32(0.9595), np.float32(0.9059)] 
2025-01-25 21:14:13.320225: Epoch time: 31.7 s 
2025-01-25 21:14:14.827329:  
2025-01-25 21:14:14.831389: Epoch 300 
2025-01-25 21:14:14.833913: Current learning rate: 0.00725 
2025-01-25 21:14:43.989656: train_loss -0.8105 
2025-01-25 21:14:43.994903: val_loss -0.7142 
2025-01-25 21:14:43.997522: Pseudo dice [np.float32(0.9392), np.float32(0.7883)] 
2025-01-25 21:14:43.999949: Epoch time: 29.16 s 
2025-01-25 21:14:45.046858:  
2025-01-25 21:14:45.049303: Epoch 301 
2025-01-25 21:14:45.051981: Current learning rate: 0.00724 
2025-01-25 21:15:14.678254: train_loss -0.7948 
2025-01-25 21:15:14.681216: val_loss -0.729 
2025-01-25 21:15:14.683960: Pseudo dice [np.float32(0.9356), np.float32(0.708)] 
2025-01-25 21:15:14.686265: Epoch time: 29.63 s 
2025-01-25 21:15:15.727551:  
2025-01-25 21:15:15.730015: Epoch 302 
2025-01-25 21:15:15.732143: Current learning rate: 0.00724 
2025-01-25 21:15:46.100895: train_loss -0.778 
2025-01-25 21:15:46.106554: val_loss -0.756 
2025-01-25 21:15:46.109018: Pseudo dice [np.float32(0.9465), np.float32(0.8757)] 
2025-01-25 21:15:46.111166: Epoch time: 30.37 s 
2025-01-25 21:15:47.142766:  
2025-01-25 21:15:47.145488: Epoch 303 
2025-01-25 21:15:47.147851: Current learning rate: 0.00723 
2025-01-25 21:16:17.867888: train_loss -0.7957 
2025-01-25 21:16:17.870243: val_loss -0.748 
2025-01-25 21:16:17.872508: Pseudo dice [np.float32(0.9512), np.float32(0.8885)] 
2025-01-25 21:16:17.874725: Epoch time: 30.73 s 
2025-01-25 21:16:18.920083:  
2025-01-25 21:16:18.922739: Epoch 304 
2025-01-25 21:16:18.925339: Current learning rate: 0.00722 
2025-01-25 21:16:48.883700: train_loss -0.7991 
2025-01-25 21:16:48.896342: val_loss -0.7947 
2025-01-25 21:16:48.898530: Pseudo dice [np.float32(0.9603), np.float32(0.8972)] 
2025-01-25 21:16:48.901015: Epoch time: 29.96 s 
2025-01-25 21:16:49.954148:  
2025-01-25 21:16:49.956504: Epoch 305 
2025-01-25 21:16:49.958543: Current learning rate: 0.00721 
2025-01-25 21:17:18.525998: train_loss -0.7992 
2025-01-25 21:17:18.528661: val_loss -0.7797 
2025-01-25 21:17:18.531065: Pseudo dice [np.float32(0.9527), np.float32(0.8792)] 
2025-01-25 21:17:18.533111: Epoch time: 28.57 s 
2025-01-25 21:17:19.572043:  
2025-01-25 21:17:19.574546: Epoch 306 
2025-01-25 21:17:19.576926: Current learning rate: 0.0072 
2025-01-25 21:17:51.069016: train_loss -0.796 
2025-01-25 21:17:51.073800: val_loss -0.7657 
2025-01-25 21:17:51.076112: Pseudo dice [np.float32(0.9606), np.float32(0.9012)] 
2025-01-25 21:17:51.078436: Epoch time: 31.5 s 
2025-01-25 21:17:52.117754:  
2025-01-25 21:17:52.120353: Epoch 307 
2025-01-25 21:17:52.122703: Current learning rate: 0.00719 
2025-01-25 21:18:22.141467: train_loss -0.8093 
2025-01-25 21:18:22.145163: val_loss -0.7335 
2025-01-25 21:18:22.148126: Pseudo dice [np.float32(0.9485), np.float32(0.8558)] 
2025-01-25 21:18:22.151213: Epoch time: 30.02 s 
2025-01-25 21:18:23.194165:  
2025-01-25 21:18:23.197075: Epoch 308 
2025-01-25 21:18:23.199672: Current learning rate: 0.00718 
2025-01-25 21:18:52.152844: train_loss -0.8126 
2025-01-25 21:18:52.158141: val_loss -0.7394 
2025-01-25 21:18:52.160647: Pseudo dice [np.float32(0.9531), np.float32(0.8576)] 
2025-01-25 21:18:52.163027: Epoch time: 28.96 s 
2025-01-25 21:18:53.252848:  
2025-01-25 21:18:53.255570: Epoch 309 
2025-01-25 21:18:53.258286: Current learning rate: 0.00717 
2025-01-25 21:19:22.498402: train_loss -0.8104 
2025-01-25 21:19:22.501476: val_loss -0.7616 
2025-01-25 21:19:22.503982: Pseudo dice [np.float32(0.9469), np.float32(0.8856)] 
2025-01-25 21:19:22.506251: Epoch time: 29.25 s 
2025-01-25 21:19:23.538725:  
2025-01-25 21:19:23.541469: Epoch 310 
2025-01-25 21:19:23.544208: Current learning rate: 0.00716 
2025-01-25 21:19:52.264404: train_loss -0.7919 
2025-01-25 21:19:52.270141: val_loss -0.7682 
2025-01-25 21:19:52.272694: Pseudo dice [np.float32(0.9511), np.float32(0.867)] 
2025-01-25 21:19:52.274913: Epoch time: 28.73 s 
2025-01-25 21:19:53.750961:  
2025-01-25 21:19:53.753363: Epoch 311 
2025-01-25 21:19:53.755686: Current learning rate: 0.00715 
2025-01-25 21:20:23.431151: train_loss -0.8048 
2025-01-25 21:20:23.433759: val_loss -0.7449 
2025-01-25 21:20:23.436099: Pseudo dice [np.float32(0.953), np.float32(0.8376)] 
2025-01-25 21:20:23.438514: Epoch time: 29.68 s 
2025-01-25 21:20:24.484835:  
2025-01-25 21:20:24.487482: Epoch 312 
2025-01-25 21:20:24.490026: Current learning rate: 0.00714 
2025-01-25 21:20:54.411112: train_loss -0.8071 
2025-01-25 21:20:54.416967: val_loss -0.8107 
2025-01-25 21:20:54.419796: Pseudo dice [np.float32(0.954), np.float32(0.8947)] 
2025-01-25 21:20:54.422264: Epoch time: 29.93 s 
2025-01-25 21:20:55.475000:  
2025-01-25 21:20:55.477524: Epoch 313 
2025-01-25 21:20:55.479656: Current learning rate: 0.00713 
2025-01-25 21:21:26.309630: train_loss -0.8255 
2025-01-25 21:21:26.312943: val_loss -0.7673 
2025-01-25 21:21:26.315630: Pseudo dice [np.float32(0.9561), np.float32(0.7611)] 
2025-01-25 21:21:26.318395: Epoch time: 30.84 s 
2025-01-25 21:21:27.359295:  
2025-01-25 21:21:27.361808: Epoch 314 
2025-01-25 21:21:27.364213: Current learning rate: 0.00712 
2025-01-25 21:21:56.467439: train_loss -0.7991 
2025-01-25 21:21:56.473276: val_loss -0.7846 
2025-01-25 21:21:56.475687: Pseudo dice [np.float32(0.955), np.float32(0.88)] 
2025-01-25 21:21:56.477961: Epoch time: 29.11 s 
2025-01-25 21:21:57.534813:  
2025-01-25 21:21:57.537699: Epoch 315 
2025-01-25 21:21:57.540046: Current learning rate: 0.00711 
2025-01-25 21:22:27.707343: train_loss -0.7918 
2025-01-25 21:22:27.710408: val_loss -0.7857 
2025-01-25 21:22:27.714715: Pseudo dice [np.float32(0.9568), np.float32(0.9011)] 
2025-01-25 21:22:27.717335: Epoch time: 30.17 s 
2025-01-25 21:22:28.796089:  
2025-01-25 21:22:28.798634: Epoch 316 
2025-01-25 21:22:28.801123: Current learning rate: 0.0071 
2025-01-25 21:22:58.566812: train_loss -0.8021 
2025-01-25 21:22:58.575079: val_loss -0.7679 
2025-01-25 21:22:58.577624: Pseudo dice [np.float32(0.9583), np.float32(0.8669)] 
2025-01-25 21:22:58.579975: Epoch time: 29.77 s 
2025-01-25 21:22:59.726202:  
2025-01-25 21:22:59.728902: Epoch 317 
2025-01-25 21:22:59.731407: Current learning rate: 0.0071 
2025-01-25 21:23:29.298770: train_loss -0.802 
2025-01-25 21:23:29.301587: val_loss -0.8027 
2025-01-25 21:23:29.304178: Pseudo dice [np.float32(0.9489), np.float32(0.8857)] 
2025-01-25 21:23:29.306527: Epoch time: 29.57 s 
2025-01-25 21:23:30.356162:  
2025-01-25 21:23:30.358559: Epoch 318 
2025-01-25 21:23:30.361119: Current learning rate: 0.00709 
2025-01-25 21:24:00.547060: train_loss -0.8064 
2025-01-25 21:24:00.552776: val_loss -0.7942 
2025-01-25 21:24:00.555197: Pseudo dice [np.float32(0.9547), np.float32(0.8972)] 
2025-01-25 21:24:00.557622: Epoch time: 30.19 s 
2025-01-25 21:24:01.605636:  
2025-01-25 21:24:01.608714: Epoch 319 
2025-01-25 21:24:01.611933: Current learning rate: 0.00708 
2025-01-25 21:24:30.627385: train_loss -0.7875 
2025-01-25 21:24:30.633887: val_loss -0.7743 
2025-01-25 21:24:30.636291: Pseudo dice [np.float32(0.9571), np.float32(0.8765)] 
2025-01-25 21:24:30.638442: Epoch time: 29.02 s 
2025-01-25 21:24:31.824683:  
2025-01-25 21:24:31.827185: Epoch 320 
2025-01-25 21:24:31.829691: Current learning rate: 0.00707 
2025-01-25 21:25:00.975816: train_loss -0.8012 
2025-01-25 21:25:00.981240: val_loss -0.7532 
2025-01-25 21:25:00.983776: Pseudo dice [np.float32(0.948), np.float32(0.8199)] 
2025-01-25 21:25:00.986043: Epoch time: 29.15 s 
2025-01-25 21:25:02.032169:  
2025-01-25 21:25:02.034868: Epoch 321 
2025-01-25 21:25:02.037392: Current learning rate: 0.00706 
2025-01-25 21:25:31.298913: train_loss -0.8111 
2025-01-25 21:25:31.302235: val_loss -0.7706 
2025-01-25 21:25:31.304835: Pseudo dice [np.float32(0.9513), np.float32(0.8791)] 
2025-01-25 21:25:31.307329: Epoch time: 29.27 s 
2025-01-25 21:25:32.351563:  
2025-01-25 21:25:32.354117: Epoch 322 
2025-01-25 21:25:32.356809: Current learning rate: 0.00705 
2025-01-25 21:26:01.662131: train_loss -0.8181 
2025-01-25 21:26:01.673159: val_loss -0.7843 
2025-01-25 21:26:01.675568: Pseudo dice [np.float32(0.9544), np.float32(0.8935)] 
2025-01-25 21:26:01.679829: Epoch time: 29.31 s 
2025-01-25 21:26:02.741497:  
2025-01-25 21:26:02.744238: Epoch 323 
2025-01-25 21:26:02.746963: Current learning rate: 0.00704 
2025-01-25 21:26:31.558598: train_loss -0.7913 
2025-01-25 21:26:31.561211: val_loss -0.7233 
2025-01-25 21:26:31.563601: Pseudo dice [np.float32(0.9533), np.float32(0.8396)] 
2025-01-25 21:26:31.565921: Epoch time: 28.82 s 
2025-01-25 21:26:32.603530:  
2025-01-25 21:26:32.605958: Epoch 324 
2025-01-25 21:26:32.608363: Current learning rate: 0.00703 
2025-01-25 21:27:01.561622: train_loss -0.8093 
2025-01-25 21:27:01.565913: val_loss -0.7684 
2025-01-25 21:27:01.569445: Pseudo dice [np.float32(0.9531), np.float32(0.87)] 
2025-01-25 21:27:01.571786: Epoch time: 28.96 s 
2025-01-25 21:27:02.666906:  
2025-01-25 21:27:02.669516: Epoch 325 
2025-01-25 21:27:02.671746: Current learning rate: 0.00702 
2025-01-25 21:27:31.959033: train_loss -0.8132 
2025-01-25 21:27:31.962056: val_loss -0.7662 
2025-01-25 21:27:31.964395: Pseudo dice [np.float32(0.9545), np.float32(0.8824)] 
2025-01-25 21:27:31.966697: Epoch time: 29.29 s 
2025-01-25 21:27:33.007355:  
2025-01-25 21:27:33.009893: Epoch 326 
2025-01-25 21:27:33.012212: Current learning rate: 0.00701 
2025-01-25 21:28:02.898103: train_loss -0.8147 
2025-01-25 21:28:02.903840: val_loss -0.7872 
2025-01-25 21:28:02.906245: Pseudo dice [np.float32(0.9493), np.float32(0.8707)] 
2025-01-25 21:28:02.908499: Epoch time: 29.89 s 
2025-01-25 21:28:03.969127:  
2025-01-25 21:28:03.971567: Epoch 327 
2025-01-25 21:28:03.974013: Current learning rate: 0.007 
2025-01-25 21:28:33.488024: train_loss -0.8192 
2025-01-25 21:28:33.503563: val_loss -0.7924 
2025-01-25 21:28:33.506051: Pseudo dice [np.float32(0.954), np.float32(0.8942)] 
2025-01-25 21:28:33.508370: Epoch time: 29.52 s 
2025-01-25 21:28:34.579178:  
2025-01-25 21:28:34.581560: Epoch 328 
2025-01-25 21:28:34.583953: Current learning rate: 0.00699 
2025-01-25 21:29:05.107981: train_loss -0.8254 
2025-01-25 21:29:05.113224: val_loss -0.74 
2025-01-25 21:29:05.115873: Pseudo dice [np.float32(0.9559), np.float32(0.869)] 
2025-01-25 21:29:05.118288: Epoch time: 30.53 s 
2025-01-25 21:29:06.602448:  
2025-01-25 21:29:06.604942: Epoch 329 
2025-01-25 21:29:06.607303: Current learning rate: 0.00698 
2025-01-25 21:29:37.527719: train_loss -0.8063 
2025-01-25 21:29:37.534714: val_loss -0.76 
2025-01-25 21:29:37.537318: Pseudo dice [np.float32(0.9629), np.float32(0.8795)] 
2025-01-25 21:29:37.539451: Epoch time: 30.93 s 
2025-01-25 21:29:38.635235:  
2025-01-25 21:29:38.637651: Epoch 330 
2025-01-25 21:29:38.639949: Current learning rate: 0.00697 
2025-01-25 21:30:08.241132: train_loss -0.7946 
2025-01-25 21:30:08.246987: val_loss -0.7558 
2025-01-25 21:30:08.249621: Pseudo dice [np.float32(0.9607), np.float32(0.8853)] 
2025-01-25 21:30:08.252186: Epoch time: 29.61 s 
2025-01-25 21:30:09.315920:  
2025-01-25 21:30:09.318588: Epoch 331 
2025-01-25 21:30:09.321091: Current learning rate: 0.00696 
2025-01-25 21:30:39.693998: train_loss -0.8098 
2025-01-25 21:30:39.697990: val_loss -0.7386 
2025-01-25 21:30:39.700387: Pseudo dice [np.float32(0.9556), np.float32(0.8998)] 
2025-01-25 21:30:39.702558: Epoch time: 30.38 s 
2025-01-25 21:30:40.748139:  
2025-01-25 21:30:40.750569: Epoch 332 
2025-01-25 21:30:40.752913: Current learning rate: 0.00696 
2025-01-25 21:31:10.181785: train_loss -0.8059 
2025-01-25 21:31:10.190771: val_loss -0.7235 
2025-01-25 21:31:10.193593: Pseudo dice [np.float32(0.9589), np.float32(0.8747)] 
2025-01-25 21:31:10.196248: Epoch time: 29.43 s 
2025-01-25 21:31:11.245704:  
2025-01-25 21:31:11.248316: Epoch 333 
2025-01-25 21:31:11.250620: Current learning rate: 0.00695 
2025-01-25 21:31:40.410190: train_loss -0.7844 
2025-01-25 21:31:40.414841: val_loss -0.7462 
2025-01-25 21:31:40.417598: Pseudo dice [np.float32(0.9492), np.float32(0.826)] 
2025-01-25 21:31:40.420032: Epoch time: 29.17 s 
2025-01-25 21:31:41.477812:  
2025-01-25 21:31:41.480283: Epoch 334 
2025-01-25 21:31:41.482482: Current learning rate: 0.00694 
2025-01-25 21:32:10.931437: train_loss -0.8188 
2025-01-25 21:32:10.937016: val_loss -0.7474 
2025-01-25 21:32:10.939461: Pseudo dice [np.float32(0.9479), np.float32(0.8482)] 
2025-01-25 21:32:10.942094: Epoch time: 29.45 s 
2025-01-25 21:32:11.999772:  
2025-01-25 21:32:12.002969: Epoch 335 
2025-01-25 21:32:12.005733: Current learning rate: 0.00693 
2025-01-25 21:32:41.241022: train_loss -0.7907 
2025-01-25 21:32:41.246520: val_loss -0.7867 
2025-01-25 21:32:41.249203: Pseudo dice [np.float32(0.9536), np.float32(0.8563)] 
2025-01-25 21:32:41.252529: Epoch time: 29.24 s 
2025-01-25 21:32:42.331176:  
2025-01-25 21:32:42.333448: Epoch 336 
2025-01-25 21:32:42.335662: Current learning rate: 0.00692 
2025-01-25 21:33:11.151973: train_loss -0.8129 
2025-01-25 21:33:11.157959: val_loss -0.7768 
2025-01-25 21:33:11.160264: Pseudo dice [np.float32(0.9504), np.float32(0.8735)] 
2025-01-25 21:33:11.162337: Epoch time: 28.82 s 
2025-01-25 21:33:12.219165:  
2025-01-25 21:33:12.221830: Epoch 337 
2025-01-25 21:33:12.224087: Current learning rate: 0.00691 
2025-01-25 21:33:41.180871: train_loss -0.8068 
2025-01-25 21:33:41.189372: val_loss -0.7468 
2025-01-25 21:33:41.193712: Pseudo dice [np.float32(0.9504), np.float32(0.8696)] 
2025-01-25 21:33:41.197032: Epoch time: 28.96 s 
2025-01-25 21:33:42.300336:  
2025-01-25 21:33:42.302761: Epoch 338 
2025-01-25 21:33:42.304938: Current learning rate: 0.0069 
2025-01-25 21:34:11.932220: train_loss -0.8296 
2025-01-25 21:34:11.938121: val_loss -0.7553 
2025-01-25 21:34:11.940371: Pseudo dice [np.float32(0.956), np.float32(0.882)] 
2025-01-25 21:34:11.942511: Epoch time: 29.63 s 
2025-01-25 21:34:13.000710:  
2025-01-25 21:34:13.003129: Epoch 339 
2025-01-25 21:34:13.005262: Current learning rate: 0.00689 
2025-01-25 21:34:42.078923: train_loss -0.8234 
2025-01-25 21:34:42.087527: val_loss -0.7553 
2025-01-25 21:34:42.092120: Pseudo dice [np.float32(0.9554), np.float32(0.8872)] 
2025-01-25 21:34:42.094523: Epoch time: 29.08 s 
2025-01-25 21:34:43.626227:  
2025-01-25 21:34:43.628713: Epoch 340 
2025-01-25 21:34:43.631039: Current learning rate: 0.00688 
2025-01-25 21:35:12.375156: train_loss -0.8057 
2025-01-25 21:35:12.380943: val_loss -0.7539 
2025-01-25 21:35:12.383456: Pseudo dice [np.float32(0.9495), np.float32(0.9045)] 
2025-01-25 21:35:12.385854: Epoch time: 28.75 s 
2025-01-25 21:35:13.446495:  
2025-01-25 21:35:13.449378: Epoch 341 
2025-01-25 21:35:13.452140: Current learning rate: 0.00687 
2025-01-25 21:35:43.333781: train_loss -0.805 
2025-01-25 21:35:43.339713: val_loss -0.732 
2025-01-25 21:35:43.341905: Pseudo dice [np.float32(0.9504), np.float32(0.8201)] 
2025-01-25 21:35:43.344029: Epoch time: 29.89 s 
2025-01-25 21:35:44.403418:  
2025-01-25 21:35:44.406203: Epoch 342 
2025-01-25 21:35:44.409026: Current learning rate: 0.00686 
2025-01-25 21:36:14.980642: train_loss -0.7909 
2025-01-25 21:36:14.989246: val_loss -0.7806 
2025-01-25 21:36:14.991727: Pseudo dice [np.float32(0.9561), np.float32(0.8528)] 
2025-01-25 21:36:14.994092: Epoch time: 30.58 s 
2025-01-25 21:36:16.085650:  
2025-01-25 21:36:16.088084: Epoch 343 
2025-01-25 21:36:16.090342: Current learning rate: 0.00685 
2025-01-25 21:36:46.135672: train_loss -0.7996 
2025-01-25 21:36:46.141495: val_loss -0.7719 
2025-01-25 21:36:46.143764: Pseudo dice [np.float32(0.9592), np.float32(0.8732)] 
2025-01-25 21:36:46.146106: Epoch time: 30.05 s 
2025-01-25 21:36:47.208403:  
2025-01-25 21:36:47.211156: Epoch 344 
2025-01-25 21:36:47.213529: Current learning rate: 0.00684 
2025-01-25 21:37:15.869385: train_loss -0.8014 
2025-01-25 21:37:15.875110: val_loss -0.7799 
2025-01-25 21:37:15.877296: Pseudo dice [np.float32(0.9497), np.float32(0.8485)] 
2025-01-25 21:37:15.879690: Epoch time: 28.66 s 
2025-01-25 21:37:16.995538:  
2025-01-25 21:37:16.999204: Epoch 345 
2025-01-25 21:37:17.001450: Current learning rate: 0.00683 
2025-01-25 21:37:48.174243: train_loss -0.8025 
2025-01-25 21:37:48.178914: val_loss -0.7893 
2025-01-25 21:37:48.181527: Pseudo dice [np.float32(0.9574), np.float32(0.8468)] 
2025-01-25 21:37:48.183799: Epoch time: 31.18 s 
2025-01-25 21:37:49.247908:  
2025-01-25 21:37:49.250414: Epoch 346 
2025-01-25 21:37:49.252794: Current learning rate: 0.00682 
2025-01-25 21:38:20.134509: train_loss -0.81 
2025-01-25 21:38:20.141514: val_loss -0.7371 
2025-01-25 21:38:20.143806: Pseudo dice [np.float32(0.9499), np.float32(0.8399)] 
2025-01-25 21:38:20.146065: Epoch time: 30.89 s 
2025-01-25 21:38:21.648302:  
2025-01-25 21:38:21.651028: Epoch 347 
2025-01-25 21:38:21.653696: Current learning rate: 0.00681 
2025-01-25 21:38:51.117917: train_loss -0.8131 
2025-01-25 21:38:51.122667: val_loss -0.7685 
2025-01-25 21:38:51.124924: Pseudo dice [np.float32(0.9604), np.float32(0.8558)] 
2025-01-25 21:38:51.127153: Epoch time: 29.47 s 
2025-01-25 21:38:52.189358:  
2025-01-25 21:38:52.191534: Epoch 348 
2025-01-25 21:38:52.193623: Current learning rate: 0.0068 
2025-01-25 21:39:21.983311: train_loss -0.8024 
2025-01-25 21:39:21.988852: val_loss -0.7863 
2025-01-25 21:39:21.991185: Pseudo dice [np.float32(0.9512), np.float32(0.8829)] 
2025-01-25 21:39:21.993549: Epoch time: 29.79 s 
2025-01-25 21:39:23.051161:  
2025-01-25 21:39:23.053831: Epoch 349 
2025-01-25 21:39:23.056290: Current learning rate: 0.0068 
2025-01-25 21:39:53.546047: train_loss -0.8096 
2025-01-25 21:39:53.551258: val_loss -0.7587 
2025-01-25 21:39:53.554159: Pseudo dice [np.float32(0.9405), np.float32(0.849)] 
2025-01-25 21:39:53.556766: Epoch time: 30.5 s 
2025-01-25 21:39:55.114713:  
2025-01-25 21:39:55.117172: Epoch 350 
2025-01-25 21:39:55.119706: Current learning rate: 0.00679 
2025-01-25 21:40:23.566691: train_loss -0.8159 
2025-01-25 21:40:23.573711: val_loss -0.786 
2025-01-25 21:40:23.576251: Pseudo dice [np.float32(0.9515), np.float32(0.8891)] 
2025-01-25 21:40:23.578705: Epoch time: 28.45 s 
2025-01-25 21:40:24.634769:  
2025-01-25 21:40:24.637426: Epoch 351 
2025-01-25 21:40:24.639650: Current learning rate: 0.00678 
2025-01-25 21:40:53.777012: train_loss -0.8109 
2025-01-25 21:40:53.782125: val_loss -0.7691 
2025-01-25 21:40:53.784696: Pseudo dice [np.float32(0.9489), np.float32(0.8929)] 
2025-01-25 21:40:53.787297: Epoch time: 29.14 s 
2025-01-25 21:40:54.927655:  
2025-01-25 21:40:54.931538: Epoch 352 
2025-01-25 21:40:54.933849: Current learning rate: 0.00677 
2025-01-25 21:41:23.947740: train_loss -0.7964 
2025-01-25 21:41:23.953986: val_loss -0.7674 
2025-01-25 21:41:23.956408: Pseudo dice [np.float32(0.9597), np.float32(0.8907)] 
2025-01-25 21:41:23.958713: Epoch time: 29.02 s 
2025-01-25 21:41:25.021290:  
2025-01-25 21:41:25.023795: Epoch 353 
2025-01-25 21:41:25.025945: Current learning rate: 0.00676 
2025-01-25 21:41:55.786577: train_loss -0.8095 
2025-01-25 21:41:55.794305: val_loss -0.7751 
2025-01-25 21:41:55.797091: Pseudo dice [np.float32(0.9568), np.float32(0.893)] 
2025-01-25 21:41:55.800014: Epoch time: 30.77 s 
2025-01-25 21:41:56.856699:  
2025-01-25 21:41:56.859085: Epoch 354 
2025-01-25 21:41:56.861453: Current learning rate: 0.00675 
2025-01-25 21:42:26.107281: train_loss -0.8093 
2025-01-25 21:42:26.114014: val_loss -0.7397 
2025-01-25 21:42:26.116499: Pseudo dice [np.float32(0.9554), np.float32(0.8943)] 
2025-01-25 21:42:26.118877: Epoch time: 29.25 s 
2025-01-25 21:42:27.190606:  
2025-01-25 21:42:27.193447: Epoch 355 
2025-01-25 21:42:27.196179: Current learning rate: 0.00674 
2025-01-25 21:42:56.250992: train_loss -0.8215 
2025-01-25 21:42:56.254994: val_loss -0.7581 
2025-01-25 21:42:56.257278: Pseudo dice [np.float32(0.9525), np.float32(0.8888)] 
2025-01-25 21:42:56.259735: Epoch time: 29.06 s 
2025-01-25 21:42:57.312723:  
2025-01-25 21:42:57.315794: Epoch 356 
2025-01-25 21:42:57.318248: Current learning rate: 0.00673 
2025-01-25 21:43:26.383598: train_loss -0.815 
2025-01-25 21:43:26.389967: val_loss -0.7872 
2025-01-25 21:43:26.392344: Pseudo dice [np.float32(0.9578), np.float32(0.8823)] 
2025-01-25 21:43:26.394732: Epoch time: 29.07 s 
2025-01-25 21:43:27.464255:  
2025-01-25 21:43:27.467020: Epoch 357 
2025-01-25 21:43:27.469408: Current learning rate: 0.00672 
2025-01-25 21:43:56.274486: train_loss -0.8214 
2025-01-25 21:43:56.279184: val_loss -0.7976 
2025-01-25 21:43:56.281659: Pseudo dice [np.float32(0.9602), np.float32(0.9125)] 
2025-01-25 21:43:56.284145: Epoch time: 28.81 s 
2025-01-25 21:43:57.370764:  
2025-01-25 21:43:57.376284: Epoch 358 
2025-01-25 21:43:57.382992: Current learning rate: 0.00671 
2025-01-25 21:44:27.323047: train_loss -0.8231 
2025-01-25 21:44:27.331494: val_loss -0.7647 
2025-01-25 21:44:27.334001: Pseudo dice [np.float32(0.9546), np.float32(0.9033)] 
2025-01-25 21:44:27.336512: Epoch time: 29.95 s 
2025-01-25 21:44:27.338768: Yayy! New best EMA pseudo Dice: 0.91839998960495 
2025-01-25 21:44:28.938362:  
2025-01-25 21:44:28.940933: Epoch 359 
2025-01-25 21:44:28.943374: Current learning rate: 0.0067 
2025-01-25 21:44:57.749416: train_loss -0.8128 
2025-01-25 21:44:57.752237: val_loss -0.7837 
2025-01-25 21:44:57.754676: Pseudo dice [np.float32(0.961), np.float32(0.8983)] 
2025-01-25 21:44:57.756982: Epoch time: 28.81 s 
2025-01-25 21:44:57.759274: Yayy! New best EMA pseudo Dice: 0.9194999933242798 
2025-01-25 21:44:59.296737:  
2025-01-25 21:44:59.299007: Epoch 360 
2025-01-25 21:44:59.301324: Current learning rate: 0.00669 
2025-01-25 21:45:28.476225: train_loss -0.8086 
2025-01-25 21:45:28.481484: val_loss -0.8291 
2025-01-25 21:45:28.483951: Pseudo dice [np.float32(0.9569), np.float32(0.9032)] 
2025-01-25 21:45:28.486314: Epoch time: 29.18 s 
2025-01-25 21:45:28.488489: Yayy! New best EMA pseudo Dice: 0.9205999970436096 
2025-01-25 21:45:30.046401:  
2025-01-25 21:45:30.048938: Epoch 361 
2025-01-25 21:45:30.051378: Current learning rate: 0.00668 
2025-01-25 21:45:59.446831: train_loss -0.8338 
2025-01-25 21:45:59.449824: val_loss -0.7984 
2025-01-25 21:45:59.452140: Pseudo dice [np.float32(0.9607), np.float32(0.9105)] 
2025-01-25 21:45:59.454484: Epoch time: 29.4 s 
2025-01-25 21:45:59.456721: Yayy! New best EMA pseudo Dice: 0.9221000075340271 
2025-01-25 21:46:01.200797:  
2025-01-25 21:46:01.203465: Epoch 362 
2025-01-25 21:46:01.205986: Current learning rate: 0.00667 
2025-01-25 21:46:31.491362: train_loss -0.828 
2025-01-25 21:46:31.497048: val_loss -0.7839 
2025-01-25 21:46:31.499385: Pseudo dice [np.float32(0.9592), np.float32(0.9018)] 
2025-01-25 21:46:31.501773: Epoch time: 30.29 s 
2025-01-25 21:46:31.504096: Yayy! New best EMA pseudo Dice: 0.9229000210762024 
2025-01-25 21:46:33.053456:  
2025-01-25 21:46:33.055772: Epoch 363 
2025-01-25 21:46:33.058072: Current learning rate: 0.00666 
2025-01-25 21:47:02.359314: train_loss -0.8058 
2025-01-25 21:47:02.362461: val_loss -0.7562 
2025-01-25 21:47:02.364972: Pseudo dice [np.float32(0.9557), np.float32(0.8634)] 
2025-01-25 21:47:02.367225: Epoch time: 29.31 s 
2025-01-25 21:47:03.425587:  
2025-01-25 21:47:03.428389: Epoch 364 
2025-01-25 21:47:03.430871: Current learning rate: 0.00665 
2025-01-25 21:47:32.910092: train_loss -0.8166 
2025-01-25 21:47:32.915935: val_loss -0.8028 
2025-01-25 21:47:32.918226: Pseudo dice [np.float32(0.9539), np.float32(0.8756)] 
2025-01-25 21:47:32.920574: Epoch time: 29.49 s 
2025-01-25 21:47:34.494568:  
2025-01-25 21:47:34.496989: Epoch 365 
2025-01-25 21:47:34.499233: Current learning rate: 0.00665 
2025-01-25 21:48:03.579581: train_loss -0.8103 
2025-01-25 21:48:03.582410: val_loss -0.7989 
2025-01-25 21:48:03.584625: Pseudo dice [np.float32(0.9618), np.float32(0.8913)] 
2025-01-25 21:48:03.586973: Epoch time: 29.09 s 
2025-01-25 21:48:04.646083:  
2025-01-25 21:48:04.648585: Epoch 366 
2025-01-25 21:48:04.651038: Current learning rate: 0.00664 
2025-01-25 21:48:34.966695: train_loss -0.8141 
2025-01-25 21:48:34.976512: val_loss -0.7559 
2025-01-25 21:48:34.979003: Pseudo dice [np.float32(0.9576), np.float32(0.8844)] 
2025-01-25 21:48:34.981347: Epoch time: 30.32 s 
2025-01-25 21:48:36.209511:  
2025-01-25 21:48:36.212095: Epoch 367 
2025-01-25 21:48:36.214495: Current learning rate: 0.00663 
2025-01-25 21:49:06.079112: train_loss -0.8072 
2025-01-25 21:49:06.082831: val_loss -0.7414 
2025-01-25 21:49:06.085476: Pseudo dice [np.float32(0.9569), np.float32(0.8618)] 
2025-01-25 21:49:06.087646: Epoch time: 29.87 s 
2025-01-25 21:49:07.193725:  
2025-01-25 21:49:07.196480: Epoch 368 
2025-01-25 21:49:07.198986: Current learning rate: 0.00662 
2025-01-25 21:49:36.852880: train_loss -0.8094 
2025-01-25 21:49:36.868063: val_loss -0.7736 
2025-01-25 21:49:36.870573: Pseudo dice [np.float32(0.9548), np.float32(0.8935)] 
2025-01-25 21:49:36.872864: Epoch time: 29.66 s 
2025-01-25 21:49:38.009507:  
2025-01-25 21:49:38.011822: Epoch 369 
2025-01-25 21:49:38.014299: Current learning rate: 0.00661 
2025-01-25 21:50:06.873911: train_loss -0.8208 
2025-01-25 21:50:06.878367: val_loss -0.7407 
2025-01-25 21:50:06.880901: Pseudo dice [np.float32(0.9474), np.float32(0.8083)] 
2025-01-25 21:50:06.883598: Epoch time: 28.87 s 
2025-01-25 21:50:08.012016:  
2025-01-25 21:50:08.014517: Epoch 370 
2025-01-25 21:50:08.016732: Current learning rate: 0.0066 
2025-01-25 21:50:37.566011: train_loss -0.8025 
2025-01-25 21:50:37.575646: val_loss -0.7682 
2025-01-25 21:50:37.578039: Pseudo dice [np.float32(0.9471), np.float32(0.8631)] 
2025-01-25 21:50:37.580316: Epoch time: 29.55 s 
2025-01-25 21:50:38.664404:  
2025-01-25 21:50:38.667478: Epoch 371 
2025-01-25 21:50:38.670295: Current learning rate: 0.00659 
2025-01-25 21:51:08.696844: train_loss -0.7842 
2025-01-25 21:51:08.700759: val_loss -0.7346 
2025-01-25 21:51:08.703045: Pseudo dice [np.float32(0.9439), np.float32(0.8538)] 
2025-01-25 21:51:08.705474: Epoch time: 30.03 s 
2025-01-25 21:51:09.762240:  
2025-01-25 21:51:09.764728: Epoch 372 
2025-01-25 21:51:09.766985: Current learning rate: 0.00658 
2025-01-25 21:51:39.405820: train_loss -0.8134 
2025-01-25 21:51:39.411186: val_loss -0.7558 
2025-01-25 21:51:39.413687: Pseudo dice [np.float32(0.9543), np.float32(0.8978)] 
2025-01-25 21:51:39.416088: Epoch time: 29.64 s 
2025-01-25 21:51:40.491928:  
2025-01-25 21:51:40.494233: Epoch 373 
2025-01-25 21:51:40.496595: Current learning rate: 0.00657 
2025-01-25 21:52:09.156941: train_loss -0.8186 
2025-01-25 21:52:09.160480: val_loss -0.793 
2025-01-25 21:52:09.163199: Pseudo dice [np.float32(0.9635), np.float32(0.9021)] 
2025-01-25 21:52:09.165710: Epoch time: 28.67 s 
2025-01-25 21:52:10.248355:  
2025-01-25 21:52:10.251170: Epoch 374 
2025-01-25 21:52:10.253455: Current learning rate: 0.00656 
2025-01-25 21:52:40.588172: train_loss -0.8252 
2025-01-25 21:52:40.592908: val_loss -0.7477 
2025-01-25 21:52:40.595005: Pseudo dice [np.float32(0.9532), np.float32(0.838)] 
2025-01-25 21:52:40.597225: Epoch time: 30.34 s 
2025-01-25 21:52:41.658368:  
2025-01-25 21:52:41.661182: Epoch 375 
2025-01-25 21:52:41.663750: Current learning rate: 0.00655 
2025-01-25 21:53:10.850779: train_loss -0.806 
2025-01-25 21:53:10.855091: val_loss -0.7437 
2025-01-25 21:53:10.858345: Pseudo dice [np.float32(0.9524), np.float32(0.8753)] 
2025-01-25 21:53:10.860984: Epoch time: 29.19 s 
2025-01-25 21:53:11.957586:  
2025-01-25 21:53:11.960689: Epoch 376 
2025-01-25 21:53:11.963157: Current learning rate: 0.00654 
2025-01-25 21:53:42.530439: train_loss -0.8205 
2025-01-25 21:53:42.537403: val_loss -0.7876 
2025-01-25 21:53:42.539907: Pseudo dice [np.float32(0.9522), np.float32(0.8557)] 
2025-01-25 21:53:42.542380: Epoch time: 30.57 s 
2025-01-25 21:53:43.640430:  
2025-01-25 21:53:43.643483: Epoch 377 
2025-01-25 21:53:43.646446: Current learning rate: 0.00653 
2025-01-25 21:54:13.591345: train_loss -0.8079 
2025-01-25 21:54:13.597123: val_loss -0.7209 
2025-01-25 21:54:13.599620: Pseudo dice [np.float32(0.954), np.float32(0.8731)] 
2025-01-25 21:54:13.602241: Epoch time: 29.95 s 
2025-01-25 21:54:14.675489:  
2025-01-25 21:54:14.677901: Epoch 378 
2025-01-25 21:54:14.680338: Current learning rate: 0.00652 
2025-01-25 21:54:43.587676: train_loss -0.7957 
2025-01-25 21:54:43.593407: val_loss -0.7469 
2025-01-25 21:54:43.595740: Pseudo dice [np.float32(0.9462), np.float32(0.8612)] 
2025-01-25 21:54:43.597897: Epoch time: 28.91 s 
2025-01-25 21:54:44.654505:  
2025-01-25 21:54:44.656970: Epoch 379 
2025-01-25 21:54:44.659258: Current learning rate: 0.00651 
2025-01-25 21:55:13.259937: train_loss -0.811 
2025-01-25 21:55:13.265158: val_loss -0.7902 
2025-01-25 21:55:13.267862: Pseudo dice [np.float32(0.9577), np.float32(0.8911)] 
2025-01-25 21:55:13.270058: Epoch time: 28.61 s 
2025-01-25 21:55:14.328204:  
2025-01-25 21:55:14.330637: Epoch 380 
2025-01-25 21:55:14.333246: Current learning rate: 0.0065 
2025-01-25 21:55:43.693564: train_loss -0.8172 
2025-01-25 21:55:43.701556: val_loss -0.7733 
2025-01-25 21:55:43.704267: Pseudo dice [np.float32(0.9578), np.float32(0.8663)] 
2025-01-25 21:55:43.706605: Epoch time: 29.37 s 
2025-01-25 21:55:44.898269:  
2025-01-25 21:55:44.900835: Epoch 381 
2025-01-25 21:55:44.903169: Current learning rate: 0.00649 
2025-01-25 21:56:14.719515: train_loss -0.8116 
2025-01-25 21:56:14.723642: val_loss -0.7538 
2025-01-25 21:56:14.726020: Pseudo dice [np.float32(0.9532), np.float32(0.8645)] 
2025-01-25 21:56:14.728393: Epoch time: 29.82 s 
2025-01-25 21:56:16.277060:  
2025-01-25 21:56:16.279534: Epoch 382 
2025-01-25 21:56:16.281762: Current learning rate: 0.00648 
2025-01-25 21:56:45.192892: train_loss -0.8031 
2025-01-25 21:56:45.198881: val_loss -0.7857 
2025-01-25 21:56:45.201312: Pseudo dice [np.float32(0.9574), np.float32(0.8704)] 
2025-01-25 21:56:45.203726: Epoch time: 28.92 s 
2025-01-25 21:56:46.287093:  
2025-01-25 21:56:46.289500: Epoch 383 
2025-01-25 21:56:46.292004: Current learning rate: 0.00648 
2025-01-25 21:57:14.688360: train_loss -0.806 
2025-01-25 21:57:14.691175: val_loss -0.7754 
2025-01-25 21:57:14.693606: Pseudo dice [np.float32(0.9519), np.float32(0.8851)] 
2025-01-25 21:57:14.695791: Epoch time: 28.4 s 
2025-01-25 21:57:15.767859:  
2025-01-25 21:57:15.770313: Epoch 384 
2025-01-25 21:57:15.772757: Current learning rate: 0.00647 
2025-01-25 21:57:44.995910: train_loss -0.8193 
2025-01-25 21:57:44.998908: val_loss -0.7534 
2025-01-25 21:57:45.001442: Pseudo dice [np.float32(0.9547), np.float32(0.8751)] 
2025-01-25 21:57:45.003649: Epoch time: 29.23 s 
2025-01-25 21:57:46.103217:  
2025-01-25 21:57:46.105879: Epoch 385 
2025-01-25 21:57:46.108198: Current learning rate: 0.00646 
2025-01-25 21:58:15.024159: train_loss -0.814 
2025-01-25 21:58:15.026901: val_loss -0.7901 
2025-01-25 21:58:15.029299: Pseudo dice [np.float32(0.9525), np.float32(0.8875)] 
2025-01-25 21:58:15.031826: Epoch time: 28.92 s 
2025-01-25 21:58:16.107740:  
2025-01-25 21:58:16.110403: Epoch 386 
2025-01-25 21:58:16.112691: Current learning rate: 0.00645 
2025-01-25 21:58:46.235897: train_loss -0.8141 
2025-01-25 21:58:46.246063: val_loss -0.7586 
2025-01-25 21:58:46.248534: Pseudo dice [np.float32(0.9581), np.float32(0.8784)] 
2025-01-25 21:58:46.250910: Epoch time: 30.13 s 
2025-01-25 21:58:47.333052:  
2025-01-25 21:58:47.335632: Epoch 387 
2025-01-25 21:58:47.338284: Current learning rate: 0.00644 
2025-01-25 21:59:17.683592: train_loss -0.8048 
2025-01-25 21:59:17.694503: val_loss -0.7694 
2025-01-25 21:59:17.696901: Pseudo dice [np.float32(0.95), np.float32(0.8795)] 
2025-01-25 21:59:17.699249: Epoch time: 30.35 s 
2025-01-25 21:59:18.823161:  
2025-01-25 21:59:18.825942: Epoch 388 
2025-01-25 21:59:18.828331: Current learning rate: 0.00643 
2025-01-25 21:59:47.504674: train_loss -0.8007 
2025-01-25 21:59:47.510903: val_loss -0.7607 
2025-01-25 21:59:47.513390: Pseudo dice [np.float32(0.9572), np.float32(0.8759)] 
2025-01-25 21:59:47.515888: Epoch time: 28.68 s 
2025-01-25 21:59:48.589541:  
2025-01-25 21:59:48.592031: Epoch 389 
2025-01-25 21:59:48.594404: Current learning rate: 0.00642 
2025-01-25 22:00:17.082030: train_loss -0.8212 
2025-01-25 22:00:17.088809: val_loss -0.7668 
2025-01-25 22:00:17.091191: Pseudo dice [np.float32(0.9537), np.float32(0.8719)] 
2025-01-25 22:00:17.093497: Epoch time: 28.49 s 
2025-01-25 22:00:18.177545:  
2025-01-25 22:00:18.181022: Epoch 390 
2025-01-25 22:00:18.183416: Current learning rate: 0.00641 
2025-01-25 22:00:49.014063: train_loss -0.8061 
2025-01-25 22:00:49.022936: val_loss -0.725 
2025-01-25 22:00:49.025315: Pseudo dice [np.float32(0.9535), np.float32(0.8073)] 
2025-01-25 22:00:49.027610: Epoch time: 30.84 s 
2025-01-25 22:00:50.113388:  
2025-01-25 22:00:50.115892: Epoch 391 
2025-01-25 22:00:50.118216: Current learning rate: 0.0064 
2025-01-25 22:01:19.728258: train_loss -0.8095 
2025-01-25 22:01:19.734819: val_loss -0.7865 
2025-01-25 22:01:19.737410: Pseudo dice [np.float32(0.9541), np.float32(0.8131)] 
2025-01-25 22:01:19.739920: Epoch time: 29.62 s 
2025-01-25 22:01:20.829401:  
2025-01-25 22:01:20.832258: Epoch 392 
2025-01-25 22:01:20.834954: Current learning rate: 0.00639 
2025-01-25 22:01:49.950722: train_loss -0.7845 
2025-01-25 22:01:49.959293: val_loss -0.7458 
2025-01-25 22:01:49.961888: Pseudo dice [np.float32(0.9472), np.float32(0.8188)] 
2025-01-25 22:01:49.964357: Epoch time: 29.12 s 
2025-01-25 22:01:51.081514:  
2025-01-25 22:01:51.084158: Epoch 393 
2025-01-25 22:01:51.086427: Current learning rate: 0.00638 
2025-01-25 22:02:20.657035: train_loss -0.796 
2025-01-25 22:02:20.659610: val_loss -0.802 
2025-01-25 22:02:20.662184: Pseudo dice [np.float32(0.9542), np.float32(0.894)] 
2025-01-25 22:02:20.664706: Epoch time: 29.58 s 
2025-01-25 22:02:21.738392:  
2025-01-25 22:02:21.740682: Epoch 394 
2025-01-25 22:02:21.742857: Current learning rate: 0.00637 
2025-01-25 22:02:51.135445: train_loss -0.7832 
2025-01-25 22:02:51.140861: val_loss -0.7295 
2025-01-25 22:02:51.143064: Pseudo dice [np.float32(0.9408), np.float32(0.6321)] 
2025-01-25 22:02:51.145413: Epoch time: 29.4 s 
2025-01-25 22:02:52.222405:  
2025-01-25 22:02:52.224866: Epoch 395 
2025-01-25 22:02:52.227528: Current learning rate: 0.00636 
2025-01-25 22:03:21.756288: train_loss -0.7764 
2025-01-25 22:03:21.763120: val_loss -0.7314 
2025-01-25 22:03:21.765519: Pseudo dice [np.float32(0.9527), np.float32(0.8765)] 
2025-01-25 22:03:21.767814: Epoch time: 29.53 s 
2025-01-25 22:03:23.052303:  
2025-01-25 22:03:23.054958: Epoch 396 
2025-01-25 22:03:23.057218: Current learning rate: 0.00635 
2025-01-25 22:03:52.223726: train_loss -0.7874 
2025-01-25 22:03:52.229211: val_loss -0.7091 
2025-01-25 22:03:52.231878: Pseudo dice [np.float32(0.9454), np.float32(0.8249)] 
2025-01-25 22:03:52.234537: Epoch time: 29.17 s 
2025-01-25 22:03:53.319357:  
2025-01-25 22:03:53.321999: Epoch 397 
2025-01-25 22:03:53.324306: Current learning rate: 0.00634 
2025-01-25 22:04:21.801731: train_loss -0.8073 
2025-01-25 22:04:21.804794: val_loss -0.7373 
2025-01-25 22:04:21.807092: Pseudo dice [np.float32(0.9471), np.float32(0.8444)] 
2025-01-25 22:04:21.809575: Epoch time: 28.48 s 
2025-01-25 22:04:22.890090:  
2025-01-25 22:04:22.893075: Epoch 398 
2025-01-25 22:04:22.895592: Current learning rate: 0.00633 
2025-01-25 22:04:52.193582: train_loss -0.8271 
2025-01-25 22:04:52.196387: val_loss -0.8005 
2025-01-25 22:04:52.198950: Pseudo dice [np.float32(0.9548), np.float32(0.8908)] 
2025-01-25 22:04:52.201336: Epoch time: 29.3 s 
2025-01-25 22:04:53.284033:  
2025-01-25 22:04:53.286547: Epoch 399 
2025-01-25 22:04:53.288802: Current learning rate: 0.00632 
2025-01-25 22:05:23.845974: train_loss -0.8221 
2025-01-25 22:05:23.852078: val_loss -0.7753 
2025-01-25 22:05:23.855176: Pseudo dice [np.float32(0.9623), np.float32(0.8915)] 
2025-01-25 22:05:23.857918: Epoch time: 30.56 s 
2025-01-25 22:05:25.972416:  
2025-01-25 22:05:25.976311: Epoch 400 
2025-01-25 22:05:25.978607: Current learning rate: 0.00631 
2025-01-25 22:05:55.205978: train_loss -0.8137 
2025-01-25 22:05:55.211806: val_loss -0.768 
2025-01-25 22:05:55.214107: Pseudo dice [np.float32(0.9569), np.float32(0.8989)] 
2025-01-25 22:05:55.216408: Epoch time: 29.23 s 
2025-01-25 22:05:56.294771:  
2025-01-25 22:05:56.297526: Epoch 401 
2025-01-25 22:05:56.299793: Current learning rate: 0.0063 
2025-01-25 22:06:25.618845: train_loss -0.8074 
2025-01-25 22:06:25.622103: val_loss -0.8095 
2025-01-25 22:06:25.624688: Pseudo dice [np.float32(0.9528), np.float32(0.9077)] 
2025-01-25 22:06:25.627153: Epoch time: 29.32 s 
2025-01-25 22:06:26.712993:  
2025-01-25 22:06:26.715668: Epoch 402 
2025-01-25 22:06:26.718137: Current learning rate: 0.0063 
2025-01-25 22:06:55.554153: train_loss -0.8206 
2025-01-25 22:06:55.559590: val_loss -0.7489 
2025-01-25 22:06:55.562026: Pseudo dice [np.float32(0.9446), np.float32(0.8787)] 
2025-01-25 22:06:55.564565: Epoch time: 28.84 s 
2025-01-25 22:06:56.653263:  
2025-01-25 22:06:56.655776: Epoch 403 
2025-01-25 22:06:56.657972: Current learning rate: 0.00629 
2025-01-25 22:07:26.383851: train_loss -0.8174 
2025-01-25 22:07:26.387147: val_loss -0.7947 
2025-01-25 22:07:26.389634: Pseudo dice [np.float32(0.96), np.float32(0.8922)] 
2025-01-25 22:07:26.392230: Epoch time: 29.73 s 
2025-01-25 22:07:27.472963:  
2025-01-25 22:07:27.475570: Epoch 404 
2025-01-25 22:07:27.478056: Current learning rate: 0.00628 
2025-01-25 22:07:56.085368: train_loss -0.7999 
2025-01-25 22:07:56.090300: val_loss -0.7688 
2025-01-25 22:07:56.092607: Pseudo dice [np.float32(0.9549), np.float32(0.8691)] 
2025-01-25 22:07:56.094961: Epoch time: 28.61 s 
2025-01-25 22:07:57.177190:  
2025-01-25 22:07:57.179894: Epoch 405 
2025-01-25 22:07:57.182402: Current learning rate: 0.00627 
2025-01-25 22:08:27.693289: train_loss -0.8065 
2025-01-25 22:08:27.698174: val_loss -0.753 
2025-01-25 22:08:27.702158: Pseudo dice [np.float32(0.9527), np.float32(0.8789)] 
2025-01-25 22:08:27.704551: Epoch time: 30.52 s 
2025-01-25 22:08:28.911615:  
2025-01-25 22:08:28.914472: Epoch 406 
2025-01-25 22:08:28.917186: Current learning rate: 0.00626 
2025-01-25 22:08:57.917094: train_loss -0.8109 
2025-01-25 22:08:57.922419: val_loss -0.7914 
2025-01-25 22:08:57.924670: Pseudo dice [np.float32(0.9566), np.float32(0.8711)] 
2025-01-25 22:08:57.927092: Epoch time: 29.01 s 
2025-01-25 22:08:59.009707:  
2025-01-25 22:08:59.012455: Epoch 407 
2025-01-25 22:08:59.014983: Current learning rate: 0.00625 
2025-01-25 22:09:28.871523: train_loss -0.827 
2025-01-25 22:09:28.875648: val_loss -0.8197 
2025-01-25 22:09:28.878083: Pseudo dice [np.float32(0.9577), np.float32(0.9091)] 
2025-01-25 22:09:28.880416: Epoch time: 29.86 s 
2025-01-25 22:09:29.965672:  
2025-01-25 22:09:29.968660: Epoch 408 
2025-01-25 22:09:29.971477: Current learning rate: 0.00624 
2025-01-25 22:10:00.208487: train_loss -0.8217 
2025-01-25 22:10:00.214462: val_loss -0.7372 
2025-01-25 22:10:00.216652: Pseudo dice [np.float32(0.9406), np.float32(0.87)] 
2025-01-25 22:10:00.219010: Epoch time: 30.24 s 
2025-01-25 22:10:01.314038:  
2025-01-25 22:10:01.316631: Epoch 409 
2025-01-25 22:10:01.319131: Current learning rate: 0.00623 
2025-01-25 22:10:30.232283: train_loss -0.8248 
2025-01-25 22:10:30.239037: val_loss -0.7965 
2025-01-25 22:10:30.241751: Pseudo dice [np.float32(0.952), np.float32(0.9057)] 
2025-01-25 22:10:30.244376: Epoch time: 28.92 s 
2025-01-25 22:10:31.400823:  
2025-01-25 22:10:31.403364: Epoch 410 
2025-01-25 22:10:31.406040: Current learning rate: 0.00622 
2025-01-25 22:11:01.107160: train_loss -0.8262 
2025-01-25 22:11:01.114070: val_loss -0.7655 
2025-01-25 22:11:01.116403: Pseudo dice [np.float32(0.953), np.float32(0.8879)] 
2025-01-25 22:11:01.118787: Epoch time: 29.71 s 
2025-01-25 22:11:02.158705:  
2025-01-25 22:11:02.161618: Epoch 411 
2025-01-25 22:11:02.164380: Current learning rate: 0.00621 
2025-01-25 22:11:31.894350: train_loss -0.8205 
2025-01-25 22:11:31.901498: val_loss -0.79 
2025-01-25 22:11:31.904467: Pseudo dice [np.float32(0.9524), np.float32(0.8832)] 
2025-01-25 22:11:31.906869: Epoch time: 29.74 s 
2025-01-25 22:11:32.945032:  
2025-01-25 22:11:32.948131: Epoch 412 
2025-01-25 22:11:32.951084: Current learning rate: 0.0062 
2025-01-25 22:12:02.130627: train_loss -0.807 
2025-01-25 22:12:02.137377: val_loss -0.7409 
2025-01-25 22:12:02.140002: Pseudo dice [np.float32(0.9615), np.float32(0.8966)] 
2025-01-25 22:12:02.142491: Epoch time: 29.19 s 
2025-01-25 22:12:03.164027:  
2025-01-25 22:12:03.166716: Epoch 413 
2025-01-25 22:12:03.169069: Current learning rate: 0.00619 
2025-01-25 22:12:32.547581: train_loss -0.8026 
2025-01-25 22:12:32.550753: val_loss -0.7703 
2025-01-25 22:12:32.553594: Pseudo dice [np.float32(0.9605), np.float32(0.8905)] 
2025-01-25 22:12:32.556100: Epoch time: 29.38 s 
2025-01-25 22:12:33.581453:  
2025-01-25 22:12:33.583941: Epoch 414 
2025-01-25 22:12:33.586378: Current learning rate: 0.00618 
2025-01-25 22:13:02.386756: train_loss -0.8123 
2025-01-25 22:13:02.392993: val_loss -0.7343 
2025-01-25 22:13:02.395377: Pseudo dice [np.float32(0.9581), np.float32(0.9006)] 
2025-01-25 22:13:02.397793: Epoch time: 28.81 s 
2025-01-25 22:13:03.425918:  
2025-01-25 22:13:03.428572: Epoch 415 
2025-01-25 22:13:03.430881: Current learning rate: 0.00617 
2025-01-25 22:13:33.459322: train_loss -0.8264 
2025-01-25 22:13:33.465424: val_loss -0.7702 
2025-01-25 22:13:33.468251: Pseudo dice [np.float32(0.963), np.float32(0.8739)] 
2025-01-25 22:13:33.470767: Epoch time: 30.03 s 
2025-01-25 22:13:34.517423:  
2025-01-25 22:13:34.520083: Epoch 416 
2025-01-25 22:13:34.522443: Current learning rate: 0.00616 
2025-01-25 22:14:04.453204: train_loss -0.8316 
2025-01-25 22:14:04.478009: val_loss -0.7505 
2025-01-25 22:14:04.480764: Pseudo dice [np.float32(0.9616), np.float32(0.8953)] 
2025-01-25 22:14:04.483069: Epoch time: 29.94 s 
2025-01-25 22:14:06.651674:  
2025-01-25 22:14:06.654128: Epoch 417 
2025-01-25 22:14:06.656326: Current learning rate: 0.00615 
2025-01-25 22:14:35.628525: train_loss -0.8298 
2025-01-25 22:14:35.631124: val_loss -0.7952 
2025-01-25 22:14:35.633228: Pseudo dice [np.float32(0.9576), np.float32(0.8936)] 
2025-01-25 22:14:35.635459: Epoch time: 28.98 s 
2025-01-25 22:14:36.677164:  
2025-01-25 22:14:36.679478: Epoch 418 
2025-01-25 22:14:36.681552: Current learning rate: 0.00614 
2025-01-25 22:15:06.899617: train_loss -0.8223 
2025-01-25 22:15:06.907366: val_loss -0.7722 
2025-01-25 22:15:06.910017: Pseudo dice [np.float32(0.9558), np.float32(0.9095)] 
2025-01-25 22:15:06.912523: Epoch time: 30.22 s 
2025-01-25 22:15:08.044840:  
2025-01-25 22:15:08.047455: Epoch 419 
2025-01-25 22:15:08.050102: Current learning rate: 0.00613 
2025-01-25 22:15:36.663242: train_loss -0.828 
2025-01-25 22:15:36.668692: val_loss -0.7435 
2025-01-25 22:15:36.671158: Pseudo dice [np.float32(0.9507), np.float32(0.8853)] 
2025-01-25 22:15:36.673511: Epoch time: 28.62 s 
2025-01-25 22:15:37.699500:  
2025-01-25 22:15:37.702466: Epoch 420 
2025-01-25 22:15:37.705003: Current learning rate: 0.00612 
2025-01-25 22:16:06.239539: train_loss -0.8326 
2025-01-25 22:16:06.245785: val_loss -0.8172 
2025-01-25 22:16:06.248247: Pseudo dice [np.float32(0.9626), np.float32(0.9024)] 
2025-01-25 22:16:06.250731: Epoch time: 28.54 s 
2025-01-25 22:16:07.280886:  
2025-01-25 22:16:07.284752: Epoch 421 
2025-01-25 22:16:07.287015: Current learning rate: 0.00612 
2025-01-25 22:16:36.276321: train_loss -0.8094 
2025-01-25 22:16:36.283021: val_loss -0.7988 
2025-01-25 22:16:36.285615: Pseudo dice [np.float32(0.9589), np.float32(0.8865)] 
2025-01-25 22:16:36.288036: Epoch time: 29.0 s 
2025-01-25 22:16:37.325247:  
2025-01-25 22:16:37.327977: Epoch 422 
2025-01-25 22:16:37.330384: Current learning rate: 0.00611 
2025-01-25 22:17:08.053504: train_loss -0.7893 
2025-01-25 22:17:08.061533: val_loss -0.7358 
2025-01-25 22:17:08.063930: Pseudo dice [np.float32(0.9577), np.float32(0.8746)] 
2025-01-25 22:17:08.066382: Epoch time: 30.73 s 
2025-01-25 22:17:09.373125:  
2025-01-25 22:17:09.375563: Epoch 423 
2025-01-25 22:17:09.378099: Current learning rate: 0.0061 
2025-01-25 22:17:40.597374: train_loss -0.8217 
2025-01-25 22:17:40.603391: val_loss -0.8055 
2025-01-25 22:17:40.605875: Pseudo dice [np.float32(0.9596), np.float32(0.8988)] 
2025-01-25 22:17:40.608324: Epoch time: 31.23 s 
2025-01-25 22:17:41.652714:  
2025-01-25 22:17:41.655876: Epoch 424 
2025-01-25 22:17:41.658128: Current learning rate: 0.00609 
2025-01-25 22:18:11.097080: train_loss -0.8395 
2025-01-25 22:18:11.103466: val_loss -0.7792 
2025-01-25 22:18:11.106194: Pseudo dice [np.float32(0.9564), np.float32(0.9109)] 
2025-01-25 22:18:11.108795: Epoch time: 29.45 s 
2025-01-25 22:18:11.111275: Yayy! New best EMA pseudo Dice: 0.9233999848365784 
2025-01-25 22:18:12.625573:  
2025-01-25 22:18:12.628914: Epoch 425 
2025-01-25 22:18:12.631508: Current learning rate: 0.00608 
2025-01-25 22:18:41.433286: train_loss -0.8484 
2025-01-25 22:18:41.438700: val_loss -0.764 
2025-01-25 22:18:41.441707: Pseudo dice [np.float32(0.9616), np.float32(0.9003)] 
2025-01-25 22:18:41.444006: Epoch time: 28.81 s 
2025-01-25 22:18:41.446287: Yayy! New best EMA pseudo Dice: 0.9241999983787537 
2025-01-25 22:18:43.005214:  
2025-01-25 22:18:43.007879: Epoch 426 
2025-01-25 22:18:43.010151: Current learning rate: 0.00607 
2025-01-25 22:19:12.321391: train_loss -0.8238 
2025-01-25 22:19:12.328100: val_loss -0.7812 
2025-01-25 22:19:12.330763: Pseudo dice [np.float32(0.9548), np.float32(0.9082)] 
2025-01-25 22:19:12.336755: Epoch time: 29.32 s 
2025-01-25 22:19:12.340919: Yayy! New best EMA pseudo Dice: 0.9248999953269958 
2025-01-25 22:19:14.010875:  
2025-01-25 22:19:14.013439: Epoch 427 
2025-01-25 22:19:14.015607: Current learning rate: 0.00606 
2025-01-25 22:19:43.535316: train_loss -0.815 
2025-01-25 22:19:43.539401: val_loss -0.7603 
2025-01-25 22:19:43.541856: Pseudo dice [np.float32(0.9504), np.float32(0.8827)] 
2025-01-25 22:19:43.544255: Epoch time: 29.53 s 
2025-01-25 22:19:44.570094:  
2025-01-25 22:19:44.572603: Epoch 428 
2025-01-25 22:19:44.574873: Current learning rate: 0.00605 
2025-01-25 22:20:14.357091: train_loss -0.8266 
2025-01-25 22:20:14.363090: val_loss -0.8063 
2025-01-25 22:20:14.365340: Pseudo dice [np.float32(0.961), np.float32(0.895)] 
2025-01-25 22:20:14.367559: Epoch time: 29.79 s 
2025-01-25 22:20:15.397812:  
2025-01-25 22:20:15.400788: Epoch 429 
2025-01-25 22:20:15.403323: Current learning rate: 0.00604 
2025-01-25 22:20:45.573324: train_loss -0.8222 
2025-01-25 22:20:45.578476: val_loss -0.7868 
2025-01-25 22:20:45.580871: Pseudo dice [np.float32(0.9607), np.float32(0.8881)] 
2025-01-25 22:20:45.583955: Epoch time: 30.18 s 
2025-01-25 22:20:46.616918:  
2025-01-25 22:20:46.619404: Epoch 430 
2025-01-25 22:20:46.621770: Current learning rate: 0.00603 
2025-01-25 22:21:16.025573: train_loss -0.8112 
2025-01-25 22:21:16.032119: val_loss -0.8008 
2025-01-25 22:21:16.034508: Pseudo dice [np.float32(0.9536), np.float32(0.8893)] 
2025-01-25 22:21:16.036969: Epoch time: 29.41 s 
2025-01-25 22:21:17.070619:  
2025-01-25 22:21:17.073721: Epoch 431 
2025-01-25 22:21:17.076233: Current learning rate: 0.00602 
2025-01-25 22:21:46.747678: train_loss -0.8221 
2025-01-25 22:21:46.751432: val_loss -0.768 
2025-01-25 22:21:46.753809: Pseudo dice [np.float32(0.9602), np.float32(0.8744)] 
2025-01-25 22:21:46.756011: Epoch time: 29.68 s 
2025-01-25 22:21:47.789965:  
2025-01-25 22:21:47.792552: Epoch 432 
2025-01-25 22:21:47.795092: Current learning rate: 0.00601 
2025-01-25 22:22:18.422604: train_loss -0.8092 
2025-01-25 22:22:18.428982: val_loss -0.7806 
2025-01-25 22:22:18.431381: Pseudo dice [np.float32(0.9542), np.float32(0.8878)] 
2025-01-25 22:22:18.433756: Epoch time: 30.63 s 
2025-01-25 22:22:19.464884:  
2025-01-25 22:22:19.468949: Epoch 433 
2025-01-25 22:22:19.471321: Current learning rate: 0.006 
2025-01-25 22:22:49.001001: train_loss -0.809 
2025-01-25 22:22:49.007140: val_loss -0.804 
2025-01-25 22:22:49.009821: Pseudo dice [np.float32(0.9588), np.float32(0.9055)] 
2025-01-25 22:22:49.012365: Epoch time: 29.54 s 
2025-01-25 22:22:50.142940:  
2025-01-25 22:22:50.145873: Epoch 434 
2025-01-25 22:22:50.148234: Current learning rate: 0.00599 
2025-01-25 22:23:20.114600: train_loss -0.8081 
2025-01-25 22:23:20.121330: val_loss -0.7658 
2025-01-25 22:23:20.123752: Pseudo dice [np.float32(0.9568), np.float32(0.8379)] 
2025-01-25 22:23:20.126159: Epoch time: 29.97 s 
2025-01-25 22:23:21.161881:  
2025-01-25 22:23:21.164629: Epoch 435 
2025-01-25 22:23:21.166946: Current learning rate: 0.00598 
2025-01-25 22:23:50.228915: train_loss -0.8062 
2025-01-25 22:23:50.235067: val_loss -0.7655 
2025-01-25 22:23:50.237373: Pseudo dice [np.float32(0.9488), np.float32(0.859)] 
2025-01-25 22:23:50.239722: Epoch time: 29.07 s 
2025-01-25 22:23:51.739160:  
2025-01-25 22:23:51.741870: Epoch 436 
2025-01-25 22:23:51.744537: Current learning rate: 0.00597 
2025-01-25 22:24:20.607781: train_loss -0.8197 
2025-01-25 22:24:20.615912: val_loss -0.79 
2025-01-25 22:24:20.618413: Pseudo dice [np.float32(0.9558), np.float32(0.8898)] 
2025-01-25 22:24:20.620619: Epoch time: 28.87 s 
2025-01-25 22:24:21.704774:  
2025-01-25 22:24:21.707361: Epoch 437 
2025-01-25 22:24:21.709846: Current learning rate: 0.00596 
2025-01-25 22:24:52.631148: train_loss -0.8339 
2025-01-25 22:24:52.637344: val_loss -0.7721 
2025-01-25 22:24:52.639869: Pseudo dice [np.float32(0.9559), np.float32(0.878)] 
2025-01-25 22:24:52.642147: Epoch time: 30.93 s 
2025-01-25 22:24:53.685230:  
2025-01-25 22:24:53.688204: Epoch 438 
2025-01-25 22:24:53.690552: Current learning rate: 0.00595 
2025-01-25 22:25:23.940435: train_loss -0.8038 
2025-01-25 22:25:23.950376: val_loss -0.766 
2025-01-25 22:25:23.952714: Pseudo dice [np.float32(0.9519), np.float32(0.8629)] 
2025-01-25 22:25:23.955592: Epoch time: 30.26 s 
2025-01-25 22:25:25.081187:  
2025-01-25 22:25:25.084131: Epoch 439 
2025-01-25 22:25:25.086884: Current learning rate: 0.00594 
2025-01-25 22:25:54.661901: train_loss -0.7983 
2025-01-25 22:25:54.665031: val_loss -0.771 
2025-01-25 22:25:54.667479: Pseudo dice [np.float32(0.9605), np.float32(0.8836)] 
2025-01-25 22:25:54.669659: Epoch time: 29.58 s 
2025-01-25 22:25:55.698652:  
2025-01-25 22:25:55.701192: Epoch 440 
2025-01-25 22:25:55.703821: Current learning rate: 0.00593 
2025-01-25 22:26:24.212718: train_loss -0.8123 
2025-01-25 22:26:24.218574: val_loss -0.7535 
2025-01-25 22:26:24.221018: Pseudo dice [np.float32(0.9454), np.float32(0.8672)] 
2025-01-25 22:26:24.223529: Epoch time: 28.51 s 
2025-01-25 22:26:25.264634:  
2025-01-25 22:26:25.267158: Epoch 441 
2025-01-25 22:26:25.269359: Current learning rate: 0.00592 
2025-01-25 22:26:54.493082: train_loss -0.8188 
2025-01-25 22:26:54.496309: val_loss -0.7573 
2025-01-25 22:26:54.499267: Pseudo dice [np.float32(0.9554), np.float32(0.8779)] 
2025-01-25 22:26:54.502073: Epoch time: 29.23 s 
2025-01-25 22:26:55.550040:  
2025-01-25 22:26:55.554339: Epoch 442 
2025-01-25 22:26:55.560517: Current learning rate: 0.00592 
2025-01-25 22:27:26.380492: train_loss -0.7863 
2025-01-25 22:27:26.387224: val_loss -0.7587 
2025-01-25 22:27:26.389928: Pseudo dice [np.float32(0.9493), np.float32(0.8678)] 
2025-01-25 22:27:26.392691: Epoch time: 30.83 s 
2025-01-25 22:27:27.424243:  
2025-01-25 22:27:27.426902: Epoch 443 
2025-01-25 22:27:27.429672: Current learning rate: 0.00591 
2025-01-25 22:27:56.349006: train_loss -0.807 
2025-01-25 22:27:56.353852: val_loss -0.7794 
2025-01-25 22:27:56.356343: Pseudo dice [np.float32(0.9563), np.float32(0.8993)] 
2025-01-25 22:27:56.358584: Epoch time: 28.93 s 
2025-01-25 22:27:57.394250:  
2025-01-25 22:27:57.396736: Epoch 444 
2025-01-25 22:27:57.398984: Current learning rate: 0.0059 
2025-01-25 22:28:27.586068: train_loss -0.8235 
2025-01-25 22:28:27.593327: val_loss -0.7525 
2025-01-25 22:28:27.595774: Pseudo dice [np.float32(0.9536), np.float32(0.8729)] 
2025-01-25 22:28:27.598408: Epoch time: 30.19 s 
2025-01-25 22:28:28.639328:  
2025-01-25 22:28:28.642037: Epoch 445 
2025-01-25 22:28:28.644643: Current learning rate: 0.00589 
2025-01-25 22:28:57.784498: train_loss -0.8292 
2025-01-25 22:28:57.790330: val_loss -0.8052 
2025-01-25 22:28:57.792872: Pseudo dice [np.float32(0.9575), np.float32(0.9119)] 
2025-01-25 22:28:57.795316: Epoch time: 29.15 s 
2025-01-25 22:28:58.815917:  
2025-01-25 22:28:58.818579: Epoch 446 
2025-01-25 22:28:58.820978: Current learning rate: 0.00588 
2025-01-25 22:29:27.959636: train_loss -0.8133 
2025-01-25 22:29:27.967298: val_loss -0.7438 
2025-01-25 22:29:27.970024: Pseudo dice [np.float32(0.9537), np.float32(0.8929)] 
2025-01-25 22:29:27.972909: Epoch time: 29.14 s 
2025-01-25 22:29:28.994654:  
2025-01-25 22:29:28.997189: Epoch 447 
2025-01-25 22:29:28.999737: Current learning rate: 0.00587 
2025-01-25 22:29:57.640925: train_loss -0.8104 
2025-01-25 22:29:57.643401: val_loss -0.7672 
2025-01-25 22:29:57.645614: Pseudo dice [np.float32(0.9528), np.float32(0.8733)] 
2025-01-25 22:29:57.647628: Epoch time: 28.65 s 
2025-01-25 22:29:58.660591:  
2025-01-25 22:29:58.663153: Epoch 448 
2025-01-25 22:29:58.665341: Current learning rate: 0.00586 
2025-01-25 22:30:28.291211: train_loss -0.8159 
2025-01-25 22:30:28.297224: val_loss -0.7655 
2025-01-25 22:30:28.300462: Pseudo dice [np.float32(0.9572), np.float32(0.8791)] 
2025-01-25 22:30:28.302935: Epoch time: 29.63 s 
2025-01-25 22:30:29.488713:  
2025-01-25 22:30:29.491247: Epoch 449 
2025-01-25 22:30:29.494068: Current learning rate: 0.00585 
2025-01-25 22:30:58.698804: train_loss -0.8004 
2025-01-25 22:30:58.702833: val_loss -0.7368 
2025-01-25 22:30:58.705214: Pseudo dice [np.float32(0.9511), np.float32(0.8576)] 
2025-01-25 22:30:58.707503: Epoch time: 29.21 s 
2025-01-25 22:31:00.187019:  
2025-01-25 22:31:00.189894: Epoch 450 
2025-01-25 22:31:00.192391: Current learning rate: 0.00584 
2025-01-25 22:31:29.388939: train_loss -0.8248 
2025-01-25 22:31:29.395188: val_loss -0.7396 
2025-01-25 22:31:29.397892: Pseudo dice [np.float32(0.9596), np.float32(0.8992)] 
2025-01-25 22:31:29.400373: Epoch time: 29.2 s 
2025-01-25 22:31:30.420419:  
2025-01-25 22:31:30.422805: Epoch 451 
2025-01-25 22:31:30.425041: Current learning rate: 0.00583 
2025-01-25 22:32:00.968118: train_loss -0.8011 
2025-01-25 22:32:00.974048: val_loss -0.7946 
2025-01-25 22:32:00.976478: Pseudo dice [np.float32(0.9602), np.float32(0.9142)] 
2025-01-25 22:32:00.978847: Epoch time: 30.55 s 
2025-01-25 22:32:02.015699:  
2025-01-25 22:32:02.018433: Epoch 452 
2025-01-25 22:32:02.021011: Current learning rate: 0.00582 
2025-01-25 22:32:31.334228: train_loss -0.8207 
2025-01-25 22:32:31.339451: val_loss -0.8058 
2025-01-25 22:32:31.341865: Pseudo dice [np.float32(0.9602), np.float32(0.8758)] 
2025-01-25 22:32:31.344188: Epoch time: 29.32 s 
2025-01-25 22:32:32.369491:  
2025-01-25 22:32:32.371877: Epoch 453 
2025-01-25 22:32:32.374131: Current learning rate: 0.00581 
2025-01-25 22:33:01.169548: train_loss -0.8077 
2025-01-25 22:33:01.174741: val_loss -0.7991 
2025-01-25 22:33:01.177235: Pseudo dice [np.float32(0.9561), np.float32(0.8996)] 
2025-01-25 22:33:01.179529: Epoch time: 28.8 s 
2025-01-25 22:33:02.195693:  
2025-01-25 22:33:02.198124: Epoch 454 
2025-01-25 22:33:02.200299: Current learning rate: 0.0058 
2025-01-25 22:33:32.163279: train_loss -0.8037 
2025-01-25 22:33:32.168909: val_loss -0.7946 
2025-01-25 22:33:32.171256: Pseudo dice [np.float32(0.9568), np.float32(0.8931)] 
2025-01-25 22:33:32.173484: Epoch time: 29.97 s 
2025-01-25 22:33:33.668427:  
2025-01-25 22:33:33.671111: Epoch 455 
2025-01-25 22:33:33.673573: Current learning rate: 0.00579 
2025-01-25 22:34:03.035200: train_loss -0.8304 
2025-01-25 22:34:03.038104: val_loss -0.7724 
2025-01-25 22:34:03.040650: Pseudo dice [np.float32(0.9541), np.float32(0.9036)] 
2025-01-25 22:34:03.043207: Epoch time: 29.37 s 
2025-01-25 22:34:04.082013:  
2025-01-25 22:34:04.084318: Epoch 456 
2025-01-25 22:34:04.086650: Current learning rate: 0.00578 
2025-01-25 22:34:34.182819: train_loss -0.8113 
2025-01-25 22:34:34.191209: val_loss -0.7477 
2025-01-25 22:34:34.193554: Pseudo dice [np.float32(0.9555), np.float32(0.8599)] 
2025-01-25 22:34:34.196110: Epoch time: 30.1 s 
2025-01-25 22:34:35.401647:  
2025-01-25 22:34:35.404150: Epoch 457 
2025-01-25 22:34:35.406566: Current learning rate: 0.00577 
2025-01-25 22:35:07.373827: train_loss -0.8093 
2025-01-25 22:35:07.380322: val_loss -0.7833 
2025-01-25 22:35:07.383056: Pseudo dice [np.float32(0.9596), np.float32(0.9039)] 
2025-01-25 22:35:07.385719: Epoch time: 31.97 s 
2025-01-25 22:35:08.422615:  
2025-01-25 22:35:08.424963: Epoch 458 
2025-01-25 22:35:08.427105: Current learning rate: 0.00576 
2025-01-25 22:35:37.856147: train_loss -0.8214 
2025-01-25 22:35:37.861583: val_loss -0.8195 
2025-01-25 22:35:37.864512: Pseudo dice [np.float32(0.9578), np.float32(0.9024)] 
2025-01-25 22:35:37.866993: Epoch time: 29.43 s 
2025-01-25 22:35:38.892599:  
2025-01-25 22:35:38.895386: Epoch 459 
2025-01-25 22:35:38.897893: Current learning rate: 0.00575 
2025-01-25 22:36:08.245645: train_loss -0.838 
2025-01-25 22:36:08.249407: val_loss -0.7425 
2025-01-25 22:36:08.251614: Pseudo dice [np.float32(0.9557), np.float32(0.8889)] 
2025-01-25 22:36:08.253793: Epoch time: 29.35 s 
2025-01-25 22:36:09.270333:  
2025-01-25 22:36:09.273181: Epoch 460 
2025-01-25 22:36:09.275746: Current learning rate: 0.00574 
2025-01-25 22:36:38.744421: train_loss -0.8287 
2025-01-25 22:36:38.749757: val_loss -0.7896 
2025-01-25 22:36:38.752173: Pseudo dice [np.float32(0.9569), np.float32(0.888)] 
2025-01-25 22:36:38.754667: Epoch time: 29.47 s 
2025-01-25 22:36:39.772249:  
2025-01-25 22:36:39.774592: Epoch 461 
2025-01-25 22:36:39.776784: Current learning rate: 0.00573 
2025-01-25 22:37:09.753453: train_loss -0.8359 
2025-01-25 22:37:09.756750: val_loss -0.7795 
2025-01-25 22:37:09.759156: Pseudo dice [np.float32(0.9568), np.float32(0.9067)] 
2025-01-25 22:37:09.761603: Epoch time: 29.98 s 
2025-01-25 22:37:10.790457:  
2025-01-25 22:37:10.793246: Epoch 462 
2025-01-25 22:37:10.795709: Current learning rate: 0.00572 
2025-01-25 22:37:39.921893: train_loss -0.8219 
2025-01-25 22:37:39.927587: val_loss -0.7866 
2025-01-25 22:37:39.930031: Pseudo dice [np.float32(0.9601), np.float32(0.9056)] 
2025-01-25 22:37:39.932830: Epoch time: 29.13 s 
2025-01-25 22:37:40.946177:  
2025-01-25 22:37:40.948547: Epoch 463 
2025-01-25 22:37:40.950868: Current learning rate: 0.00571 
2025-01-25 22:38:09.648615: train_loss -0.8197 
2025-01-25 22:38:09.651492: val_loss -0.7839 
2025-01-25 22:38:09.653925: Pseudo dice [np.float32(0.961), np.float32(0.8844)] 
2025-01-25 22:38:09.656216: Epoch time: 28.7 s 
2025-01-25 22:38:10.673850:  
2025-01-25 22:38:10.676387: Epoch 464 
2025-01-25 22:38:10.678731: Current learning rate: 0.0057 
2025-01-25 22:38:40.849605: train_loss -0.8234 
2025-01-25 22:38:40.855006: val_loss -0.7712 
2025-01-25 22:38:40.857481: Pseudo dice [np.float32(0.9616), np.float32(0.9044)] 
2025-01-25 22:38:40.859905: Epoch time: 30.18 s 
2025-01-25 22:38:40.862071: Yayy! New best EMA pseudo Dice: 0.9251000285148621 
2025-01-25 22:38:42.403410:  
2025-01-25 22:38:42.406001: Epoch 465 
2025-01-25 22:38:42.408922: Current learning rate: 0.0057 
2025-01-25 22:39:10.678065: train_loss -0.8348 
2025-01-25 22:39:10.680831: val_loss -0.7899 
2025-01-25 22:39:10.683300: Pseudo dice [np.float32(0.9603), np.float32(0.907)] 
2025-01-25 22:39:10.685640: Epoch time: 28.28 s 
2025-01-25 22:39:10.688111: Yayy! New best EMA pseudo Dice: 0.9259999990463257 
2025-01-25 22:39:12.259197:  
2025-01-25 22:39:12.261639: Epoch 466 
2025-01-25 22:39:12.264129: Current learning rate: 0.00569 
2025-01-25 22:39:41.900846: train_loss -0.8386 
2025-01-25 22:39:41.907199: val_loss -0.7976 
2025-01-25 22:39:41.911048: Pseudo dice [np.float32(0.9543), np.float32(0.9035)] 
2025-01-25 22:39:41.913985: Epoch time: 29.64 s 
2025-01-25 22:39:41.916416: Yayy! New best EMA pseudo Dice: 0.9262999892234802 
2025-01-25 22:39:43.459770:  
2025-01-25 22:39:43.462696: Epoch 467 
2025-01-25 22:39:43.465324: Current learning rate: 0.00568 
2025-01-25 22:40:12.924357: train_loss -0.8547 
2025-01-25 22:40:12.929209: val_loss -0.7987 
2025-01-25 22:40:12.931525: Pseudo dice [np.float32(0.9642), np.float32(0.9098)] 
2025-01-25 22:40:12.933986: Epoch time: 29.47 s 
2025-01-25 22:40:12.936365: Yayy! New best EMA pseudo Dice: 0.927299976348877 
2025-01-25 22:40:14.516844:  
2025-01-25 22:40:14.519315: Epoch 468 
2025-01-25 22:40:14.521651: Current learning rate: 0.00567 
2025-01-25 22:40:45.606497: train_loss -0.8162 
2025-01-25 22:40:45.615791: val_loss -0.7868 
2025-01-25 22:40:45.618762: Pseudo dice [np.float32(0.9603), np.float32(0.9064)] 
2025-01-25 22:40:45.621163: Epoch time: 31.09 s 
2025-01-25 22:40:45.623728: Yayy! New best EMA pseudo Dice: 0.9279000163078308 
2025-01-25 22:40:47.383807:  
2025-01-25 22:40:47.386463: Epoch 469 
2025-01-25 22:40:47.388897: Current learning rate: 0.00566 
2025-01-25 22:41:17.390525: train_loss -0.8225 
2025-01-25 22:41:17.395228: val_loss -0.7743 
2025-01-25 22:41:17.397742: Pseudo dice [np.float32(0.9605), np.float32(0.8942)] 
2025-01-25 22:41:17.400334: Epoch time: 30.01 s 
2025-01-25 22:41:18.420986:  
2025-01-25 22:41:18.423670: Epoch 470 
2025-01-25 22:41:18.426104: Current learning rate: 0.00565 
2025-01-25 22:41:47.327754: train_loss -0.8279 
2025-01-25 22:41:47.334244: val_loss -0.8136 
2025-01-25 22:41:47.336975: Pseudo dice [np.float32(0.9583), np.float32(0.8777)] 
2025-01-25 22:41:47.339566: Epoch time: 28.91 s 
2025-01-25 22:41:48.358329:  
2025-01-25 22:41:48.360956: Epoch 471 
2025-01-25 22:41:48.363554: Current learning rate: 0.00564 
2025-01-25 22:42:17.655723: train_loss -0.8265 
2025-01-25 22:42:17.659739: val_loss -0.7549 
2025-01-25 22:42:17.662178: Pseudo dice [np.float32(0.9497), np.float32(0.8308)] 
2025-01-25 22:42:17.664500: Epoch time: 29.3 s 
2025-01-25 22:42:18.695397:  
2025-01-25 22:42:18.698341: Epoch 472 
2025-01-25 22:42:18.700999: Current learning rate: 0.00563 
2025-01-25 22:42:48.003806: train_loss -0.8284 
2025-01-25 22:42:48.013134: val_loss -0.7869 
2025-01-25 22:42:48.015509: Pseudo dice [np.float32(0.9546), np.float32(0.8701)] 
2025-01-25 22:42:48.017899: Epoch time: 29.31 s 
2025-01-25 22:42:49.152982:  
2025-01-25 22:42:49.155370: Epoch 473 
2025-01-25 22:42:49.157827: Current learning rate: 0.00562 
2025-01-25 22:43:17.632076: train_loss -0.843 
2025-01-25 22:43:17.636319: val_loss -0.7727 
2025-01-25 22:43:17.638852: Pseudo dice [np.float32(0.9582), np.float32(0.8808)] 
2025-01-25 22:43:17.641245: Epoch time: 28.48 s 
2025-01-25 22:43:19.112705:  
2025-01-25 22:43:19.115391: Epoch 474 
2025-01-25 22:43:19.118026: Current learning rate: 0.00561 
2025-01-25 22:43:48.658973: train_loss -0.8301 
2025-01-25 22:43:48.664904: val_loss -0.7839 
2025-01-25 22:43:48.667358: Pseudo dice [np.float32(0.9589), np.float32(0.9008)] 
2025-01-25 22:43:48.669669: Epoch time: 29.55 s 
2025-01-25 22:43:49.689008:  
2025-01-25 22:43:49.691266: Epoch 475 
2025-01-25 22:43:49.693691: Current learning rate: 0.0056 
2025-01-25 22:44:18.435762: train_loss -0.8209 
2025-01-25 22:44:18.442032: val_loss -0.7409 
2025-01-25 22:44:18.444559: Pseudo dice [np.float32(0.9549), np.float32(0.8649)] 
2025-01-25 22:44:18.456486: Epoch time: 28.75 s 
2025-01-25 22:44:19.507825:  
2025-01-25 22:44:19.510336: Epoch 476 
2025-01-25 22:44:19.512633: Current learning rate: 0.00559 
2025-01-25 22:44:48.311449: train_loss -0.8238 
2025-01-25 22:44:48.315437: val_loss -0.7813 
2025-01-25 22:44:48.317864: Pseudo dice [np.float32(0.9603), np.float32(0.8907)] 
2025-01-25 22:44:48.320242: Epoch time: 28.8 s 
2025-01-25 22:44:49.335073:  
2025-01-25 22:44:49.337398: Epoch 477 
2025-01-25 22:44:49.339647: Current learning rate: 0.00558 
2025-01-25 22:45:18.314329: train_loss -0.8248 
2025-01-25 22:45:18.319763: val_loss -0.7646 
2025-01-25 22:45:18.322339: Pseudo dice [np.float32(0.954), np.float32(0.8636)] 
2025-01-25 22:45:18.325109: Epoch time: 28.98 s 
2025-01-25 22:45:19.361131:  
2025-01-25 22:45:19.363705: Epoch 478 
2025-01-25 22:45:19.366106: Current learning rate: 0.00557 
2025-01-25 22:45:48.060297: train_loss -0.8201 
2025-01-25 22:45:48.066069: val_loss -0.7618 
2025-01-25 22:45:48.068356: Pseudo dice [np.float32(0.9598), np.float32(0.8949)] 
2025-01-25 22:45:48.070349: Epoch time: 28.7 s 
2025-01-25 22:45:49.106408:  
2025-01-25 22:45:49.110155: Epoch 479 
2025-01-25 22:45:49.112478: Current learning rate: 0.00556 
2025-01-25 22:46:18.795043: train_loss -0.8231 
2025-01-25 22:46:18.797856: val_loss -0.797 
2025-01-25 22:46:18.800297: Pseudo dice [np.float32(0.9535), np.float32(0.8634)] 
2025-01-25 22:46:18.802760: Epoch time: 29.69 s 
2025-01-25 22:46:19.840353:  
2025-01-25 22:46:19.843324: Epoch 480 
2025-01-25 22:46:19.846029: Current learning rate: 0.00555 
2025-01-25 22:46:49.986042: train_loss -0.8324 
2025-01-25 22:46:49.991456: val_loss -0.7584 
2025-01-25 22:46:49.993881: Pseudo dice [np.float32(0.9565), np.float32(0.899)] 
2025-01-25 22:46:49.995960: Epoch time: 30.15 s 
2025-01-25 22:46:51.035676:  
2025-01-25 22:46:51.038082: Epoch 481 
2025-01-25 22:46:51.040390: Current learning rate: 0.00554 
2025-01-25 22:47:21.401356: train_loss -0.819 
2025-01-25 22:47:21.406237: val_loss -0.7592 
2025-01-25 22:47:21.408705: Pseudo dice [np.float32(0.9589), np.float32(0.9007)] 
2025-01-25 22:47:21.411235: Epoch time: 30.37 s 
2025-01-25 22:47:22.513959:  
2025-01-25 22:47:22.516819: Epoch 482 
2025-01-25 22:47:22.519261: Current learning rate: 0.00553 
2025-01-25 22:47:51.903377: train_loss -0.8083 
2025-01-25 22:47:51.910452: val_loss -0.8189 
2025-01-25 22:47:51.913371: Pseudo dice [np.float32(0.9564), np.float32(0.9082)] 
2025-01-25 22:47:51.915924: Epoch time: 29.39 s 
2025-01-25 22:47:53.051858:  
2025-01-25 22:47:53.054757: Epoch 483 
2025-01-25 22:47:53.057306: Current learning rate: 0.00552 
2025-01-25 22:48:23.325671: train_loss -0.8081 
2025-01-25 22:48:23.328627: val_loss -0.8057 
2025-01-25 22:48:23.331076: Pseudo dice [np.float32(0.9596), np.float32(0.9018)] 
2025-01-25 22:48:23.333374: Epoch time: 30.27 s 
2025-01-25 22:48:24.378520:  
2025-01-25 22:48:24.380816: Epoch 484 
2025-01-25 22:48:24.382805: Current learning rate: 0.00551 
2025-01-25 22:48:53.763295: train_loss -0.8073 
2025-01-25 22:48:53.771983: val_loss -0.7529 
2025-01-25 22:48:53.774533: Pseudo dice [np.float32(0.9536), np.float32(0.8786)] 
2025-01-25 22:48:53.777061: Epoch time: 29.39 s 
2025-01-25 22:48:55.152522:  
2025-01-25 22:48:55.154984: Epoch 485 
2025-01-25 22:48:55.157340: Current learning rate: 0.0055 
2025-01-25 22:49:24.441942: train_loss -0.8041 
2025-01-25 22:49:24.447461: val_loss -0.7716 
2025-01-25 22:49:24.449725: Pseudo dice [np.float32(0.9568), np.float32(0.865)] 
2025-01-25 22:49:24.452231: Epoch time: 29.29 s 
2025-01-25 22:49:25.489741:  
2025-01-25 22:49:25.492275: Epoch 486 
2025-01-25 22:49:25.494629: Current learning rate: 0.00549 
2025-01-25 22:49:54.153769: train_loss -0.8273 
2025-01-25 22:49:54.160340: val_loss -0.761 
2025-01-25 22:49:54.163060: Pseudo dice [np.float32(0.9601), np.float32(0.8974)] 
2025-01-25 22:49:54.165744: Epoch time: 28.66 s 
2025-01-25 22:49:55.198732:  
2025-01-25 22:49:55.201378: Epoch 487 
2025-01-25 22:49:55.203598: Current learning rate: 0.00548 
2025-01-25 22:50:25.085974: train_loss -0.8246 
2025-01-25 22:50:25.090238: val_loss -0.7727 
2025-01-25 22:50:25.092833: Pseudo dice [np.float32(0.9621), np.float32(0.8592)] 
2025-01-25 22:50:25.095198: Epoch time: 29.89 s 
2025-01-25 22:50:26.291845:  
2025-01-25 22:50:26.294480: Epoch 488 
2025-01-25 22:50:26.296969: Current learning rate: 0.00547 
2025-01-25 22:50:55.506930: train_loss -0.8179 
2025-01-25 22:50:55.512924: val_loss -0.7637 
2025-01-25 22:50:55.515546: Pseudo dice [np.float32(0.9551), np.float32(0.8776)] 
2025-01-25 22:50:55.517947: Epoch time: 29.22 s 
2025-01-25 22:50:56.566821:  
2025-01-25 22:50:56.569529: Epoch 489 
2025-01-25 22:50:56.572206: Current learning rate: 0.00546 
2025-01-25 22:51:25.658276: train_loss -0.8136 
2025-01-25 22:51:25.661129: val_loss -0.7809 
2025-01-25 22:51:25.663563: Pseudo dice [np.float32(0.9621), np.float32(0.8924)] 
2025-01-25 22:51:25.665877: Epoch time: 29.09 s 
2025-01-25 22:51:26.697940:  
2025-01-25 22:51:26.701183: Epoch 490 
2025-01-25 22:51:26.703889: Current learning rate: 0.00546 
2025-01-25 22:51:56.860564: train_loss -0.8203 
2025-01-25 22:51:56.869316: val_loss -0.7592 
2025-01-25 22:51:56.871558: Pseudo dice [np.float32(0.9587), np.float32(0.8869)] 
2025-01-25 22:51:56.874098: Epoch time: 30.16 s 
2025-01-25 22:51:57.928688:  
2025-01-25 22:51:57.931314: Epoch 491 
2025-01-25 22:51:57.933925: Current learning rate: 0.00545 
2025-01-25 22:52:27.632383: train_loss -0.8307 
2025-01-25 22:52:27.635018: val_loss -0.7773 
2025-01-25 22:52:27.637286: Pseudo dice [np.float32(0.9599), np.float32(0.8963)] 
2025-01-25 22:52:27.639658: Epoch time: 29.7 s 
2025-01-25 22:52:28.684672:  
2025-01-25 22:52:28.686962: Epoch 492 
2025-01-25 22:52:28.689426: Current learning rate: 0.00544 
2025-01-25 22:52:57.803205: train_loss -0.8222 
2025-01-25 22:52:57.808888: val_loss -0.7882 
2025-01-25 22:52:57.811597: Pseudo dice [np.float32(0.9508), np.float32(0.8718)] 
2025-01-25 22:52:57.813683: Epoch time: 29.12 s 
2025-01-25 22:52:59.287492:  
2025-01-25 22:52:59.290236: Epoch 493 
2025-01-25 22:52:59.292625: Current learning rate: 0.00543 
2025-01-25 22:53:28.996768: train_loss -0.8331 
2025-01-25 22:53:28.999424: val_loss -0.7613 
2025-01-25 22:53:29.001873: Pseudo dice [np.float32(0.9564), np.float32(0.8939)] 
2025-01-25 22:53:29.004132: Epoch time: 29.71 s 
2025-01-25 22:53:30.057132:  
2025-01-25 22:53:30.059496: Epoch 494 
2025-01-25 22:53:30.061924: Current learning rate: 0.00542 
2025-01-25 22:53:58.820601: train_loss -0.8488 
2025-01-25 22:53:58.825586: val_loss -0.7934 
2025-01-25 22:53:58.827837: Pseudo dice [np.float32(0.9647), np.float32(0.8936)] 
2025-01-25 22:53:58.830234: Epoch time: 28.76 s 
2025-01-25 22:53:59.861701:  
2025-01-25 22:53:59.864774: Epoch 495 
2025-01-25 22:53:59.867489: Current learning rate: 0.00541 
2025-01-25 22:54:29.563251: train_loss -0.8309 
2025-01-25 22:54:29.566240: val_loss -0.7713 
2025-01-25 22:54:29.568868: Pseudo dice [np.float32(0.9628), np.float32(0.8779)] 
2025-01-25 22:54:29.571652: Epoch time: 29.7 s 
2025-01-25 22:54:30.611917:  
2025-01-25 22:54:30.614414: Epoch 496 
2025-01-25 22:54:30.616760: Current learning rate: 0.0054 
2025-01-25 22:54:59.999271: train_loss -0.8209 
2025-01-25 22:55:00.005308: val_loss -0.7602 
2025-01-25 22:55:00.007748: Pseudo dice [np.float32(0.9535), np.float32(0.856)] 
2025-01-25 22:55:00.010100: Epoch time: 29.39 s 
2025-01-25 22:55:01.046939:  
2025-01-25 22:55:01.049260: Epoch 497 
2025-01-25 22:55:01.051475: Current learning rate: 0.00539 
2025-01-25 22:55:30.036139: train_loss -0.8261 
2025-01-25 22:55:30.039126: val_loss -0.797 
2025-01-25 22:55:30.041342: Pseudo dice [np.float32(0.9538), np.float32(0.8875)] 
2025-01-25 22:55:30.043718: Epoch time: 28.99 s 
2025-01-25 22:55:31.080551:  
2025-01-25 22:55:31.083015: Epoch 498 
2025-01-25 22:55:31.085298: Current learning rate: 0.00538 
2025-01-25 22:56:00.072199: train_loss -0.8199 
2025-01-25 22:56:00.081003: val_loss -0.7833 
2025-01-25 22:56:00.083835: Pseudo dice [np.float32(0.9591), np.float32(0.9003)] 
2025-01-25 22:56:00.086532: Epoch time: 28.99 s 
2025-01-25 22:56:01.139985:  
2025-01-25 22:56:01.142445: Epoch 499 
2025-01-25 22:56:01.144935: Current learning rate: 0.00537 
2025-01-25 22:56:29.682961: train_loss -0.8116 
2025-01-25 22:56:29.685716: val_loss -0.7225 
2025-01-25 22:56:29.688082: Pseudo dice [np.float32(0.961), np.float32(0.8646)] 
2025-01-25 22:56:29.690227: Epoch time: 28.54 s 
2025-01-25 22:56:31.177346:  
2025-01-25 22:56:31.179821: Epoch 500 
2025-01-25 22:56:31.182242: Current learning rate: 0.00536 
2025-01-25 22:57:01.925375: train_loss -0.7954 
2025-01-25 22:57:01.930520: val_loss -0.7726 
2025-01-25 22:57:01.932811: Pseudo dice [np.float32(0.9604), np.float32(0.8928)] 
2025-01-25 22:57:01.934949: Epoch time: 30.75 s 
2025-01-25 22:57:02.975977:  
2025-01-25 22:57:02.978614: Epoch 501 
2025-01-25 22:57:02.981542: Current learning rate: 0.00535 
2025-01-25 22:57:32.239621: train_loss -0.8194 
2025-01-25 22:57:32.242379: val_loss -0.7872 
2025-01-25 22:57:32.244819: Pseudo dice [np.float32(0.9554), np.float32(0.8895)] 
2025-01-25 22:57:32.247285: Epoch time: 29.26 s 
2025-01-25 22:57:33.282696:  
2025-01-25 22:57:33.285107: Epoch 502 
2025-01-25 22:57:33.287638: Current learning rate: 0.00534 
2025-01-25 22:58:03.500921: train_loss -0.8296 
2025-01-25 22:58:03.507173: val_loss -0.729 
2025-01-25 22:58:03.509725: Pseudo dice [np.float32(0.9561), np.float32(0.8833)] 
2025-01-25 22:58:03.512299: Epoch time: 30.22 s 
2025-01-25 22:58:04.552887:  
2025-01-25 22:58:04.555426: Epoch 503 
2025-01-25 22:58:04.558006: Current learning rate: 0.00533 
2025-01-25 22:58:33.864868: train_loss -0.8208 
2025-01-25 22:58:33.867714: val_loss -0.7507 
2025-01-25 22:58:33.870047: Pseudo dice [np.float32(0.957), np.float32(0.8869)] 
2025-01-25 22:58:33.872210: Epoch time: 29.31 s 
2025-01-25 22:58:34.901945:  
2025-01-25 22:58:34.904438: Epoch 504 
2025-01-25 22:58:34.906830: Current learning rate: 0.00532 
2025-01-25 22:59:04.871416: train_loss -0.8324 
2025-01-25 22:59:04.878490: val_loss -0.8027 
2025-01-25 22:59:04.881182: Pseudo dice [np.float32(0.9621), np.float32(0.9046)] 
2025-01-25 22:59:04.883594: Epoch time: 29.97 s 
2025-01-25 22:59:05.968523:  
2025-01-25 22:59:05.970870: Epoch 505 
2025-01-25 22:59:05.973172: Current learning rate: 0.00531 
2025-01-25 22:59:37.038789: train_loss -0.8214 
2025-01-25 22:59:37.041740: val_loss -0.786 
2025-01-25 22:59:37.044056: Pseudo dice [np.float32(0.9537), np.float32(0.8431)] 
2025-01-25 22:59:37.046593: Epoch time: 31.07 s 
2025-01-25 22:59:38.098437:  
2025-01-25 22:59:38.101247: Epoch 506 
2025-01-25 22:59:38.103866: Current learning rate: 0.0053 
2025-01-25 23:00:07.915502: train_loss -0.8281 
2025-01-25 23:00:07.923315: val_loss -0.7605 
2025-01-25 23:00:07.926682: Pseudo dice [np.float32(0.9391), np.float32(0.9053)] 
2025-01-25 23:00:07.929273: Epoch time: 29.82 s 
2025-01-25 23:00:08.967014:  
2025-01-25 23:00:08.969563: Epoch 507 
2025-01-25 23:00:08.971787: Current learning rate: 0.00529 
2025-01-25 23:00:40.317307: train_loss -0.8138 
2025-01-25 23:00:40.321723: val_loss -0.7463 
2025-01-25 23:00:40.324582: Pseudo dice [np.float32(0.9475), np.float32(0.8563)] 
2025-01-25 23:00:40.327277: Epoch time: 31.35 s 
2025-01-25 23:00:41.547886:  
2025-01-25 23:00:41.550352: Epoch 508 
2025-01-25 23:00:41.552860: Current learning rate: 0.00528 
2025-01-25 23:01:12.128876: train_loss -0.8276 
2025-01-25 23:01:12.134242: val_loss -0.7708 
2025-01-25 23:01:12.136643: Pseudo dice [np.float32(0.9525), np.float32(0.8542)] 
2025-01-25 23:01:12.139003: Epoch time: 30.58 s 
2025-01-25 23:01:13.177654:  
2025-01-25 23:01:13.180409: Epoch 509 
2025-01-25 23:01:13.183228: Current learning rate: 0.00527 
2025-01-25 23:01:42.853294: train_loss -0.8152 
2025-01-25 23:01:42.856167: val_loss -0.7577 
2025-01-25 23:01:42.859851: Pseudo dice [np.float32(0.9548), np.float32(0.8948)] 
2025-01-25 23:01:42.862377: Epoch time: 29.68 s 
2025-01-25 23:01:43.937112:  
2025-01-25 23:01:43.939548: Epoch 510 
2025-01-25 23:01:43.942112: Current learning rate: 0.00526 
2025-01-25 23:02:13.945881: train_loss -0.8007 
2025-01-25 23:02:13.951293: val_loss -0.7636 
2025-01-25 23:02:13.953981: Pseudo dice [np.float32(0.956), np.float32(0.8743)] 
2025-01-25 23:02:13.956414: Epoch time: 30.01 s 
2025-01-25 23:02:15.110509:  
2025-01-25 23:02:15.113086: Epoch 511 
2025-01-25 23:02:15.115587: Current learning rate: 0.00525 
2025-01-25 23:02:46.570421: train_loss -0.8068 
2025-01-25 23:02:46.573458: val_loss -0.7766 
2025-01-25 23:02:46.575908: Pseudo dice [np.float32(0.9528), np.float32(0.8544)] 
2025-01-25 23:02:46.578378: Epoch time: 31.46 s 
2025-01-25 23:02:48.075445:  
2025-01-25 23:02:48.077885: Epoch 512 
2025-01-25 23:02:48.080367: Current learning rate: 0.00524 
2025-01-25 23:03:18.269925: train_loss -0.8097 
2025-01-25 23:03:18.275473: val_loss -0.7499 
2025-01-25 23:03:18.278027: Pseudo dice [np.float32(0.9541), np.float32(0.8515)] 
2025-01-25 23:03:18.280603: Epoch time: 30.2 s 
2025-01-25 23:03:19.322454:  
2025-01-25 23:03:19.325200: Epoch 513 
2025-01-25 23:03:19.327701: Current learning rate: 0.00523 
2025-01-25 23:03:49.939277: train_loss -0.8291 
2025-01-25 23:03:49.941889: val_loss -0.7544 
2025-01-25 23:03:49.944283: Pseudo dice [np.float32(0.9591), np.float32(0.8535)] 
2025-01-25 23:03:49.946615: Epoch time: 30.62 s 
2025-01-25 23:03:51.001666:  
2025-01-25 23:03:51.004517: Epoch 514 
2025-01-25 23:03:51.006756: Current learning rate: 0.00522 
2025-01-25 23:04:22.087244: train_loss -0.8139 
2025-01-25 23:04:22.093205: val_loss -0.7746 
2025-01-25 23:04:22.095690: Pseudo dice [np.float32(0.9564), np.float32(0.8378)] 
2025-01-25 23:04:22.098136: Epoch time: 31.09 s 
2025-01-25 23:04:23.140541:  
2025-01-25 23:04:23.143024: Epoch 515 
2025-01-25 23:04:23.145577: Current learning rate: 0.00521 
2025-01-25 23:04:52.412897: train_loss -0.8133 
2025-01-25 23:04:52.415918: val_loss -0.7859 
2025-01-25 23:04:52.418342: Pseudo dice [np.float32(0.9503), np.float32(0.8454)] 
2025-01-25 23:04:52.420716: Epoch time: 29.27 s 
2025-01-25 23:04:53.473715:  
2025-01-25 23:04:53.476054: Epoch 516 
2025-01-25 23:04:53.478484: Current learning rate: 0.0052 
2025-01-25 23:05:24.272749: train_loss -0.7911 
2025-01-25 23:05:24.277903: val_loss -0.751 
2025-01-25 23:05:24.280178: Pseudo dice [np.float32(0.9495), np.float32(0.8073)] 
2025-01-25 23:05:24.282531: Epoch time: 30.8 s 
2025-01-25 23:05:25.316500:  
2025-01-25 23:05:25.318563: Epoch 517 
2025-01-25 23:05:25.320670: Current learning rate: 0.00519 
2025-01-25 23:05:54.836607: train_loss -0.8161 
2025-01-25 23:05:54.839372: val_loss -0.7693 
2025-01-25 23:05:54.841606: Pseudo dice [np.float32(0.9587), np.float32(0.8835)] 
2025-01-25 23:05:54.843966: Epoch time: 29.52 s 
2025-01-25 23:05:55.889787:  
2025-01-25 23:05:55.892215: Epoch 518 
2025-01-25 23:05:55.894748: Current learning rate: 0.00518 
2025-01-25 23:06:25.502325: train_loss -0.8143 
2025-01-25 23:06:25.507304: val_loss -0.8024 
2025-01-25 23:06:25.509424: Pseudo dice [np.float32(0.9598), np.float32(0.8905)] 
2025-01-25 23:06:25.511566: Epoch time: 29.61 s 
2025-01-25 23:06:26.549932:  
2025-01-25 23:06:26.552754: Epoch 519 
2025-01-25 23:06:26.554919: Current learning rate: 0.00518 
2025-01-25 23:06:56.977474: train_loss -0.8145 
2025-01-25 23:06:56.984417: val_loss -0.7603 
2025-01-25 23:06:56.987076: Pseudo dice [np.float32(0.9565), np.float32(0.6969)] 
2025-01-25 23:06:56.989474: Epoch time: 30.43 s 
2025-01-25 23:06:58.047366:  
2025-01-25 23:06:58.049647: Epoch 520 
2025-01-25 23:06:58.052022: Current learning rate: 0.00517 
2025-01-25 23:07:26.709585: train_loss -0.8276 
2025-01-25 23:07:26.715481: val_loss -0.8112 
2025-01-25 23:07:26.717928: Pseudo dice [np.float32(0.9598), np.float32(0.9115)] 
2025-01-25 23:07:26.720293: Epoch time: 28.66 s 
2025-01-25 23:07:27.761834:  
2025-01-25 23:07:27.764492: Epoch 521 
2025-01-25 23:07:27.766945: Current learning rate: 0.00516 
2025-01-25 23:07:56.757067: train_loss -0.826 
2025-01-25 23:07:56.759933: val_loss -0.7467 
2025-01-25 23:07:56.762402: Pseudo dice [np.float32(0.9609), np.float32(0.8647)] 
2025-01-25 23:07:56.765151: Epoch time: 29.0 s 
2025-01-25 23:07:57.935641:  
2025-01-25 23:07:57.937869: Epoch 522 
2025-01-25 23:07:57.940180: Current learning rate: 0.00515 
2025-01-25 23:08:28.446286: train_loss -0.8248 
2025-01-25 23:08:28.453140: val_loss -0.7673 
2025-01-25 23:08:28.455977: Pseudo dice [np.float32(0.9524), np.float32(0.872)] 
2025-01-25 23:08:28.458572: Epoch time: 30.51 s 
2025-01-25 23:08:29.504381:  
2025-01-25 23:08:29.506753: Epoch 523 
2025-01-25 23:08:29.509140: Current learning rate: 0.00514 
2025-01-25 23:08:59.226437: train_loss -0.8372 
2025-01-25 23:08:59.229682: val_loss -0.7798 
2025-01-25 23:08:59.232417: Pseudo dice [np.float32(0.9587), np.float32(0.8916)] 
2025-01-25 23:08:59.234816: Epoch time: 29.72 s 
2025-01-25 23:09:00.270571:  
2025-01-25 23:09:00.273653: Epoch 524 
2025-01-25 23:09:00.276222: Current learning rate: 0.00513 
2025-01-25 23:09:28.640814: train_loss -0.8289 
2025-01-25 23:09:28.646122: val_loss -0.7846 
2025-01-25 23:09:28.648659: Pseudo dice [np.float32(0.9623), np.float32(0.8814)] 
2025-01-25 23:09:28.651474: Epoch time: 28.37 s 
2025-01-25 23:09:29.695054:  
2025-01-25 23:09:29.697410: Epoch 525 
2025-01-25 23:09:29.699474: Current learning rate: 0.00512 
2025-01-25 23:09:58.060477: train_loss -0.8428 
2025-01-25 23:09:58.063260: val_loss -0.7381 
2025-01-25 23:09:58.065923: Pseudo dice [np.float32(0.952), np.float32(0.8403)] 
2025-01-25 23:09:58.068245: Epoch time: 28.37 s 
2025-01-25 23:09:59.109264:  
2025-01-25 23:09:59.112119: Epoch 526 
2025-01-25 23:09:59.114807: Current learning rate: 0.00511 
2025-01-25 23:10:28.725821: train_loss -0.8343 
2025-01-25 23:10:28.730636: val_loss -0.7693 
2025-01-25 23:10:28.732761: Pseudo dice [np.float32(0.9589), np.float32(0.9031)] 
2025-01-25 23:10:28.734910: Epoch time: 29.62 s 
2025-01-25 23:10:29.790943:  
2025-01-25 23:10:29.793597: Epoch 527 
2025-01-25 23:10:29.796110: Current learning rate: 0.0051 
2025-01-25 23:10:59.680171: train_loss -0.8397 
2025-01-25 23:10:59.685689: val_loss -0.782 
2025-01-25 23:10:59.688321: Pseudo dice [np.float32(0.9596), np.float32(0.8879)] 
2025-01-25 23:10:59.690901: Epoch time: 29.89 s 
2025-01-25 23:11:00.805060:  
2025-01-25 23:11:00.807799: Epoch 528 
2025-01-25 23:11:00.810117: Current learning rate: 0.00509 
2025-01-25 23:11:32.457317: train_loss -0.8088 
2025-01-25 23:11:32.463302: val_loss -0.7955 
2025-01-25 23:11:32.465823: Pseudo dice [np.float32(0.9633), np.float32(0.9009)] 
2025-01-25 23:11:32.468340: Epoch time: 31.65 s 
2025-01-25 23:11:33.508748:  
2025-01-25 23:11:33.511580: Epoch 529 
2025-01-25 23:11:33.514103: Current learning rate: 0.00508 
2025-01-25 23:12:02.648569: train_loss -0.8237 
2025-01-25 23:12:02.651545: val_loss -0.7709 
2025-01-25 23:12:02.653866: Pseudo dice [np.float32(0.9507), np.float32(0.8583)] 
2025-01-25 23:12:02.656332: Epoch time: 29.14 s 
2025-01-25 23:12:03.689454:  
2025-01-25 23:12:03.691795: Epoch 530 
2025-01-25 23:12:03.694042: Current learning rate: 0.00507 
2025-01-25 23:12:33.026023: train_loss -0.8325 
2025-01-25 23:12:33.031893: val_loss -0.7931 
2025-01-25 23:12:33.034323: Pseudo dice [np.float32(0.9556), np.float32(0.8858)] 
2025-01-25 23:12:33.036774: Epoch time: 29.34 s 
2025-01-25 23:12:34.540440:  
2025-01-25 23:12:34.543197: Epoch 531 
2025-01-25 23:12:34.545547: Current learning rate: 0.00506 
2025-01-25 23:13:03.437139: train_loss -0.826 
2025-01-25 23:13:03.440023: val_loss -0.7871 
2025-01-25 23:13:03.442247: Pseudo dice [np.float32(0.9556), np.float32(0.8735)] 
2025-01-25 23:13:03.444729: Epoch time: 28.9 s 
2025-01-25 23:13:04.480577:  
2025-01-25 23:13:04.483135: Epoch 532 
2025-01-25 23:13:04.485601: Current learning rate: 0.00505 
2025-01-25 23:13:34.476965: train_loss -0.8348 
2025-01-25 23:13:34.482489: val_loss -0.7903 
2025-01-25 23:13:34.485019: Pseudo dice [np.float32(0.9647), np.float32(0.9085)] 
2025-01-25 23:13:34.487527: Epoch time: 30.0 s 
2025-01-25 23:13:35.525085:  
2025-01-25 23:13:35.527504: Epoch 533 
2025-01-25 23:13:35.529635: Current learning rate: 0.00504 
2025-01-25 23:14:06.917432: train_loss -0.8115 
2025-01-25 23:14:06.922601: val_loss -0.7503 
2025-01-25 23:14:06.925247: Pseudo dice [np.float32(0.9556), np.float32(0.8945)] 
2025-01-25 23:14:06.927330: Epoch time: 31.39 s 
2025-01-25 23:14:08.043372:  
2025-01-25 23:14:08.045765: Epoch 534 
2025-01-25 23:14:08.048194: Current learning rate: 0.00503 
2025-01-25 23:14:37.388650: train_loss -0.8219 
2025-01-25 23:14:37.393724: val_loss -0.7698 
2025-01-25 23:14:37.396010: Pseudo dice [np.float32(0.9516), np.float32(0.8819)] 
2025-01-25 23:14:37.398466: Epoch time: 29.35 s 
2025-01-25 23:14:38.432458:  
2025-01-25 23:14:38.435111: Epoch 535 
2025-01-25 23:14:38.437338: Current learning rate: 0.00502 
2025-01-25 23:15:07.798654: train_loss -0.819 
2025-01-25 23:15:07.802401: val_loss -0.807 
2025-01-25 23:15:07.805166: Pseudo dice [np.float32(0.9566), np.float32(0.8477)] 
2025-01-25 23:15:07.807897: Epoch time: 29.37 s 
2025-01-25 23:15:08.855776:  
2025-01-25 23:15:08.858462: Epoch 536 
2025-01-25 23:15:08.860990: Current learning rate: 0.00501 
2025-01-25 23:15:37.759784: train_loss -0.815 
2025-01-25 23:15:37.764757: val_loss -0.7772 
2025-01-25 23:15:37.767019: Pseudo dice [np.float32(0.9529), np.float32(0.8856)] 
2025-01-25 23:15:37.769397: Epoch time: 28.9 s 
2025-01-25 23:15:38.816288:  
2025-01-25 23:15:38.818705: Epoch 537 
2025-01-25 23:15:38.821187: Current learning rate: 0.005 
2025-01-25 23:16:08.093976: train_loss -0.8196 
2025-01-25 23:16:08.096572: val_loss -0.8017 
2025-01-25 23:16:08.099216: Pseudo dice [np.float32(0.9632), np.float32(0.9115)] 
2025-01-25 23:16:08.101459: Epoch time: 29.28 s 
2025-01-25 23:16:09.134308:  
2025-01-25 23:16:09.137054: Epoch 538 
2025-01-25 23:16:09.139497: Current learning rate: 0.00499 
2025-01-25 23:16:37.830374: train_loss -0.8235 
2025-01-25 23:16:37.836055: val_loss -0.7407 
2025-01-25 23:16:37.838365: Pseudo dice [np.float32(0.9585), np.float32(0.8851)] 
2025-01-25 23:16:37.840647: Epoch time: 28.7 s 
2025-01-25 23:16:38.879895:  
2025-01-25 23:16:38.882585: Epoch 539 
2025-01-25 23:16:38.885256: Current learning rate: 0.00498 
2025-01-25 23:17:07.792507: train_loss -0.8186 
2025-01-25 23:17:07.795139: val_loss -0.78 
2025-01-25 23:17:07.797320: Pseudo dice [np.float32(0.957), np.float32(0.8976)] 
2025-01-25 23:17:07.799700: Epoch time: 28.91 s 
2025-01-25 23:17:08.833838:  
2025-01-25 23:17:08.836452: Epoch 540 
2025-01-25 23:17:08.838912: Current learning rate: 0.00497 
2025-01-25 23:17:39.114239: train_loss -0.8032 
2025-01-25 23:17:39.120341: val_loss -0.7443 
2025-01-25 23:17:39.122808: Pseudo dice [np.float32(0.9579), np.float32(0.8334)] 
2025-01-25 23:17:39.125230: Epoch time: 30.28 s 
2025-01-25 23:17:40.157609:  
2025-01-25 23:17:40.159898: Epoch 541 
2025-01-25 23:17:40.162027: Current learning rate: 0.00496 
2025-01-25 23:18:08.788485: train_loss -0.8382 
2025-01-25 23:18:08.791255: val_loss -0.7897 
2025-01-25 23:18:08.793609: Pseudo dice [np.float32(0.9613), np.float32(0.8956)] 
2025-01-25 23:18:08.796158: Epoch time: 28.63 s 
2025-01-25 23:18:09.834459:  
2025-01-25 23:18:09.837189: Epoch 542 
2025-01-25 23:18:09.839880: Current learning rate: 0.00495 
2025-01-25 23:18:39.343896: train_loss -0.8151 
2025-01-25 23:18:39.349630: val_loss -0.7097 
2025-01-25 23:18:39.352202: Pseudo dice [np.float32(0.9569), np.float32(0.81)] 
2025-01-25 23:18:39.354643: Epoch time: 29.51 s 
2025-01-25 23:18:40.386657:  
2025-01-25 23:18:40.389154: Epoch 543 
2025-01-25 23:18:40.391216: Current learning rate: 0.00494 
2025-01-25 23:19:09.248858: train_loss -0.793 
2025-01-25 23:19:09.251813: val_loss -0.7499 
2025-01-25 23:19:09.254156: Pseudo dice [np.float32(0.9522), np.float32(0.8855)] 
2025-01-25 23:19:09.256637: Epoch time: 28.86 s 
2025-01-25 23:19:10.287642:  
2025-01-25 23:19:10.290214: Epoch 544 
2025-01-25 23:19:10.292712: Current learning rate: 0.00493 
2025-01-25 23:19:40.349889: train_loss -0.7721 
2025-01-25 23:19:40.354833: val_loss -0.7257 
2025-01-25 23:19:40.357387: Pseudo dice [np.float32(0.9454), np.float32(0.8643)] 
2025-01-25 23:19:40.359869: Epoch time: 30.06 s 
2025-01-25 23:19:41.432166:  
2025-01-25 23:19:41.435312: Epoch 545 
2025-01-25 23:19:41.438124: Current learning rate: 0.00492 
2025-01-25 23:20:10.087266: train_loss -0.8043 
2025-01-25 23:20:10.090055: val_loss -0.7597 
2025-01-25 23:20:10.092400: Pseudo dice [np.float32(0.9553), np.float32(0.8801)] 
2025-01-25 23:20:10.094812: Epoch time: 28.66 s 
2025-01-25 23:20:11.130865:  
2025-01-25 23:20:11.133205: Epoch 546 
2025-01-25 23:20:11.135479: Current learning rate: 0.00491 
2025-01-25 23:20:42.108353: train_loss -0.824 
2025-01-25 23:20:42.113399: val_loss -0.7747 
2025-01-25 23:20:42.116138: Pseudo dice [np.float32(0.9592), np.float32(0.8868)] 
2025-01-25 23:20:42.118640: Epoch time: 30.98 s 
2025-01-25 23:20:43.158276:  
2025-01-25 23:20:43.160855: Epoch 547 
2025-01-25 23:20:43.163201: Current learning rate: 0.0049 
2025-01-25 23:21:11.387522: train_loss -0.8303 
2025-01-25 23:21:11.390142: val_loss -0.7852 
2025-01-25 23:21:11.392483: Pseudo dice [np.float32(0.9585), np.float32(0.9039)] 
2025-01-25 23:21:11.394803: Epoch time: 28.23 s 
2025-01-25 23:21:12.426145:  
2025-01-25 23:21:12.428694: Epoch 548 
2025-01-25 23:21:12.431350: Current learning rate: 0.00489 
2025-01-25 23:21:42.096144: train_loss -0.8309 
2025-01-25 23:21:42.099165: val_loss -0.7559 
2025-01-25 23:21:42.101398: Pseudo dice [np.float32(0.9549), np.float32(0.8804)] 
2025-01-25 23:21:42.103740: Epoch time: 29.67 s 
2025-01-25 23:21:43.139086:  
2025-01-25 23:21:43.141418: Epoch 549 
2025-01-25 23:21:43.143663: Current learning rate: 0.00488 
2025-01-25 23:22:12.897177: train_loss -0.8121 
2025-01-25 23:22:12.905726: val_loss -0.785 
2025-01-25 23:22:12.908489: Pseudo dice [np.float32(0.9592), np.float32(0.8813)] 
2025-01-25 23:22:12.911358: Epoch time: 29.76 s 
2025-01-25 23:22:15.212966:  
2025-01-25 23:22:15.215440: Epoch 550 
2025-01-25 23:22:15.217541: Current learning rate: 0.00487 
2025-01-25 23:22:46.595006: train_loss -0.8243 
2025-01-25 23:22:46.600332: val_loss -0.7387 
2025-01-25 23:22:46.602535: Pseudo dice [np.float32(0.9469), np.float32(0.877)] 
2025-01-25 23:22:46.604866: Epoch time: 31.38 s 
2025-01-25 23:22:47.641410:  
2025-01-25 23:22:47.643967: Epoch 551 
2025-01-25 23:22:47.646565: Current learning rate: 0.00486 
2025-01-25 23:23:16.669828: train_loss -0.8118 
2025-01-25 23:23:16.674756: val_loss -0.7501 
2025-01-25 23:23:16.677269: Pseudo dice [np.float32(0.9506), np.float32(0.8592)] 
2025-01-25 23:23:16.679743: Epoch time: 29.03 s 
2025-01-25 23:23:17.855373:  
2025-01-25 23:23:17.858079: Epoch 552 
2025-01-25 23:23:17.860355: Current learning rate: 0.00485 
2025-01-25 23:23:46.531296: train_loss -0.8204 
2025-01-25 23:23:46.533972: val_loss -0.76 
2025-01-25 23:23:46.536176: Pseudo dice [np.float32(0.9605), np.float32(0.8665)] 
2025-01-25 23:23:46.538632: Epoch time: 28.68 s 
2025-01-25 23:23:47.578909:  
2025-01-25 23:23:47.581614: Epoch 553 
2025-01-25 23:23:47.583913: Current learning rate: 0.00484 
2025-01-25 23:24:17.396844: train_loss -0.8434 
2025-01-25 23:24:17.399791: val_loss -0.8129 
2025-01-25 23:24:17.402088: Pseudo dice [np.float32(0.9613), np.float32(0.8875)] 
2025-01-25 23:24:17.404269: Epoch time: 29.82 s 
2025-01-25 23:24:18.444643:  
2025-01-25 23:24:18.447134: Epoch 554 
2025-01-25 23:24:18.451930: Current learning rate: 0.00484 
2025-01-25 23:24:48.902634: train_loss -0.8189 
2025-01-25 23:24:48.911109: val_loss -0.7969 
2025-01-25 23:24:48.914300: Pseudo dice [np.float32(0.9594), np.float32(0.8873)] 
2025-01-25 23:24:48.916689: Epoch time: 30.46 s 
2025-01-25 23:24:50.003669:  
2025-01-25 23:24:50.006323: Epoch 555 
2025-01-25 23:24:50.009055: Current learning rate: 0.00483 
2025-01-25 23:25:19.724230: train_loss -0.8195 
2025-01-25 23:25:19.730033: val_loss -0.777 
2025-01-25 23:25:19.733061: Pseudo dice [np.float32(0.9641), np.float32(0.8993)] 
2025-01-25 23:25:19.735844: Epoch time: 29.72 s 
2025-01-25 23:25:21.059357:  
2025-01-25 23:25:21.061859: Epoch 556 
2025-01-25 23:25:21.064294: Current learning rate: 0.00482 
2025-01-25 23:25:50.337631: train_loss -0.8245 
2025-01-25 23:25:50.343029: val_loss -0.8084 
2025-01-25 23:25:50.345285: Pseudo dice [np.float32(0.9622), np.float32(0.8959)] 
2025-01-25 23:25:50.347816: Epoch time: 29.28 s 
2025-01-25 23:25:51.417907:  
2025-01-25 23:25:51.420507: Epoch 557 
2025-01-25 23:25:51.422772: Current learning rate: 0.00481 
2025-01-25 23:26:20.950389: train_loss -0.8248 
2025-01-25 23:26:20.953161: val_loss -0.7675 
2025-01-25 23:26:20.955556: Pseudo dice [np.float32(0.9622), np.float32(0.9047)] 
2025-01-25 23:26:20.957752: Epoch time: 29.53 s 
2025-01-25 23:26:21.989027:  
2025-01-25 23:26:21.991448: Epoch 558 
2025-01-25 23:26:21.993630: Current learning rate: 0.0048 
2025-01-25 23:26:52.193714: train_loss -0.819 
2025-01-25 23:26:52.203754: val_loss -0.7447 
2025-01-25 23:26:52.206644: Pseudo dice [np.float32(0.9575), np.float32(0.8687)] 
2025-01-25 23:26:52.209104: Epoch time: 30.21 s 
2025-01-25 23:26:53.254598:  
2025-01-25 23:26:53.257084: Epoch 559 
2025-01-25 23:26:53.259461: Current learning rate: 0.00479 
2025-01-25 23:27:22.575181: train_loss -0.8198 
2025-01-25 23:27:22.578381: val_loss -0.7702 
2025-01-25 23:27:22.580878: Pseudo dice [np.float32(0.9486), np.float32(0.8696)] 
2025-01-25 23:27:22.583568: Epoch time: 29.32 s 
2025-01-25 23:27:23.616231:  
2025-01-25 23:27:23.618968: Epoch 560 
2025-01-25 23:27:23.621469: Current learning rate: 0.00478 
2025-01-25 23:27:54.804880: train_loss -0.8319 
2025-01-25 23:27:54.810098: val_loss -0.8215 
2025-01-25 23:27:54.812670: Pseudo dice [np.float32(0.9593), np.float32(0.8931)] 
2025-01-25 23:27:54.815206: Epoch time: 31.19 s 
2025-01-25 23:27:55.865363:  
2025-01-25 23:27:55.867650: Epoch 561 
2025-01-25 23:27:55.869828: Current learning rate: 0.00477 
2025-01-25 23:28:24.966576: train_loss -0.8154 
2025-01-25 23:28:24.970014: val_loss -0.7939 
2025-01-25 23:28:24.972421: Pseudo dice [np.float32(0.9575), np.float32(0.8737)] 
2025-01-25 23:28:24.974687: Epoch time: 29.1 s 
2025-01-25 23:28:26.009064:  
2025-01-25 23:28:26.011927: Epoch 562 
2025-01-25 23:28:26.014316: Current learning rate: 0.00476 
2025-01-25 23:28:55.387669: train_loss -0.8276 
2025-01-25 23:28:55.395592: val_loss -0.7919 
2025-01-25 23:28:55.398054: Pseudo dice [np.float32(0.9568), np.float32(0.8929)] 
2025-01-25 23:28:55.400305: Epoch time: 29.38 s 
2025-01-25 23:28:56.454224:  
2025-01-25 23:28:56.457259: Epoch 563 
2025-01-25 23:28:56.459858: Current learning rate: 0.00475 
2025-01-25 23:29:26.101995: train_loss -0.8313 
2025-01-25 23:29:26.104678: val_loss -0.7922 
2025-01-25 23:29:26.106903: Pseudo dice [np.float32(0.9592), np.float32(0.9021)] 
2025-01-25 23:29:26.109024: Epoch time: 29.65 s 
2025-01-25 23:29:27.143306:  
2025-01-25 23:29:27.146257: Epoch 564 
2025-01-25 23:29:27.149042: Current learning rate: 0.00474 
2025-01-25 23:29:55.965266: train_loss -0.8183 
2025-01-25 23:29:55.970634: val_loss -0.772 
2025-01-25 23:29:55.973075: Pseudo dice [np.float32(0.9596), np.float32(0.8734)] 
2025-01-25 23:29:55.975416: Epoch time: 28.82 s 
2025-01-25 23:29:57.015707:  
2025-01-25 23:29:57.018394: Epoch 565 
2025-01-25 23:29:57.021059: Current learning rate: 0.00473 
2025-01-25 23:30:26.571606: train_loss -0.8248 
2025-01-25 23:30:26.574708: val_loss -0.7782 
2025-01-25 23:30:26.577472: Pseudo dice [np.float32(0.954), np.float32(0.86)] 
2025-01-25 23:30:26.579808: Epoch time: 29.56 s 
2025-01-25 23:30:27.632461:  
2025-01-25 23:30:27.635769: Epoch 566 
2025-01-25 23:30:27.638140: Current learning rate: 0.00472 
2025-01-25 23:30:56.636676: train_loss -0.8453 
2025-01-25 23:30:56.641356: val_loss -0.7643 
2025-01-25 23:30:56.643708: Pseudo dice [np.float32(0.9591), np.float32(0.8898)] 
2025-01-25 23:30:56.645922: Epoch time: 29.01 s 
2025-01-25 23:30:57.676718:  
2025-01-25 23:30:57.679375: Epoch 567 
2025-01-25 23:30:57.681643: Current learning rate: 0.00471 
2025-01-25 23:31:26.307209: train_loss -0.8218 
2025-01-25 23:31:26.310031: val_loss -0.8051 
2025-01-25 23:31:26.312517: Pseudo dice [np.float32(0.9566), np.float32(0.9069)] 
2025-01-25 23:31:26.315014: Epoch time: 28.63 s 
2025-01-25 23:31:27.753915:  
2025-01-25 23:31:27.756261: Epoch 568 
2025-01-25 23:31:27.758583: Current learning rate: 0.0047 
2025-01-25 23:31:56.355094: train_loss -0.8276 
2025-01-25 23:31:56.357677: val_loss -0.7522 
2025-01-25 23:31:56.360069: Pseudo dice [np.float32(0.958), np.float32(0.8778)] 
2025-01-25 23:31:56.362265: Epoch time: 28.6 s 
2025-01-25 23:31:57.412558:  
2025-01-25 23:31:57.415109: Epoch 569 
2025-01-25 23:31:57.417730: Current learning rate: 0.00469 
2025-01-25 23:32:26.472451: train_loss -0.8194 
2025-01-25 23:32:26.475169: val_loss -0.7766 
2025-01-25 23:32:26.477555: Pseudo dice [np.float32(0.9601), np.float32(0.8798)] 
2025-01-25 23:32:26.479860: Epoch time: 29.06 s 
2025-01-25 23:32:27.518195:  
2025-01-25 23:32:27.521056: Epoch 570 
2025-01-25 23:32:27.523313: Current learning rate: 0.00468 
2025-01-25 23:32:58.166216: train_loss -0.8175 
2025-01-25 23:32:58.171231: val_loss -0.7463 
2025-01-25 23:32:58.173326: Pseudo dice [np.float32(0.9604), np.float32(0.8757)] 
2025-01-25 23:32:58.175533: Epoch time: 30.65 s 
2025-01-25 23:32:59.214856:  
2025-01-25 23:32:59.217431: Epoch 571 
2025-01-25 23:32:59.219805: Current learning rate: 0.00467 
2025-01-25 23:33:27.821579: train_loss -0.8289 
2025-01-25 23:33:27.824527: val_loss -0.7951 
2025-01-25 23:33:27.827137: Pseudo dice [np.float32(0.9599), np.float32(0.9023)] 
2025-01-25 23:33:27.829660: Epoch time: 28.61 s 
2025-01-25 23:33:28.863134:  
2025-01-25 23:33:28.865547: Epoch 572 
2025-01-25 23:33:28.867953: Current learning rate: 0.00466 
2025-01-25 23:33:58.516412: train_loss -0.846 
2025-01-25 23:33:58.531208: val_loss -0.8359 
2025-01-25 23:33:58.534063: Pseudo dice [np.float32(0.9612), np.float32(0.9001)] 
2025-01-25 23:33:58.536770: Epoch time: 29.65 s 
2025-01-25 23:33:59.608405:  
2025-01-25 23:33:59.611633: Epoch 573 
2025-01-25 23:33:59.614674: Current learning rate: 0.00465 
2025-01-25 23:34:28.292190: train_loss -0.8256 
2025-01-25 23:34:28.297211: val_loss -0.7814 
2025-01-25 23:34:28.306562: Pseudo dice [np.float32(0.9449), np.float32(0.8869)] 
2025-01-25 23:34:28.309003: Epoch time: 28.68 s 
2025-01-25 23:34:29.386598:  
2025-01-25 23:34:29.389019: Epoch 574 
2025-01-25 23:34:29.391451: Current learning rate: 0.00464 
2025-01-25 23:34:57.811296: train_loss -0.8258 
2025-01-25 23:34:57.815199: val_loss -0.7753 
2025-01-25 23:34:57.817929: Pseudo dice [np.float32(0.9551), np.float32(0.8828)] 
2025-01-25 23:34:57.820516: Epoch time: 28.43 s 
2025-01-25 23:34:58.902997:  
2025-01-25 23:34:58.908034: Epoch 575 
2025-01-25 23:34:58.910666: Current learning rate: 0.00463 
2025-01-25 23:35:27.651565: train_loss -0.8153 
2025-01-25 23:35:27.654369: val_loss -0.8189 
2025-01-25 23:35:27.656739: Pseudo dice [np.float32(0.9626), np.float32(0.9045)] 
2025-01-25 23:35:27.659075: Epoch time: 28.75 s 
2025-01-25 23:35:28.718873:  
2025-01-25 23:35:28.721497: Epoch 576 
2025-01-25 23:35:28.723982: Current learning rate: 0.00462 
2025-01-25 23:35:58.563522: train_loss -0.836 
2025-01-25 23:35:58.566820: val_loss -0.8099 
2025-01-25 23:35:58.569637: Pseudo dice [np.float32(0.9533), np.float32(0.8856)] 
2025-01-25 23:35:58.572238: Epoch time: 29.85 s 
2025-01-25 23:35:59.622122:  
2025-01-25 23:35:59.624664: Epoch 577 
2025-01-25 23:35:59.627019: Current learning rate: 0.00461 
2025-01-25 23:36:29.563471: train_loss -0.8196 
2025-01-25 23:36:29.566299: val_loss -0.7633 
2025-01-25 23:36:29.568954: Pseudo dice [np.float32(0.9507), np.float32(0.8594)] 
2025-01-25 23:36:29.571239: Epoch time: 29.94 s 
2025-01-25 23:36:30.620197:  
2025-01-25 23:36:30.622551: Epoch 578 
2025-01-25 23:36:30.624743: Current learning rate: 0.0046 
2025-01-25 23:36:59.616811: train_loss -0.8127 
2025-01-25 23:36:59.622684: val_loss -0.7654 
2025-01-25 23:36:59.625021: Pseudo dice [np.float32(0.9525), np.float32(0.8629)] 
2025-01-25 23:36:59.627480: Epoch time: 29.0 s 
2025-01-25 23:37:00.677063:  
2025-01-25 23:37:00.679796: Epoch 579 
2025-01-25 23:37:00.682211: Current learning rate: 0.00459 
2025-01-25 23:37:29.601171: train_loss -0.8288 
2025-01-25 23:37:29.604171: val_loss -0.7876 
2025-01-25 23:37:29.606991: Pseudo dice [np.float32(0.9612), np.float32(0.9012)] 
2025-01-25 23:37:29.609306: Epoch time: 28.92 s 
2025-01-25 23:37:30.655872:  
2025-01-25 23:37:30.658627: Epoch 580 
2025-01-25 23:37:30.661146: Current learning rate: 0.00458 
2025-01-25 23:38:01.533635: train_loss -0.8357 
2025-01-25 23:38:01.540360: val_loss -0.7619 
2025-01-25 23:38:01.542705: Pseudo dice [np.float32(0.9567), np.float32(0.8511)] 
2025-01-25 23:38:01.544717: Epoch time: 30.88 s 
2025-01-25 23:38:02.614869:  
2025-01-25 23:38:02.617862: Epoch 581 
2025-01-25 23:38:02.620124: Current learning rate: 0.00457 
2025-01-25 23:38:32.637286: train_loss -0.8255 
2025-01-25 23:38:32.641399: val_loss -0.7791 
2025-01-25 23:38:32.644429: Pseudo dice [np.float32(0.9629), np.float32(0.9024)] 
2025-01-25 23:38:32.646800: Epoch time: 30.02 s 
2025-01-25 23:38:33.756093:  
2025-01-25 23:38:33.759232: Epoch 582 
2025-01-25 23:38:33.761966: Current learning rate: 0.00456 
2025-01-25 23:39:04.405006: train_loss -0.8369 
2025-01-25 23:39:04.410479: val_loss -0.7868 
2025-01-25 23:39:04.413012: Pseudo dice [np.float32(0.9612), np.float32(0.8953)] 
2025-01-25 23:39:04.415450: Epoch time: 30.65 s 
2025-01-25 23:39:05.469730:  
2025-01-25 23:39:05.472211: Epoch 583 
2025-01-25 23:39:05.475007: Current learning rate: 0.00455 
2025-01-25 23:39:35.087438: train_loss -0.829 
2025-01-25 23:39:35.090633: val_loss -0.7906 
2025-01-25 23:39:35.093711: Pseudo dice [np.float32(0.9617), np.float32(0.8975)] 
2025-01-25 23:39:35.096160: Epoch time: 29.62 s 
2025-01-25 23:39:36.141766:  
2025-01-25 23:39:36.144010: Epoch 584 
2025-01-25 23:39:36.146246: Current learning rate: 0.00454 
2025-01-25 23:40:07.168033: train_loss -0.831 
2025-01-25 23:40:07.177599: val_loss -0.7884 
2025-01-25 23:40:07.180269: Pseudo dice [np.float32(0.955), np.float32(0.8918)] 
2025-01-25 23:40:07.182748: Epoch time: 31.03 s 
2025-01-25 23:40:08.256588:  
2025-01-25 23:40:08.259294: Epoch 585 
2025-01-25 23:40:08.262149: Current learning rate: 0.00453 
2025-01-25 23:40:38.886810: train_loss -0.8124 
2025-01-25 23:40:38.889624: val_loss -0.7641 
2025-01-25 23:40:38.891952: Pseudo dice [np.float32(0.9567), np.float32(0.8311)] 
2025-01-25 23:40:38.894194: Epoch time: 30.63 s 
2025-01-25 23:40:39.942041:  
2025-01-25 23:40:39.944426: Epoch 586 
2025-01-25 23:40:39.946841: Current learning rate: 0.00452 
2025-01-25 23:41:09.630908: train_loss -0.8259 
2025-01-25 23:41:09.636263: val_loss -0.7546 
2025-01-25 23:41:09.638953: Pseudo dice [np.float32(0.9503), np.float32(0.8661)] 
2025-01-25 23:41:09.641317: Epoch time: 29.69 s 
2025-01-25 23:41:11.120423:  
2025-01-25 23:41:11.122853: Epoch 587 
2025-01-25 23:41:11.125116: Current learning rate: 0.00451 
2025-01-25 23:41:40.528892: train_loss -0.8211 
2025-01-25 23:41:40.532017: val_loss -0.7999 
2025-01-25 23:41:40.534529: Pseudo dice [np.float32(0.9592), np.float32(0.9072)] 
2025-01-25 23:41:40.537038: Epoch time: 29.41 s 
2025-01-25 23:41:41.583120:  
2025-01-25 23:41:41.585634: Epoch 588 
2025-01-25 23:41:41.587966: Current learning rate: 0.0045 
2025-01-25 23:42:10.781030: train_loss -0.8261 
2025-01-25 23:42:10.786324: val_loss -0.826 
2025-01-25 23:42:10.788645: Pseudo dice [np.float32(0.9585), np.float32(0.9132)] 
2025-01-25 23:42:10.790723: Epoch time: 29.2 s 
2025-01-25 23:42:11.840458:  
2025-01-25 23:42:11.843124: Epoch 589 
2025-01-25 23:42:11.845682: Current learning rate: 0.00449 
2025-01-25 23:42:42.631709: train_loss -0.835 
2025-01-25 23:42:42.634515: val_loss -0.8128 
2025-01-25 23:42:42.636787: Pseudo dice [np.float32(0.9522), np.float32(0.8999)] 
2025-01-25 23:42:42.639014: Epoch time: 30.79 s 
2025-01-25 23:42:43.947406:  
2025-01-25 23:42:43.950006: Epoch 590 
2025-01-25 23:42:43.952198: Current learning rate: 0.00448 
2025-01-25 23:43:14.100123: train_loss -0.8296 
2025-01-25 23:43:14.105068: val_loss -0.7959 
2025-01-25 23:43:14.107472: Pseudo dice [np.float32(0.955), np.float32(0.8961)] 
2025-01-25 23:43:14.109754: Epoch time: 30.15 s 
2025-01-25 23:43:15.156197:  
2025-01-25 23:43:15.158769: Epoch 591 
2025-01-25 23:43:15.161076: Current learning rate: 0.00447 
2025-01-25 23:43:44.881557: train_loss -0.8321 
2025-01-25 23:43:44.885407: val_loss -0.8175 
2025-01-25 23:43:44.887872: Pseudo dice [np.float32(0.964), np.float32(0.9089)] 
2025-01-25 23:43:44.890208: Epoch time: 29.73 s 
2025-01-25 23:43:45.939591:  
2025-01-25 23:43:45.941825: Epoch 592 
2025-01-25 23:43:45.944037: Current learning rate: 0.00446 
2025-01-25 23:44:14.962665: train_loss -0.8407 
2025-01-25 23:44:14.968322: val_loss -0.7747 
2025-01-25 23:44:14.970823: Pseudo dice [np.float32(0.956), np.float32(0.9174)] 
2025-01-25 23:44:14.973288: Epoch time: 29.02 s 
2025-01-25 23:44:16.030082:  
2025-01-25 23:44:16.032741: Epoch 593 
2025-01-25 23:44:16.035073: Current learning rate: 0.00445 
2025-01-25 23:44:45.171173: train_loss -0.8357 
2025-01-25 23:44:45.173981: val_loss -0.7817 
2025-01-25 23:44:45.176611: Pseudo dice [np.float32(0.959), np.float32(0.8989)] 
2025-01-25 23:44:45.179085: Epoch time: 29.14 s 
2025-01-25 23:44:46.246698:  
2025-01-25 23:44:46.249361: Epoch 594 
2025-01-25 23:44:46.251915: Current learning rate: 0.00444 
2025-01-25 23:45:16.998024: train_loss -0.8236 
2025-01-25 23:45:17.003725: val_loss -0.7867 
2025-01-25 23:45:17.006061: Pseudo dice [np.float32(0.9636), np.float32(0.9035)] 
2025-01-25 23:45:17.008451: Epoch time: 30.75 s 
2025-01-25 23:45:18.072402:  
2025-01-25 23:45:18.074733: Epoch 595 
2025-01-25 23:45:18.076936: Current learning rate: 0.00443 
2025-01-25 23:45:48.339369: train_loss -0.8228 
2025-01-25 23:45:48.342327: val_loss -0.8113 
2025-01-25 23:45:48.344895: Pseudo dice [np.float32(0.9576), np.float32(0.8847)] 
2025-01-25 23:45:48.347054: Epoch time: 30.27 s 
2025-01-25 23:45:49.394952:  
2025-01-25 23:45:49.397556: Epoch 596 
2025-01-25 23:45:49.400224: Current learning rate: 0.00442 
2025-01-25 23:46:18.661372: train_loss -0.8257 
2025-01-25 23:46:18.666902: val_loss -0.7635 
2025-01-25 23:46:18.669442: Pseudo dice [np.float32(0.9577), np.float32(0.8992)] 
2025-01-25 23:46:18.671665: Epoch time: 29.27 s 
2025-01-25 23:46:19.722713:  
2025-01-25 23:46:19.725578: Epoch 597 
2025-01-25 23:46:19.728099: Current learning rate: 0.00441 
2025-01-25 23:46:50.275338: train_loss -0.8408 
2025-01-25 23:46:50.278844: val_loss -0.7743 
2025-01-25 23:46:50.281739: Pseudo dice [np.float32(0.956), np.float32(0.8889)] 
2025-01-25 23:46:50.284461: Epoch time: 30.55 s 
2025-01-25 23:46:51.339919:  
2025-01-25 23:46:51.342374: Epoch 598 
2025-01-25 23:46:51.344665: Current learning rate: 0.0044 
2025-01-25 23:47:20.616818: train_loss -0.8196 
2025-01-25 23:47:20.622400: val_loss -0.7791 
2025-01-25 23:47:20.625059: Pseudo dice [np.float32(0.9494), np.float32(0.8906)] 
2025-01-25 23:47:20.627529: Epoch time: 29.28 s 
2025-01-25 23:47:21.691892:  
2025-01-25 23:47:21.695001: Epoch 599 
2025-01-25 23:47:21.697942: Current learning rate: 0.00439 
2025-01-25 23:47:51.888072: train_loss -0.836 
2025-01-25 23:47:51.891006: val_loss -0.7949 
2025-01-25 23:47:51.893373: Pseudo dice [np.float32(0.954), np.float32(0.8943)] 
2025-01-25 23:47:51.895752: Epoch time: 30.2 s 
2025-01-25 23:47:53.461347:  
2025-01-25 23:47:53.463856: Epoch 600 
2025-01-25 23:47:53.466362: Current learning rate: 0.00438 
2025-01-25 23:48:22.573191: train_loss -0.83 
2025-01-25 23:48:22.579095: val_loss -0.799 
2025-01-25 23:48:22.581758: Pseudo dice [np.float32(0.9618), np.float32(0.9062)] 
2025-01-25 23:48:22.584368: Epoch time: 29.11 s 
2025-01-25 23:48:23.633152:  
2025-01-25 23:48:23.635878: Epoch 601 
2025-01-25 23:48:23.638316: Current learning rate: 0.00437 
2025-01-25 23:48:53.090056: train_loss -0.8298 
2025-01-25 23:48:53.093249: val_loss -0.7603 
2025-01-25 23:48:53.095979: Pseudo dice [np.float32(0.948), np.float32(0.9077)] 
2025-01-25 23:48:53.098656: Epoch time: 29.46 s 
2025-01-25 23:48:54.145051:  
2025-01-25 23:48:54.147820: Epoch 602 
2025-01-25 23:48:54.150069: Current learning rate: 0.00436 
2025-01-25 23:49:22.874090: train_loss -0.8173 
2025-01-25 23:49:22.883138: val_loss -0.7649 
2025-01-25 23:49:22.885765: Pseudo dice [np.float32(0.9578), np.float32(0.8874)] 
2025-01-25 23:49:22.888143: Epoch time: 28.73 s 
2025-01-25 23:49:23.985809:  
2025-01-25 23:49:23.989920: Epoch 603 
2025-01-25 23:49:23.992413: Current learning rate: 0.00435 
2025-01-25 23:49:53.273991: train_loss -0.8359 
2025-01-25 23:49:53.286072: val_loss -0.8098 
2025-01-25 23:49:53.288888: Pseudo dice [np.float32(0.9581), np.float32(0.9073)] 
2025-01-25 23:49:53.291272: Epoch time: 29.29 s 
2025-01-25 23:49:54.501600:  
2025-01-25 23:49:54.504187: Epoch 604 
2025-01-25 23:49:54.506692: Current learning rate: 0.00434 
2025-01-25 23:50:25.497166: train_loss -0.8403 
2025-01-25 23:50:25.502766: val_loss -0.7733 
2025-01-25 23:50:25.505211: Pseudo dice [np.float32(0.96), np.float32(0.8976)] 
2025-01-25 23:50:25.507800: Epoch time: 31.0 s 
2025-01-25 23:50:27.032709:  
2025-01-25 23:50:27.035437: Epoch 605 
2025-01-25 23:50:27.037880: Current learning rate: 0.00433 
2025-01-25 23:50:56.257001: train_loss -0.8348 
2025-01-25 23:50:56.259857: val_loss -0.8167 
2025-01-25 23:50:56.262142: Pseudo dice [np.float32(0.9609), np.float32(0.8846)] 
2025-01-25 23:50:56.264510: Epoch time: 29.23 s 
2025-01-25 23:50:57.323895:  
2025-01-25 23:50:57.326715: Epoch 606 
2025-01-25 23:50:57.329272: Current learning rate: 0.00432 
2025-01-25 23:51:28.759738: train_loss -0.8397 
2025-01-25 23:51:28.765282: val_loss -0.8011 
2025-01-25 23:51:28.767727: Pseudo dice [np.float32(0.9598), np.float32(0.9152)] 
2025-01-25 23:51:28.770051: Epoch time: 31.44 s 
2025-01-25 23:51:29.817055:  
2025-01-25 23:51:29.819698: Epoch 607 
2025-01-25 23:51:29.822200: Current learning rate: 0.00431 
2025-01-25 23:52:00.098982: train_loss -0.8275 
2025-01-25 23:52:00.103336: val_loss -0.8041 
2025-01-25 23:52:00.105891: Pseudo dice [np.float32(0.9565), np.float32(0.9105)] 
2025-01-25 23:52:00.108532: Epoch time: 30.28 s 
2025-01-25 23:52:00.110778: Yayy! New best EMA pseudo Dice: 0.9279999732971191 
2025-01-25 23:52:01.715169:  
2025-01-25 23:52:01.717609: Epoch 608 
2025-01-25 23:52:01.720022: Current learning rate: 0.0043 
2025-01-25 23:52:30.873019: train_loss -0.8314 
2025-01-25 23:52:30.879019: val_loss -0.7775 
2025-01-25 23:52:30.882740: Pseudo dice [np.float32(0.9596), np.float32(0.8986)] 
2025-01-25 23:52:30.885185: Epoch time: 29.16 s 
2025-01-25 23:52:30.887485: Yayy! New best EMA pseudo Dice: 0.9280999898910522 
2025-01-25 23:52:32.422532:  
2025-01-25 23:52:32.424900: Epoch 609 
2025-01-25 23:52:32.427480: Current learning rate: 0.00429 
2025-01-25 23:53:01.307364: train_loss -0.837 
2025-01-25 23:53:01.310238: val_loss -0.7833 
2025-01-25 23:53:01.312903: Pseudo dice [np.float32(0.9613), np.float32(0.8998)] 
2025-01-25 23:53:01.315795: Epoch time: 28.89 s 
2025-01-25 23:53:01.318376: Yayy! New best EMA pseudo Dice: 0.9283000230789185 
2025-01-25 23:53:02.885009:  
2025-01-25 23:53:02.887222: Epoch 610 
2025-01-25 23:53:02.889806: Current learning rate: 0.00429 
2025-01-25 23:53:32.272316: train_loss -0.8274 
2025-01-25 23:53:32.277689: val_loss -0.775 
2025-01-25 23:53:32.280263: Pseudo dice [np.float32(0.9624), np.float32(0.8982)] 
2025-01-25 23:53:32.282679: Epoch time: 29.39 s 
2025-01-25 23:53:32.285093: Yayy! New best EMA pseudo Dice: 0.9284999966621399 
2025-01-25 23:53:33.824694:  
2025-01-25 23:53:33.827255: Epoch 611 
2025-01-25 23:53:33.829699: Current learning rate: 0.00428 
2025-01-25 23:54:03.336292: train_loss -0.8257 
2025-01-25 23:54:03.340275: val_loss -0.7935 
2025-01-25 23:54:03.344355: Pseudo dice [np.float32(0.9559), np.float32(0.9027)] 
2025-01-25 23:54:03.346766: Epoch time: 29.51 s 
2025-01-25 23:54:03.349261: Yayy! New best EMA pseudo Dice: 0.928600013256073 
2025-01-25 23:54:04.897398:  
2025-01-25 23:54:04.899894: Epoch 612 
2025-01-25 23:54:04.902273: Current learning rate: 0.00427 
2025-01-25 23:54:35.496538: train_loss -0.8352 
2025-01-25 23:54:35.501528: val_loss -0.777 
2025-01-25 23:54:35.504189: Pseudo dice [np.float32(0.96), np.float32(0.8731)] 
2025-01-25 23:54:35.506559: Epoch time: 30.6 s 
2025-01-25 23:54:36.562110:  
2025-01-25 23:54:36.564582: Epoch 613 
2025-01-25 23:54:36.566805: Current learning rate: 0.00426 
2025-01-25 23:55:04.642091: train_loss -0.8304 
2025-01-25 23:55:04.644650: val_loss -0.7875 
2025-01-25 23:55:04.646710: Pseudo dice [np.float32(0.9608), np.float32(0.9175)] 
2025-01-25 23:55:04.648762: Epoch time: 28.08 s 
2025-01-25 23:55:05.698521:  
2025-01-25 23:55:05.700796: Epoch 614 
2025-01-25 23:55:05.703298: Current learning rate: 0.00425 
2025-01-25 23:55:34.805890: train_loss -0.8341 
2025-01-25 23:55:34.808629: val_loss -0.7985 
2025-01-25 23:55:34.811048: Pseudo dice [np.float32(0.9583), np.float32(0.8874)] 
2025-01-25 23:55:34.813300: Epoch time: 29.11 s 
2025-01-25 23:55:35.859551:  
2025-01-25 23:55:35.864244: Epoch 615 
2025-01-25 23:55:35.866623: Current learning rate: 0.00424 
2025-01-25 23:56:03.886206: train_loss -0.8293 
2025-01-25 23:56:03.888995: val_loss -0.7764 
2025-01-25 23:56:03.891259: Pseudo dice [np.float32(0.9634), np.float32(0.9072)] 
2025-01-25 23:56:03.893400: Epoch time: 28.03 s 
2025-01-25 23:56:03.895643: Yayy! New best EMA pseudo Dice: 0.9286999702453613 
2025-01-25 23:56:05.448697:  
2025-01-25 23:56:05.451339: Epoch 616 
2025-01-25 23:56:05.453942: Current learning rate: 0.00423 
2025-01-25 23:56:34.348979: train_loss -0.8148 
2025-01-25 23:56:34.351698: val_loss -0.782 
2025-01-25 23:56:34.353898: Pseudo dice [np.float32(0.9612), np.float32(0.8914)] 
2025-01-25 23:56:34.356123: Epoch time: 28.9 s 
2025-01-25 23:56:35.404213:  
2025-01-25 23:56:35.407013: Epoch 617 
2025-01-25 23:56:35.409807: Current learning rate: 0.00422 
2025-01-25 23:57:04.468297: train_loss -0.8108 
2025-01-25 23:57:04.473265: val_loss -0.7929 
2025-01-25 23:57:04.475827: Pseudo dice [np.float32(0.9611), np.float32(0.8919)] 
2025-01-25 23:57:04.478182: Epoch time: 29.06 s 
2025-01-25 23:57:05.594552:  
2025-01-25 23:57:05.597353: Epoch 618 
2025-01-25 23:57:05.599939: Current learning rate: 0.00421 
2025-01-25 23:57:36.275976: train_loss -0.8193 
2025-01-25 23:57:36.279079: val_loss -0.7599 
2025-01-25 23:57:36.281555: Pseudo dice [np.float32(0.9494), np.float32(0.8874)] 
2025-01-25 23:57:36.284035: Epoch time: 30.68 s 
2025-01-25 23:57:37.354778:  
2025-01-25 23:57:37.357304: Epoch 619 
2025-01-25 23:57:37.359752: Current learning rate: 0.0042 
2025-01-25 23:58:08.656906: train_loss -0.826 
2025-01-25 23:58:08.664427: val_loss -0.7666 
2025-01-25 23:58:08.666870: Pseudo dice [np.float32(0.9603), np.float32(0.8366)] 
2025-01-25 23:58:08.669303: Epoch time: 31.3 s 
2025-01-25 23:58:09.791366:  
2025-01-25 23:58:09.793644: Epoch 620 
2025-01-25 23:58:09.796175: Current learning rate: 0.00419 
2025-01-25 23:58:39.001426: train_loss -0.8071 
2025-01-25 23:58:39.004025: val_loss -0.7918 
2025-01-25 23:58:39.006426: Pseudo dice [np.float32(0.9585), np.float32(0.9089)] 
2025-01-25 23:58:39.008755: Epoch time: 29.21 s 
2025-01-25 23:58:40.062088:  
2025-01-25 23:58:40.064781: Epoch 621 
2025-01-25 23:58:40.067099: Current learning rate: 0.00418 
2025-01-25 23:59:09.157768: train_loss -0.833 
2025-01-25 23:59:09.162448: val_loss -0.7614 
2025-01-25 23:59:09.164628: Pseudo dice [np.float32(0.9572), np.float32(0.8899)] 
2025-01-25 23:59:09.166677: Epoch time: 29.1 s 
2025-01-25 23:59:10.660560:  
2025-01-25 23:59:10.663376: Epoch 622 
2025-01-25 23:59:10.665775: Current learning rate: 0.00417 
2025-01-25 23:59:41.513587: train_loss -0.806 
2025-01-25 23:59:41.520083: val_loss -0.7509 
2025-01-25 23:59:41.522713: Pseudo dice [np.float32(0.9542), np.float32(0.8872)] 
2025-01-25 23:59:41.525093: Epoch time: 30.85 s 
2025-01-25 23:59:42.588483:  
2025-01-25 23:59:42.590819: Epoch 623 
2025-01-25 23:59:42.593290: Current learning rate: 0.00416 
2025-01-26 00:00:12.545488: train_loss -0.8171 
2025-01-26 00:00:12.550618: val_loss -0.7633 
2025-01-26 00:00:12.553122: Pseudo dice [np.float32(0.9556), np.float32(0.8886)] 
2025-01-26 00:00:12.555363: Epoch time: 29.96 s 
2025-01-26 00:00:13.607122:  
2025-01-26 00:00:13.609635: Epoch 624 
2025-01-26 00:00:13.611990: Current learning rate: 0.00415 
2025-01-26 00:00:45.422786: train_loss -0.8193 
2025-01-26 00:00:45.426006: val_loss -0.8131 
2025-01-26 00:00:45.428657: Pseudo dice [np.float32(0.9606), np.float32(0.905)] 
2025-01-26 00:00:45.431154: Epoch time: 31.82 s 
2025-01-26 00:00:46.490806:  
2025-01-26 00:00:46.493518: Epoch 625 
2025-01-26 00:00:46.496071: Current learning rate: 0.00414 
2025-01-26 00:01:15.837514: train_loss -0.8308 
2025-01-26 00:01:15.845492: val_loss -0.8051 
2025-01-26 00:01:15.848031: Pseudo dice [np.float32(0.96), np.float32(0.8819)] 
2025-01-26 00:01:15.850299: Epoch time: 29.35 s 
2025-01-26 00:01:17.078083:  
2025-01-26 00:01:17.081010: Epoch 626 
2025-01-26 00:01:17.084023: Current learning rate: 0.00413 
2025-01-26 00:01:46.776046: train_loss -0.8065 
2025-01-26 00:01:46.778862: val_loss -0.7771 
2025-01-26 00:01:46.781471: Pseudo dice [np.float32(0.9511), np.float32(0.8802)] 
2025-01-26 00:01:46.783774: Epoch time: 29.7 s 
2025-01-26 00:01:47.841066:  
2025-01-26 00:01:47.843718: Epoch 627 
2025-01-26 00:01:47.846554: Current learning rate: 0.00412 
2025-01-26 00:02:19.005898: train_loss -0.8327 
2025-01-26 00:02:19.013852: val_loss -0.8081 
2025-01-26 00:02:19.016396: Pseudo dice [np.float32(0.9566), np.float32(0.8813)] 
2025-01-26 00:02:19.018809: Epoch time: 31.17 s 
2025-01-26 00:02:20.122067:  
2025-01-26 00:02:20.124879: Epoch 628 
2025-01-26 00:02:20.127271: Current learning rate: 0.00411 
2025-01-26 00:02:51.087598: train_loss -0.8327 
2025-01-26 00:02:51.094170: val_loss -0.7899 
2025-01-26 00:02:51.097159: Pseudo dice [np.float32(0.9619), np.float32(0.9047)] 
2025-01-26 00:02:51.099507: Epoch time: 30.97 s 
2025-01-26 00:02:52.422433:  
2025-01-26 00:02:52.425362: Epoch 629 
2025-01-26 00:02:52.428316: Current learning rate: 0.0041 
2025-01-26 00:03:21.863381: train_loss -0.8212 
2025-01-26 00:03:21.869502: val_loss -0.8179 
2025-01-26 00:03:21.872058: Pseudo dice [np.float32(0.9623), np.float32(0.899)] 
2025-01-26 00:03:21.874513: Epoch time: 29.44 s 
2025-01-26 00:03:22.922210:  
2025-01-26 00:03:22.924627: Epoch 630 
2025-01-26 00:03:22.926929: Current learning rate: 0.00409 
2025-01-26 00:03:52.240883: train_loss -0.8192 
2025-01-26 00:03:52.245500: val_loss -0.7815 
2025-01-26 00:03:52.249621: Pseudo dice [np.float32(0.9595), np.float32(0.9058)] 
2025-01-26 00:03:52.252187: Epoch time: 29.32 s 
2025-01-26 00:03:53.307572:  
2025-01-26 00:03:53.310857: Epoch 631 
2025-01-26 00:03:53.313478: Current learning rate: 0.00408 
2025-01-26 00:04:23.712469: train_loss -0.8238 
2025-01-26 00:04:23.721500: val_loss -0.7975 
2025-01-26 00:04:23.724064: Pseudo dice [np.float32(0.9624), np.float32(0.9105)] 
2025-01-26 00:04:23.726490: Epoch time: 30.41 s 
2025-01-26 00:04:24.802741:  
2025-01-26 00:04:24.806787: Epoch 632 
2025-01-26 00:04:24.809270: Current learning rate: 0.00407 
2025-01-26 00:04:53.637444: train_loss -0.8456 
2025-01-26 00:04:53.640958: val_loss -0.7764 
2025-01-26 00:04:53.643558: Pseudo dice [np.float32(0.9583), np.float32(0.8984)] 
2025-01-26 00:04:53.646572: Epoch time: 28.84 s 
2025-01-26 00:04:54.702401:  
2025-01-26 00:04:54.704902: Epoch 633 
2025-01-26 00:04:54.707064: Current learning rate: 0.00406 
2025-01-26 00:05:24.420913: train_loss -0.8497 
2025-01-26 00:05:24.426495: val_loss -0.8037 
2025-01-26 00:05:24.428932: Pseudo dice [np.float32(0.962), np.float32(0.87)] 
2025-01-26 00:05:24.430964: Epoch time: 29.72 s 
2025-01-26 00:05:25.493347:  
2025-01-26 00:05:25.495955: Epoch 634 
2025-01-26 00:05:25.498227: Current learning rate: 0.00405 
2025-01-26 00:05:56.617643: train_loss -0.8338 
2025-01-26 00:05:56.620617: val_loss -0.7965 
2025-01-26 00:05:56.622934: Pseudo dice [np.float32(0.9586), np.float32(0.8818)] 
2025-01-26 00:05:56.625125: Epoch time: 31.13 s 
2025-01-26 00:05:57.687663:  
2025-01-26 00:05:57.690846: Epoch 635 
2025-01-26 00:05:57.693459: Current learning rate: 0.00404 
2025-01-26 00:06:27.293255: train_loss -0.8206 
2025-01-26 00:06:27.300998: val_loss -0.8127 
2025-01-26 00:06:27.303431: Pseudo dice [np.float32(0.9609), np.float32(0.8991)] 
2025-01-26 00:06:27.305830: Epoch time: 29.61 s 
2025-01-26 00:06:28.366639:  
2025-01-26 00:06:28.369508: Epoch 636 
2025-01-26 00:06:28.372216: Current learning rate: 0.00403 
2025-01-26 00:06:57.019034: train_loss -0.8249 
2025-01-26 00:06:57.023106: val_loss -0.8052 
2025-01-26 00:06:57.025514: Pseudo dice [np.float32(0.9607), np.float32(0.8975)] 
2025-01-26 00:06:57.027823: Epoch time: 28.65 s 
2025-01-26 00:06:58.076027:  
2025-01-26 00:06:58.078510: Epoch 637 
2025-01-26 00:06:58.080778: Current learning rate: 0.00402 
2025-01-26 00:07:28.239520: train_loss -0.838 
2025-01-26 00:07:28.249362: val_loss -0.7712 
2025-01-26 00:07:28.251722: Pseudo dice [np.float32(0.9624), np.float32(0.9009)] 
2025-01-26 00:07:28.253903: Epoch time: 30.16 s 
2025-01-26 00:07:29.353747:  
2025-01-26 00:07:29.356300: Epoch 638 
2025-01-26 00:07:29.358630: Current learning rate: 0.00401 
2025-01-26 00:07:58.508497: train_loss -0.8224 
2025-01-26 00:07:58.514015: val_loss -0.7509 
2025-01-26 00:07:58.516952: Pseudo dice [np.float32(0.9518), np.float32(0.7855)] 
2025-01-26 00:07:58.519645: Epoch time: 29.16 s 
2025-01-26 00:07:59.588896:  
2025-01-26 00:07:59.591384: Epoch 639 
2025-01-26 00:07:59.594306: Current learning rate: 0.004 
2025-01-26 00:08:28.314224: train_loss -0.8102 
2025-01-26 00:08:28.320471: val_loss -0.793 
2025-01-26 00:08:28.322985: Pseudo dice [np.float32(0.9602), np.float32(0.8967)] 
2025-01-26 00:08:28.325514: Epoch time: 28.73 s 
2025-01-26 00:08:29.379262:  
2025-01-26 00:08:29.382003: Epoch 640 
2025-01-26 00:08:29.384602: Current learning rate: 0.00399 
2025-01-26 00:08:58.089745: train_loss -0.832 
2025-01-26 00:08:58.092884: val_loss -0.8214 
2025-01-26 00:08:58.095392: Pseudo dice [np.float32(0.9577), np.float32(0.8949)] 
2025-01-26 00:08:58.097796: Epoch time: 28.71 s 
2025-01-26 00:08:59.146899:  
2025-01-26 00:08:59.149610: Epoch 641 
2025-01-26 00:08:59.152134: Current learning rate: 0.00398 
2025-01-26 00:09:28.718256: train_loss -0.834 
2025-01-26 00:09:28.728175: val_loss -0.7365 
2025-01-26 00:09:28.730871: Pseudo dice [np.float32(0.9583), np.float32(0.8844)] 
2025-01-26 00:09:28.733631: Epoch time: 29.57 s 
2025-01-26 00:09:29.812563:  
2025-01-26 00:09:29.815140: Epoch 642 
2025-01-26 00:09:29.817614: Current learning rate: 0.00397 
2025-01-26 00:09:59.768367: train_loss -0.8283 
2025-01-26 00:09:59.771416: val_loss -0.8114 
2025-01-26 00:09:59.773854: Pseudo dice [np.float32(0.959), np.float32(0.9112)] 
2025-01-26 00:09:59.776417: Epoch time: 29.96 s 
2025-01-26 00:10:00.837946:  
2025-01-26 00:10:00.840779: Epoch 643 
2025-01-26 00:10:00.843267: Current learning rate: 0.00396 
2025-01-26 00:10:30.662926: train_loss -0.8526 
2025-01-26 00:10:30.670708: val_loss -0.7951 
2025-01-26 00:10:30.673315: Pseudo dice [np.float32(0.9564), np.float32(0.9015)] 
2025-01-26 00:10:30.675662: Epoch time: 29.83 s 
2025-01-26 00:10:31.758669:  
2025-01-26 00:10:31.761221: Epoch 644 
2025-01-26 00:10:31.763607: Current learning rate: 0.00395 
2025-01-26 00:11:01.277617: train_loss -0.8588 
2025-01-26 00:11:01.281735: val_loss -0.7995 
2025-01-26 00:11:01.283989: Pseudo dice [np.float32(0.9629), np.float32(0.915)] 
2025-01-26 00:11:01.286159: Epoch time: 29.52 s 
2025-01-26 00:11:02.347471:  
2025-01-26 00:11:02.350013: Epoch 645 
2025-01-26 00:11:02.352587: Current learning rate: 0.00394 
2025-01-26 00:11:32.455740: train_loss -0.8441 
2025-01-26 00:11:32.463990: val_loss -0.8043 
2025-01-26 00:11:32.466233: Pseudo dice [np.float32(0.9631), np.float32(0.9125)] 
2025-01-26 00:11:32.468475: Epoch time: 30.11 s 
2025-01-26 00:11:33.614458:  
2025-01-26 00:11:33.616842: Epoch 646 
2025-01-26 00:11:33.619112: Current learning rate: 0.00393 
2025-01-26 00:12:02.924126: train_loss -0.8406 
2025-01-26 00:12:02.928199: val_loss -0.7989 
2025-01-26 00:12:02.930796: Pseudo dice [np.float32(0.9619), np.float32(0.9055)] 
2025-01-26 00:12:02.933330: Epoch time: 29.31 s 
2025-01-26 00:12:03.989377:  
2025-01-26 00:12:03.992018: Epoch 647 
2025-01-26 00:12:03.994290: Current learning rate: 0.00392 
2025-01-26 00:12:33.484929: train_loss -0.8341 
2025-01-26 00:12:33.490652: val_loss -0.7904 
2025-01-26 00:12:33.493046: Pseudo dice [np.float32(0.9597), np.float32(0.9019)] 
2025-01-26 00:12:33.495395: Epoch time: 29.5 s 
2025-01-26 00:12:34.547093:  
2025-01-26 00:12:34.549832: Epoch 648 
2025-01-26 00:12:34.552673: Current learning rate: 0.00391 
2025-01-26 00:13:03.717019: train_loss -0.8398 
2025-01-26 00:13:03.719998: val_loss -0.798 
2025-01-26 00:13:03.722268: Pseudo dice [np.float32(0.9625), np.float32(0.879)] 
2025-01-26 00:13:03.724514: Epoch time: 29.17 s 
2025-01-26 00:13:04.802452:  
2025-01-26 00:13:04.805264: Epoch 649 
2025-01-26 00:13:04.807545: Current learning rate: 0.0039 
2025-01-26 00:13:33.008356: train_loss -0.8348 
2025-01-26 00:13:33.011969: val_loss -0.7419 
2025-01-26 00:13:33.014460: Pseudo dice [np.float32(0.956), np.float32(0.8788)] 
2025-01-26 00:13:33.016871: Epoch time: 28.21 s 
2025-01-26 00:13:34.573741:  
2025-01-26 00:13:34.575888: Epoch 650 
2025-01-26 00:13:34.578134: Current learning rate: 0.00389 
2025-01-26 00:14:03.462125: train_loss -0.8287 
2025-01-26 00:14:03.465382: val_loss -0.7753 
2025-01-26 00:14:03.468288: Pseudo dice [np.float32(0.9567), np.float32(0.8931)] 
2025-01-26 00:14:03.471506: Epoch time: 28.89 s 
2025-01-26 00:14:04.525173:  
2025-01-26 00:14:04.527748: Epoch 651 
2025-01-26 00:14:04.530160: Current learning rate: 0.00388 
2025-01-26 00:14:33.506937: train_loss -0.8268 
2025-01-26 00:14:33.509503: val_loss -0.7669 
2025-01-26 00:14:33.511921: Pseudo dice [np.float32(0.9658), np.float32(0.9109)] 
2025-01-26 00:14:33.514141: Epoch time: 28.98 s 
2025-01-26 00:14:34.613091:  
2025-01-26 00:14:34.615565: Epoch 652 
2025-01-26 00:14:34.618021: Current learning rate: 0.00387 
2025-01-26 00:15:02.982006: train_loss -0.8347 
2025-01-26 00:15:02.986854: val_loss -0.7992 
2025-01-26 00:15:02.989127: Pseudo dice [np.float32(0.9591), np.float32(0.9073)] 
2025-01-26 00:15:02.991555: Epoch time: 28.37 s 
2025-01-26 00:15:04.046812:  
2025-01-26 00:15:04.049482: Epoch 653 
2025-01-26 00:15:04.052105: Current learning rate: 0.00386 
2025-01-26 00:15:35.439969: train_loss -0.8369 
2025-01-26 00:15:35.445513: val_loss -0.7891 
2025-01-26 00:15:35.448226: Pseudo dice [np.float32(0.9628), np.float32(0.9246)] 
2025-01-26 00:15:35.450561: Epoch time: 31.39 s 
2025-01-26 00:15:35.453931: Yayy! New best EMA pseudo Dice: 0.9294000267982483 
2025-01-26 00:15:37.031436:  
2025-01-26 00:15:37.034119: Epoch 654 
2025-01-26 00:15:37.036514: Current learning rate: 0.00385 
2025-01-26 00:16:06.484236: train_loss -0.8427 
2025-01-26 00:16:06.490946: val_loss -0.7745 
2025-01-26 00:16:06.493495: Pseudo dice [np.float32(0.9595), np.float32(0.9006)] 
2025-01-26 00:16:06.496145: Epoch time: 29.45 s 
2025-01-26 00:16:06.498752: Yayy! New best EMA pseudo Dice: 0.9294000267982483 
2025-01-26 00:16:08.247087:  
2025-01-26 00:16:08.249748: Epoch 655 
2025-01-26 00:16:08.252293: Current learning rate: 0.00384 
2025-01-26 00:16:38.169016: train_loss -0.8495 
2025-01-26 00:16:38.174767: val_loss -0.7847 
2025-01-26 00:16:38.177356: Pseudo dice [np.float32(0.959), np.float32(0.9026)] 
2025-01-26 00:16:38.179768: Epoch time: 29.92 s 
2025-01-26 00:16:38.182013: Yayy! New best EMA pseudo Dice: 0.9296000003814697 
2025-01-26 00:16:39.717870:  
2025-01-26 00:16:39.720372: Epoch 656 
2025-01-26 00:16:39.722682: Current learning rate: 0.00383 
2025-01-26 00:17:08.835556: train_loss -0.8192 
2025-01-26 00:17:08.838073: val_loss -0.785 
2025-01-26 00:17:08.840427: Pseudo dice [np.float32(0.9557), np.float32(0.8777)] 
2025-01-26 00:17:08.842525: Epoch time: 29.12 s 
2025-01-26 00:17:09.893703:  
2025-01-26 00:17:09.896180: Epoch 657 
2025-01-26 00:17:09.898676: Current learning rate: 0.00382 
2025-01-26 00:17:38.482785: train_loss -0.8199 
2025-01-26 00:17:38.487891: val_loss -0.7784 
2025-01-26 00:17:38.490065: Pseudo dice [np.float32(0.9623), np.float32(0.9036)] 
2025-01-26 00:17:38.492287: Epoch time: 28.59 s 
2025-01-26 00:17:40.015349:  
2025-01-26 00:17:40.017728: Epoch 658 
2025-01-26 00:17:40.020056: Current learning rate: 0.00381 
2025-01-26 00:18:09.608146: train_loss -0.8341 
2025-01-26 00:18:09.612488: val_loss -0.8041 
2025-01-26 00:18:09.616747: Pseudo dice [np.float32(0.9588), np.float32(0.9007)] 
2025-01-26 00:18:09.619072: Epoch time: 29.59 s 
2025-01-26 00:18:10.685610:  
2025-01-26 00:18:10.688663: Epoch 659 
2025-01-26 00:18:10.691224: Current learning rate: 0.0038 
2025-01-26 00:18:39.217179: train_loss -0.8407 
2025-01-26 00:18:39.223078: val_loss -0.7802 
2025-01-26 00:18:39.226307: Pseudo dice [np.float32(0.964), np.float32(0.9009)] 
2025-01-26 00:18:39.230442: Epoch time: 28.53 s 
2025-01-26 00:18:40.426526:  
2025-01-26 00:18:40.429116: Epoch 660 
2025-01-26 00:18:40.431648: Current learning rate: 0.00379 
2025-01-26 00:19:10.561078: train_loss -0.8383 
2025-01-26 00:19:10.564522: val_loss -0.7934 
2025-01-26 00:19:10.567800: Pseudo dice [np.float32(0.9598), np.float32(0.92)] 
2025-01-26 00:19:10.570266: Epoch time: 30.14 s 
2025-01-26 00:19:10.572641: Yayy! New best EMA pseudo Dice: 0.9302999973297119 
2025-01-26 00:19:12.173514:  
2025-01-26 00:19:12.176037: Epoch 661 
2025-01-26 00:19:12.178293: Current learning rate: 0.00378 
2025-01-26 00:19:41.720334: train_loss -0.8352 
2025-01-26 00:19:41.726264: val_loss -0.773 
2025-01-26 00:19:41.728679: Pseudo dice [np.float32(0.9622), np.float32(0.9005)] 
2025-01-26 00:19:41.730914: Epoch time: 29.55 s 
2025-01-26 00:19:41.733235: Yayy! New best EMA pseudo Dice: 0.930400013923645 
2025-01-26 00:19:43.321518:  
2025-01-26 00:19:43.324036: Epoch 662 
2025-01-26 00:19:43.326362: Current learning rate: 0.00377 
2025-01-26 00:20:14.766611: train_loss -0.824 
2025-01-26 00:20:14.769993: val_loss -0.8125 
2025-01-26 00:20:14.773177: Pseudo dice [np.float32(0.9611), np.float32(0.9131)] 
2025-01-26 00:20:14.776149: Epoch time: 31.45 s 
2025-01-26 00:20:14.779059: Yayy! New best EMA pseudo Dice: 0.9311000108718872 
2025-01-26 00:20:16.398948:  
2025-01-26 00:20:16.401698: Epoch 663 
2025-01-26 00:20:16.404057: Current learning rate: 0.00376 
2025-01-26 00:20:47.284761: train_loss -0.8396 
2025-01-26 00:20:47.289708: val_loss -0.7548 
2025-01-26 00:20:47.291893: Pseudo dice [np.float32(0.9576), np.float32(0.8709)] 
2025-01-26 00:20:47.294225: Epoch time: 30.89 s 
2025-01-26 00:20:48.352105:  
2025-01-26 00:20:48.354353: Epoch 664 
2025-01-26 00:20:48.356586: Current learning rate: 0.00375 
2025-01-26 00:21:19.015446: train_loss -0.8227 
2025-01-26 00:21:19.020422: val_loss -0.7947 
2025-01-26 00:21:19.022795: Pseudo dice [np.float32(0.9579), np.float32(0.9086)] 
2025-01-26 00:21:19.025266: Epoch time: 30.66 s 
2025-01-26 00:21:20.073873:  
2025-01-26 00:21:20.076454: Epoch 665 
2025-01-26 00:21:20.078734: Current learning rate: 0.00374 
2025-01-26 00:21:52.383311: train_loss -0.8458 
2025-01-26 00:21:52.393675: val_loss -0.7862 
2025-01-26 00:21:52.396358: Pseudo dice [np.float32(0.9645), np.float32(0.8904)] 
2025-01-26 00:21:52.398715: Epoch time: 32.31 s 
2025-01-26 00:21:53.482980:  
2025-01-26 00:21:53.485847: Epoch 666 
2025-01-26 00:21:53.488434: Current learning rate: 0.00373 
2025-01-26 00:22:23.152030: train_loss -0.8364 
2025-01-26 00:22:23.154699: val_loss -0.7625 
2025-01-26 00:22:23.156802: Pseudo dice [np.float32(0.9524), np.float32(0.8751)] 
2025-01-26 00:22:23.159192: Epoch time: 29.67 s 
2025-01-26 00:22:24.207142:  
2025-01-26 00:22:24.209607: Epoch 667 
2025-01-26 00:22:24.212285: Current learning rate: 0.00372 
2025-01-26 00:22:54.052356: train_loss -0.8216 
2025-01-26 00:22:54.057134: val_loss -0.7984 
2025-01-26 00:22:54.059707: Pseudo dice [np.float32(0.9525), np.float32(0.9009)] 
2025-01-26 00:22:54.061894: Epoch time: 29.85 s 
2025-01-26 00:22:55.125997:  
2025-01-26 00:22:55.128726: Epoch 668 
2025-01-26 00:22:55.131032: Current learning rate: 0.00371 
2025-01-26 00:23:24.351178: train_loss -0.8331 
2025-01-26 00:23:24.354097: val_loss -0.7576 
2025-01-26 00:23:24.356961: Pseudo dice [np.float32(0.9524), np.float32(0.8258)] 
2025-01-26 00:23:24.359561: Epoch time: 29.23 s 
2025-01-26 00:23:25.475752:  
2025-01-26 00:23:25.480837: Epoch 669 
2025-01-26 00:23:25.483054: Current learning rate: 0.0037 
2025-01-26 00:23:54.936229: train_loss -0.8349 
2025-01-26 00:23:54.952836: val_loss -0.7937 
2025-01-26 00:23:54.955453: Pseudo dice [np.float32(0.9583), np.float32(0.8871)] 
2025-01-26 00:23:54.959564: Epoch time: 29.46 s 
2025-01-26 00:23:56.099713:  
2025-01-26 00:23:56.102064: Epoch 670 
2025-01-26 00:23:56.104438: Current learning rate: 0.00369 
2025-01-26 00:24:27.169215: train_loss -0.8424 
2025-01-26 00:24:27.173690: val_loss -0.7895 
2025-01-26 00:24:27.176161: Pseudo dice [np.float32(0.9643), np.float32(0.9094)] 
2025-01-26 00:24:27.178586: Epoch time: 31.07 s 
2025-01-26 00:24:28.260867:  
2025-01-26 00:24:28.263649: Epoch 671 
2025-01-26 00:24:28.265905: Current learning rate: 0.00368 
2025-01-26 00:24:57.412367: train_loss -0.8188 
2025-01-26 00:24:57.418365: val_loss -0.7651 
2025-01-26 00:24:57.420832: Pseudo dice [np.float32(0.9578), np.float32(0.8936)] 
2025-01-26 00:24:57.423584: Epoch time: 29.15 s 
2025-01-26 00:24:58.504198:  
2025-01-26 00:24:58.506991: Epoch 672 
2025-01-26 00:24:58.509376: Current learning rate: 0.00367 
2025-01-26 00:25:28.336143: train_loss -0.8359 
2025-01-26 00:25:28.340119: val_loss -0.7932 
2025-01-26 00:25:28.342516: Pseudo dice [np.float32(0.958), np.float32(0.8663)] 
2025-01-26 00:25:28.344963: Epoch time: 29.83 s 
2025-01-26 00:25:29.414286:  
2025-01-26 00:25:29.417190: Epoch 673 
2025-01-26 00:25:29.419752: Current learning rate: 0.00366 
2025-01-26 00:25:59.204374: train_loss -0.8286 
2025-01-26 00:25:59.209764: val_loss -0.7911 
2025-01-26 00:25:59.212089: Pseudo dice [np.float32(0.9619), np.float32(0.8906)] 
2025-01-26 00:25:59.214421: Epoch time: 29.79 s 
2025-01-26 00:26:00.279096:  
2025-01-26 00:26:00.281556: Epoch 674 
2025-01-26 00:26:00.283983: Current learning rate: 0.00365 
2025-01-26 00:26:31.200218: train_loss -0.8243 
2025-01-26 00:26:31.203011: val_loss -0.8307 
2025-01-26 00:26:31.205417: Pseudo dice [np.float32(0.953), np.float32(0.8789)] 
2025-01-26 00:26:31.207880: Epoch time: 30.92 s 
2025-01-26 00:26:32.616060:  
2025-01-26 00:26:32.618492: Epoch 675 
2025-01-26 00:26:32.621353: Current learning rate: 0.00364 
2025-01-26 00:27:04.227920: train_loss -0.8227 
2025-01-26 00:27:04.233919: val_loss -0.7936 
2025-01-26 00:27:04.236485: Pseudo dice [np.float32(0.9564), np.float32(0.8734)] 
2025-01-26 00:27:04.239286: Epoch time: 31.61 s 
2025-01-26 00:27:05.870104:  
2025-01-26 00:27:05.873034: Epoch 676 
2025-01-26 00:27:05.875705: Current learning rate: 0.00363 
2025-01-26 00:27:36.816670: train_loss -0.8309 
2025-01-26 00:27:36.820226: val_loss -0.8286 
2025-01-26 00:27:36.823157: Pseudo dice [np.float32(0.9624), np.float32(0.906)] 
2025-01-26 00:27:36.825835: Epoch time: 30.95 s 
2025-01-26 00:27:37.888264:  
2025-01-26 00:27:37.891038: Epoch 677 
2025-01-26 00:27:37.894351: Current learning rate: 0.00362 
2025-01-26 00:28:07.805684: train_loss -0.8246 
2025-01-26 00:28:07.812047: val_loss -0.7984 
2025-01-26 00:28:07.814694: Pseudo dice [np.float32(0.9614), np.float32(0.8986)] 
2025-01-26 00:28:07.817257: Epoch time: 29.92 s 
2025-01-26 00:28:08.893946:  
2025-01-26 00:28:08.896390: Epoch 678 
2025-01-26 00:28:08.898557: Current learning rate: 0.00361 
2025-01-26 00:28:37.902374: train_loss -0.8372 
2025-01-26 00:28:37.905067: val_loss -0.7973 
2025-01-26 00:28:37.907446: Pseudo dice [np.float32(0.9614), np.float32(0.8711)] 
2025-01-26 00:28:37.909663: Epoch time: 29.01 s 
2025-01-26 00:28:38.975931:  
2025-01-26 00:28:38.978329: Epoch 679 
2025-01-26 00:28:38.981482: Current learning rate: 0.0036 
2025-01-26 00:29:07.936620: train_loss -0.8101 
2025-01-26 00:29:07.941340: val_loss -0.7757 
2025-01-26 00:29:07.943587: Pseudo dice [np.float32(0.9596), np.float32(0.8981)] 
2025-01-26 00:29:07.945813: Epoch time: 28.96 s 
2025-01-26 00:29:09.011478:  
2025-01-26 00:29:09.014087: Epoch 680 
2025-01-26 00:29:09.016397: Current learning rate: 0.00359 
2025-01-26 00:29:38.124819: train_loss -0.8409 
2025-01-26 00:29:38.128014: val_loss -0.7788 
2025-01-26 00:29:38.130563: Pseudo dice [np.float32(0.9643), np.float32(0.9056)] 
2025-01-26 00:29:38.132947: Epoch time: 29.11 s 
2025-01-26 00:29:39.199759:  
2025-01-26 00:29:39.202345: Epoch 681 
2025-01-26 00:29:39.205444: Current learning rate: 0.00358 
2025-01-26 00:30:08.591205: train_loss -0.8338 
2025-01-26 00:30:08.596700: val_loss -0.8252 
2025-01-26 00:30:08.598923: Pseudo dice [np.float32(0.9565), np.float32(0.9102)] 
2025-01-26 00:30:08.601171: Epoch time: 29.39 s 
2025-01-26 00:30:09.673936:  
2025-01-26 00:30:09.676369: Epoch 682 
2025-01-26 00:30:09.678678: Current learning rate: 0.00357 
2025-01-26 00:30:40.784877: train_loss -0.8414 
2025-01-26 00:30:40.799779: val_loss -0.7838 
2025-01-26 00:30:40.802294: Pseudo dice [np.float32(0.9607), np.float32(0.8929)] 
2025-01-26 00:30:40.805081: Epoch time: 31.11 s 
2025-01-26 00:30:41.945418:  
2025-01-26 00:30:41.947961: Epoch 683 
2025-01-26 00:30:41.950474: Current learning rate: 0.00356 
2025-01-26 00:31:12.062381: train_loss -0.8314 
2025-01-26 00:31:12.068029: val_loss -0.8156 
2025-01-26 00:31:12.070330: Pseudo dice [np.float32(0.9624), np.float32(0.9089)] 
2025-01-26 00:31:12.072742: Epoch time: 30.12 s 
2025-01-26 00:31:13.136916:  
2025-01-26 00:31:13.139595: Epoch 684 
2025-01-26 00:31:13.142537: Current learning rate: 0.00355 
2025-01-26 00:31:43.047790: train_loss -0.8407 
2025-01-26 00:31:43.051106: val_loss -0.816 
2025-01-26 00:31:43.053652: Pseudo dice [np.float32(0.9648), np.float32(0.9119)] 
2025-01-26 00:31:43.056332: Epoch time: 29.91 s 
2025-01-26 00:31:44.136294:  
2025-01-26 00:31:44.138763: Epoch 685 
2025-01-26 00:31:44.142714: Current learning rate: 0.00354 
2025-01-26 00:32:13.438188: train_loss -0.8221 
2025-01-26 00:32:13.446292: val_loss -0.8091 
2025-01-26 00:32:13.448962: Pseudo dice [np.float32(0.9622), np.float32(0.9153)] 
2025-01-26 00:32:13.451447: Epoch time: 29.3 s 
2025-01-26 00:32:14.539816:  
2025-01-26 00:32:14.542113: Epoch 686 
2025-01-26 00:32:14.544539: Current learning rate: 0.00353 
2025-01-26 00:32:44.206827: train_loss -0.834 
2025-01-26 00:32:44.211489: val_loss -0.7927 
2025-01-26 00:32:44.213815: Pseudo dice [np.float32(0.9618), np.float32(0.9153)] 
2025-01-26 00:32:44.216331: Epoch time: 29.67 s 
2025-01-26 00:32:45.319361:  
2025-01-26 00:32:45.322409: Epoch 687 
2025-01-26 00:32:45.325158: Current learning rate: 0.00352 
2025-01-26 00:33:16.210265: train_loss -0.8239 
2025-01-26 00:33:16.216103: val_loss -0.7836 
2025-01-26 00:33:16.218628: Pseudo dice [np.float32(0.9594), np.float32(0.9055)] 
2025-01-26 00:33:16.221180: Epoch time: 30.89 s 
2025-01-26 00:33:17.289124:  
2025-01-26 00:33:17.291619: Epoch 688 
2025-01-26 00:33:17.294461: Current learning rate: 0.00351 
2025-01-26 00:33:47.577404: train_loss -0.8165 
2025-01-26 00:33:47.581299: val_loss -0.7774 
2025-01-26 00:33:47.583717: Pseudo dice [np.float32(0.959), np.float32(0.8643)] 
2025-01-26 00:33:47.585953: Epoch time: 30.29 s 
2025-01-26 00:33:48.664025:  
2025-01-26 00:33:48.666479: Epoch 689 
2025-01-26 00:33:48.669177: Current learning rate: 0.0035 
2025-01-26 00:34:17.653931: train_loss -0.8432 
2025-01-26 00:34:17.660310: val_loss -0.781 
2025-01-26 00:34:17.662705: Pseudo dice [np.float32(0.9614), np.float32(0.8655)] 
2025-01-26 00:34:17.665198: Epoch time: 28.99 s 
2025-01-26 00:34:18.734917:  
2025-01-26 00:34:18.737796: Epoch 690 
2025-01-26 00:34:18.740903: Current learning rate: 0.00349 
2025-01-26 00:34:48.951777: train_loss -0.8275 
2025-01-26 00:34:48.957974: val_loss -0.811 
2025-01-26 00:34:48.960634: Pseudo dice [np.float32(0.9571), np.float32(0.8983)] 
2025-01-26 00:34:48.962914: Epoch time: 30.22 s 
2025-01-26 00:34:50.354440:  
2025-01-26 00:34:50.357064: Epoch 691 
2025-01-26 00:34:50.359695: Current learning rate: 0.00348 
2025-01-26 00:35:20.502126: train_loss -0.8377 
2025-01-26 00:35:20.508931: val_loss -0.7975 
2025-01-26 00:35:20.511589: Pseudo dice [np.float32(0.962), np.float32(0.91)] 
2025-01-26 00:35:20.514143: Epoch time: 30.15 s 
2025-01-26 00:35:21.586007:  
2025-01-26 00:35:21.588300: Epoch 692 
2025-01-26 00:35:21.590474: Current learning rate: 0.00346 
2025-01-26 00:35:51.610895: train_loss -0.8503 
2025-01-26 00:35:51.615618: val_loss -0.7833 
2025-01-26 00:35:51.617836: Pseudo dice [np.float32(0.9513), np.float32(0.8724)] 
2025-01-26 00:35:51.619973: Epoch time: 30.03 s 
2025-01-26 00:35:52.693168:  
2025-01-26 00:35:52.695712: Epoch 693 
2025-01-26 00:35:52.698505: Current learning rate: 0.00345 
2025-01-26 00:36:23.193488: train_loss -0.8322 
2025-01-26 00:36:23.199326: val_loss -0.7981 
2025-01-26 00:36:23.201744: Pseudo dice [np.float32(0.9624), np.float32(0.9184)] 
2025-01-26 00:36:23.204000: Epoch time: 30.5 s 
2025-01-26 00:36:24.683493:  
2025-01-26 00:36:24.685894: Epoch 694 
2025-01-26 00:36:24.688080: Current learning rate: 0.00344 
2025-01-26 00:36:53.217171: train_loss -0.8345 
2025-01-26 00:36:53.221638: val_loss -0.7781 
2025-01-26 00:36:53.223951: Pseudo dice [np.float32(0.9538), np.float32(0.8686)] 
2025-01-26 00:36:53.226253: Epoch time: 28.53 s 
2025-01-26 00:36:54.331663:  
2025-01-26 00:36:54.337351: Epoch 695 
2025-01-26 00:36:54.339718: Current learning rate: 0.00343 
2025-01-26 00:37:23.481280: train_loss -0.8377 
2025-01-26 00:37:23.486743: val_loss -0.7947 
2025-01-26 00:37:23.488979: Pseudo dice [np.float32(0.9631), np.float32(0.9184)] 
2025-01-26 00:37:23.491181: Epoch time: 29.15 s 
2025-01-26 00:37:24.562860:  
2025-01-26 00:37:24.565377: Epoch 696 
2025-01-26 00:37:24.568497: Current learning rate: 0.00342 
2025-01-26 00:37:54.118347: train_loss -0.8249 
2025-01-26 00:37:54.120994: val_loss -0.781 
2025-01-26 00:37:54.123145: Pseudo dice [np.float32(0.9609), np.float32(0.8829)] 
2025-01-26 00:37:54.125406: Epoch time: 29.56 s 
2025-01-26 00:37:55.202413:  
2025-01-26 00:37:55.205084: Epoch 697 
2025-01-26 00:37:55.207372: Current learning rate: 0.00341 
2025-01-26 00:38:25.969023: train_loss -0.8413 
2025-01-26 00:38:25.976574: val_loss -0.8078 
2025-01-26 00:38:25.979434: Pseudo dice [np.float32(0.9583), np.float32(0.9073)] 
2025-01-26 00:38:25.982188: Epoch time: 30.77 s 
2025-01-26 00:38:27.160187:  
2025-01-26 00:38:27.162596: Epoch 698 
2025-01-26 00:38:27.165678: Current learning rate: 0.0034 
2025-01-26 00:38:57.286798: train_loss -0.8277 
2025-01-26 00:38:57.289629: val_loss -0.7703 
2025-01-26 00:38:57.291913: Pseudo dice [np.float32(0.9587), np.float32(0.8964)] 
2025-01-26 00:38:57.294202: Epoch time: 30.13 s 
2025-01-26 00:38:58.364176:  
2025-01-26 00:38:58.366642: Epoch 699 
2025-01-26 00:38:58.369141: Current learning rate: 0.00339 
2025-01-26 00:39:27.200271: train_loss -0.8316 
2025-01-26 00:39:27.205237: val_loss -0.793 
2025-01-26 00:39:27.207355: Pseudo dice [np.float32(0.9631), np.float32(0.9198)] 
2025-01-26 00:39:27.209737: Epoch time: 28.84 s 
2025-01-26 00:39:28.801739:  
2025-01-26 00:39:28.804635: Epoch 700 
2025-01-26 00:39:28.807008: Current learning rate: 0.00338 
2025-01-26 00:39:58.221798: train_loss -0.8489 
2025-01-26 00:39:58.224772: val_loss -0.8048 
2025-01-26 00:39:58.227080: Pseudo dice [np.float32(0.9605), np.float32(0.9052)] 
2025-01-26 00:39:58.229891: Epoch time: 29.42 s 
2025-01-26 00:39:59.310731:  
2025-01-26 00:39:59.313128: Epoch 701 
2025-01-26 00:39:59.315775: Current learning rate: 0.00337 
2025-01-26 00:40:30.026773: train_loss -0.8353 
2025-01-26 00:40:30.035833: val_loss -0.7672 
2025-01-26 00:40:30.038577: Pseudo dice [np.float32(0.9619), np.float32(0.9004)] 
2025-01-26 00:40:30.041353: Epoch time: 30.72 s 
2025-01-26 00:40:31.306548:  
2025-01-26 00:40:31.309133: Epoch 702 
2025-01-26 00:40:31.311630: Current learning rate: 0.00336 
2025-01-26 00:41:00.880367: train_loss -0.8397 
2025-01-26 00:41:00.892802: val_loss -0.821 
2025-01-26 00:41:00.895071: Pseudo dice [np.float32(0.9606), np.float32(0.9017)] 
2025-01-26 00:41:00.897731: Epoch time: 29.57 s 
2025-01-26 00:41:02.020656:  
2025-01-26 00:41:02.023322: Epoch 703 
2025-01-26 00:41:02.025712: Current learning rate: 0.00335 
2025-01-26 00:41:32.187857: train_loss -0.8275 
2025-01-26 00:41:32.196048: val_loss -0.7862 
2025-01-26 00:41:32.198466: Pseudo dice [np.float32(0.9582), np.float32(0.9063)] 
2025-01-26 00:41:32.200617: Epoch time: 30.17 s 
2025-01-26 00:41:33.284485:  
2025-01-26 00:41:33.287167: Epoch 704 
2025-01-26 00:41:33.290258: Current learning rate: 0.00334 
2025-01-26 00:42:04.112405: train_loss -0.8405 
2025-01-26 00:42:04.115159: val_loss -0.7953 
2025-01-26 00:42:04.117924: Pseudo dice [np.float32(0.9623), np.float32(0.8962)] 
2025-01-26 00:42:04.120480: Epoch time: 30.83 s 
2025-01-26 00:42:05.198652:  
2025-01-26 00:42:05.201501: Epoch 705 
2025-01-26 00:42:05.203837: Current learning rate: 0.00333 
2025-01-26 00:42:34.491812: train_loss -0.8527 
2025-01-26 00:42:34.497157: val_loss -0.7993 
2025-01-26 00:42:34.499905: Pseudo dice [np.float32(0.964), np.float32(0.9066)] 
2025-01-26 00:42:34.502294: Epoch time: 29.29 s 
2025-01-26 00:42:35.577492:  
2025-01-26 00:42:35.579631: Epoch 706 
2025-01-26 00:42:35.582857: Current learning rate: 0.00332 
2025-01-26 00:43:05.835096: train_loss -0.8342 
2025-01-26 00:43:05.839502: val_loss -0.7776 
2025-01-26 00:43:05.842737: Pseudo dice [np.float32(0.9643), np.float32(0.9263)] 
2025-01-26 00:43:05.845210: Epoch time: 30.26 s 
2025-01-26 00:43:05.847689: Yayy! New best EMA pseudo Dice: 0.9319000244140625 
2025-01-26 00:43:07.701636:  
2025-01-26 00:43:07.704230: Epoch 707 
2025-01-26 00:43:07.706857: Current learning rate: 0.00331 
2025-01-26 00:43:37.452269: train_loss -0.8431 
2025-01-26 00:43:37.457391: val_loss -0.7756 
2025-01-26 00:43:37.459730: Pseudo dice [np.float32(0.9614), np.float32(0.9037)] 
2025-01-26 00:43:37.462007: Epoch time: 29.75 s 
2025-01-26 00:43:37.464270: Yayy! New best EMA pseudo Dice: 0.9319999814033508 
2025-01-26 00:43:39.027011:  
2025-01-26 00:43:39.029720: Epoch 708 
2025-01-26 00:43:39.032279: Current learning rate: 0.0033 
2025-01-26 00:44:07.750492: train_loss -0.8311 
2025-01-26 00:44:07.753249: val_loss -0.7981 
2025-01-26 00:44:07.755736: Pseudo dice [np.float32(0.9631), np.float32(0.917)] 
2025-01-26 00:44:07.758235: Epoch time: 28.72 s 
2025-01-26 00:44:07.760652: Yayy! New best EMA pseudo Dice: 0.9327999949455261 
2025-01-26 00:44:09.316099:  
2025-01-26 00:44:09.318991: Epoch 709 
2025-01-26 00:44:09.321973: Current learning rate: 0.00329 
2025-01-26 00:44:38.370089: train_loss -0.8376 
2025-01-26 00:44:38.374962: val_loss -0.7893 
2025-01-26 00:44:38.377377: Pseudo dice [np.float32(0.9644), np.float32(0.9229)] 
2025-01-26 00:44:38.379859: Epoch time: 29.05 s 
2025-01-26 00:44:38.382174: Yayy! New best EMA pseudo Dice: 0.933899998664856 
2025-01-26 00:44:40.015662:  
2025-01-26 00:44:40.018240: Epoch 710 
2025-01-26 00:44:40.020809: Current learning rate: 0.00328 
2025-01-26 00:45:10.388206: train_loss -0.8408 
2025-01-26 00:45:10.390924: val_loss -0.7771 
2025-01-26 00:45:10.393395: Pseudo dice [np.float32(0.9654), np.float32(0.9131)] 
2025-01-26 00:45:10.395670: Epoch time: 30.37 s 
2025-01-26 00:45:10.397973: Yayy! New best EMA pseudo Dice: 0.9344000220298767 
2025-01-26 00:45:12.437407:  
2025-01-26 00:45:12.440109: Epoch 711 
2025-01-26 00:45:12.442661: Current learning rate: 0.00327 
2025-01-26 00:45:41.808209: train_loss -0.8348 
2025-01-26 00:45:41.815206: val_loss -0.7971 
2025-01-26 00:45:41.817909: Pseudo dice [np.float32(0.9616), np.float32(0.9066)] 
2025-01-26 00:45:41.820364: Epoch time: 29.37 s 
2025-01-26 00:45:42.898729:  
2025-01-26 00:45:42.901260: Epoch 712 
2025-01-26 00:45:42.903905: Current learning rate: 0.00326 
2025-01-26 00:46:12.201643: train_loss -0.831 
2025-01-26 00:46:12.208167: val_loss -0.7861 
2025-01-26 00:46:12.210456: Pseudo dice [np.float32(0.9622), np.float32(0.9072)] 
2025-01-26 00:46:12.212852: Epoch time: 29.3 s 
2025-01-26 00:46:12.215057: Yayy! New best EMA pseudo Dice: 0.9344000220298767 
2025-01-26 00:46:13.838438:  
2025-01-26 00:46:13.841077: Epoch 713 
2025-01-26 00:46:13.844526: Current learning rate: 0.00325 
2025-01-26 00:46:43.351103: train_loss -0.8339 
2025-01-26 00:46:43.371552: val_loss -0.7748 
2025-01-26 00:46:43.378723: Pseudo dice [np.float32(0.9568), np.float32(0.848)] 
2025-01-26 00:46:43.380996: Epoch time: 29.51 s 
2025-01-26 00:46:44.453956:  
2025-01-26 00:46:44.456787: Epoch 714 
2025-01-26 00:46:44.460243: Current learning rate: 0.00324 
2025-01-26 00:47:13.940286: train_loss -0.8274 
2025-01-26 00:47:13.942781: val_loss -0.7986 
2025-01-26 00:47:13.945058: Pseudo dice [np.float32(0.9613), np.float32(0.9084)] 
2025-01-26 00:47:13.947203: Epoch time: 29.49 s 
2025-01-26 00:47:15.025336:  
2025-01-26 00:47:15.027649: Epoch 715 
2025-01-26 00:47:15.029955: Current learning rate: 0.00323 
2025-01-26 00:47:45.266288: train_loss -0.8426 
2025-01-26 00:47:45.273968: val_loss -0.8266 
2025-01-26 00:47:45.276653: Pseudo dice [np.float32(0.9619), np.float32(0.89)] 
2025-01-26 00:47:45.279195: Epoch time: 30.24 s 
2025-01-26 00:47:46.461653:  
2025-01-26 00:47:46.464405: Epoch 716 
2025-01-26 00:47:46.466921: Current learning rate: 0.00322 
2025-01-26 00:48:14.966192: train_loss -0.8281 
2025-01-26 00:48:14.968961: val_loss -0.795 
2025-01-26 00:48:14.971178: Pseudo dice [np.float32(0.9601), np.float32(0.906)] 
2025-01-26 00:48:14.973480: Epoch time: 28.51 s 
2025-01-26 00:48:16.050038:  
2025-01-26 00:48:16.052695: Epoch 717 
2025-01-26 00:48:16.055000: Current learning rate: 0.00321 
2025-01-26 00:48:44.996670: train_loss -0.8369 
2025-01-26 00:48:45.001997: val_loss -0.7786 
2025-01-26 00:48:45.004600: Pseudo dice [np.float32(0.9617), np.float32(0.9118)] 
2025-01-26 00:48:45.007356: Epoch time: 28.95 s 
2025-01-26 00:48:46.194224:  
2025-01-26 00:48:46.197149: Epoch 718 
2025-01-26 00:48:46.199872: Current learning rate: 0.0032 
2025-01-26 00:49:15.939068: train_loss -0.8165 
2025-01-26 00:49:15.941955: val_loss -0.8185 
2025-01-26 00:49:15.946107: Pseudo dice [np.float32(0.9578), np.float32(0.9154)] 
2025-01-26 00:49:15.948709: Epoch time: 29.75 s 
2025-01-26 00:49:17.026637:  
2025-01-26 00:49:17.032295: Epoch 719 
2025-01-26 00:49:17.035049: Current learning rate: 0.00319 
2025-01-26 00:49:46.163397: train_loss -0.8324 
2025-01-26 00:49:46.169299: val_loss -0.8138 
2025-01-26 00:49:46.171879: Pseudo dice [np.float32(0.9521), np.float32(0.8793)] 
2025-01-26 00:49:46.174549: Epoch time: 29.14 s 
2025-01-26 00:49:47.341291:  
2025-01-26 00:49:47.343971: Epoch 720 
2025-01-26 00:49:47.347044: Current learning rate: 0.00318 
2025-01-26 00:50:18.158221: train_loss -0.8393 
2025-01-26 00:50:18.160957: val_loss -0.7763 
2025-01-26 00:50:18.163366: Pseudo dice [np.float32(0.9592), np.float32(0.9048)] 
2025-01-26 00:50:18.165763: Epoch time: 30.82 s 
2025-01-26 00:50:19.240273:  
2025-01-26 00:50:19.242877: Epoch 721 
2025-01-26 00:50:19.245252: Current learning rate: 0.00317 
2025-01-26 00:50:49.279773: train_loss -0.8457 
2025-01-26 00:50:49.285413: val_loss -0.7917 
2025-01-26 00:50:49.288072: Pseudo dice [np.float32(0.9545), np.float32(0.8919)] 
2025-01-26 00:50:49.290429: Epoch time: 30.04 s 
2025-01-26 00:50:50.364601:  
2025-01-26 00:50:50.367180: Epoch 722 
2025-01-26 00:50:50.370200: Current learning rate: 0.00316 
2025-01-26 00:51:21.903901: train_loss -0.825 
2025-01-26 00:51:21.906761: val_loss -0.7998 
2025-01-26 00:51:21.909895: Pseudo dice [np.float32(0.9552), np.float32(0.9066)] 
2025-01-26 00:51:21.912663: Epoch time: 31.54 s 
2025-01-26 00:51:23.000405:  
2025-01-26 00:51:23.003378: Epoch 723 
2025-01-26 00:51:23.005648: Current learning rate: 0.00315 
2025-01-26 00:51:52.256460: train_loss -0.8341 
2025-01-26 00:51:52.261347: val_loss -0.7819 
2025-01-26 00:51:52.263756: Pseudo dice [np.float32(0.964), np.float32(0.8855)] 
2025-01-26 00:51:52.266107: Epoch time: 29.26 s 
2025-01-26 00:51:53.336251:  
2025-01-26 00:51:53.338636: Epoch 724 
2025-01-26 00:51:53.341703: Current learning rate: 0.00314 
2025-01-26 00:52:22.147543: train_loss -0.8413 
2025-01-26 00:52:22.150530: val_loss -0.7705 
2025-01-26 00:52:22.153021: Pseudo dice [np.float32(0.962), np.float32(0.8665)] 
2025-01-26 00:52:22.155439: Epoch time: 28.81 s 
2025-01-26 00:52:23.221775:  
2025-01-26 00:52:23.224495: Epoch 725 
2025-01-26 00:52:23.227050: Current learning rate: 0.00313 
2025-01-26 00:52:53.626684: train_loss -0.8224 
2025-01-26 00:52:53.631714: val_loss -0.7891 
2025-01-26 00:52:53.634191: Pseudo dice [np.float32(0.9601), np.float32(0.9026)] 
2025-01-26 00:52:53.636377: Epoch time: 30.41 s 
2025-01-26 00:52:54.704573:  
2025-01-26 00:52:54.706997: Epoch 726 
2025-01-26 00:52:54.709217: Current learning rate: 0.00312 
2025-01-26 00:53:26.254434: train_loss -0.8252 
2025-01-26 00:53:26.257014: val_loss -0.7882 
2025-01-26 00:53:26.259147: Pseudo dice [np.float32(0.9582), np.float32(0.895)] 
2025-01-26 00:53:26.261686: Epoch time: 31.55 s 
2025-01-26 00:53:27.333930:  
2025-01-26 00:53:27.336712: Epoch 727 
2025-01-26 00:53:27.339398: Current learning rate: 0.00311 
2025-01-26 00:53:56.886352: train_loss -0.8245 
2025-01-26 00:53:56.891572: val_loss -0.8176 
2025-01-26 00:53:56.894227: Pseudo dice [np.float32(0.962), np.float32(0.9156)] 
2025-01-26 00:53:56.896601: Epoch time: 29.55 s 
2025-01-26 00:53:58.361504:  
2025-01-26 00:53:58.364443: Epoch 728 
2025-01-26 00:53:58.367029: Current learning rate: 0.0031 
2025-01-26 00:54:27.632554: train_loss -0.8401 
2025-01-26 00:54:27.635187: val_loss -0.8051 
2025-01-26 00:54:27.637394: Pseudo dice [np.float32(0.958), np.float32(0.8873)] 
2025-01-26 00:54:27.639533: Epoch time: 29.27 s 
2025-01-26 00:54:28.736505:  
2025-01-26 00:54:28.739468: Epoch 729 
2025-01-26 00:54:28.742318: Current learning rate: 0.00309 
2025-01-26 00:54:58.459489: train_loss -0.8072 
2025-01-26 00:54:58.467943: val_loss -0.7796 
2025-01-26 00:54:58.470266: Pseudo dice [np.float32(0.9555), np.float32(0.8228)] 
2025-01-26 00:54:58.472556: Epoch time: 29.72 s 
2025-01-26 00:54:59.601862:  
2025-01-26 00:54:59.604491: Epoch 730 
2025-01-26 00:54:59.607088: Current learning rate: 0.00308 
2025-01-26 00:55:29.268326: train_loss -0.7941 
2025-01-26 00:55:29.271378: val_loss -0.7363 
2025-01-26 00:55:29.273785: Pseudo dice [np.float32(0.9433), np.float32(0.8467)] 
2025-01-26 00:55:29.276166: Epoch time: 29.67 s 
2025-01-26 00:55:30.345988:  
2025-01-26 00:55:30.348780: Epoch 731 
2025-01-26 00:55:30.351100: Current learning rate: 0.00307 
2025-01-26 00:56:01.264197: train_loss -0.8125 
2025-01-26 00:56:01.271520: val_loss -0.7879 
2025-01-26 00:56:01.274055: Pseudo dice [np.float32(0.9605), np.float32(0.8575)] 
2025-01-26 00:56:01.276436: Epoch time: 30.92 s 
2025-01-26 00:56:02.366825:  
2025-01-26 00:56:02.369330: Epoch 732 
2025-01-26 00:56:02.372298: Current learning rate: 0.00306 
2025-01-26 00:56:31.862848: train_loss -0.8122 
2025-01-26 00:56:31.869358: val_loss -0.8081 
2025-01-26 00:56:31.872222: Pseudo dice [np.float32(0.9606), np.float32(0.8773)] 
2025-01-26 00:56:31.875034: Epoch time: 29.5 s 
2025-01-26 00:56:32.979865:  
2025-01-26 00:56:32.982496: Epoch 733 
2025-01-26 00:56:32.985621: Current learning rate: 0.00305 
2025-01-26 00:57:03.059618: train_loss -0.8254 
2025-01-26 00:57:03.066544: val_loss -0.7882 
2025-01-26 00:57:03.069182: Pseudo dice [np.float32(0.9597), np.float32(0.917)] 
2025-01-26 00:57:03.071688: Epoch time: 30.08 s 
2025-01-26 00:57:04.160600:  
2025-01-26 00:57:04.163167: Epoch 734 
2025-01-26 00:57:04.165639: Current learning rate: 0.00304 
2025-01-26 00:57:33.383181: train_loss -0.8419 
2025-01-26 00:57:33.385674: val_loss -0.7676 
2025-01-26 00:57:33.387679: Pseudo dice [np.float32(0.9594), np.float32(0.8376)] 
2025-01-26 00:57:33.389692: Epoch time: 29.22 s 
2025-01-26 00:57:34.469927:  
2025-01-26 00:57:34.475206: Epoch 735 
2025-01-26 00:57:34.477414: Current learning rate: 0.00303 
2025-01-26 00:58:03.041075: train_loss -0.8282 
2025-01-26 00:58:03.044009: val_loss -0.7832 
2025-01-26 00:58:03.046196: Pseudo dice [np.float32(0.953), np.float32(0.8999)] 
2025-01-26 00:58:03.048478: Epoch time: 28.57 s 
2025-01-26 00:58:04.129687:  
2025-01-26 00:58:04.132032: Epoch 736 
2025-01-26 00:58:04.135139: Current learning rate: 0.00302 
2025-01-26 00:58:33.458005: train_loss -0.8171 
2025-01-26 00:58:33.463474: val_loss -0.7676 
2025-01-26 00:58:33.466190: Pseudo dice [np.float32(0.9632), np.float32(0.9066)] 
2025-01-26 00:58:33.468538: Epoch time: 29.33 s 
2025-01-26 00:58:34.552374:  
2025-01-26 00:58:34.554632: Epoch 737 
2025-01-26 00:58:34.557648: Current learning rate: 0.00301 
2025-01-26 00:59:05.524822: train_loss -0.8312 
2025-01-26 00:59:05.539760: val_loss -0.8078 
2025-01-26 00:59:05.542110: Pseudo dice [np.float32(0.9575), np.float32(0.8917)] 
2025-01-26 00:59:05.544525: Epoch time: 30.97 s 
2025-01-26 00:59:06.804325:  
2025-01-26 00:59:06.807022: Epoch 738 
2025-01-26 00:59:06.809078: Current learning rate: 0.003 
2025-01-26 00:59:36.031452: train_loss -0.8348 
2025-01-26 00:59:36.034247: val_loss -0.8031 
2025-01-26 00:59:36.037207: Pseudo dice [np.float32(0.9593), np.float32(0.8853)] 
2025-01-26 00:59:36.039681: Epoch time: 29.23 s 
2025-01-26 00:59:37.120272:  
2025-01-26 00:59:37.122983: Epoch 739 
2025-01-26 00:59:37.125318: Current learning rate: 0.00299 
2025-01-26 01:00:06.049350: train_loss -0.8377 
2025-01-26 01:00:06.054462: val_loss -0.8276 
2025-01-26 01:00:06.056776: Pseudo dice [np.float32(0.957), np.float32(0.9192)] 
2025-01-26 01:00:06.059149: Epoch time: 28.93 s 
2025-01-26 01:00:07.138051:  
2025-01-26 01:00:07.140665: Epoch 740 
2025-01-26 01:00:07.143229: Current learning rate: 0.00297 
2025-01-26 01:00:37.598712: train_loss -0.8419 
2025-01-26 01:00:37.601485: val_loss -0.7921 
2025-01-26 01:00:37.603963: Pseudo dice [np.float32(0.9552), np.float32(0.9089)] 
2025-01-26 01:00:37.606312: Epoch time: 30.46 s 
2025-01-26 01:00:38.685690:  
2025-01-26 01:00:38.688377: Epoch 741 
2025-01-26 01:00:38.691088: Current learning rate: 0.00296 
2025-01-26 01:01:07.705389: train_loss -0.8384 
2025-01-26 01:01:07.710694: val_loss -0.8156 
2025-01-26 01:01:07.713191: Pseudo dice [np.float32(0.9568), np.float32(0.906)] 
2025-01-26 01:01:07.715529: Epoch time: 29.02 s 
2025-01-26 01:01:08.783477:  
2025-01-26 01:01:08.786087: Epoch 742 
2025-01-26 01:01:08.788231: Current learning rate: 0.00295 
2025-01-26 01:01:37.901397: train_loss -0.8368 
2025-01-26 01:01:37.904397: val_loss -0.8103 
2025-01-26 01:01:37.906814: Pseudo dice [np.float32(0.9593), np.float32(0.8963)] 
2025-01-26 01:01:37.910198: Epoch time: 29.12 s 
2025-01-26 01:01:39.192847:  
2025-01-26 01:01:39.195432: Epoch 743 
2025-01-26 01:01:39.198014: Current learning rate: 0.00294 
2025-01-26 01:02:07.987936: train_loss -0.8393 
2025-01-26 01:02:07.993317: val_loss -0.7944 
2025-01-26 01:02:07.995638: Pseudo dice [np.float32(0.9633), np.float32(0.9109)] 
2025-01-26 01:02:07.998246: Epoch time: 28.8 s 
2025-01-26 01:02:09.088427:  
2025-01-26 01:02:09.091085: Epoch 744 
2025-01-26 01:02:09.093898: Current learning rate: 0.00293 
2025-01-26 01:02:38.647895: train_loss -0.8468 
2025-01-26 01:02:38.652521: val_loss -0.7857 
2025-01-26 01:02:38.655380: Pseudo dice [np.float32(0.9655), np.float32(0.9086)] 
2025-01-26 01:02:38.658050: Epoch time: 29.56 s 
2025-01-26 01:02:39.755791:  
2025-01-26 01:02:39.758166: Epoch 745 
2025-01-26 01:02:39.760607: Current learning rate: 0.00292 
2025-01-26 01:03:08.923812: train_loss -0.8403 
2025-01-26 01:03:08.928842: val_loss -0.802 
2025-01-26 01:03:08.931095: Pseudo dice [np.float32(0.9626), np.float32(0.9208)] 
2025-01-26 01:03:08.933478: Epoch time: 29.17 s 
2025-01-26 01:03:10.411494:  
2025-01-26 01:03:10.414474: Epoch 746 
2025-01-26 01:03:10.417431: Current learning rate: 0.00291 
2025-01-26 01:03:41.181558: train_loss -0.8642 
2025-01-26 01:03:41.184950: val_loss -0.8151 
2025-01-26 01:03:41.188951: Pseudo dice [np.float32(0.9632), np.float32(0.9071)] 
2025-01-26 01:03:41.191278: Epoch time: 30.77 s 
2025-01-26 01:03:42.279451:  
2025-01-26 01:03:42.282212: Epoch 747 
2025-01-26 01:03:42.285574: Current learning rate: 0.0029 
2025-01-26 01:04:11.568876: train_loss -0.8414 
2025-01-26 01:04:11.577538: val_loss -0.8371 
2025-01-26 01:04:11.580064: Pseudo dice [np.float32(0.9635), np.float32(0.9155)] 
2025-01-26 01:04:11.582744: Epoch time: 29.29 s 
2025-01-26 01:04:12.722781:  
2025-01-26 01:04:12.725617: Epoch 748 
2025-01-26 01:04:12.728083: Current learning rate: 0.00289 
2025-01-26 01:04:44.775810: train_loss -0.8295 
2025-01-26 01:04:44.782345: val_loss -0.7792 
2025-01-26 01:04:44.784949: Pseudo dice [np.float32(0.9547), np.float32(0.9114)] 
2025-01-26 01:04:44.787627: Epoch time: 32.05 s 
2025-01-26 01:04:45.902107:  
2025-01-26 01:04:45.904955: Epoch 749 
2025-01-26 01:04:45.907508: Current learning rate: 0.00288 
2025-01-26 01:05:16.450177: train_loss -0.8322 
2025-01-26 01:05:16.455522: val_loss -0.8169 
2025-01-26 01:05:16.457932: Pseudo dice [np.float32(0.9599), np.float32(0.9043)] 
2025-01-26 01:05:16.460391: Epoch time: 30.55 s 
2025-01-26 01:05:18.094804:  
2025-01-26 01:05:18.097432: Epoch 750 
2025-01-26 01:05:18.099845: Current learning rate: 0.00287 
2025-01-26 01:05:48.122663: train_loss -0.8146 
2025-01-26 01:05:48.125446: val_loss -0.7635 
2025-01-26 01:05:48.127738: Pseudo dice [np.float32(0.9565), np.float32(0.8876)] 
2025-01-26 01:05:48.130108: Epoch time: 30.03 s 
2025-01-26 01:05:49.206151:  
2025-01-26 01:05:49.208909: Epoch 751 
2025-01-26 01:05:49.211498: Current learning rate: 0.00286 
2025-01-26 01:06:17.734002: train_loss -0.8341 
2025-01-26 01:06:17.739986: val_loss -0.7935 
2025-01-26 01:06:17.742352: Pseudo dice [np.float32(0.9589), np.float32(0.9081)] 
2025-01-26 01:06:17.744632: Epoch time: 28.53 s 
2025-01-26 01:06:18.812373:  
2025-01-26 01:06:18.814715: Epoch 752 
2025-01-26 01:06:18.816962: Current learning rate: 0.00285 
2025-01-26 01:06:48.758636: train_loss -0.831 
2025-01-26 01:06:48.764559: val_loss -0.7781 
2025-01-26 01:06:48.767259: Pseudo dice [np.float32(0.9622), np.float32(0.9069)] 
2025-01-26 01:06:48.769931: Epoch time: 29.95 s 
2025-01-26 01:06:49.882024:  
2025-01-26 01:06:49.888184: Epoch 753 
2025-01-26 01:06:49.890532: Current learning rate: 0.00284 
2025-01-26 01:07:19.574683: train_loss -0.8223 
2025-01-26 01:07:19.581298: val_loss -0.8118 
2025-01-26 01:07:19.583875: Pseudo dice [np.float32(0.961), np.float32(0.8949)] 
2025-01-26 01:07:19.586475: Epoch time: 29.69 s 
2025-01-26 01:07:20.659259:  
2025-01-26 01:07:20.661982: Epoch 754 
2025-01-26 01:07:20.664598: Current learning rate: 0.00283 
2025-01-26 01:07:50.447567: train_loss -0.8281 
2025-01-26 01:07:50.450495: val_loss -0.7797 
2025-01-26 01:07:50.452800: Pseudo dice [np.float32(0.9521), np.float32(0.8556)] 
2025-01-26 01:07:50.454991: Epoch time: 29.79 s 
2025-01-26 01:07:51.523121:  
2025-01-26 01:07:51.525819: Epoch 755 
2025-01-26 01:07:51.528712: Current learning rate: 0.00282 
2025-01-26 01:08:21.085881: train_loss -0.8235 
2025-01-26 01:08:21.091112: val_loss -0.7947 
2025-01-26 01:08:21.093503: Pseudo dice [np.float32(0.9627), np.float32(0.8902)] 
2025-01-26 01:08:21.095747: Epoch time: 29.56 s 
2025-01-26 01:08:22.162303:  
2025-01-26 01:08:22.165205: Epoch 756 
2025-01-26 01:08:22.167883: Current learning rate: 0.00281 
2025-01-26 01:08:50.898182: train_loss -0.8393 
2025-01-26 01:08:50.900979: val_loss -0.8046 
2025-01-26 01:08:50.903349: Pseudo dice [np.float32(0.9648), np.float32(0.9136)] 
2025-01-26 01:08:50.905582: Epoch time: 28.74 s 
2025-01-26 01:08:51.971912:  
2025-01-26 01:08:51.975075: Epoch 757 
2025-01-26 01:08:51.977720: Current learning rate: 0.0028 
2025-01-26 01:09:20.664652: train_loss -0.8407 
2025-01-26 01:09:20.667588: val_loss -0.7861 
2025-01-26 01:09:20.669989: Pseudo dice [np.float32(0.9591), np.float32(0.9067)] 
2025-01-26 01:09:20.672389: Epoch time: 28.69 s 
2025-01-26 01:09:21.744808:  
2025-01-26 01:09:21.747217: Epoch 758 
2025-01-26 01:09:21.749714: Current learning rate: 0.00279 
2025-01-26 01:09:50.343240: train_loss -0.8385 
2025-01-26 01:09:50.345753: val_loss -0.8016 
2025-01-26 01:09:50.348219: Pseudo dice [np.float32(0.9614), np.float32(0.8916)] 
2025-01-26 01:09:50.350433: Epoch time: 28.6 s 
2025-01-26 01:09:51.418880:  
2025-01-26 01:09:51.421907: Epoch 759 
2025-01-26 01:09:51.424434: Current learning rate: 0.00278 
2025-01-26 01:10:22.294638: train_loss -0.8428 
2025-01-26 01:10:22.301023: val_loss -0.8234 
2025-01-26 01:10:22.303928: Pseudo dice [np.float32(0.956), np.float32(0.8994)] 
2025-01-26 01:10:22.306459: Epoch time: 30.88 s 
2025-01-26 01:10:23.394544:  
2025-01-26 01:10:23.397448: Epoch 760 
2025-01-26 01:10:23.400180: Current learning rate: 0.00277 
2025-01-26 01:10:53.149371: train_loss -0.8497 
2025-01-26 01:10:53.152600: val_loss -0.7956 
2025-01-26 01:10:53.155473: Pseudo dice [np.float32(0.9576), np.float32(0.8995)] 
2025-01-26 01:10:53.157794: Epoch time: 29.76 s 
2025-01-26 01:10:54.250427:  
2025-01-26 01:10:54.252910: Epoch 761 
2025-01-26 01:10:54.256160: Current learning rate: 0.00276 
2025-01-26 01:11:23.471852: train_loss -0.8346 
2025-01-26 01:11:23.477522: val_loss -0.7607 
2025-01-26 01:11:23.479938: Pseudo dice [np.float32(0.9629), np.float32(0.9032)] 
2025-01-26 01:11:23.482323: Epoch time: 29.22 s 
2025-01-26 01:11:24.563516:  
2025-01-26 01:11:24.566261: Epoch 762 
2025-01-26 01:11:24.568781: Current learning rate: 0.00275 
2025-01-26 01:11:54.016723: train_loss -0.8402 
2025-01-26 01:11:54.019997: val_loss -0.8084 
2025-01-26 01:11:54.022574: Pseudo dice [np.float32(0.9602), np.float32(0.8622)] 
2025-01-26 01:11:54.025029: Epoch time: 29.45 s 
2025-01-26 01:11:55.525257:  
2025-01-26 01:11:55.528064: Epoch 763 
2025-01-26 01:11:55.530435: Current learning rate: 0.00274 
2025-01-26 01:12:24.472972: train_loss -0.8356 
2025-01-26 01:12:24.478088: val_loss -0.7861 
2025-01-26 01:12:24.480390: Pseudo dice [np.float32(0.9604), np.float32(0.9138)] 
2025-01-26 01:12:24.482774: Epoch time: 28.95 s 
2025-01-26 01:12:25.560389:  
2025-01-26 01:12:25.563378: Epoch 764 
2025-01-26 01:12:25.565962: Current learning rate: 0.00273 
2025-01-26 01:12:55.164154: train_loss -0.8411 
2025-01-26 01:12:55.169210: val_loss -0.7736 
2025-01-26 01:12:55.172678: Pseudo dice [np.float32(0.9622), np.float32(0.9081)] 
2025-01-26 01:12:55.175302: Epoch time: 29.6 s 
2025-01-26 01:12:56.503237:  
2025-01-26 01:12:56.505866: Epoch 765 
2025-01-26 01:12:56.508468: Current learning rate: 0.00272 
2025-01-26 01:13:28.104390: train_loss -0.8317 
2025-01-26 01:13:28.110411: val_loss -0.8168 
2025-01-26 01:13:28.112906: Pseudo dice [np.float32(0.9646), np.float32(0.9258)] 
2025-01-26 01:13:28.115535: Epoch time: 31.6 s 
2025-01-26 01:13:29.204043:  
2025-01-26 01:13:29.206733: Epoch 766 
2025-01-26 01:13:29.209582: Current learning rate: 0.00271 
2025-01-26 01:13:58.464362: train_loss -0.8487 
2025-01-26 01:13:58.467391: val_loss -0.8095 
2025-01-26 01:13:58.469948: Pseudo dice [np.float32(0.9691), np.float32(0.9118)] 
2025-01-26 01:13:58.472327: Epoch time: 29.26 s 
2025-01-26 01:13:59.560878:  
2025-01-26 01:13:59.563575: Epoch 767 
2025-01-26 01:13:59.566061: Current learning rate: 0.0027 
2025-01-26 01:14:29.073971: train_loss -0.8401 
2025-01-26 01:14:29.079968: val_loss -0.7958 
2025-01-26 01:14:29.082466: Pseudo dice [np.float32(0.9615), np.float32(0.9173)] 
2025-01-26 01:14:29.084826: Epoch time: 29.51 s 
2025-01-26 01:14:30.167626:  
2025-01-26 01:14:30.170444: Epoch 768 
2025-01-26 01:14:30.173536: Current learning rate: 0.00268 
2025-01-26 01:15:00.120383: train_loss -0.8325 
2025-01-26 01:15:00.123390: val_loss -0.8358 
2025-01-26 01:15:00.125580: Pseudo dice [np.float32(0.9628), np.float32(0.9016)] 
2025-01-26 01:15:00.127906: Epoch time: 29.95 s 
2025-01-26 01:15:01.208814:  
2025-01-26 01:15:01.211405: Epoch 769 
2025-01-26 01:15:01.213786: Current learning rate: 0.00267 
2025-01-26 01:15:30.488502: train_loss -0.8425 
2025-01-26 01:15:30.493830: val_loss -0.7956 
2025-01-26 01:15:30.496207: Pseudo dice [np.float32(0.9648), np.float32(0.9185)] 
2025-01-26 01:15:30.498380: Epoch time: 29.28 s 
2025-01-26 01:15:31.583460:  
2025-01-26 01:15:31.589745: Epoch 770 
2025-01-26 01:15:31.591931: Current learning rate: 0.00266 
2025-01-26 01:16:00.197517: train_loss -0.8303 
2025-01-26 01:16:00.200624: val_loss -0.7599 
2025-01-26 01:16:00.202994: Pseudo dice [np.float32(0.9605), np.float32(0.9042)] 
2025-01-26 01:16:00.205525: Epoch time: 28.61 s 
2025-01-26 01:16:01.286573:  
2025-01-26 01:16:01.289090: Epoch 771 
2025-01-26 01:16:01.291379: Current learning rate: 0.00265 
2025-01-26 01:16:30.736304: train_loss -0.8436 
2025-01-26 01:16:30.742651: val_loss -0.8153 
2025-01-26 01:16:30.745506: Pseudo dice [np.float32(0.9626), np.float32(0.8939)] 
2025-01-26 01:16:30.748198: Epoch time: 29.45 s 
2025-01-26 01:16:31.830800:  
2025-01-26 01:16:31.833537: Epoch 772 
2025-01-26 01:16:31.836018: Current learning rate: 0.00264 
2025-01-26 01:17:00.386593: train_loss -0.8346 
2025-01-26 01:17:00.389216: val_loss -0.7915 
2025-01-26 01:17:00.391538: Pseudo dice [np.float32(0.9629), np.float32(0.9049)] 
2025-01-26 01:17:00.393951: Epoch time: 28.56 s 
2025-01-26 01:17:01.470347:  
2025-01-26 01:17:01.472961: Epoch 773 
2025-01-26 01:17:01.475209: Current learning rate: 0.00263 
2025-01-26 01:17:31.426128: train_loss -0.8444 
2025-01-26 01:17:31.431383: val_loss -0.7902 
2025-01-26 01:17:31.433982: Pseudo dice [np.float32(0.9656), np.float32(0.9011)] 
2025-01-26 01:17:31.436257: Epoch time: 29.96 s 
2025-01-26 01:17:32.552764:  
2025-01-26 01:17:32.555573: Epoch 774 
2025-01-26 01:17:32.557814: Current learning rate: 0.00262 
2025-01-26 01:18:03.565851: train_loss -0.8296 
2025-01-26 01:18:03.570207: val_loss -0.7714 
2025-01-26 01:18:03.572964: Pseudo dice [np.float32(0.9655), np.float32(0.9095)] 
2025-01-26 01:18:03.575352: Epoch time: 31.01 s 
2025-01-26 01:18:04.731447:  
2025-01-26 01:18:04.733786: Epoch 775 
2025-01-26 01:18:04.736016: Current learning rate: 0.00261 
2025-01-26 01:18:34.131883: train_loss -0.8426 
2025-01-26 01:18:34.136514: val_loss -0.8218 
2025-01-26 01:18:34.138781: Pseudo dice [np.float32(0.9588), np.float32(0.9143)] 
2025-01-26 01:18:34.141238: Epoch time: 29.4 s 
2025-01-26 01:18:35.227399:  
2025-01-26 01:18:35.231473: Epoch 776 
2025-01-26 01:18:35.233811: Current learning rate: 0.0026 
2025-01-26 01:19:04.773517: train_loss -0.8365 
2025-01-26 01:19:04.776531: val_loss -0.7467 
2025-01-26 01:19:04.779194: Pseudo dice [np.float32(0.9615), np.float32(0.9074)] 
2025-01-26 01:19:04.781601: Epoch time: 29.55 s 
2025-01-26 01:19:05.875812:  
2025-01-26 01:19:05.878431: Epoch 777 
2025-01-26 01:19:05.881007: Current learning rate: 0.00259 
2025-01-26 01:19:35.912544: train_loss -0.8475 
2025-01-26 01:19:35.917706: val_loss -0.7937 
2025-01-26 01:19:35.920134: Pseudo dice [np.float32(0.9601), np.float32(0.9097)] 
2025-01-26 01:19:35.922372: Epoch time: 30.04 s 
2025-01-26 01:19:37.009526:  
2025-01-26 01:19:37.011913: Epoch 778 
2025-01-26 01:19:37.015118: Current learning rate: 0.00258 
2025-01-26 01:20:06.323164: train_loss -0.8216 
2025-01-26 01:20:06.327095: val_loss -0.779 
2025-01-26 01:20:06.329621: Pseudo dice [np.float32(0.954), np.float32(0.871)] 
2025-01-26 01:20:06.332143: Epoch time: 29.31 s 
2025-01-26 01:20:07.424167:  
2025-01-26 01:20:07.427243: Epoch 779 
2025-01-26 01:20:07.430260: Current learning rate: 0.00257 
2025-01-26 01:20:36.921068: train_loss -0.8108 
2025-01-26 01:20:36.926775: val_loss -0.8114 
2025-01-26 01:20:36.929396: Pseudo dice [np.float32(0.9618), np.float32(0.9042)] 
2025-01-26 01:20:36.931911: Epoch time: 29.5 s 
2025-01-26 01:20:38.011293:  
2025-01-26 01:20:38.014026: Epoch 780 
2025-01-26 01:20:38.017028: Current learning rate: 0.00256 
2025-01-26 01:21:07.411056: train_loss -0.8404 
2025-01-26 01:21:07.413659: val_loss -0.77 
2025-01-26 01:21:07.416102: Pseudo dice [np.float32(0.961), np.float32(0.8977)] 
2025-01-26 01:21:07.418367: Epoch time: 29.4 s 
2025-01-26 01:21:08.907620:  
2025-01-26 01:21:08.910166: Epoch 781 
2025-01-26 01:21:08.912700: Current learning rate: 0.00255 
2025-01-26 01:21:39.121133: train_loss -0.8332 
2025-01-26 01:21:39.130489: val_loss -0.7911 
2025-01-26 01:21:39.132982: Pseudo dice [np.float32(0.9604), np.float32(0.908)] 
2025-01-26 01:21:39.135478: Epoch time: 30.21 s 
2025-01-26 01:21:40.418170:  
2025-01-26 01:21:40.420738: Epoch 782 
2025-01-26 01:21:40.423795: Current learning rate: 0.00254 
2025-01-26 01:22:09.670154: train_loss -0.8382 
2025-01-26 01:22:09.674532: val_loss -0.8023 
2025-01-26 01:22:09.678639: Pseudo dice [np.float32(0.9596), np.float32(0.9064)] 
2025-01-26 01:22:09.681050: Epoch time: 29.25 s 
2025-01-26 01:22:10.874939:  
2025-01-26 01:22:10.877387: Epoch 783 
2025-01-26 01:22:10.879833: Current learning rate: 0.00253 
2025-01-26 01:22:41.265859: train_loss -0.8454 
2025-01-26 01:22:41.275681: val_loss -0.7903 
2025-01-26 01:22:41.278289: Pseudo dice [np.float32(0.9659), np.float32(0.924)] 
2025-01-26 01:22:41.280579: Epoch time: 30.39 s 
2025-01-26 01:22:42.609423:  
2025-01-26 01:22:42.611857: Epoch 784 
2025-01-26 01:22:42.614327: Current learning rate: 0.00252 
2025-01-26 01:23:11.503515: train_loss -0.8455 
2025-01-26 01:23:11.508033: val_loss -0.7856 
2025-01-26 01:23:11.512675: Pseudo dice [np.float32(0.9605), np.float32(0.9223)] 
2025-01-26 01:23:11.515141: Epoch time: 28.89 s 
2025-01-26 01:23:12.731241:  
2025-01-26 01:23:12.734080: Epoch 785 
2025-01-26 01:23:12.736855: Current learning rate: 0.00251 
2025-01-26 01:23:41.488121: train_loss -0.8545 
2025-01-26 01:23:41.495752: val_loss -0.7825 
2025-01-26 01:23:41.498294: Pseudo dice [np.float32(0.9602), np.float32(0.9102)] 
2025-01-26 01:23:41.500643: Epoch time: 28.76 s 
2025-01-26 01:23:42.801784:  
2025-01-26 01:23:42.804603: Epoch 786 
2025-01-26 01:23:42.807211: Current learning rate: 0.0025 
2025-01-26 01:24:11.341532: train_loss -0.8382 
2025-01-26 01:24:11.344875: val_loss -0.7951 
2025-01-26 01:24:11.347864: Pseudo dice [np.float32(0.9599), np.float32(0.8986)] 
2025-01-26 01:24:11.350667: Epoch time: 28.54 s 
2025-01-26 01:24:12.434938:  
2025-01-26 01:24:12.441576: Epoch 787 
2025-01-26 01:24:12.444221: Current learning rate: 0.00249 
2025-01-26 01:24:41.468697: train_loss -0.8348 
2025-01-26 01:24:41.471536: val_loss -0.8025 
2025-01-26 01:24:41.473836: Pseudo dice [np.float32(0.9622), np.float32(0.9191)] 
2025-01-26 01:24:41.476095: Epoch time: 29.03 s 
2025-01-26 01:24:42.559860:  
2025-01-26 01:24:42.562739: Epoch 788 
2025-01-26 01:24:42.565435: Current learning rate: 0.00248 
2025-01-26 01:25:13.484572: train_loss -0.8416 
2025-01-26 01:25:13.487720: val_loss -0.8071 
2025-01-26 01:25:13.490416: Pseudo dice [np.float32(0.9643), np.float32(0.903)] 
2025-01-26 01:25:13.492528: Epoch time: 30.93 s 
2025-01-26 01:25:14.595629:  
2025-01-26 01:25:14.598382: Epoch 789 
2025-01-26 01:25:14.601010: Current learning rate: 0.00247 
2025-01-26 01:25:44.796329: train_loss -0.8372 
2025-01-26 01:25:44.804969: val_loss -0.7649 
2025-01-26 01:25:44.807405: Pseudo dice [np.float32(0.9622), np.float32(0.9144)] 
2025-01-26 01:25:44.809896: Epoch time: 30.2 s 
2025-01-26 01:25:44.812403: Yayy! New best EMA pseudo Dice: 0.9347000122070312 
2025-01-26 01:25:46.551633:  
2025-01-26 01:25:46.554286: Epoch 790 
2025-01-26 01:25:46.557534: Current learning rate: 0.00245 
2025-01-26 01:26:15.853068: train_loss -0.8458 
2025-01-26 01:26:15.856025: val_loss -0.7914 
2025-01-26 01:26:15.858673: Pseudo dice [np.float32(0.9656), np.float32(0.917)] 
2025-01-26 01:26:15.861225: Epoch time: 29.3 s 
2025-01-26 01:26:15.863550: Yayy! New best EMA pseudo Dice: 0.9354000091552734 
2025-01-26 01:26:17.478753:  
2025-01-26 01:26:17.481627: Epoch 791 
2025-01-26 01:26:17.484138: Current learning rate: 0.00244 
2025-01-26 01:26:46.364155: train_loss -0.8466 
2025-01-26 01:26:46.369738: val_loss -0.7813 
2025-01-26 01:26:46.372288: Pseudo dice [np.float32(0.9644), np.float32(0.9068)] 
2025-01-26 01:26:46.374718: Epoch time: 28.89 s 
2025-01-26 01:26:46.377194: Yayy! New best EMA pseudo Dice: 0.9354000091552734 
2025-01-26 01:26:47.874964:  
2025-01-26 01:26:47.877338: Epoch 792 
2025-01-26 01:26:47.880071: Current learning rate: 0.00243 
2025-01-26 01:27:18.115582: train_loss -0.8522 
2025-01-26 01:27:18.120609: val_loss -0.7993 
2025-01-26 01:27:18.125224: Pseudo dice [np.float32(0.9618), np.float32(0.9108)] 
2025-01-26 01:27:18.127856: Epoch time: 30.24 s 
2025-01-26 01:27:18.130451: Yayy! New best EMA pseudo Dice: 0.9355000257492065 
2025-01-26 01:27:19.804225:  
2025-01-26 01:27:19.806658: Epoch 793 
2025-01-26 01:27:19.809578: Current learning rate: 0.00242 
2025-01-26 01:27:48.570233: train_loss -0.8448 
2025-01-26 01:27:48.576585: val_loss -0.8138 
2025-01-26 01:27:48.578988: Pseudo dice [np.float32(0.962), np.float32(0.8617)] 
2025-01-26 01:27:48.581203: Epoch time: 28.77 s 
2025-01-26 01:27:49.684848:  
2025-01-26 01:27:49.687570: Epoch 794 
2025-01-26 01:27:49.690382: Current learning rate: 0.00241 
2025-01-26 01:28:18.782421: train_loss -0.8467 
2025-01-26 01:28:18.785352: val_loss -0.7887 
2025-01-26 01:28:18.787709: Pseudo dice [np.float32(0.9636), np.float32(0.9196)] 
2025-01-26 01:28:18.790140: Epoch time: 29.1 s 
2025-01-26 01:28:19.880096:  
2025-01-26 01:28:19.882527: Epoch 795 
2025-01-26 01:28:19.885204: Current learning rate: 0.0024 
2025-01-26 01:28:49.296913: train_loss -0.8629 
2025-01-26 01:28:49.302216: val_loss -0.8078 
2025-01-26 01:28:49.304660: Pseudo dice [np.float32(0.9646), np.float32(0.9151)] 
2025-01-26 01:28:49.307105: Epoch time: 29.42 s 
2025-01-26 01:28:50.386715:  
2025-01-26 01:28:50.389487: Epoch 796 
2025-01-26 01:28:50.391656: Current learning rate: 0.00239 
2025-01-26 01:29:19.662377: train_loss -0.8418 
2025-01-26 01:29:19.665317: val_loss -0.7973 
2025-01-26 01:29:19.668035: Pseudo dice [np.float32(0.97), np.float32(0.9316)] 
2025-01-26 01:29:19.670758: Epoch time: 29.28 s 
2025-01-26 01:29:19.673003: Yayy! New best EMA pseudo Dice: 0.9362000226974487 
2025-01-26 01:29:21.672707:  
2025-01-26 01:29:21.675318: Epoch 797 
2025-01-26 01:29:21.678635: Current learning rate: 0.00238 
2025-01-26 01:29:50.148033: train_loss -0.8436 
2025-01-26 01:29:50.153224: val_loss -0.7909 
2025-01-26 01:29:50.155756: Pseudo dice [np.float32(0.9592), np.float32(0.9162)] 
2025-01-26 01:29:50.160870: Epoch time: 28.48 s 
2025-01-26 01:29:50.164594: Yayy! New best EMA pseudo Dice: 0.9362999796867371 
2025-01-26 01:29:51.809674:  
2025-01-26 01:29:51.812619: Epoch 798 
2025-01-26 01:29:51.815350: Current learning rate: 0.00237 
2025-01-26 01:30:21.207412: train_loss -0.8392 
2025-01-26 01:30:21.210297: val_loss -0.7958 
2025-01-26 01:30:21.212624: Pseudo dice [np.float32(0.9632), np.float32(0.9132)] 
2025-01-26 01:30:21.215012: Epoch time: 29.4 s 
2025-01-26 01:30:21.217360: Yayy! New best EMA pseudo Dice: 0.9365000128746033 
2025-01-26 01:30:22.843277:  
2025-01-26 01:30:22.846069: Epoch 799 
2025-01-26 01:30:22.849303: Current learning rate: 0.00236 
2025-01-26 01:30:51.248142: train_loss -0.8379 
2025-01-26 01:30:51.253180: val_loss -0.8207 
2025-01-26 01:30:51.255503: Pseudo dice [np.float32(0.9653), np.float32(0.9169)] 
2025-01-26 01:30:51.257918: Epoch time: 28.41 s 
2025-01-26 01:30:51.782886: Yayy! New best EMA pseudo Dice: 0.9369999766349792 
2025-01-26 01:30:53.418725:  
2025-01-26 01:30:53.424461: Epoch 800 
2025-01-26 01:30:53.427474: Current learning rate: 0.00235 
2025-01-26 01:31:23.426817: train_loss -0.8398 
2025-01-26 01:31:23.429712: val_loss -0.7946 
2025-01-26 01:31:23.432203: Pseudo dice [np.float32(0.9662), np.float32(0.9159)] 
2025-01-26 01:31:23.434680: Epoch time: 30.01 s 
2025-01-26 01:31:23.437205: Yayy! New best EMA pseudo Dice: 0.9373999834060669 
2025-01-26 01:31:25.019959:  
2025-01-26 01:31:25.023747: Epoch 801 
2025-01-26 01:31:25.026848: Current learning rate: 0.00234 
2025-01-26 01:31:54.749591: train_loss -0.8303 
2025-01-26 01:31:54.755622: val_loss -0.8172 
2025-01-26 01:31:54.758418: Pseudo dice [np.float32(0.9653), np.float32(0.9194)] 
2025-01-26 01:31:54.761309: Epoch time: 29.73 s 
2025-01-26 01:31:54.763795: Yayy! New best EMA pseudo Dice: 0.9379000067710876 
2025-01-26 01:31:56.368036:  
2025-01-26 01:31:56.370437: Epoch 802 
2025-01-26 01:31:56.373263: Current learning rate: 0.00233 
2025-01-26 01:32:27.927832: train_loss -0.8535 
2025-01-26 01:32:27.930656: val_loss -0.7926 
2025-01-26 01:32:27.932950: Pseudo dice [np.float32(0.9623), np.float32(0.9152)] 
2025-01-26 01:32:27.935165: Epoch time: 31.56 s 
2025-01-26 01:32:27.938210: Yayy! New best EMA pseudo Dice: 0.9380000233650208 
2025-01-26 01:32:29.501707:  
2025-01-26 01:32:29.504246: Epoch 803 
2025-01-26 01:32:29.507478: Current learning rate: 0.00232 
2025-01-26 01:32:59.323737: train_loss -0.8309 
2025-01-26 01:32:59.328752: val_loss -0.8016 
2025-01-26 01:32:59.331083: Pseudo dice [np.float32(0.9649), np.float32(0.9173)] 
2025-01-26 01:32:59.333216: Epoch time: 29.82 s 
2025-01-26 01:32:59.335367: Yayy! New best EMA pseudo Dice: 0.9383000135421753 
2025-01-26 01:33:00.916788:  
2025-01-26 01:33:00.919150: Epoch 804 
2025-01-26 01:33:00.923255: Current learning rate: 0.00231 
2025-01-26 01:33:30.920956: train_loss -0.8527 
2025-01-26 01:33:30.923898: val_loss -0.8012 
2025-01-26 01:33:30.926288: Pseudo dice [np.float32(0.9639), np.float32(0.9226)] 
2025-01-26 01:33:30.928920: Epoch time: 30.0 s 
2025-01-26 01:33:30.931204: Yayy! New best EMA pseudo Dice: 0.9387999773025513 
2025-01-26 01:33:32.537979:  
2025-01-26 01:33:32.540443: Epoch 805 
2025-01-26 01:33:32.543256: Current learning rate: 0.0023 
2025-01-26 01:34:01.692965: train_loss -0.8413 
2025-01-26 01:34:01.697664: val_loss -0.8135 
2025-01-26 01:34:01.699771: Pseudo dice [np.float32(0.9603), np.float32(0.915)] 
2025-01-26 01:34:01.701787: Epoch time: 29.16 s 
2025-01-26 01:34:02.789676:  
2025-01-26 01:34:02.792211: Epoch 806 
2025-01-26 01:34:02.794714: Current learning rate: 0.00229 
2025-01-26 01:34:31.848111: train_loss -0.843 
2025-01-26 01:34:31.850976: val_loss -0.8044 
2025-01-26 01:34:31.854858: Pseudo dice [np.float32(0.9599), np.float32(0.9119)] 
2025-01-26 01:34:31.857138: Epoch time: 29.06 s 
2025-01-26 01:34:32.976849:  
2025-01-26 01:34:32.979723: Epoch 807 
2025-01-26 01:34:32.982277: Current learning rate: 0.00228 
2025-01-26 01:35:01.652877: train_loss -0.8442 
2025-01-26 01:35:01.655561: val_loss -0.7923 
2025-01-26 01:35:01.657882: Pseudo dice [np.float32(0.9634), np.float32(0.9067)] 
2025-01-26 01:35:01.660043: Epoch time: 28.68 s 
2025-01-26 01:35:02.749876:  
2025-01-26 01:35:02.752759: Epoch 808 
2025-01-26 01:35:02.755326: Current learning rate: 0.00226 
2025-01-26 01:35:32.501197: train_loss -0.8442 
2025-01-26 01:35:32.504357: val_loss -0.8059 
2025-01-26 01:35:32.507134: Pseudo dice [np.float32(0.9653), np.float32(0.9258)] 
2025-01-26 01:35:32.509902: Epoch time: 29.75 s 
2025-01-26 01:35:32.512686: Yayy! New best EMA pseudo Dice: 0.9387999773025513 
2025-01-26 01:35:34.257354:  
2025-01-26 01:35:34.259904: Epoch 809 
2025-01-26 01:35:34.262473: Current learning rate: 0.00225 
2025-01-26 01:36:03.440982: train_loss -0.841 
2025-01-26 01:36:03.446462: val_loss -0.7868 
2025-01-26 01:36:03.449205: Pseudo dice [np.float32(0.9601), np.float32(0.8996)] 
2025-01-26 01:36:03.451487: Epoch time: 29.18 s 
2025-01-26 01:36:04.556812:  
2025-01-26 01:36:04.559231: Epoch 810 
2025-01-26 01:36:04.561603: Current learning rate: 0.00224 
2025-01-26 01:36:33.046243: train_loss -0.8527 
2025-01-26 01:36:33.049073: val_loss -0.7982 
2025-01-26 01:36:33.051338: Pseudo dice [np.float32(0.9636), np.float32(0.9162)] 
2025-01-26 01:36:33.053770: Epoch time: 28.49 s 
2025-01-26 01:36:34.135672:  
2025-01-26 01:36:34.141912: Epoch 811 
2025-01-26 01:36:34.144492: Current learning rate: 0.00223 
2025-01-26 01:37:04.730008: train_loss -0.8416 
2025-01-26 01:37:04.735536: val_loss -0.83 
2025-01-26 01:37:04.737824: Pseudo dice [np.float32(0.9663), np.float32(0.9205)] 
2025-01-26 01:37:04.740182: Epoch time: 30.6 s 
2025-01-26 01:37:05.838160:  
2025-01-26 01:37:05.841278: Epoch 812 
2025-01-26 01:37:05.843928: Current learning rate: 0.00222 
2025-01-26 01:37:34.952488: train_loss -0.852 
2025-01-26 01:37:34.956161: val_loss -0.8101 
2025-01-26 01:37:34.958961: Pseudo dice [np.float32(0.9602), np.float32(0.9171)] 
2025-01-26 01:37:34.961650: Epoch time: 29.12 s 
2025-01-26 01:37:36.457174:  
2025-01-26 01:37:36.463696: Epoch 813 
2025-01-26 01:37:36.466014: Current learning rate: 0.00221 
2025-01-26 01:38:06.478408: train_loss -0.8455 
2025-01-26 01:38:06.483618: val_loss -0.7975 
2025-01-26 01:38:06.485886: Pseudo dice [np.float32(0.962), np.float32(0.9089)] 
2025-01-26 01:38:06.488397: Epoch time: 30.02 s 
2025-01-26 01:38:07.588780:  
2025-01-26 01:38:07.591387: Epoch 814 
2025-01-26 01:38:07.594184: Current learning rate: 0.0022 
2025-01-26 01:38:36.386476: train_loss -0.8537 
2025-01-26 01:38:36.389213: val_loss -0.8188 
2025-01-26 01:38:36.391673: Pseudo dice [np.float32(0.9648), np.float32(0.9319)] 
2025-01-26 01:38:36.394012: Epoch time: 28.8 s 
2025-01-26 01:38:36.396635: Yayy! New best EMA pseudo Dice: 0.939300000667572 
2025-01-26 01:38:38.012036:  
2025-01-26 01:38:38.014576: Epoch 815 
2025-01-26 01:38:38.017354: Current learning rate: 0.00219 
2025-01-26 01:39:08.182375: train_loss -0.8499 
2025-01-26 01:39:08.187948: val_loss -0.812 
2025-01-26 01:39:08.190432: Pseudo dice [np.float32(0.9608), np.float32(0.9252)] 
2025-01-26 01:39:08.192864: Epoch time: 30.17 s 
2025-01-26 01:39:08.195353: Yayy! New best EMA pseudo Dice: 0.9397000074386597 
2025-01-26 01:39:09.764466:  
2025-01-26 01:39:09.767271: Epoch 816 
2025-01-26 01:39:09.770450: Current learning rate: 0.00218 
2025-01-26 01:39:38.350459: train_loss -0.843 
2025-01-26 01:39:38.352998: val_loss -0.7574 
2025-01-26 01:39:38.355346: Pseudo dice [np.float32(0.9665), np.float32(0.9233)] 
2025-01-26 01:39:38.357630: Epoch time: 28.59 s 
2025-01-26 01:39:38.359795: Yayy! New best EMA pseudo Dice: 0.9401999711990356 
2025-01-26 01:39:39.955536:  
2025-01-26 01:39:39.958060: Epoch 817 
2025-01-26 01:39:39.961866: Current learning rate: 0.00217 
2025-01-26 01:40:09.318049: train_loss -0.8407 
2025-01-26 01:40:09.323550: val_loss -0.8235 
2025-01-26 01:40:09.326065: Pseudo dice [np.float32(0.9618), np.float32(0.9209)] 
2025-01-26 01:40:09.328260: Epoch time: 29.36 s 
2025-01-26 01:40:09.330339: Yayy! New best EMA pseudo Dice: 0.9402999877929688 
2025-01-26 01:40:10.999188:  
2025-01-26 01:40:11.001662: Epoch 818 
2025-01-26 01:40:11.005131: Current learning rate: 0.00216 
2025-01-26 01:40:40.093083: train_loss -0.8555 
2025-01-26 01:40:40.096241: val_loss -0.7852 
2025-01-26 01:40:40.099053: Pseudo dice [np.float32(0.9643), np.float32(0.9248)] 
2025-01-26 01:40:40.101541: Epoch time: 29.09 s 
2025-01-26 01:40:40.104171: Yayy! New best EMA pseudo Dice: 0.9406999945640564 
2025-01-26 01:40:41.774962:  
2025-01-26 01:40:41.777270: Epoch 819 
2025-01-26 01:40:41.780120: Current learning rate: 0.00215 
2025-01-26 01:41:11.881072: train_loss -0.8507 
2025-01-26 01:41:11.887088: val_loss -0.7919 
2025-01-26 01:41:11.889682: Pseudo dice [np.float32(0.9592), np.float32(0.8317)] 
2025-01-26 01:41:11.892145: Epoch time: 30.11 s 
2025-01-26 01:41:12.938826:  
2025-01-26 01:41:12.941631: Epoch 820 
2025-01-26 01:41:12.944286: Current learning rate: 0.00214 
2025-01-26 01:41:42.167887: train_loss -0.8427 
2025-01-26 01:41:42.172715: val_loss -0.8436 
2025-01-26 01:41:42.175368: Pseudo dice [np.float32(0.9632), np.float32(0.9176)] 
2025-01-26 01:41:42.177714: Epoch time: 29.23 s 
2025-01-26 01:41:43.428743:  
2025-01-26 01:41:43.431473: Epoch 821 
2025-01-26 01:41:43.433907: Current learning rate: 0.00213 
2025-01-26 01:42:14.294504: train_loss -0.8421 
2025-01-26 01:42:14.300178: val_loss -0.7824 
2025-01-26 01:42:14.302512: Pseudo dice [np.float32(0.9601), np.float32(0.9155)] 
2025-01-26 01:42:14.304907: Epoch time: 30.87 s 
2025-01-26 01:42:15.387718:  
2025-01-26 01:42:15.390306: Epoch 822 
2025-01-26 01:42:15.393452: Current learning rate: 0.00212 
2025-01-26 01:42:45.037057: train_loss -0.8388 
2025-01-26 01:42:45.040522: val_loss -0.8275 
2025-01-26 01:42:45.043290: Pseudo dice [np.float32(0.9599), np.float32(0.9235)] 
2025-01-26 01:42:45.045970: Epoch time: 29.65 s 
2025-01-26 01:42:46.079458:  
2025-01-26 01:42:46.082083: Epoch 823 
2025-01-26 01:42:46.084562: Current learning rate: 0.0021 
2025-01-26 01:43:16.903678: train_loss -0.8349 
2025-01-26 01:43:16.908923: val_loss -0.7895 
2025-01-26 01:43:16.911353: Pseudo dice [np.float32(0.9606), np.float32(0.9169)] 
2025-01-26 01:43:16.913788: Epoch time: 30.83 s 
2025-01-26 01:43:17.950840:  
2025-01-26 01:43:17.953443: Epoch 824 
2025-01-26 01:43:17.956391: Current learning rate: 0.00209 
2025-01-26 01:43:49.116325: train_loss -0.8485 
2025-01-26 01:43:49.119578: val_loss -0.7851 
2025-01-26 01:43:49.122195: Pseudo dice [np.float32(0.9596), np.float32(0.8963)] 
2025-01-26 01:43:49.124850: Epoch time: 31.17 s 
2025-01-26 01:43:50.156643:  
2025-01-26 01:43:50.158911: Epoch 825 
2025-01-26 01:43:50.161185: Current learning rate: 0.00208 
2025-01-26 01:44:18.823271: train_loss -0.8364 
2025-01-26 01:44:18.828430: val_loss -0.8125 
2025-01-26 01:44:18.830794: Pseudo dice [np.float32(0.9612), np.float32(0.9033)] 
2025-01-26 01:44:18.833172: Epoch time: 28.67 s 
2025-01-26 01:44:19.857292:  
2025-01-26 01:44:19.863439: Epoch 826 
2025-01-26 01:44:19.866033: Current learning rate: 0.00207 
2025-01-26 01:44:49.737371: train_loss -0.8609 
2025-01-26 01:44:49.740284: val_loss -0.8154 
2025-01-26 01:44:49.742708: Pseudo dice [np.float32(0.9605), np.float32(0.9167)] 
2025-01-26 01:44:49.745113: Epoch time: 29.88 s 
2025-01-26 01:44:50.819056:  
2025-01-26 01:44:50.821681: Epoch 827 
2025-01-26 01:44:50.823860: Current learning rate: 0.00206 
2025-01-26 01:45:20.466125: train_loss -0.8367 
2025-01-26 01:45:20.471146: val_loss -0.7771 
2025-01-26 01:45:20.473398: Pseudo dice [np.float32(0.967), np.float32(0.8987)] 
2025-01-26 01:45:20.475622: Epoch time: 29.65 s 
2025-01-26 01:45:21.510821:  
2025-01-26 01:45:21.517241: Epoch 828 
2025-01-26 01:45:21.519465: Current learning rate: 0.00205 
2025-01-26 01:45:52.106745: train_loss -0.8382 
2025-01-26 01:45:52.111058: val_loss -0.7997 
2025-01-26 01:45:52.114869: Pseudo dice [np.float32(0.9587), np.float32(0.9079)] 
2025-01-26 01:45:52.117260: Epoch time: 30.6 s 
2025-01-26 01:45:53.179375:  
2025-01-26 01:45:53.181793: Epoch 829 
2025-01-26 01:45:53.184461: Current learning rate: 0.00204 
2025-01-26 01:46:21.663574: train_loss -0.8407 
2025-01-26 01:46:21.669816: val_loss -0.7944 
2025-01-26 01:46:21.672861: Pseudo dice [np.float32(0.9651), np.float32(0.9096)] 
2025-01-26 01:46:21.676371: Epoch time: 28.49 s 
2025-01-26 01:46:22.705722:  
2025-01-26 01:46:22.712289: Epoch 830 
2025-01-26 01:46:22.714904: Current learning rate: 0.00203 
2025-01-26 01:46:53.340124: train_loss -0.8516 
2025-01-26 01:46:53.343040: val_loss -0.8525 
2025-01-26 01:46:53.345693: Pseudo dice [np.float32(0.9602), np.float32(0.9069)] 
2025-01-26 01:46:53.348187: Epoch time: 30.64 s 
2025-01-26 01:46:54.396498:  
2025-01-26 01:46:54.398823: Epoch 831 
2025-01-26 01:46:54.400957: Current learning rate: 0.00202 
2025-01-26 01:47:25.074931: train_loss -0.8415 
2025-01-26 01:47:25.084719: val_loss -0.8077 
2025-01-26 01:47:25.087375: Pseudo dice [np.float32(0.9597), np.float32(0.9311)] 
2025-01-26 01:47:25.089835: Epoch time: 30.68 s 
2025-01-26 01:47:26.166803:  
2025-01-26 01:47:26.173331: Epoch 832 
2025-01-26 01:47:26.175584: Current learning rate: 0.00201 
2025-01-26 01:47:56.199934: train_loss -0.8305 
2025-01-26 01:47:56.203061: val_loss -0.7816 
2025-01-26 01:47:56.205638: Pseudo dice [np.float32(0.9553), np.float32(0.9052)] 
2025-01-26 01:47:56.208346: Epoch time: 30.03 s 
2025-01-26 01:47:57.248182:  
2025-01-26 01:47:57.250670: Epoch 833 
2025-01-26 01:47:57.253372: Current learning rate: 0.002 
2025-01-26 01:48:26.855725: train_loss -0.838 
2025-01-26 01:48:26.865483: val_loss -0.8631 
2025-01-26 01:48:26.868027: Pseudo dice [np.float32(0.9655), np.float32(0.9123)] 
2025-01-26 01:48:26.870254: Epoch time: 29.61 s 
2025-01-26 01:48:28.001702:  
2025-01-26 01:48:28.005158: Epoch 834 
2025-01-26 01:48:28.007709: Current learning rate: 0.00199 
2025-01-26 01:48:56.929350: train_loss -0.8422 
2025-01-26 01:48:56.932639: val_loss -0.7862 
2025-01-26 01:48:56.935523: Pseudo dice [np.float32(0.9617), np.float32(0.8452)] 
2025-01-26 01:48:56.938117: Epoch time: 28.93 s 
2025-01-26 01:48:57.965699:  
2025-01-26 01:48:57.968335: Epoch 835 
2025-01-26 01:48:57.970751: Current learning rate: 0.00198 
2025-01-26 01:49:27.637456: train_loss -0.8336 
2025-01-26 01:49:27.644636: val_loss -0.7969 
2025-01-26 01:49:27.647185: Pseudo dice [np.float32(0.9533), np.float32(0.8958)] 
2025-01-26 01:49:27.649672: Epoch time: 29.67 s 
2025-01-26 01:49:28.741169:  
2025-01-26 01:49:28.744705: Epoch 836 
2025-01-26 01:49:28.748929: Current learning rate: 0.00196 
2025-01-26 01:49:57.589641: train_loss -0.839 
2025-01-26 01:49:57.592413: val_loss -0.8153 
2025-01-26 01:49:57.594691: Pseudo dice [np.float32(0.9604), np.float32(0.8982)] 
2025-01-26 01:49:57.596957: Epoch time: 28.85 s 
2025-01-26 01:49:58.642990:  
2025-01-26 01:49:58.645400: Epoch 837 
2025-01-26 01:49:58.647654: Current learning rate: 0.00195 
2025-01-26 01:50:29.011048: train_loss -0.8332 
2025-01-26 01:50:29.016722: val_loss -0.7774 
2025-01-26 01:50:29.019482: Pseudo dice [np.float32(0.9587), np.float32(0.9111)] 
2025-01-26 01:50:29.022148: Epoch time: 30.37 s 
2025-01-26 01:50:30.063195:  
2025-01-26 01:50:30.065543: Epoch 838 
2025-01-26 01:50:30.069304: Current learning rate: 0.00194 
2025-01-26 01:50:58.624629: train_loss -0.8492 
2025-01-26 01:50:58.629171: val_loss -0.7936 
2025-01-26 01:50:58.631788: Pseudo dice [np.float32(0.9634), np.float32(0.922)] 
2025-01-26 01:50:58.634278: Epoch time: 28.56 s 
2025-01-26 01:50:59.916315:  
2025-01-26 01:50:59.918805: Epoch 839 
2025-01-26 01:50:59.921618: Current learning rate: 0.00193 
2025-01-26 01:51:29.543866: train_loss -0.8538 
2025-01-26 01:51:29.549457: val_loss -0.8178 
2025-01-26 01:51:29.552031: Pseudo dice [np.float32(0.9651), np.float32(0.9126)] 
2025-01-26 01:51:29.554289: Epoch time: 29.63 s 
2025-01-26 01:51:30.583228:  
2025-01-26 01:51:30.586432: Epoch 840 
2025-01-26 01:51:30.589014: Current learning rate: 0.00192 
2025-01-26 01:51:59.965196: train_loss -0.849 
2025-01-26 01:51:59.968740: val_loss -0.8107 
2025-01-26 01:51:59.971333: Pseudo dice [np.float32(0.9632), np.float32(0.9205)] 
2025-01-26 01:51:59.973938: Epoch time: 29.38 s 
2025-01-26 01:52:01.010376:  
2025-01-26 01:52:01.013443: Epoch 841 
2025-01-26 01:52:01.016059: Current learning rate: 0.00191 
2025-01-26 01:52:29.605044: train_loss -0.8513 
2025-01-26 01:52:29.610970: val_loss -0.8358 
2025-01-26 01:52:29.613363: Pseudo dice [np.float32(0.9645), np.float32(0.9201)] 
2025-01-26 01:52:29.615558: Epoch time: 28.6 s 
2025-01-26 01:52:30.648398:  
2025-01-26 01:52:30.651325: Epoch 842 
2025-01-26 01:52:30.654140: Current learning rate: 0.0019 
2025-01-26 01:53:00.811821: train_loss -0.8479 
2025-01-26 01:53:00.814646: val_loss -0.798 
2025-01-26 01:53:00.817151: Pseudo dice [np.float32(0.964), np.float32(0.9111)] 
2025-01-26 01:53:00.819465: Epoch time: 30.16 s 
2025-01-26 01:53:01.888744:  
2025-01-26 01:53:01.891424: Epoch 843 
2025-01-26 01:53:01.894309: Current learning rate: 0.00189 
2025-01-26 01:53:31.738766: train_loss -0.8542 
2025-01-26 01:53:31.744676: val_loss -0.7804 
2025-01-26 01:53:31.747254: Pseudo dice [np.float32(0.961), np.float32(0.9207)] 
2025-01-26 01:53:31.749959: Epoch time: 29.85 s 
2025-01-26 01:53:32.787874:  
2025-01-26 01:53:32.790758: Epoch 844 
2025-01-26 01:53:32.793242: Current learning rate: 0.00188 
2025-01-26 01:54:01.846663: train_loss -0.835 
2025-01-26 01:54:01.849476: val_loss -0.8095 
2025-01-26 01:54:01.851713: Pseudo dice [np.float32(0.9624), np.float32(0.9268)] 
2025-01-26 01:54:01.854027: Epoch time: 29.06 s 
2025-01-26 01:54:02.892323:  
2025-01-26 01:54:02.898822: Epoch 845 
2025-01-26 01:54:02.901113: Current learning rate: 0.00187 
2025-01-26 01:54:32.283174: train_loss -0.8466 
2025-01-26 01:54:32.288291: val_loss -0.8079 
2025-01-26 01:54:32.290560: Pseudo dice [np.float32(0.9686), np.float32(0.9192)] 
2025-01-26 01:54:32.292866: Epoch time: 29.39 s 
2025-01-26 01:54:33.335104:  
2025-01-26 01:54:33.337848: Epoch 846 
2025-01-26 01:54:33.340405: Current learning rate: 0.00186 
2025-01-26 01:55:04.720494: train_loss -0.8575 
2025-01-26 01:55:04.723512: val_loss -0.807 
2025-01-26 01:55:04.726249: Pseudo dice [np.float32(0.9638), np.float32(0.9223)] 
2025-01-26 01:55:04.728771: Epoch time: 31.39 s 
2025-01-26 01:55:05.765411:  
2025-01-26 01:55:05.768074: Epoch 847 
2025-01-26 01:55:05.770694: Current learning rate: 0.00185 
2025-01-26 01:55:37.085720: train_loss -0.8372 
2025-01-26 01:55:37.090512: val_loss -0.8014 
2025-01-26 01:55:37.092726: Pseudo dice [np.float32(0.9617), np.float32(0.8978)] 
2025-01-26 01:55:37.095317: Epoch time: 31.32 s 
2025-01-26 01:55:38.128902:  
2025-01-26 01:55:38.131512: Epoch 848 
2025-01-26 01:55:38.134030: Current learning rate: 0.00184 
2025-01-26 01:56:07.301470: train_loss -0.8374 
2025-01-26 01:56:07.304644: val_loss -0.7925 
2025-01-26 01:56:07.307265: Pseudo dice [np.float32(0.9632), np.float32(0.9166)] 
2025-01-26 01:56:07.309534: Epoch time: 29.17 s 
2025-01-26 01:56:08.876691:  
2025-01-26 01:56:08.882922: Epoch 849 
2025-01-26 01:56:08.885220: Current learning rate: 0.00182 
2025-01-26 01:56:38.217540: train_loss -0.8436 
2025-01-26 01:56:38.225735: val_loss -0.8238 
2025-01-26 01:56:38.228454: Pseudo dice [np.float32(0.9612), np.float32(0.9203)] 
2025-01-26 01:56:38.231074: Epoch time: 29.34 s 
2025-01-26 01:56:40.162904:  
2025-01-26 01:56:40.169071: Epoch 850 
2025-01-26 01:56:40.171385: Current learning rate: 0.00181 
2025-01-26 01:57:10.308988: train_loss -0.8342 
2025-01-26 01:57:10.311876: val_loss -0.827 
2025-01-26 01:57:10.314109: Pseudo dice [np.float32(0.9611), np.float32(0.9138)] 
2025-01-26 01:57:10.316422: Epoch time: 30.15 s 
2025-01-26 01:57:11.334424:  
2025-01-26 01:57:11.340491: Epoch 851 
2025-01-26 01:57:11.342859: Current learning rate: 0.0018 
2025-01-26 01:57:42.268786: train_loss -0.8496 
2025-01-26 01:57:42.279299: val_loss -0.7987 
2025-01-26 01:57:42.281902: Pseudo dice [np.float32(0.9671), np.float32(0.9211)] 
2025-01-26 01:57:42.285144: Epoch time: 30.94 s 
2025-01-26 01:57:43.359328:  
2025-01-26 01:57:43.361976: Epoch 852 
2025-01-26 01:57:43.364460: Current learning rate: 0.00179 
2025-01-26 01:58:12.920698: train_loss -0.8391 
2025-01-26 01:58:12.925027: val_loss -0.8019 
2025-01-26 01:58:12.927722: Pseudo dice [np.float32(0.9618), np.float32(0.8991)] 
2025-01-26 01:58:12.930278: Epoch time: 29.56 s 
2025-01-26 01:58:14.228690:  
2025-01-26 01:58:14.231051: Epoch 853 
2025-01-26 01:58:14.233961: Current learning rate: 0.00178 
2025-01-26 01:58:43.069638: train_loss -0.8679 
2025-01-26 01:58:43.077070: val_loss -0.8254 
2025-01-26 01:58:43.079636: Pseudo dice [np.float32(0.961), np.float32(0.9208)] 
2025-01-26 01:58:43.082079: Epoch time: 28.84 s 
2025-01-26 01:58:44.176297:  
2025-01-26 01:58:44.178758: Epoch 854 
2025-01-26 01:58:44.181280: Current learning rate: 0.00177 
2025-01-26 01:59:13.257646: train_loss -0.8353 
2025-01-26 01:59:13.261159: val_loss -0.7887 
2025-01-26 01:59:13.263857: Pseudo dice [np.float32(0.9608), np.float32(0.9166)] 
2025-01-26 01:59:13.266491: Epoch time: 29.08 s 
2025-01-26 01:59:14.286975:  
2025-01-26 01:59:14.289829: Epoch 855 
2025-01-26 01:59:14.292565: Current learning rate: 0.00176 
2025-01-26 01:59:44.976798: train_loss -0.8455 
2025-01-26 01:59:44.981562: val_loss -0.7838 
2025-01-26 01:59:44.983892: Pseudo dice [np.float32(0.9627), np.float32(0.916)] 
2025-01-26 01:59:44.986148: Epoch time: 30.69 s 
2025-01-26 01:59:46.018023:  
2025-01-26 01:59:46.020672: Epoch 856 
2025-01-26 01:59:46.023824: Current learning rate: 0.00175 
2025-01-26 02:00:14.393124: train_loss -0.8415 
2025-01-26 02:00:14.395848: val_loss -0.7621 
2025-01-26 02:00:14.398300: Pseudo dice [np.float32(0.9624), np.float32(0.9002)] 
2025-01-26 02:00:14.400738: Epoch time: 28.38 s 
2025-01-26 02:00:15.418231:  
2025-01-26 02:00:15.420915: Epoch 857 
2025-01-26 02:00:15.424185: Current learning rate: 0.00174 
2025-01-26 02:00:45.139113: train_loss -0.8335 
2025-01-26 02:00:45.144545: val_loss -0.7965 
2025-01-26 02:00:45.147183: Pseudo dice [np.float32(0.9653), np.float32(0.9088)] 
2025-01-26 02:00:45.149729: Epoch time: 29.72 s 
2025-01-26 02:00:46.171880:  
2025-01-26 02:00:46.174627: Epoch 858 
2025-01-26 02:00:46.177030: Current learning rate: 0.00173 
2025-01-26 02:01:14.782241: train_loss -0.8699 
2025-01-26 02:01:14.785004: val_loss -0.7845 
2025-01-26 02:01:14.787270: Pseudo dice [np.float32(0.9655), np.float32(0.9166)] 
2025-01-26 02:01:14.789648: Epoch time: 28.61 s 
2025-01-26 02:01:15.814884:  
2025-01-26 02:01:15.817504: Epoch 859 
2025-01-26 02:01:15.820724: Current learning rate: 0.00172 
2025-01-26 02:01:45.098507: train_loss -0.8479 
2025-01-26 02:01:45.101685: val_loss -0.7933 
2025-01-26 02:01:45.104661: Pseudo dice [np.float32(0.9614), np.float32(0.9265)] 
2025-01-26 02:01:45.107346: Epoch time: 29.28 s 
2025-01-26 02:01:46.152230:  
2025-01-26 02:01:46.154902: Epoch 860 
2025-01-26 02:01:46.157200: Current learning rate: 0.0017 
2025-01-26 02:02:15.145740: train_loss -0.8234 
2025-01-26 02:02:15.148624: val_loss -0.7754 
2025-01-26 02:02:15.150977: Pseudo dice [np.float32(0.9542), np.float32(0.8681)] 
2025-01-26 02:02:15.153418: Epoch time: 28.99 s 
2025-01-26 02:02:16.170790:  
2025-01-26 02:02:16.176761: Epoch 861 
2025-01-26 02:02:16.179365: Current learning rate: 0.00169 
2025-01-26 02:02:45.300863: train_loss -0.8444 
2025-01-26 02:02:45.304799: val_loss -0.7798 
2025-01-26 02:02:45.307245: Pseudo dice [np.float32(0.959), np.float32(0.9191)] 
2025-01-26 02:02:45.309510: Epoch time: 29.13 s 
2025-01-26 02:02:46.334325:  
2025-01-26 02:02:46.336656: Epoch 862 
2025-01-26 02:02:46.338867: Current learning rate: 0.00168 
2025-01-26 02:03:16.220709: train_loss -0.8592 
2025-01-26 02:03:16.225045: val_loss -0.784 
2025-01-26 02:03:16.227407: Pseudo dice [np.float32(0.9619), np.float32(0.9066)] 
2025-01-26 02:03:16.229856: Epoch time: 29.89 s 
2025-01-26 02:03:17.633089:  
2025-01-26 02:03:17.635547: Epoch 863 
2025-01-26 02:03:17.637828: Current learning rate: 0.00167 
2025-01-26 02:03:46.836304: train_loss -0.8436 
2025-01-26 02:03:46.841502: val_loss -0.8262 
2025-01-26 02:03:46.843871: Pseudo dice [np.float32(0.9616), np.float32(0.9022)] 
2025-01-26 02:03:46.846011: Epoch time: 29.2 s 
2025-01-26 02:03:47.872689:  
2025-01-26 02:03:47.875449: Epoch 864 
2025-01-26 02:03:47.877913: Current learning rate: 0.00166 
2025-01-26 02:04:16.351818: train_loss -0.8363 
2025-01-26 02:04:16.355297: val_loss -0.7916 
2025-01-26 02:04:16.357966: Pseudo dice [np.float32(0.9623), np.float32(0.9184)] 
2025-01-26 02:04:16.360355: Epoch time: 28.48 s 
2025-01-26 02:04:17.388195:  
2025-01-26 02:04:17.390639: Epoch 865 
2025-01-26 02:04:17.397606: Current learning rate: 0.00165 
2025-01-26 02:04:45.745904: train_loss -0.8437 
2025-01-26 02:04:45.752105: val_loss -0.7778 
2025-01-26 02:04:45.754814: Pseudo dice [np.float32(0.9574), np.float32(0.9122)] 
2025-01-26 02:04:45.757125: Epoch time: 28.36 s 
2025-01-26 02:04:47.110081:  
2025-01-26 02:04:47.114550: Epoch 866 
2025-01-26 02:04:47.116892: Current learning rate: 0.00164 
2025-01-26 02:05:16.716420: train_loss -0.8485 
2025-01-26 02:05:16.722502: val_loss -0.7785 
2025-01-26 02:05:16.725036: Pseudo dice [np.float32(0.9649), np.float32(0.9107)] 
2025-01-26 02:05:16.727568: Epoch time: 29.61 s 
2025-01-26 02:05:17.887992:  
2025-01-26 02:05:17.890644: Epoch 867 
2025-01-26 02:05:17.894435: Current learning rate: 0.00163 
2025-01-26 02:05:46.931828: train_loss -0.8539 
2025-01-26 02:05:46.937234: val_loss -0.8136 
2025-01-26 02:05:46.940094: Pseudo dice [np.float32(0.9596), np.float32(0.9168)] 
2025-01-26 02:05:46.942421: Epoch time: 29.04 s 
2025-01-26 02:05:47.962882:  
2025-01-26 02:05:47.965393: Epoch 868 
2025-01-26 02:05:47.968846: Current learning rate: 0.00162 
2025-01-26 02:06:19.885237: train_loss -0.8602 
2025-01-26 02:06:19.891920: val_loss -0.8023 
2025-01-26 02:06:19.894332: Pseudo dice [np.float32(0.9604), np.float32(0.9265)] 
2025-01-26 02:06:19.897048: Epoch time: 31.92 s 
2025-01-26 02:06:21.400574:  
2025-01-26 02:06:21.404356: Epoch 869 
2025-01-26 02:06:21.406831: Current learning rate: 0.00161 
2025-01-26 02:06:49.854933: train_loss -0.8381 
2025-01-26 02:06:49.860543: val_loss -0.8241 
2025-01-26 02:06:49.862849: Pseudo dice [np.float32(0.9618), np.float32(0.8734)] 
2025-01-26 02:06:49.865210: Epoch time: 28.46 s 
2025-01-26 02:06:50.904552:  
2025-01-26 02:06:50.907157: Epoch 870 
2025-01-26 02:06:50.910368: Current learning rate: 0.00159 
2025-01-26 02:07:20.045398: train_loss -0.8455 
2025-01-26 02:07:20.050044: val_loss -0.7596 
2025-01-26 02:07:20.052832: Pseudo dice [np.float32(0.9666), np.float32(0.9171)] 
2025-01-26 02:07:20.055172: Epoch time: 29.14 s 
2025-01-26 02:07:21.076573:  
2025-01-26 02:07:21.079350: Epoch 871 
2025-01-26 02:07:21.081861: Current learning rate: 0.00158 
2025-01-26 02:07:51.052831: train_loss -0.8621 
2025-01-26 02:07:51.058515: val_loss -0.7832 
2025-01-26 02:07:51.061179: Pseudo dice [np.float32(0.9636), np.float32(0.9096)] 
2025-01-26 02:07:51.063294: Epoch time: 29.98 s 
2025-01-26 02:07:52.085930:  
2025-01-26 02:07:52.090166: Epoch 872 
2025-01-26 02:07:52.092454: Current learning rate: 0.00157 
2025-01-26 02:08:21.331448: train_loss -0.8265 
2025-01-26 02:08:21.336561: val_loss -0.8186 
2025-01-26 02:08:21.338987: Pseudo dice [np.float32(0.9598), np.float32(0.9144)] 
2025-01-26 02:08:21.341575: Epoch time: 29.25 s 
2025-01-26 02:08:22.374456:  
2025-01-26 02:08:22.376950: Epoch 873 
2025-01-26 02:08:22.379222: Current learning rate: 0.00156 
