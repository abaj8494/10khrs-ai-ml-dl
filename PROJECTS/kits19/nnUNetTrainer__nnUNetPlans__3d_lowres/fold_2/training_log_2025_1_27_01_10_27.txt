
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-01-27 01:10:27.366262: do_dummy_2d_data_aug: False 
2025-01-27 01:10:27.371611: Using splits from existing split file: /srv/scratch/z5362216/kits19/nnUNet_db/nnUNet_preprocessed/Dataset001_Kits19/splits_final.json 
2025-01-27 01:10:27.374589: The split file contains 5 splits. 
2025-01-27 01:10:27.376878: Desired fold for training: 2 
2025-01-27 01:10:27.379123: This split has 80 training and 20 validation cases. 
2025-01-27 01:10:32.589267: Using torch.compile... 

This is the configuration used by this training:
Configuration name: 3d_lowres
 {'data_identifier': 'nnUNetPlans_3d_lowres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [128, 128, 128], 'median_image_size_in_voxels': [200, 205, 205], 'spacing': [1.9849520718478983, 1.9849270710444444, 1.9849270710444444], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False, 'next_stage': '3d_cascade_fullres'} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset001_Kits19', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [3.0, 0.7939453125, 0.7939453125], 'original_median_shape_after_transp': [104, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [2, 0, 1], 'transpose_backward': [1, 2, 0], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 2553.0, 'mean': 104.46720886230469, 'median': 104.0, 'min': -277.0, 'percentile_00_5': -73.0, 'percentile_99_5': 292.0, 'std': 74.68063354492188}}} 
 
2025-01-27 01:10:35.719632: unpacking dataset... 
2025-01-27 01:10:42.622313: unpacking done... 
2025-01-27 01:10:42.647558: 
printing the network instead:
 
2025-01-27 01:10:42.650828: OptimizedModule(
  (_orig_mod): PlainConvUNet(
    (encoder): PlainConvEncoder(
      (stages): Sequential(
        (0): Sequential(
          (0): StackedConvBlocks(
            (convs): Sequential(
              (0): ConvDropoutNormReLU(
                (conv): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (1): ConvDropoutNormReLU(
                (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
            )
          )
        )
        (1): Sequential(
          (0): StackedConvBlocks(
            (convs): Sequential(
              (0): ConvDropoutNormReLU(
                (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (1): ConvDropoutNormReLU(
                (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
            )
          )
        )
        (2): Sequential(
          (0): StackedConvBlocks(
            (convs): Sequential(
              (0): ConvDropoutNormReLU(
                (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (1): ConvDropoutNormReLU(
                (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
            )
          )
        )
        (3): Sequential(
          (0): StackedConvBlocks(
            (convs): Sequential(
              (0): ConvDropoutNormReLU(
                (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (1): ConvDropoutNormReLU(
                (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
            )
          )
        )
        (4): Sequential(
          (0): StackedConvBlocks(
            (convs): Sequential(
              (0): ConvDropoutNormReLU(
                (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (1): ConvDropoutNormReLU(
                (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
            )
          )
        )
        (5): Sequential(
          (0): StackedConvBlocks(
            (convs): Sequential(
              (0): ConvDropoutNormReLU(
                (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
              (1): ConvDropoutNormReLU(
                (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                (all_modules): Sequential(
                  (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (2): LeakyReLU(negative_slope=0.01, inplace=True)
                )
              )
            )
          )
        )
      )
    )
    (decoder): UNetDecoder(
      (encoder): PlainConvEncoder(
        (stages): Sequential(
          (0): Sequential(
            (0): StackedConvBlocks(
              (convs): Sequential(
                (0): ConvDropoutNormReLU(
                  (conv): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                  (all_modules): Sequential(
                    (0): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                    (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                    (2): LeakyReLU(negative_slope=0.01, inplace=True)
                  )
                )
                (1): ConvDropoutNormReLU(
                  (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                  (all_modules): Sequential(
                    (0): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                    (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                    (2): LeakyReLU(negative_slope=0.01, inplace=True)
                  )
                )
              )
            )
          )
          (1): Sequential(
            (0): StackedConvBlocks(
              (convs): Sequential(
                (0): ConvDropoutNormReLU(
                  (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                  (all_modules): Sequential(
                    (0): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                    (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                    (2): LeakyReLU(negative_slope=0.01, inplace=True)
                  )
                )
                (1): ConvDropoutNormReLU(
                  (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                  (all_modules): Sequential(
                    (0): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                    (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                    (2): LeakyReLU(negative_slope=0.01, inplace=True)
                  )
                )
              )
            )
          )
          (2): Sequential(
            (0): StackedConvBlocks(
              (convs): Sequential(
                (0): ConvDropoutNormReLU(
                  (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                  (all_modules): Sequential(
                    (0): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                    (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                    (2): LeakyReLU(negative_slope=0.01, inplace=True)
                  )
                )
                (1): ConvDropoutNormReLU(
                  (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                  (all_modules): Sequential(
                    (0): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                    (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                    (2): LeakyReLU(negative_slope=0.01, inplace=True)
                  )
                )
              )
            )
          )
          (3): Sequential(
            (0): StackedConvBlocks(
              (convs): Sequential(
                (0): ConvDropoutNormReLU(
                  (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                  (all_modules): Sequential(
                    (0): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                    (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                    (2): LeakyReLU(negative_slope=0.01, inplace=True)
                  )
                )
                (1): ConvDropoutNormReLU(
                  (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                  (all_modules): Sequential(
                    (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                    (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                    (2): LeakyReLU(negative_slope=0.01, inplace=True)
                  )
                )
              )
            )
          )
          (4): Sequential(
            (0): StackedConvBlocks(
              (convs): Sequential(
                (0): ConvDropoutNormReLU(
                  (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                  (all_modules): Sequential(
                    (0): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                    (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                    (2): LeakyReLU(negative_slope=0.01, inplace=True)
                  )
                )
                (1): ConvDropoutNormReLU(
                  (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                  (all_modules): Sequential(
                    (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                    (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                    (2): LeakyReLU(negative_slope=0.01, inplace=True)
                  )
                )
              )
            )
          )
          (5): Sequential(
            (0): StackedConvBlocks(
              (convs): Sequential(
                (0): ConvDropoutNormReLU(
                  (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                  (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                  (all_modules): Sequential(
                    (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
                    (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                    (2): LeakyReLU(negative_slope=0.01, inplace=True)
                  )
                )
                (1): ConvDropoutNormReLU(
                  (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                  (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                  (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
                  (all_modules): Sequential(
                    (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                    (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                    (2): LeakyReLU(negative_slope=0.01, inplace=True)
                  )
                )
              )
            )
          )
        )
      )
      (stages): ModuleList(
        (0): StackedConvBlocks(
          (convs): Sequential(
            (0): ConvDropoutNormReLU(
              (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
              (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (1): ConvDropoutNormReLU(
              (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
              (norm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
          )
        )
        (1): StackedConvBlocks(
          (convs): Sequential(
            (0): ConvDropoutNormReLU(
              (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
              (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (1): ConvDropoutNormReLU(
              (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
              (norm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
          )
        )
        (2): StackedConvBlocks(
          (convs): Sequential(
            (0): ConvDropoutNormReLU(
              (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (1): ConvDropoutNormReLU(
              (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
              (norm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
          )
        )
        (3): StackedConvBlocks(
          (convs): Sequential(
            (0): ConvDropoutNormReLU(
              (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (1): ConvDropoutNormReLU(
              (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
              (norm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
          )
        )
        (4): StackedConvBlocks(
          (convs): Sequential(
            (0): ConvDropoutNormReLU(
              (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
            (1): ConvDropoutNormReLU(
              (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
              (norm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
              (nonlin): LeakyReLU(negative_slope=0.01, inplace=True)
              (all_modules): Sequential(
                (0): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
                (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.01, inplace=True)
              )
            )
          )
        )
      )
      (transpconvs): ModuleList(
        (0): ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2))
        (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2))
        (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2))
        (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2))
        (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2))
      )
      (seg_layers): ModuleList(
        (0): Conv3d(320, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1))
        (1): Conv3d(256, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1))
        (2): Conv3d(128, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1))
        (3): Conv3d(64, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1))
        (4): Conv3d(32, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1))
      )
    )
  )
) 
2025-01-27 01:10:42.658782: 
 
2025-01-27 01:10:42.661526: Unable to plot network architecture: nnUNet_compile is enabled! 
2025-01-27 01:10:42.678871:  
2025-01-27 01:10:42.681584: Epoch 0 
2025-01-27 01:10:42.684215: Current learning rate: 0.01 
2025-01-27 01:12:36.231075: train_loss 0.0639 
2025-01-27 01:12:36.241313: val_loss -0.1389 
2025-01-27 01:12:36.244184: Pseudo dice [np.float32(0.0), np.float32(0.0)] 
2025-01-27 01:12:36.247024: Epoch time: 113.55 s 
2025-01-27 01:12:36.249465: Yayy! New best EMA pseudo Dice: 0.0 
2025-01-27 01:12:40.930626:  
2025-01-27 01:12:40.933121: Epoch 1 
2025-01-27 01:12:40.935752: Current learning rate: 0.00999 
2025-01-27 01:13:29.294682: train_loss -0.2817 
2025-01-27 01:13:29.301184: val_loss -0.3595 
2025-01-27 01:13:29.304120: Pseudo dice [np.float32(0.8039), np.float32(0.0)] 
2025-01-27 01:13:29.306893: Epoch time: 48.36 s 
2025-01-27 01:13:29.309407: Yayy! New best EMA pseudo Dice: 0.04019999876618385 
2025-01-27 01:13:31.082102:  
2025-01-27 01:13:31.085152: Epoch 2 
2025-01-27 01:13:31.088003: Current learning rate: 0.00998 
2025-01-27 01:14:19.577840: train_loss -0.3587 
2025-01-27 01:14:19.586024: val_loss -0.4584 
2025-01-27 01:14:19.588717: Pseudo dice [np.float32(0.8603), np.float32(0.4514)] 
2025-01-27 01:14:19.591215: Epoch time: 48.5 s 
2025-01-27 01:14:19.593872: Yayy! New best EMA pseudo Dice: 0.10180000215768814 
2025-01-27 01:14:21.364072:  
2025-01-27 01:14:21.367044: Epoch 3 
2025-01-27 01:14:21.369901: Current learning rate: 0.00997 
2025-01-27 01:15:10.337005: train_loss -0.4082 
2025-01-27 01:15:10.343547: val_loss -0.4191 
2025-01-27 01:15:10.346536: Pseudo dice [np.float32(0.8752), np.float32(0.1672)] 
2025-01-27 01:15:10.349652: Epoch time: 48.97 s 
2025-01-27 01:15:10.352616: Yayy! New best EMA pseudo Dice: 0.1437000036239624 
2025-01-27 01:15:12.204221:  
2025-01-27 01:15:12.207023: Epoch 4 
2025-01-27 01:15:12.209700: Current learning rate: 0.00996 
2025-01-27 01:16:00.791498: train_loss -0.4396 
2025-01-27 01:16:00.801183: val_loss -0.4799 
2025-01-27 01:16:00.804226: Pseudo dice [np.float32(0.8578), np.float32(0.428)] 
2025-01-27 01:16:00.807456: Epoch time: 48.59 s 
2025-01-27 01:16:00.810328: Yayy! New best EMA pseudo Dice: 0.19359999895095825 
2025-01-27 01:16:02.638761:  
2025-01-27 01:16:02.642534: Epoch 5 
2025-01-27 01:16:02.645793: Current learning rate: 0.00995 
2025-01-27 01:16:50.968981: train_loss -0.4693 
2025-01-27 01:16:50.973916: val_loss -0.501 
2025-01-27 01:16:50.976831: Pseudo dice [np.float32(0.8819), np.float32(0.5048)] 
2025-01-27 01:16:50.979536: Epoch time: 48.33 s 
2025-01-27 01:16:50.982092: Yayy! New best EMA pseudo Dice: 0.243599995970726 
2025-01-27 01:16:52.745046:  
2025-01-27 01:16:52.748018: Epoch 6 
2025-01-27 01:16:52.750761: Current learning rate: 0.00995 
2025-01-27 01:17:41.626930: train_loss -0.5157 
2025-01-27 01:17:41.634986: val_loss -0.5662 
2025-01-27 01:17:41.637948: Pseudo dice [np.float32(0.894), np.float32(0.5595)] 
2025-01-27 01:17:41.640768: Epoch time: 48.88 s 
2025-01-27 01:17:41.643568: Yayy! New best EMA pseudo Dice: 0.29190000891685486 
2025-01-27 01:17:43.432147:  
2025-01-27 01:17:43.435524: Epoch 7 
2025-01-27 01:17:43.438460: Current learning rate: 0.00994 
2025-01-27 01:18:31.953215: train_loss -0.5255 
2025-01-27 01:18:31.958584: val_loss -0.5283 
2025-01-27 01:18:31.961596: Pseudo dice [np.float32(0.8946), np.float32(0.506)] 
2025-01-27 01:18:31.965196: Epoch time: 48.52 s 
2025-01-27 01:18:31.967964: Yayy! New best EMA pseudo Dice: 0.3327000141143799 
2025-01-27 01:18:33.892570:  
2025-01-27 01:18:33.896760: Epoch 8 
2025-01-27 01:18:33.899744: Current learning rate: 0.00993 
2025-01-27 01:19:22.359976: train_loss -0.5313 
2025-01-27 01:19:22.367719: val_loss -0.5801 
2025-01-27 01:19:22.370515: Pseudo dice [np.float32(0.8966), np.float32(0.6516)] 
2025-01-27 01:19:22.373048: Epoch time: 48.47 s 
2025-01-27 01:19:22.375359: Yayy! New best EMA pseudo Dice: 0.37689998745918274 
2025-01-27 01:19:24.146032:  
2025-01-27 01:19:24.149055: Epoch 9 
2025-01-27 01:19:24.151955: Current learning rate: 0.00992 
2025-01-27 01:20:12.779859: train_loss -0.5511 
2025-01-27 01:20:12.783807: val_loss -0.6057 
2025-01-27 01:20:12.786905: Pseudo dice [np.float32(0.9144), np.float32(0.6115)] 
2025-01-27 01:20:12.789843: Epoch time: 48.63 s 
2025-01-27 01:20:12.792132: Yayy! New best EMA pseudo Dice: 0.4154999852180481 
2025-01-27 01:20:14.561245:  
2025-01-27 01:20:14.564114: Epoch 10 
2025-01-27 01:20:14.567031: Current learning rate: 0.00991 
2025-01-27 01:21:03.368028: train_loss -0.5726 
2025-01-27 01:21:03.375304: val_loss -0.5797 
2025-01-27 01:21:03.378140: Pseudo dice [np.float32(0.8861), np.float32(0.6597)] 
2025-01-27 01:21:03.381023: Epoch time: 48.81 s 
2025-01-27 01:21:03.383415: Yayy! New best EMA pseudo Dice: 0.451200008392334 
2025-01-27 01:21:05.107571:  
2025-01-27 01:21:05.111461: Epoch 11 
2025-01-27 01:21:05.115064: Current learning rate: 0.0099 
2025-01-27 01:21:53.949878: train_loss -0.5473 
2025-01-27 01:21:53.955632: val_loss -0.6124 
2025-01-27 01:21:53.958970: Pseudo dice [np.float32(0.9032), np.float32(0.6699)] 
2025-01-27 01:21:53.962243: Epoch time: 48.84 s 
2025-01-27 01:21:53.964823: Yayy! New best EMA pseudo Dice: 0.4848000109195709 
2025-01-27 01:21:55.730429:  
2025-01-27 01:21:55.733146: Epoch 12 
2025-01-27 01:21:55.736075: Current learning rate: 0.00989 
2025-01-27 01:22:44.570095: train_loss -0.5755 
2025-01-27 01:22:44.577733: val_loss -0.5954 
2025-01-27 01:22:44.580698: Pseudo dice [np.float32(0.9005), np.float32(0.6741)] 
2025-01-27 01:22:44.583297: Epoch time: 48.84 s 
2025-01-27 01:22:44.586006: Yayy! New best EMA pseudo Dice: 0.5149999856948853 
2025-01-27 01:22:46.388766:  
2025-01-27 01:22:46.392501: Epoch 13 
2025-01-27 01:22:46.395783: Current learning rate: 0.00988 
2025-01-27 01:23:34.921451: train_loss -0.586 
2025-01-27 01:23:34.925115: val_loss -0.6549 
2025-01-27 01:23:34.927861: Pseudo dice [np.float32(0.9212), np.float32(0.7299)] 
2025-01-27 01:23:34.930300: Epoch time: 48.53 s 
2025-01-27 01:23:34.932922: Yayy! New best EMA pseudo Dice: 0.5461000204086304 
2025-01-27 01:23:36.683120:  
2025-01-27 01:23:36.687479: Epoch 14 
2025-01-27 01:23:36.690547: Current learning rate: 0.00987 
2025-01-27 01:24:25.957405: train_loss -0.6178 
2025-01-27 01:24:25.964637: val_loss -0.6424 
2025-01-27 01:24:25.967558: Pseudo dice [np.float32(0.9248), np.float32(0.7177)] 
2025-01-27 01:24:25.970631: Epoch time: 49.28 s 
2025-01-27 01:24:25.973679: Yayy! New best EMA pseudo Dice: 0.5735999941825867 
2025-01-27 01:24:27.839000:  
2025-01-27 01:24:27.842172: Epoch 15 
2025-01-27 01:24:27.845398: Current learning rate: 0.00986 
2025-01-27 01:25:16.408155: train_loss -0.6322 
2025-01-27 01:25:16.411724: val_loss -0.6437 
2025-01-27 01:25:16.414346: Pseudo dice [np.float32(0.9067), np.float32(0.7164)] 
2025-01-27 01:25:16.416989: Epoch time: 48.57 s 
2025-01-27 01:25:16.419442: Yayy! New best EMA pseudo Dice: 0.5974000096321106 
2025-01-27 01:25:18.183270:  
2025-01-27 01:25:18.186494: Epoch 16 
2025-01-27 01:25:18.189718: Current learning rate: 0.00986 
2025-01-27 01:26:06.765782: train_loss -0.6471 
2025-01-27 01:26:06.773579: val_loss -0.6361 
2025-01-27 01:26:06.776262: Pseudo dice [np.float32(0.9222), np.float32(0.6741)] 
2025-01-27 01:26:06.779057: Epoch time: 48.58 s 
2025-01-27 01:26:06.781971: Yayy! New best EMA pseudo Dice: 0.6175000071525574 
2025-01-27 01:26:08.771280:  
2025-01-27 01:26:08.774445: Epoch 17 
2025-01-27 01:26:08.777486: Current learning rate: 0.00985 
2025-01-27 01:26:57.447715: train_loss -0.6481 
2025-01-27 01:26:57.453916: val_loss -0.6129 
2025-01-27 01:26:57.456662: Pseudo dice [np.float32(0.9079), np.float32(0.5567)] 
2025-01-27 01:26:57.459336: Epoch time: 48.68 s 
2025-01-27 01:26:57.461897: Yayy! New best EMA pseudo Dice: 0.6288999915122986 
2025-01-27 01:26:59.211915:  
2025-01-27 01:26:59.214787: Epoch 18 
2025-01-27 01:26:59.217660: Current learning rate: 0.00984 
2025-01-27 01:27:47.537156: train_loss -0.6226 
2025-01-27 01:27:47.546059: val_loss -0.6337 
2025-01-27 01:27:47.549084: Pseudo dice [np.float32(0.9199), np.float32(0.7073)] 
2025-01-27 01:27:47.551636: Epoch time: 48.33 s 
2025-01-27 01:27:47.554210: Yayy! New best EMA pseudo Dice: 0.6474000215530396 
2025-01-27 01:27:49.976507:  
2025-01-27 01:27:49.979591: Epoch 19 
2025-01-27 01:27:49.982260: Current learning rate: 0.00983 
2025-01-27 01:28:38.675264: train_loss -0.6534 
2025-01-27 01:28:38.678421: val_loss -0.5902 
2025-01-27 01:28:38.680917: Pseudo dice [np.float32(0.9127), np.float32(0.5995)] 
2025-01-27 01:28:38.683275: Epoch time: 48.7 s 
2025-01-27 01:28:38.685463: Yayy! New best EMA pseudo Dice: 0.65829998254776 
2025-01-27 01:28:40.488581:  
2025-01-27 01:28:40.491508: Epoch 20 
2025-01-27 01:28:40.494276: Current learning rate: 0.00982 
2025-01-27 01:29:28.866944: train_loss -0.6586 
2025-01-27 01:29:28.873679: val_loss -0.6702 
2025-01-27 01:29:28.876688: Pseudo dice [np.float32(0.9311), np.float32(0.6943)] 
2025-01-27 01:29:28.879409: Epoch time: 48.38 s 
2025-01-27 01:29:28.881930: Yayy! New best EMA pseudo Dice: 0.6736999750137329 
2025-01-27 01:29:30.671760:  
2025-01-27 01:29:30.674755: Epoch 21 
2025-01-27 01:29:30.677686: Current learning rate: 0.00981 
2025-01-27 01:30:19.390588: train_loss -0.6545 
2025-01-27 01:30:19.394767: val_loss -0.6695 
2025-01-27 01:30:19.398253: Pseudo dice [np.float32(0.9202), np.float32(0.7993)] 
2025-01-27 01:30:19.401460: Epoch time: 48.72 s 
2025-01-27 01:30:19.404845: Yayy! New best EMA pseudo Dice: 0.692300021648407 
2025-01-27 01:30:21.201013:  
2025-01-27 01:30:21.204083: Epoch 22 
2025-01-27 01:30:21.206896: Current learning rate: 0.0098 
2025-01-27 01:31:10.352489: train_loss -0.6707 
2025-01-27 01:31:10.358912: val_loss -0.6668 
2025-01-27 01:31:10.361587: Pseudo dice [np.float32(0.9361), np.float32(0.7585)] 
2025-01-27 01:31:10.364405: Epoch time: 49.15 s 
2025-01-27 01:31:10.367099: Yayy! New best EMA pseudo Dice: 0.7077999711036682 
2025-01-27 01:31:12.149193:  
2025-01-27 01:31:12.152814: Epoch 23 
2025-01-27 01:31:12.156008: Current learning rate: 0.00979 
2025-01-27 01:32:00.462018: train_loss -0.6664 
2025-01-27 01:32:00.466035: val_loss -0.6218 
2025-01-27 01:32:00.469133: Pseudo dice [np.float32(0.9263), np.float32(0.6948)] 
2025-01-27 01:32:00.471805: Epoch time: 48.31 s 
2025-01-27 01:32:00.474678: Yayy! New best EMA pseudo Dice: 0.7181000113487244 
2025-01-27 01:32:02.245656:  
2025-01-27 01:32:02.249392: Epoch 24 
2025-01-27 01:32:02.252648: Current learning rate: 0.00978 
2025-01-27 01:32:50.773077: train_loss -0.676 
2025-01-27 01:32:50.779307: val_loss -0.666 
2025-01-27 01:32:50.781749: Pseudo dice [np.float32(0.9261), np.float32(0.7519)] 
2025-01-27 01:32:50.784203: Epoch time: 48.53 s 
2025-01-27 01:32:50.786882: Yayy! New best EMA pseudo Dice: 0.7301999926567078 
2025-01-27 01:32:52.492608:  
2025-01-27 01:32:52.496093: Epoch 25 
2025-01-27 01:32:52.499132: Current learning rate: 0.00977 
2025-01-27 01:33:41.297209: train_loss -0.6736 
2025-01-27 01:33:41.301168: val_loss -0.65 
2025-01-27 01:33:41.304395: Pseudo dice [np.float32(0.9267), np.float32(0.7899)] 
2025-01-27 01:33:41.307166: Epoch time: 48.81 s 
2025-01-27 01:33:41.309925: Yayy! New best EMA pseudo Dice: 0.7429999709129333 
2025-01-27 01:33:43.055550:  
2025-01-27 01:33:43.059131: Epoch 26 
2025-01-27 01:33:43.062252: Current learning rate: 0.00977 
2025-01-27 01:34:32.040487: train_loss -0.6652 
2025-01-27 01:34:32.047061: val_loss -0.6072 
2025-01-27 01:34:32.049937: Pseudo dice [np.float32(0.9022), np.float32(0.6794)] 
2025-01-27 01:34:32.052442: Epoch time: 48.99 s 
2025-01-27 01:34:32.054881: Yayy! New best EMA pseudo Dice: 0.7477999925613403 
2025-01-27 01:34:33.809464:  
2025-01-27 01:34:33.812883: Epoch 27 
2025-01-27 01:34:33.816200: Current learning rate: 0.00976 
2025-01-27 01:35:22.756782: train_loss -0.6841 
2025-01-27 01:35:22.760675: val_loss -0.7092 
2025-01-27 01:35:22.763801: Pseudo dice [np.float32(0.936), np.float32(0.7881)] 
2025-01-27 01:35:22.766589: Epoch time: 48.95 s 
2025-01-27 01:35:22.769466: Yayy! New best EMA pseudo Dice: 0.7591999769210815 
2025-01-27 01:35:24.522676:  
2025-01-27 01:35:24.525521: Epoch 28 
2025-01-27 01:35:24.528444: Current learning rate: 0.00975 
2025-01-27 01:36:13.659904: train_loss -0.6938 
2025-01-27 01:36:13.666891: val_loss -0.7134 
2025-01-27 01:36:13.669604: Pseudo dice [np.float32(0.9373), np.float32(0.7976)] 
2025-01-27 01:36:13.671940: Epoch time: 49.14 s 
2025-01-27 01:36:13.674390: Yayy! New best EMA pseudo Dice: 0.7699999809265137 
2025-01-27 01:36:15.408804:  
2025-01-27 01:36:15.412127: Epoch 29 
2025-01-27 01:36:15.415199: Current learning rate: 0.00974 
2025-01-27 01:37:04.584680: train_loss -0.6989 
2025-01-27 01:37:04.588611: val_loss -0.7184 
2025-01-27 01:37:04.591753: Pseudo dice [np.float32(0.9364), np.float32(0.7982)] 
2025-01-27 01:37:04.594501: Epoch time: 49.18 s 
2025-01-27 01:37:04.597457: Yayy! New best EMA pseudo Dice: 0.7797999978065491 
2025-01-27 01:37:06.386347:  
2025-01-27 01:37:06.389186: Epoch 30 
2025-01-27 01:37:06.392151: Current learning rate: 0.00973 
2025-01-27 01:37:55.172647: train_loss -0.6976 
2025-01-27 01:37:55.179924: val_loss -0.6909 
2025-01-27 01:37:55.183101: Pseudo dice [np.float32(0.9306), np.float32(0.7977)] 
2025-01-27 01:37:55.185614: Epoch time: 48.79 s 
2025-01-27 01:37:55.187952: Yayy! New best EMA pseudo Dice: 0.7882000207901001 
2025-01-27 01:37:56.991362:  
2025-01-27 01:37:56.994717: Epoch 31 
2025-01-27 01:37:56.998202: Current learning rate: 0.00972 
2025-01-27 01:38:45.951855: train_loss -0.7009 
2025-01-27 01:38:45.957166: val_loss -0.6931 
2025-01-27 01:38:45.960198: Pseudo dice [np.float32(0.9336), np.float32(0.7092)] 
2025-01-27 01:38:45.963282: Epoch time: 48.96 s 
2025-01-27 01:38:45.966088: Yayy! New best EMA pseudo Dice: 0.7914999723434448 
2025-01-27 01:38:47.808932:  
2025-01-27 01:38:47.813225: Epoch 32 
2025-01-27 01:38:47.816250: Current learning rate: 0.00971 
2025-01-27 01:39:36.609753: train_loss -0.7054 
2025-01-27 01:39:36.617584: val_loss -0.6906 
2025-01-27 01:39:36.620612: Pseudo dice [np.float32(0.9357), np.float32(0.74)] 
2025-01-27 01:39:36.623447: Epoch time: 48.8 s 
2025-01-27 01:39:36.626517: Yayy! New best EMA pseudo Dice: 0.7961000204086304 
2025-01-27 01:39:38.380203:  
2025-01-27 01:39:38.382928: Epoch 33 
2025-01-27 01:39:38.385923: Current learning rate: 0.0097 
2025-01-27 01:40:27.374692: train_loss -0.7346 
2025-01-27 01:40:27.382334: val_loss -0.7131 
2025-01-27 01:40:27.385267: Pseudo dice [np.float32(0.9419), np.float32(0.7456)] 
2025-01-27 01:40:27.388671: Epoch time: 49.0 s 
2025-01-27 01:40:27.391267: Yayy! New best EMA pseudo Dice: 0.8008999824523926 
2025-01-27 01:40:29.186300:  
2025-01-27 01:40:29.189996: Epoch 34 
2025-01-27 01:40:29.193840: Current learning rate: 0.00969 
2025-01-27 01:41:18.154637: train_loss -0.7252 
2025-01-27 01:41:18.161441: val_loss -0.6692 
2025-01-27 01:41:18.164610: Pseudo dice [np.float32(0.9314), np.float32(0.6677)] 
2025-01-27 01:41:18.167407: Epoch time: 48.97 s 
2025-01-27 01:41:19.373280:  
2025-01-27 01:41:19.376341: Epoch 35 
2025-01-27 01:41:19.379591: Current learning rate: 0.00968 
2025-01-27 01:42:07.502730: train_loss -0.7023 
2025-01-27 01:42:07.506944: val_loss -0.6907 
2025-01-27 01:42:07.510087: Pseudo dice [np.float32(0.9321), np.float32(0.7867)] 
2025-01-27 01:42:07.512908: Epoch time: 48.13 s 
2025-01-27 01:42:07.515563: Yayy! New best EMA pseudo Dice: 0.8065999746322632 
2025-01-27 01:42:09.944304:  
2025-01-27 01:42:09.947906: Epoch 36 
2025-01-27 01:42:09.950988: Current learning rate: 0.00968 
2025-01-27 01:42:58.827425: train_loss -0.7219 
2025-01-27 01:42:58.836170: val_loss -0.6648 
2025-01-27 01:42:58.839146: Pseudo dice [np.float32(0.9266), np.float32(0.7648)] 
2025-01-27 01:42:58.842219: Epoch time: 48.88 s 
2025-01-27 01:42:58.845045: Yayy! New best EMA pseudo Dice: 0.8105000257492065 
2025-01-27 01:43:00.590623:  
2025-01-27 01:43:00.593800: Epoch 37 
2025-01-27 01:43:00.596583: Current learning rate: 0.00967 
2025-01-27 01:43:49.488231: train_loss -0.7173 
2025-01-27 01:43:49.492537: val_loss -0.6799 
2025-01-27 01:43:49.495752: Pseudo dice [np.float32(0.9291), np.float32(0.7097)] 
2025-01-27 01:43:49.498477: Epoch time: 48.9 s 
2025-01-27 01:43:49.501171: Yayy! New best EMA pseudo Dice: 0.8113999962806702 
2025-01-27 01:43:51.267452:  
2025-01-27 01:43:51.270882: Epoch 38 
2025-01-27 01:43:51.273796: Current learning rate: 0.00966 
2025-01-27 01:44:39.868553: train_loss -0.7225 
2025-01-27 01:44:39.875608: val_loss -0.6924 
2025-01-27 01:44:39.878618: Pseudo dice [np.float32(0.9391), np.float32(0.8085)] 
2025-01-27 01:44:39.881337: Epoch time: 48.6 s 
2025-01-27 01:44:39.884192: Yayy! New best EMA pseudo Dice: 0.8177000284194946 
2025-01-27 01:44:41.702060:  
2025-01-27 01:44:41.705275: Epoch 39 
2025-01-27 01:44:41.708137: Current learning rate: 0.00965 
2025-01-27 01:45:30.387503: train_loss -0.7512 
2025-01-27 01:45:30.391541: val_loss -0.6998 
2025-01-27 01:45:30.394541: Pseudo dice [np.float32(0.9305), np.float32(0.8057)] 
2025-01-27 01:45:30.397425: Epoch time: 48.69 s 
2025-01-27 01:45:30.399897: Yayy! New best EMA pseudo Dice: 0.822700023651123 
2025-01-27 01:45:32.240185:  
2025-01-27 01:45:32.243339: Epoch 40 
2025-01-27 01:45:32.246103: Current learning rate: 0.00964 
2025-01-27 01:46:20.759934: train_loss -0.7246 
2025-01-27 01:46:20.766426: val_loss -0.6849 
2025-01-27 01:46:20.769063: Pseudo dice [np.float32(0.9357), np.float32(0.746)] 
2025-01-27 01:46:20.771724: Epoch time: 48.52 s 
2025-01-27 01:46:20.774368: Yayy! New best EMA pseudo Dice: 0.8245000243186951 
2025-01-27 01:46:22.634958:  
2025-01-27 01:46:22.639002: Epoch 41 
2025-01-27 01:46:22.641839: Current learning rate: 0.00963 
2025-01-27 01:47:11.650936: train_loss -0.6987 
2025-01-27 01:47:11.654833: val_loss -0.7126 
2025-01-27 01:47:11.657677: Pseudo dice [np.float32(0.9366), np.float32(0.7972)] 
2025-01-27 01:47:11.660741: Epoch time: 49.02 s 
2025-01-27 01:47:11.663750: Yayy! New best EMA pseudo Dice: 0.8288000226020813 
2025-01-27 01:47:13.395878:  
2025-01-27 01:47:13.399064: Epoch 42 
2025-01-27 01:47:13.401823: Current learning rate: 0.00962 
2025-01-27 01:48:02.223484: train_loss -0.7323 
2025-01-27 01:48:02.230652: val_loss -0.7209 
2025-01-27 01:48:02.233804: Pseudo dice [np.float32(0.939), np.float32(0.8024)] 
2025-01-27 01:48:02.236789: Epoch time: 48.83 s 
2025-01-27 01:48:02.239579: Yayy! New best EMA pseudo Dice: 0.8330000042915344 
2025-01-27 01:48:03.980240:  
2025-01-27 01:48:03.983698: Epoch 43 
2025-01-27 01:48:03.987106: Current learning rate: 0.00961 
2025-01-27 01:48:52.589887: train_loss -0.7413 
2025-01-27 01:48:52.594110: val_loss -0.6896 
2025-01-27 01:48:52.597527: Pseudo dice [np.float32(0.9306), np.float32(0.7899)] 
2025-01-27 01:48:52.600265: Epoch time: 48.61 s 
2025-01-27 01:48:52.603122: Yayy! New best EMA pseudo Dice: 0.8356999754905701 
2025-01-27 01:48:54.359245:  
2025-01-27 01:48:54.362617: Epoch 44 
2025-01-27 01:48:54.365525: Current learning rate: 0.0096 
2025-01-27 01:49:42.931407: train_loss -0.741 
2025-01-27 01:49:42.938299: val_loss -0.6948 
2025-01-27 01:49:42.941113: Pseudo dice [np.float32(0.9268), np.float32(0.8217)] 
2025-01-27 01:49:42.944043: Epoch time: 48.57 s 
2025-01-27 01:49:42.946666: Yayy! New best EMA pseudo Dice: 0.8395000100135803 
2025-01-27 01:49:44.687441:  
2025-01-27 01:49:44.690671: Epoch 45 
2025-01-27 01:49:44.693918: Current learning rate: 0.00959 
2025-01-27 01:50:33.818376: train_loss -0.7466 
2025-01-27 01:50:33.822990: val_loss -0.7525 
2025-01-27 01:50:33.826052: Pseudo dice [np.float32(0.9409), np.float32(0.8556)] 
2025-01-27 01:50:33.829054: Epoch time: 49.13 s 
2025-01-27 01:50:33.832043: Yayy! New best EMA pseudo Dice: 0.8453999757766724 
2025-01-27 01:50:35.575694:  
2025-01-27 01:50:35.581043: Epoch 46 
2025-01-27 01:50:35.583959: Current learning rate: 0.00959 
2025-01-27 01:51:24.366387: train_loss -0.7484 
2025-01-27 01:51:24.373271: val_loss -0.7154 
2025-01-27 01:51:24.376096: Pseudo dice [np.float32(0.9436), np.float32(0.8407)] 
2025-01-27 01:51:24.378813: Epoch time: 48.79 s 
2025-01-27 01:51:24.381493: Yayy! New best EMA pseudo Dice: 0.8500999808311462 
2025-01-27 01:51:26.185003:  
2025-01-27 01:51:26.188628: Epoch 47 
2025-01-27 01:51:26.191758: Current learning rate: 0.00958 
2025-01-27 01:52:14.930387: train_loss -0.767 
2025-01-27 01:52:14.934088: val_loss -0.7081 
2025-01-27 01:52:14.936842: Pseudo dice [np.float32(0.9419), np.float32(0.8453)] 
2025-01-27 01:52:14.939619: Epoch time: 48.75 s 
2025-01-27 01:52:14.942235: Yayy! New best EMA pseudo Dice: 0.8543999791145325 
2025-01-27 01:52:16.669537:  
2025-01-27 01:52:16.673116: Epoch 48 
2025-01-27 01:52:16.676367: Current learning rate: 0.00957 
2025-01-27 01:53:05.283395: train_loss -0.7588 
2025-01-27 01:53:05.290473: val_loss -0.6955 
2025-01-27 01:53:05.293321: Pseudo dice [np.float32(0.9349), np.float32(0.7697)] 
2025-01-27 01:53:05.296338: Epoch time: 48.61 s 
2025-01-27 01:53:06.449593:  
2025-01-27 01:53:06.452963: Epoch 49 
2025-01-27 01:53:06.456331: Current learning rate: 0.00956 
2025-01-27 01:53:55.577983: train_loss -0.7421 
2025-01-27 01:53:55.581765: val_loss -0.6706 
2025-01-27 01:53:55.584836: Pseudo dice [np.float32(0.9342), np.float32(0.7768)] 
2025-01-27 01:53:55.588147: Epoch time: 49.13 s 
2025-01-27 01:53:57.290057:  
2025-01-27 01:53:57.293606: Epoch 50 
2025-01-27 01:53:57.296802: Current learning rate: 0.00955 
2025-01-27 01:54:46.155898: train_loss -0.7204 
2025-01-27 01:54:46.163227: val_loss -0.6942 
2025-01-27 01:54:46.166020: Pseudo dice [np.float32(0.941), np.float32(0.7971)] 
2025-01-27 01:54:46.169092: Epoch time: 48.87 s 
2025-01-27 01:54:46.171814: Yayy! New best EMA pseudo Dice: 0.8557999730110168 
2025-01-27 01:54:47.896623:  
2025-01-27 01:54:47.900058: Epoch 51 
2025-01-27 01:54:47.902755: Current learning rate: 0.00954 
2025-01-27 01:55:36.230137: train_loss -0.7313 
2025-01-27 01:55:36.234522: val_loss -0.7419 
2025-01-27 01:55:36.237687: Pseudo dice [np.float32(0.946), np.float32(0.8215)] 
2025-01-27 01:55:36.240615: Epoch time: 48.33 s 
2025-01-27 01:55:36.243152: Yayy! New best EMA pseudo Dice: 0.8586000204086304 
2025-01-27 01:55:37.971043:  
2025-01-27 01:55:37.974777: Epoch 52 
2025-01-27 01:55:37.977814: Current learning rate: 0.00953 
2025-01-27 01:56:26.378177: train_loss -0.755 
2025-01-27 01:56:26.384249: val_loss -0.7787 
2025-01-27 01:56:26.387427: Pseudo dice [np.float32(0.9465), np.float32(0.8493)] 
2025-01-27 01:56:26.390424: Epoch time: 48.41 s 
2025-01-27 01:56:26.393286: Yayy! New best EMA pseudo Dice: 0.862500011920929 
2025-01-27 01:56:28.097270:  
2025-01-27 01:56:28.100528: Epoch 53 
2025-01-27 01:56:28.103692: Current learning rate: 0.00952 
2025-01-27 01:57:16.926641: train_loss -0.7612 
2025-01-27 01:57:16.931120: val_loss -0.7176 
2025-01-27 01:57:16.934100: Pseudo dice [np.float32(0.9416), np.float32(0.8471)] 
2025-01-27 01:57:16.937159: Epoch time: 48.83 s 
2025-01-27 01:57:16.939895: Yayy! New best EMA pseudo Dice: 0.8657000064849854 
2025-01-27 01:57:18.659307:  
2025-01-27 01:57:18.662401: Epoch 54 
2025-01-27 01:57:18.665449: Current learning rate: 0.00951 
2025-01-27 01:58:07.070052: train_loss -0.7695 
2025-01-27 01:58:07.076476: val_loss -0.7283 
2025-01-27 01:58:07.079425: Pseudo dice [np.float32(0.9297), np.float32(0.7832)] 
2025-01-27 01:58:07.082431: Epoch time: 48.41 s 
2025-01-27 01:58:08.931234:  
2025-01-27 01:58:08.934494: Epoch 55 
2025-01-27 01:58:08.937574: Current learning rate: 0.0095 
2025-01-27 01:58:57.727531: train_loss -0.7536 
2025-01-27 01:58:57.732500: val_loss -0.6833 
2025-01-27 01:58:57.735493: Pseudo dice [np.float32(0.944), np.float32(0.7483)] 
2025-01-27 01:58:57.738293: Epoch time: 48.8 s 
2025-01-27 01:58:58.896683:  
2025-01-27 01:58:58.900038: Epoch 56 
2025-01-27 01:58:58.903094: Current learning rate: 0.00949 
2025-01-27 01:59:47.404968: train_loss -0.731 
2025-01-27 01:59:47.410696: val_loss -0.6964 
2025-01-27 01:59:47.413791: Pseudo dice [np.float32(0.9397), np.float32(0.7592)] 
2025-01-27 01:59:47.416658: Epoch time: 48.51 s 
2025-01-27 01:59:48.588534:  
2025-01-27 01:59:48.596334: Epoch 57 
2025-01-27 01:59:48.599345: Current learning rate: 0.00949 
2025-01-27 02:00:37.270072: train_loss -0.7532 
2025-01-27 02:00:37.278554: val_loss -0.7182 
2025-01-27 02:00:37.281926: Pseudo dice [np.float32(0.9492), np.float32(0.8356)] 
2025-01-27 02:00:37.284663: Epoch time: 48.68 s 
2025-01-27 02:00:38.483424:  
2025-01-27 02:00:38.486609: Epoch 58 
2025-01-27 02:00:38.489855: Current learning rate: 0.00948 
2025-01-27 02:01:27.417208: train_loss -0.7695 
2025-01-27 02:01:27.424464: val_loss -0.7269 
2025-01-27 02:01:27.426895: Pseudo dice [np.float32(0.9444), np.float32(0.8542)] 
2025-01-27 02:01:27.429461: Epoch time: 48.93 s 
2025-01-27 02:01:27.432043: Yayy! New best EMA pseudo Dice: 0.8680999875068665 
2025-01-27 02:01:29.206333:  
2025-01-27 02:01:29.209100: Epoch 59 
2025-01-27 02:01:29.211721: Current learning rate: 0.00947 
2025-01-27 02:02:17.751980: train_loss -0.7414 
2025-01-27 02:02:17.758442: val_loss -0.7074 
2025-01-27 02:02:17.761207: Pseudo dice [np.float32(0.9412), np.float32(0.7687)] 
2025-01-27 02:02:17.763533: Epoch time: 48.55 s 
2025-01-27 02:02:18.977695:  
2025-01-27 02:02:18.980933: Epoch 60 
2025-01-27 02:02:18.983844: Current learning rate: 0.00946 
2025-01-27 02:03:07.894042: train_loss -0.7438 
2025-01-27 02:03:07.899405: val_loss -0.7052 
2025-01-27 02:03:07.902030: Pseudo dice [np.float32(0.9284), np.float32(0.7942)] 
2025-01-27 02:03:07.904728: Epoch time: 48.92 s 
2025-01-27 02:03:09.083145:  
2025-01-27 02:03:09.086274: Epoch 61 
2025-01-27 02:03:09.089257: Current learning rate: 0.00945 
2025-01-27 02:03:58.133344: train_loss -0.7709 
2025-01-27 02:03:58.138276: val_loss -0.7462 
2025-01-27 02:03:58.141105: Pseudo dice [np.float32(0.9547), np.float32(0.8583)] 
2025-01-27 02:03:58.143683: Epoch time: 49.05 s 
2025-01-27 02:03:58.146262: Yayy! New best EMA pseudo Dice: 0.8702999949455261 
2025-01-27 02:03:59.860880:  
2025-01-27 02:03:59.864269: Epoch 62 
2025-01-27 02:03:59.867327: Current learning rate: 0.00944 
2025-01-27 02:04:48.652455: train_loss -0.752 
2025-01-27 02:04:48.659207: val_loss -0.6977 
2025-01-27 02:04:48.662169: Pseudo dice [np.float32(0.9421), np.float32(0.7311)] 
2025-01-27 02:04:48.664810: Epoch time: 48.79 s 
2025-01-27 02:04:49.850506:  
2025-01-27 02:04:49.853647: Epoch 63 
2025-01-27 02:04:49.856584: Current learning rate: 0.00943 
2025-01-27 02:05:38.396626: train_loss -0.7586 
2025-01-27 02:05:38.401066: val_loss -0.7004 
2025-01-27 02:05:38.403807: Pseudo dice [np.float32(0.9435), np.float32(0.8365)] 
2025-01-27 02:05:38.406625: Epoch time: 48.55 s 
2025-01-27 02:05:39.601377:  
2025-01-27 02:05:39.606362: Epoch 64 
2025-01-27 02:05:39.609390: Current learning rate: 0.00942 
2025-01-27 02:06:27.964766: train_loss -0.7624 
2025-01-27 02:06:27.970506: val_loss -0.7389 
2025-01-27 02:06:27.973153: Pseudo dice [np.float32(0.9392), np.float32(0.8448)] 
2025-01-27 02:06:27.975795: Epoch time: 48.37 s 
2025-01-27 02:06:27.978268: Yayy! New best EMA pseudo Dice: 0.8715000152587891 
2025-01-27 02:06:29.736101:  
2025-01-27 02:06:29.739818: Epoch 65 
2025-01-27 02:06:29.743470: Current learning rate: 0.00941 
2025-01-27 02:07:18.286611: train_loss -0.7613 
2025-01-27 02:07:18.291633: val_loss -0.7177 
2025-01-27 02:07:18.294658: Pseudo dice [np.float32(0.9422), np.float32(0.8023)] 
2025-01-27 02:07:18.300220: Epoch time: 48.55 s 
2025-01-27 02:07:18.303022: Yayy! New best EMA pseudo Dice: 0.8715999722480774 
2025-01-27 02:07:20.097170:  
2025-01-27 02:07:20.100235: Epoch 66 
2025-01-27 02:07:20.103273: Current learning rate: 0.0094 
2025-01-27 02:08:08.783925: train_loss -0.7436 
2025-01-27 02:08:08.789422: val_loss -0.7355 
2025-01-27 02:08:08.792099: Pseudo dice [np.float32(0.9504), np.float32(0.8448)] 
2025-01-27 02:08:08.794569: Epoch time: 48.69 s 
2025-01-27 02:08:08.797227: Yayy! New best EMA pseudo Dice: 0.8741999864578247 
2025-01-27 02:08:10.604886:  
2025-01-27 02:08:10.608367: Epoch 67 
2025-01-27 02:08:10.611289: Current learning rate: 0.00939 
2025-01-27 02:08:59.290554: train_loss -0.7833 
2025-01-27 02:08:59.295411: val_loss -0.7186 
2025-01-27 02:08:59.298511: Pseudo dice [np.float32(0.9457), np.float32(0.8507)] 
2025-01-27 02:08:59.301109: Epoch time: 48.69 s 
2025-01-27 02:08:59.303612: Yayy! New best EMA pseudo Dice: 0.8766000270843506 
2025-01-27 02:09:01.105651:  
2025-01-27 02:09:01.109257: Epoch 68 
2025-01-27 02:09:01.112184: Current learning rate: 0.00939 
2025-01-27 02:09:49.467684: train_loss -0.7606 
2025-01-27 02:09:49.473271: val_loss -0.7186 
2025-01-27 02:09:49.475950: Pseudo dice [np.float32(0.943), np.float32(0.8339)] 
2025-01-27 02:09:49.478575: Epoch time: 48.36 s 
2025-01-27 02:09:49.481122: Yayy! New best EMA pseudo Dice: 0.8777999877929688 
2025-01-27 02:09:51.277285:  
2025-01-27 02:09:51.280568: Epoch 69 
2025-01-27 02:09:51.283617: Current learning rate: 0.00938 
2025-01-27 02:10:39.854191: train_loss -0.7663 
2025-01-27 02:10:39.858917: val_loss -0.7102 
2025-01-27 02:10:39.862095: Pseudo dice [np.float32(0.9296), np.float32(0.7181)] 
2025-01-27 02:10:39.865332: Epoch time: 48.58 s 
2025-01-27 02:10:41.076742:  
2025-01-27 02:10:41.080178: Epoch 70 
2025-01-27 02:10:41.083170: Current learning rate: 0.00937 
2025-01-27 02:11:29.752460: train_loss -0.768 
2025-01-27 02:11:29.758087: val_loss -0.7331 
2025-01-27 02:11:29.760904: Pseudo dice [np.float32(0.9535), np.float32(0.8758)] 
2025-01-27 02:11:29.763414: Epoch time: 48.68 s 
2025-01-27 02:11:30.969755:  
2025-01-27 02:11:30.972963: Epoch 71 
2025-01-27 02:11:30.975742: Current learning rate: 0.00936 
2025-01-27 02:12:19.586815: train_loss -0.757 
2025-01-27 02:12:19.591274: val_loss -0.7455 
2025-01-27 02:12:19.594013: Pseudo dice [np.float32(0.9466), np.float32(0.8561)] 
2025-01-27 02:12:19.596871: Epoch time: 48.62 s 
2025-01-27 02:12:19.599512: Yayy! New best EMA pseudo Dice: 0.8791000247001648 
2025-01-27 02:12:21.405219:  
2025-01-27 02:12:21.408261: Epoch 72 
2025-01-27 02:12:21.411298: Current learning rate: 0.00935 
2025-01-27 02:13:09.846582: train_loss -0.7737 
2025-01-27 02:13:09.852485: val_loss -0.723 
2025-01-27 02:13:09.855121: Pseudo dice [np.float32(0.9401), np.float32(0.8674)] 
2025-01-27 02:13:09.857903: Epoch time: 48.44 s 
2025-01-27 02:13:09.860519: Yayy! New best EMA pseudo Dice: 0.8815000057220459 
2025-01-27 02:13:12.283492:  
2025-01-27 02:13:12.286999: Epoch 73 
2025-01-27 02:13:12.290102: Current learning rate: 0.00934 
2025-01-27 02:14:01.332455: train_loss -0.7655 
2025-01-27 02:14:01.338012: val_loss -0.7472 
2025-01-27 02:14:01.341209: Pseudo dice [np.float32(0.9465), np.float32(0.824)] 
2025-01-27 02:14:01.344002: Epoch time: 49.05 s 
2025-01-27 02:14:01.346973: Yayy! New best EMA pseudo Dice: 0.8819000124931335 
2025-01-27 02:14:03.175880:  
2025-01-27 02:14:03.179397: Epoch 74 
2025-01-27 02:14:03.182928: Current learning rate: 0.00933 
2025-01-27 02:14:51.726309: train_loss -0.7554 
2025-01-27 02:14:51.732219: val_loss -0.7382 
2025-01-27 02:14:51.735005: Pseudo dice [np.float32(0.9396), np.float32(0.8645)] 
2025-01-27 02:14:51.737877: Epoch time: 48.55 s 
2025-01-27 02:14:51.740556: Yayy! New best EMA pseudo Dice: 0.883899986743927 
2025-01-27 02:14:53.688629:  
2025-01-27 02:14:53.691880: Epoch 75 
2025-01-27 02:14:53.694654: Current learning rate: 0.00932 
2025-01-27 02:15:42.193967: train_loss -0.789 
2025-01-27 02:15:42.198387: val_loss -0.7874 
2025-01-27 02:15:42.201013: Pseudo dice [np.float32(0.951), np.float32(0.8944)] 
2025-01-27 02:15:42.203653: Epoch time: 48.51 s 
2025-01-27 02:15:42.206249: Yayy! New best EMA pseudo Dice: 0.8877999782562256 
2025-01-27 02:15:43.978595:  
2025-01-27 02:15:43.982267: Epoch 76 
2025-01-27 02:15:43.985814: Current learning rate: 0.00931 
2025-01-27 02:16:32.774510: train_loss -0.7763 
2025-01-27 02:16:32.779612: val_loss -0.7087 
2025-01-27 02:16:32.782179: Pseudo dice [np.float32(0.9409), np.float32(0.8626)] 
2025-01-27 02:16:32.784488: Epoch time: 48.8 s 
2025-01-27 02:16:32.786786: Yayy! New best EMA pseudo Dice: 0.88919997215271 
2025-01-27 02:16:34.636006:  
2025-01-27 02:16:34.638595: Epoch 77 
2025-01-27 02:16:34.641127: Current learning rate: 0.0093 
2025-01-27 02:17:23.206878: train_loss -0.769 
2025-01-27 02:17:23.214618: val_loss -0.7463 
2025-01-27 02:17:23.217566: Pseudo dice [np.float32(0.9387), np.float32(0.8453)] 
2025-01-27 02:17:23.220383: Epoch time: 48.57 s 
2025-01-27 02:17:23.222819: Yayy! New best EMA pseudo Dice: 0.8895000219345093 
2025-01-27 02:17:25.041821:  
2025-01-27 02:17:25.044888: Epoch 78 
2025-01-27 02:17:25.047969: Current learning rate: 0.0093 
2025-01-27 02:18:13.877272: train_loss -0.7971 
2025-01-27 02:18:13.883811: val_loss -0.7231 
2025-01-27 02:18:13.886908: Pseudo dice [np.float32(0.9432), np.float32(0.8666)] 
2025-01-27 02:18:13.890038: Epoch time: 48.84 s 
2025-01-27 02:18:13.893283: Yayy! New best EMA pseudo Dice: 0.890999972820282 
2025-01-27 02:18:15.724992:  
2025-01-27 02:18:15.728026: Epoch 79 
2025-01-27 02:18:15.731079: Current learning rate: 0.00929 
2025-01-27 02:19:04.845601: train_loss -0.7817 
2025-01-27 02:19:04.850490: val_loss -0.7697 
2025-01-27 02:19:04.853264: Pseudo dice [np.float32(0.9512), np.float32(0.8627)] 
2025-01-27 02:19:04.856121: Epoch time: 49.12 s 
2025-01-27 02:19:04.858845: Yayy! New best EMA pseudo Dice: 0.8925999999046326 
2025-01-27 02:19:06.691510:  
2025-01-27 02:19:06.694860: Epoch 80 
2025-01-27 02:19:06.698156: Current learning rate: 0.00928 
2025-01-27 02:19:55.709645: train_loss -0.7639 
2025-01-27 02:19:55.714753: val_loss -0.7209 
2025-01-27 02:19:55.717171: Pseudo dice [np.float32(0.9457), np.float32(0.8057)] 
2025-01-27 02:19:55.719944: Epoch time: 49.02 s 
2025-01-27 02:19:56.937835:  
2025-01-27 02:19:56.941053: Epoch 81 
2025-01-27 02:19:56.944229: Current learning rate: 0.00927 
2025-01-27 02:20:45.958097: train_loss -0.7491 
2025-01-27 02:20:45.962453: val_loss -0.7406 
2025-01-27 02:20:45.964889: Pseudo dice [np.float32(0.9477), np.float32(0.8521)] 
2025-01-27 02:20:45.967715: Epoch time: 49.02 s 
2025-01-27 02:20:47.202223:  
2025-01-27 02:20:47.205464: Epoch 82 
2025-01-27 02:20:47.208787: Current learning rate: 0.00926 
2025-01-27 02:21:35.890071: train_loss -0.7632 
2025-01-27 02:21:35.898564: val_loss -0.6937 
2025-01-27 02:21:35.901297: Pseudo dice [np.float32(0.9375), np.float32(0.7907)] 
2025-01-27 02:21:35.904052: Epoch time: 48.69 s 
2025-01-27 02:21:37.058990:  
2025-01-27 02:21:37.062094: Epoch 83 
2025-01-27 02:21:37.065053: Current learning rate: 0.00925 
2025-01-27 02:22:25.522312: train_loss -0.7557 
2025-01-27 02:22:25.527606: val_loss -0.783 
2025-01-27 02:22:25.530679: Pseudo dice [np.float32(0.9519), np.float32(0.8653)] 
2025-01-27 02:22:25.533220: Epoch time: 48.46 s 
2025-01-27 02:22:26.770667:  
2025-01-27 02:22:26.774094: Epoch 84 
2025-01-27 02:22:26.777355: Current learning rate: 0.00924 
2025-01-27 02:23:15.450832: train_loss -0.7615 
2025-01-27 02:23:15.456688: val_loss -0.7626 
2025-01-27 02:23:15.459225: Pseudo dice [np.float32(0.9427), np.float32(0.8476)] 
2025-01-27 02:23:15.461888: Epoch time: 48.68 s 
2025-01-27 02:23:16.618294:  
2025-01-27 02:23:16.621592: Epoch 85 
2025-01-27 02:23:16.624272: Current learning rate: 0.00923 
2025-01-27 02:24:05.449787: train_loss -0.7678 
2025-01-27 02:24:05.457332: val_loss -0.7512 
2025-01-27 02:24:05.460573: Pseudo dice [np.float32(0.9465), np.float32(0.87)] 
2025-01-27 02:24:05.463719: Epoch time: 48.83 s 
2025-01-27 02:24:05.466691: Yayy! New best EMA pseudo Dice: 0.8931000232696533 
2025-01-27 02:24:07.172160:  
2025-01-27 02:24:07.175495: Epoch 86 
2025-01-27 02:24:07.178581: Current learning rate: 0.00922 
2025-01-27 02:24:55.980912: train_loss -0.7992 
2025-01-27 02:24:55.986963: val_loss -0.7576 
2025-01-27 02:24:55.989634: Pseudo dice [np.float32(0.9452), np.float32(0.8528)] 
2025-01-27 02:24:55.992086: Epoch time: 48.81 s 
2025-01-27 02:24:55.994547: Yayy! New best EMA pseudo Dice: 0.8937000036239624 
2025-01-27 02:24:57.763819:  
2025-01-27 02:24:57.767887: Epoch 87 
2025-01-27 02:24:57.771429: Current learning rate: 0.00921 
2025-01-27 02:25:46.877974: train_loss -0.7416 
2025-01-27 02:25:46.881988: val_loss -0.7179 
2025-01-27 02:25:46.884748: Pseudo dice [np.float32(0.9311), np.float32(0.8238)] 
2025-01-27 02:25:46.887653: Epoch time: 49.12 s 
2025-01-27 02:25:48.034227:  
2025-01-27 02:25:48.037264: Epoch 88 
2025-01-27 02:25:48.040089: Current learning rate: 0.0092 
2025-01-27 02:26:36.555005: train_loss -0.761 
2025-01-27 02:26:36.560501: val_loss -0.6885 
2025-01-27 02:26:36.563116: Pseudo dice [np.float32(0.929), np.float32(0.7131)] 
2025-01-27 02:26:36.565674: Epoch time: 48.52 s 
2025-01-27 02:26:37.726599:  
2025-01-27 02:26:37.731577: Epoch 89 
2025-01-27 02:26:37.734678: Current learning rate: 0.0092 
2025-01-27 02:27:26.262377: train_loss -0.7622 
2025-01-27 02:27:26.266743: val_loss -0.7224 
2025-01-27 02:27:26.269202: Pseudo dice [np.float32(0.9391), np.float32(0.8318)] 
2025-01-27 02:27:26.272017: Epoch time: 48.54 s 
2025-01-27 02:27:27.423819:  
2025-01-27 02:27:27.427403: Epoch 90 
2025-01-27 02:27:27.430971: Current learning rate: 0.00919 
2025-01-27 02:28:16.052898: train_loss -0.7754 
2025-01-27 02:28:16.058544: val_loss -0.7262 
2025-01-27 02:28:16.061456: Pseudo dice [np.float32(0.9395), np.float32(0.8179)] 
2025-01-27 02:28:16.063918: Epoch time: 48.63 s 
2025-01-27 02:28:17.244894:  
2025-01-27 02:28:17.248128: Epoch 91 
2025-01-27 02:28:17.253775: Current learning rate: 0.00918 
2025-01-27 02:29:06.280691: train_loss -0.7722 
2025-01-27 02:29:06.287115: val_loss -0.7319 
2025-01-27 02:29:06.289963: Pseudo dice [np.float32(0.9558), np.float32(0.8583)] 
2025-01-27 02:29:06.292681: Epoch time: 49.04 s 
2025-01-27 02:29:08.066787:  
2025-01-27 02:29:08.069994: Epoch 92 
2025-01-27 02:29:08.072903: Current learning rate: 0.00917 
2025-01-27 02:29:56.510312: train_loss -0.7815 
2025-01-27 02:29:56.515263: val_loss -0.7641 
2025-01-27 02:29:56.517779: Pseudo dice [np.float32(0.946), np.float32(0.8726)] 
2025-01-27 02:29:56.520134: Epoch time: 48.44 s 
2025-01-27 02:29:57.663496:  
2025-01-27 02:29:57.666361: Epoch 93 
2025-01-27 02:29:57.668952: Current learning rate: 0.00916 
2025-01-27 02:30:46.743461: train_loss -0.7799 
2025-01-27 02:30:46.747961: val_loss -0.7839 
2025-01-27 02:30:46.750817: Pseudo dice [np.float32(0.9541), np.float32(0.8692)] 
2025-01-27 02:30:46.753571: Epoch time: 49.08 s 
2025-01-27 02:30:47.899825:  
2025-01-27 02:30:47.902868: Epoch 94 
2025-01-27 02:30:47.906105: Current learning rate: 0.00915 
2025-01-27 02:31:36.826803: train_loss -0.8016 
2025-01-27 02:31:36.833235: val_loss -0.7742 
2025-01-27 02:31:36.835954: Pseudo dice [np.float32(0.9506), np.float32(0.8825)] 
2025-01-27 02:31:36.838535: Epoch time: 48.93 s 
2025-01-27 02:31:36.841262: Yayy! New best EMA pseudo Dice: 0.8937000036239624 
2025-01-27 02:31:38.602693:  
2025-01-27 02:31:38.605767: Epoch 95 
2025-01-27 02:31:38.608593: Current learning rate: 0.00914 
2025-01-27 02:32:27.197323: train_loss -0.7602 
2025-01-27 02:32:27.203379: val_loss -0.7248 
2025-01-27 02:32:27.206133: Pseudo dice [np.float32(0.952), np.float32(0.8151)] 
2025-01-27 02:32:27.208656: Epoch time: 48.6 s 
2025-01-27 02:32:28.347835:  
2025-01-27 02:32:28.351521: Epoch 96 
2025-01-27 02:32:28.354669: Current learning rate: 0.00913 
2025-01-27 02:33:17.807505: train_loss -0.7849 
2025-01-27 02:33:17.816960: val_loss -0.7548 
2025-01-27 02:33:17.819767: Pseudo dice [np.float32(0.9506), np.float32(0.8684)] 
2025-01-27 02:33:17.822549: Epoch time: 49.46 s 
2025-01-27 02:33:17.825754: Yayy! New best EMA pseudo Dice: 0.8944000005722046 
2025-01-27 02:33:19.539111:  
2025-01-27 02:33:19.541961: Epoch 97 
2025-01-27 02:33:19.544726: Current learning rate: 0.00912 
2025-01-27 02:34:07.929380: train_loss -0.7694 
2025-01-27 02:34:07.933703: val_loss -0.7489 
2025-01-27 02:34:07.936514: Pseudo dice [np.float32(0.941), np.float32(0.8609)] 
2025-01-27 02:34:07.939388: Epoch time: 48.39 s 
2025-01-27 02:34:07.941687: Yayy! New best EMA pseudo Dice: 0.8949999809265137 
2025-01-27 02:34:09.713598:  
2025-01-27 02:34:09.716785: Epoch 98 
2025-01-27 02:34:09.719716: Current learning rate: 0.00911 
2025-01-27 02:34:58.117923: train_loss -0.7796 
2025-01-27 02:34:58.124213: val_loss -0.768 
2025-01-27 02:34:58.127121: Pseudo dice [np.float32(0.945), np.float32(0.8739)] 
2025-01-27 02:34:58.130044: Epoch time: 48.41 s 
2025-01-27 02:34:58.133018: Yayy! New best EMA pseudo Dice: 0.8964999914169312 
2025-01-27 02:34:59.891766:  
2025-01-27 02:34:59.894899: Epoch 99 
2025-01-27 02:34:59.898062: Current learning rate: 0.0091 
2025-01-27 02:35:48.679581: train_loss -0.7853 
2025-01-27 02:35:48.685456: val_loss -0.7053 
2025-01-27 02:35:48.688151: Pseudo dice [np.float32(0.9499), np.float32(0.8757)] 
2025-01-27 02:35:48.690671: Epoch time: 48.79 s 
2025-01-27 02:35:49.273961: Yayy! New best EMA pseudo Dice: 0.8981000185012817 
2025-01-27 02:35:50.994382:  
2025-01-27 02:35:50.997764: Epoch 100 
2025-01-27 02:35:51.000661: Current learning rate: 0.0091 
2025-01-27 02:36:39.838608: train_loss -0.7483 
2025-01-27 02:36:39.844584: val_loss -0.7374 
2025-01-27 02:36:39.847238: Pseudo dice [np.float32(0.945), np.float32(0.835)] 
2025-01-27 02:36:39.849854: Epoch time: 48.85 s 
2025-01-27 02:36:41.045015:  
2025-01-27 02:36:41.049077: Epoch 101 
2025-01-27 02:36:41.052188: Current learning rate: 0.00909 
2025-01-27 02:37:30.000152: train_loss -0.7613 
2025-01-27 02:37:30.004403: val_loss -0.7412 
2025-01-27 02:37:30.007093: Pseudo dice [np.float32(0.9461), np.float32(0.8725)] 
2025-01-27 02:37:30.009693: Epoch time: 48.96 s 
2025-01-27 02:37:30.012004: Yayy! New best EMA pseudo Dice: 0.8985000252723694 
2025-01-27 02:37:31.754781:  
2025-01-27 02:37:31.757711: Epoch 102 
2025-01-27 02:37:31.760447: Current learning rate: 0.00908 
2025-01-27 02:38:20.203259: train_loss -0.7755 
2025-01-27 02:38:20.209551: val_loss -0.7603 
2025-01-27 02:38:20.212514: Pseudo dice [np.float32(0.9372), np.float32(0.8464)] 
2025-01-27 02:38:20.215352: Epoch time: 48.45 s 
2025-01-27 02:38:21.373345:  
2025-01-27 02:38:21.376354: Epoch 103 
2025-01-27 02:38:21.379233: Current learning rate: 0.00907 
2025-01-27 02:39:09.952190: train_loss -0.7558 
2025-01-27 02:39:09.957082: val_loss -0.6929 
2025-01-27 02:39:09.960250: Pseudo dice [np.float32(0.9349), np.float32(0.7109)] 
2025-01-27 02:39:09.963310: Epoch time: 48.58 s 
2025-01-27 02:39:11.169094:  
2025-01-27 02:39:11.172673: Epoch 104 
2025-01-27 02:39:11.175715: Current learning rate: 0.00906 
2025-01-27 02:39:59.652797: train_loss -0.7754 
2025-01-27 02:39:59.660994: val_loss -0.7515 
2025-01-27 02:39:59.663676: Pseudo dice [np.float32(0.9475), np.float32(0.8831)] 
2025-01-27 02:39:59.666229: Epoch time: 48.48 s 
2025-01-27 02:40:00.822948:  
2025-01-27 02:40:00.825695: Epoch 105 
2025-01-27 02:40:00.828188: Current learning rate: 0.00905 
2025-01-27 02:40:49.281890: train_loss -0.7877 
2025-01-27 02:40:49.289582: val_loss -0.7687 
2025-01-27 02:40:49.293233: Pseudo dice [np.float32(0.9464), np.float32(0.8732)] 
2025-01-27 02:40:49.296418: Epoch time: 48.46 s 
2025-01-27 02:40:50.498266:  
2025-01-27 02:40:50.501237: Epoch 106 
2025-01-27 02:40:50.504060: Current learning rate: 0.00904 
2025-01-27 02:41:39.020678: train_loss -0.7817 
2025-01-27 02:41:39.027155: val_loss -0.7392 
2025-01-27 02:41:39.030782: Pseudo dice [np.float32(0.9486), np.float32(0.8601)] 
2025-01-27 02:41:39.033644: Epoch time: 48.52 s 
2025-01-27 02:41:40.207579:  
2025-01-27 02:41:40.210633: Epoch 107 
2025-01-27 02:41:40.213636: Current learning rate: 0.00903 
2025-01-27 02:42:28.958139: train_loss -0.7844 
2025-01-27 02:42:28.963133: val_loss -0.7312 
2025-01-27 02:42:28.966063: Pseudo dice [np.float32(0.9491), np.float32(0.8601)] 
2025-01-27 02:42:28.969109: Epoch time: 48.75 s 
2025-01-27 02:42:30.149870:  
2025-01-27 02:42:30.152892: Epoch 108 
2025-01-27 02:42:30.155931: Current learning rate: 0.00902 
2025-01-27 02:43:18.473788: train_loss -0.7754 
2025-01-27 02:43:18.480535: val_loss -0.7889 
2025-01-27 02:43:18.483633: Pseudo dice [np.float32(0.9535), np.float32(0.865)] 
2025-01-27 02:43:18.486580: Epoch time: 48.32 s 
2025-01-27 02:43:19.650980:  
2025-01-27 02:43:19.653897: Epoch 109 
2025-01-27 02:43:19.656567: Current learning rate: 0.00901 
2025-01-27 02:44:08.426170: train_loss -0.789 
2025-01-27 02:44:08.432360: val_loss -0.7771 
2025-01-27 02:44:08.435098: Pseudo dice [np.float32(0.9505), np.float32(0.8811)] 
2025-01-27 02:44:08.437845: Epoch time: 48.78 s 
2025-01-27 02:44:08.440681: Yayy! New best EMA pseudo Dice: 0.8995000123977661 
2025-01-27 02:44:10.206639:  
2025-01-27 02:44:10.209960: Epoch 110 
2025-01-27 02:44:10.212934: Current learning rate: 0.009 
2025-01-27 02:44:58.430138: train_loss -0.7816 
2025-01-27 02:44:58.438987: val_loss -0.7416 
2025-01-27 02:44:58.441890: Pseudo dice [np.float32(0.95), np.float32(0.8641)] 
2025-01-27 02:44:58.444692: Epoch time: 48.22 s 
2025-01-27 02:44:58.447371: Yayy! New best EMA pseudo Dice: 0.9003000259399414 
2025-01-27 02:45:00.171578:  
2025-01-27 02:45:00.175210: Epoch 111 
2025-01-27 02:45:00.178369: Current learning rate: 0.009 
2025-01-27 02:45:48.806251: train_loss -0.7863 
2025-01-27 02:45:48.812341: val_loss -0.731 
2025-01-27 02:45:48.814946: Pseudo dice [np.float32(0.9467), np.float32(0.8513)] 
2025-01-27 02:45:48.817647: Epoch time: 48.64 s 
2025-01-27 02:45:50.661267:  
2025-01-27 02:45:50.664003: Epoch 112 
2025-01-27 02:45:50.666705: Current learning rate: 0.00899 
2025-01-27 02:46:39.272422: train_loss -0.7882 
2025-01-27 02:46:39.280252: val_loss -0.7377 
2025-01-27 02:46:39.282869: Pseudo dice [np.float32(0.9431), np.float32(0.8678)] 
2025-01-27 02:46:39.285401: Epoch time: 48.61 s 
2025-01-27 02:46:39.288195: Yayy! New best EMA pseudo Dice: 0.9006999731063843 
2025-01-27 02:46:41.044535:  
2025-01-27 02:46:41.048289: Epoch 113 
2025-01-27 02:46:41.051377: Current learning rate: 0.00898 
2025-01-27 02:47:29.494241: train_loss -0.8002 
2025-01-27 02:47:29.500058: val_loss -0.7649 
2025-01-27 02:47:29.502679: Pseudo dice [np.float32(0.9475), np.float32(0.863)] 
2025-01-27 02:47:29.505646: Epoch time: 48.45 s 
2025-01-27 02:47:29.508377: Yayy! New best EMA pseudo Dice: 0.9010999798774719 
2025-01-27 02:47:31.435051:  
2025-01-27 02:47:31.438049: Epoch 114 
2025-01-27 02:47:31.441140: Current learning rate: 0.00897 
2025-01-27 02:48:20.734110: train_loss -0.7403 
2025-01-27 02:48:20.740720: val_loss -0.7476 
2025-01-27 02:48:20.743312: Pseudo dice [np.float32(0.9509), np.float32(0.8048)] 
2025-01-27 02:48:20.745930: Epoch time: 49.3 s 
2025-01-27 02:48:21.916461:  
2025-01-27 02:48:21.919744: Epoch 115 
2025-01-27 02:48:21.922797: Current learning rate: 0.00896 
2025-01-27 02:49:10.366183: train_loss -0.7773 
2025-01-27 02:49:10.373149: val_loss -0.7285 
2025-01-27 02:49:10.375755: Pseudo dice [np.float32(0.9447), np.float32(0.852)] 
2025-01-27 02:49:10.378846: Epoch time: 48.45 s 
2025-01-27 02:49:11.579350:  
2025-01-27 02:49:11.582952: Epoch 116 
2025-01-27 02:49:11.586634: Current learning rate: 0.00895 
2025-01-27 02:50:00.343164: train_loss -0.7942 
2025-01-27 02:50:00.351919: val_loss -0.7523 
2025-01-27 02:50:00.355480: Pseudo dice [np.float32(0.9536), np.float32(0.81)] 
2025-01-27 02:50:00.358582: Epoch time: 48.76 s 
2025-01-27 02:50:01.581953:  
2025-01-27 02:50:01.585503: Epoch 117 
2025-01-27 02:50:01.588403: Current learning rate: 0.00894 
2025-01-27 02:50:50.298692: train_loss -0.7908 
2025-01-27 02:50:50.305653: val_loss -0.7733 
2025-01-27 02:50:50.308450: Pseudo dice [np.float32(0.9549), np.float32(0.8574)] 
2025-01-27 02:50:50.311256: Epoch time: 48.72 s 
2025-01-27 02:50:51.500791:  
2025-01-27 02:50:51.504497: Epoch 118 
2025-01-27 02:50:51.507504: Current learning rate: 0.00893 
2025-01-27 02:51:39.864591: train_loss -0.7678 
2025-01-27 02:51:39.872778: val_loss -0.7386 
2025-01-27 02:51:39.875832: Pseudo dice [np.float32(0.9407), np.float32(0.8593)] 
2025-01-27 02:51:39.878898: Epoch time: 48.36 s 
2025-01-27 02:51:41.065157:  
2025-01-27 02:51:41.068134: Epoch 119 
2025-01-27 02:51:41.072299: Current learning rate: 0.00892 
2025-01-27 02:52:29.958967: train_loss -0.76 
2025-01-27 02:52:29.965056: val_loss -0.6913 
2025-01-27 02:52:29.967717: Pseudo dice [np.float32(0.9233), np.float32(0.7925)] 
2025-01-27 02:52:29.970225: Epoch time: 48.89 s 
2025-01-27 02:52:31.150188:  
2025-01-27 02:52:31.153764: Epoch 120 
2025-01-27 02:52:31.156607: Current learning rate: 0.00891 
2025-01-27 02:53:20.041426: train_loss -0.7237 
2025-01-27 02:53:20.049695: val_loss -0.7381 
2025-01-27 02:53:20.052757: Pseudo dice [np.float32(0.9388), np.float32(0.8346)] 
2025-01-27 02:53:20.055604: Epoch time: 48.89 s 
2025-01-27 02:53:21.279687:  
2025-01-27 02:53:21.282680: Epoch 121 
2025-01-27 02:53:21.285294: Current learning rate: 0.0089 
2025-01-27 02:54:10.291158: train_loss -0.7684 
2025-01-27 02:54:10.297422: val_loss -0.7474 
2025-01-27 02:54:10.300302: Pseudo dice [np.float32(0.9476), np.float32(0.8632)] 
2025-01-27 02:54:10.302939: Epoch time: 49.01 s 
2025-01-27 02:54:11.481284:  
2025-01-27 02:54:11.484815: Epoch 122 
2025-01-27 02:54:11.487607: Current learning rate: 0.00889 
2025-01-27 02:55:00.603841: train_loss -0.785 
2025-01-27 02:55:00.611374: val_loss -0.7661 
2025-01-27 02:55:00.615703: Pseudo dice [np.float32(0.947), np.float32(0.8856)] 
2025-01-27 02:55:00.618886: Epoch time: 49.12 s 
2025-01-27 02:55:01.795573:  
2025-01-27 02:55:01.798499: Epoch 123 
2025-01-27 02:55:01.801490: Current learning rate: 0.00889 
2025-01-27 02:55:50.762447: train_loss -0.782 
2025-01-27 02:55:50.768939: val_loss -0.7431 
2025-01-27 02:55:50.771968: Pseudo dice [np.float32(0.9448), np.float32(0.8483)] 
2025-01-27 02:55:50.775265: Epoch time: 48.97 s 
2025-01-27 02:55:51.958787:  
2025-01-27 02:55:51.962246: Epoch 124 
2025-01-27 02:55:51.965246: Current learning rate: 0.00888 
2025-01-27 02:56:41.469612: train_loss -0.7908 
2025-01-27 02:56:41.476556: val_loss -0.7497 
2025-01-27 02:56:41.479682: Pseudo dice [np.float32(0.944), np.float32(0.8616)] 
2025-01-27 02:56:41.482428: Epoch time: 49.51 s 
2025-01-27 02:56:42.681095:  
2025-01-27 02:56:42.683822: Epoch 125 
2025-01-27 02:56:42.686826: Current learning rate: 0.00887 
2025-01-27 02:57:31.269832: train_loss -0.7403 
2025-01-27 02:57:31.277251: val_loss -0.753 
2025-01-27 02:57:31.280069: Pseudo dice [np.float32(0.9488), np.float32(0.816)] 
2025-01-27 02:57:31.283335: Epoch time: 48.59 s 
2025-01-27 02:57:32.463331:  
2025-01-27 02:57:32.466286: Epoch 126 
2025-01-27 02:57:32.468872: Current learning rate: 0.00886 
2025-01-27 02:58:21.695069: train_loss -0.7653 
2025-01-27 02:58:21.701694: val_loss -0.6812 
2025-01-27 02:58:21.704362: Pseudo dice [np.float32(0.9393), np.float32(0.785)] 
2025-01-27 02:58:21.707247: Epoch time: 49.23 s 
2025-01-27 02:58:22.882936:  
2025-01-27 02:58:22.886079: Epoch 127 
2025-01-27 02:58:22.888792: Current learning rate: 0.00885 
2025-01-27 02:59:11.641778: train_loss -0.7613 
2025-01-27 02:59:11.649870: val_loss -0.7457 
2025-01-27 02:59:11.653080: Pseudo dice [np.float32(0.9357), np.float32(0.7674)] 
2025-01-27 02:59:11.655736: Epoch time: 48.76 s 
2025-01-27 02:59:12.840907:  
2025-01-27 02:59:12.844167: Epoch 128 
2025-01-27 02:59:12.846870: Current learning rate: 0.00884 
2025-01-27 03:00:01.642160: train_loss -0.7832 
2025-01-27 03:00:01.649788: val_loss -0.7878 
2025-01-27 03:00:01.652823: Pseudo dice [np.float32(0.9329), np.float32(0.8585)] 
2025-01-27 03:00:01.656029: Epoch time: 48.8 s 
2025-01-27 03:00:02.890949:  
2025-01-27 03:00:02.894637: Epoch 129 
2025-01-27 03:00:02.897593: Current learning rate: 0.00883 
2025-01-27 03:00:51.365533: train_loss -0.7944 
2025-01-27 03:00:51.373821: val_loss -0.7379 
2025-01-27 03:00:51.379097: Pseudo dice [np.float32(0.9586), np.float32(0.8888)] 
2025-01-27 03:00:51.382001: Epoch time: 48.48 s 
2025-01-27 03:00:52.570849:  
2025-01-27 03:00:52.573801: Epoch 130 
2025-01-27 03:00:52.576972: Current learning rate: 0.00882 
2025-01-27 03:01:41.398870: train_loss -0.7893 
2025-01-27 03:01:41.405705: val_loss -0.7352 
2025-01-27 03:01:41.408861: Pseudo dice [np.float32(0.9494), np.float32(0.8779)] 
2025-01-27 03:01:41.411735: Epoch time: 48.83 s 
2025-01-27 03:01:43.236228:  
2025-01-27 03:01:43.239192: Epoch 131 
2025-01-27 03:01:43.242141: Current learning rate: 0.00881 
2025-01-27 03:02:31.768347: train_loss -0.7908 
2025-01-27 03:02:31.774354: val_loss -0.7647 
2025-01-27 03:02:31.776809: Pseudo dice [np.float32(0.9507), np.float32(0.8893)] 
2025-01-27 03:02:31.779346: Epoch time: 48.53 s 
2025-01-27 03:02:32.965292:  
2025-01-27 03:02:32.968289: Epoch 132 
2025-01-27 03:02:32.971482: Current learning rate: 0.0088 
2025-01-27 03:03:21.886803: train_loss -0.7836 
2025-01-27 03:03:21.893337: val_loss -0.7543 
2025-01-27 03:03:21.896163: Pseudo dice [np.float32(0.9487), np.float32(0.8348)] 
2025-01-27 03:03:21.898958: Epoch time: 48.92 s 
2025-01-27 03:03:23.124032:  
2025-01-27 03:03:23.127097: Epoch 133 
2025-01-27 03:03:23.130732: Current learning rate: 0.00879 
2025-01-27 03:04:11.792156: train_loss -0.8095 
2025-01-27 03:04:11.798076: val_loss -0.7589 
2025-01-27 03:04:11.800862: Pseudo dice [np.float32(0.9327), np.float32(0.8521)] 
2025-01-27 03:04:11.803624: Epoch time: 48.67 s 
2025-01-27 03:04:13.008152:  
2025-01-27 03:04:13.011139: Epoch 134 
2025-01-27 03:04:13.014215: Current learning rate: 0.00879 
2025-01-27 03:05:01.285058: train_loss -0.8002 
2025-01-27 03:05:01.292161: val_loss -0.7692 
2025-01-27 03:05:01.295251: Pseudo dice [np.float32(0.9508), np.float32(0.848)] 
2025-01-27 03:05:01.298090: Epoch time: 48.28 s 
2025-01-27 03:05:02.502408:  
2025-01-27 03:05:02.505684: Epoch 135 
2025-01-27 03:05:02.508792: Current learning rate: 0.00878 
2025-01-27 03:05:50.981544: train_loss -0.7985 
2025-01-27 03:05:50.987692: val_loss -0.724 
2025-01-27 03:05:50.990591: Pseudo dice [np.float32(0.9489), np.float32(0.8417)] 
2025-01-27 03:05:50.993335: Epoch time: 48.48 s 
2025-01-27 03:05:52.194704:  
2025-01-27 03:05:52.197529: Epoch 136 
2025-01-27 03:05:52.200141: Current learning rate: 0.00877 
2025-01-27 03:06:40.786174: train_loss -0.8023 
2025-01-27 03:06:40.793594: val_loss -0.7459 
2025-01-27 03:06:40.796656: Pseudo dice [np.float32(0.9519), np.float32(0.8517)] 
2025-01-27 03:06:40.799361: Epoch time: 48.59 s 
2025-01-27 03:06:41.992513:  
2025-01-27 03:06:41.995875: Epoch 137 
2025-01-27 03:06:41.999123: Current learning rate: 0.00876 
2025-01-27 03:07:30.714870: train_loss -0.8019 
2025-01-27 03:07:30.721121: val_loss -0.7323 
2025-01-27 03:07:30.724017: Pseudo dice [np.float32(0.9485), np.float32(0.7642)] 
2025-01-27 03:07:30.726517: Epoch time: 48.72 s 
2025-01-27 03:07:31.925187:  
2025-01-27 03:07:31.928483: Epoch 138 
2025-01-27 03:07:31.931418: Current learning rate: 0.00875 
2025-01-27 03:08:20.696623: train_loss -0.7939 
2025-01-27 03:08:20.702643: val_loss -0.7219 
2025-01-27 03:08:20.705563: Pseudo dice [np.float32(0.9528), np.float32(0.8601)] 
2025-01-27 03:08:20.708386: Epoch time: 48.77 s 
2025-01-27 03:08:21.934305:  
2025-01-27 03:08:21.937507: Epoch 139 
2025-01-27 03:08:21.940129: Current learning rate: 0.00874 
2025-01-27 03:09:10.608840: train_loss -0.809 
2025-01-27 03:09:10.614809: val_loss -0.766 
2025-01-27 03:09:10.617711: Pseudo dice [np.float32(0.9485), np.float32(0.8501)] 
2025-01-27 03:09:10.621017: Epoch time: 48.68 s 
2025-01-27 03:09:11.819880:  
2025-01-27 03:09:11.823498: Epoch 140 
2025-01-27 03:09:11.826537: Current learning rate: 0.00873 
2025-01-27 03:10:00.620121: train_loss -0.7931 
2025-01-27 03:10:00.626972: val_loss -0.7488 
2025-01-27 03:10:00.629776: Pseudo dice [np.float32(0.9472), np.float32(0.858)] 
2025-01-27 03:10:00.632544: Epoch time: 48.8 s 
2025-01-27 03:10:01.829928:  
2025-01-27 03:10:01.833338: Epoch 141 
2025-01-27 03:10:01.836297: Current learning rate: 0.00872 
2025-01-27 03:10:50.570573: train_loss -0.8 
2025-01-27 03:10:50.577301: val_loss -0.7294 
2025-01-27 03:10:50.580302: Pseudo dice [np.float32(0.9417), np.float32(0.8486)] 
2025-01-27 03:10:50.582955: Epoch time: 48.74 s 
2025-01-27 03:10:51.791756:  
2025-01-27 03:10:51.794727: Epoch 142 
2025-01-27 03:10:51.797667: Current learning rate: 0.00871 
2025-01-27 03:11:39.899649: train_loss -0.795 
2025-01-27 03:11:39.906511: val_loss -0.7675 
2025-01-27 03:11:39.909221: Pseudo dice [np.float32(0.9564), np.float32(0.8968)] 
2025-01-27 03:11:39.911991: Epoch time: 48.11 s 
2025-01-27 03:11:41.133005:  
2025-01-27 03:11:41.136227: Epoch 143 
2025-01-27 03:11:41.139166: Current learning rate: 0.0087 
2025-01-27 03:12:30.065134: train_loss -0.8003 
2025-01-27 03:12:30.072431: val_loss -0.7708 
2025-01-27 03:12:30.075282: Pseudo dice [np.float32(0.9511), np.float32(0.8539)] 
2025-01-27 03:12:30.077989: Epoch time: 48.93 s 
2025-01-27 03:12:31.261693:  
2025-01-27 03:12:31.264632: Epoch 144 
2025-01-27 03:12:31.267624: Current learning rate: 0.00869 
2025-01-27 03:13:19.836525: train_loss -0.8082 
2025-01-27 03:13:19.842433: val_loss -0.7839 
2025-01-27 03:13:19.845014: Pseudo dice [np.float32(0.95), np.float32(0.8932)] 
2025-01-27 03:13:19.847348: Epoch time: 48.58 s 
2025-01-27 03:13:19.849751: Yayy! New best EMA pseudo Dice: 0.9013000130653381 
2025-01-27 03:13:21.607292:  
2025-01-27 03:13:21.610276: Epoch 145 
2025-01-27 03:13:21.612955: Current learning rate: 0.00868 
2025-01-27 03:14:10.091184: train_loss -0.8134 
2025-01-27 03:14:10.097151: val_loss -0.7691 
2025-01-27 03:14:10.099974: Pseudo dice [np.float32(0.9496), np.float32(0.8295)] 
2025-01-27 03:14:10.102520: Epoch time: 48.49 s 
2025-01-27 03:14:11.294896:  
2025-01-27 03:14:11.298295: Epoch 146 
2025-01-27 03:14:11.301769: Current learning rate: 0.00868 
2025-01-27 03:14:59.744593: train_loss -0.7967 
2025-01-27 03:14:59.751678: val_loss -0.7588 
2025-01-27 03:14:59.754586: Pseudo dice [np.float32(0.9537), np.float32(0.8755)] 
2025-01-27 03:14:59.757571: Epoch time: 48.45 s 
2025-01-27 03:14:59.760303: Yayy! New best EMA pseudo Dice: 0.9014999866485596 
2025-01-27 03:15:01.551256:  
2025-01-27 03:15:01.553921: Epoch 147 
2025-01-27 03:15:01.556919: Current learning rate: 0.00867 
2025-01-27 03:15:50.384588: train_loss -0.8036 
2025-01-27 03:15:50.391348: val_loss -0.7828 
2025-01-27 03:15:50.394677: Pseudo dice [np.float32(0.9469), np.float32(0.871)] 
2025-01-27 03:15:50.397667: Epoch time: 48.83 s 
2025-01-27 03:15:50.400506: Yayy! New best EMA pseudo Dice: 0.9023000001907349 
2025-01-27 03:15:52.155701:  
2025-01-27 03:15:52.159055: Epoch 148 
2025-01-27 03:15:52.162340: Current learning rate: 0.00866 
2025-01-27 03:16:40.899180: train_loss -0.7991 
2025-01-27 03:16:40.905636: val_loss -0.772 
2025-01-27 03:16:40.908757: Pseudo dice [np.float32(0.9552), np.float32(0.8166)] 
2025-01-27 03:16:40.911507: Epoch time: 48.74 s 
2025-01-27 03:16:42.102827:  
2025-01-27 03:16:42.105917: Epoch 149 
2025-01-27 03:16:42.108792: Current learning rate: 0.00865 
2025-01-27 03:17:31.195484: train_loss -0.799 
2025-01-27 03:17:31.202466: val_loss -0.7197 
2025-01-27 03:17:31.205608: Pseudo dice [np.float32(0.9509), np.float32(0.8762)] 
2025-01-27 03:17:31.208874: Epoch time: 49.09 s 
2025-01-27 03:17:33.018031:  
2025-01-27 03:17:33.020993: Epoch 150 
2025-01-27 03:17:33.024086: Current learning rate: 0.00864 
2025-01-27 03:18:21.838953: train_loss -0.8026 
2025-01-27 03:18:21.845596: val_loss -0.7413 
2025-01-27 03:18:21.848514: Pseudo dice [np.float32(0.9443), np.float32(0.8785)] 
2025-01-27 03:18:21.851208: Epoch time: 48.82 s 
2025-01-27 03:18:21.853761: Yayy! New best EMA pseudo Dice: 0.902899980545044 
2025-01-27 03:18:23.658110:  
2025-01-27 03:18:23.661014: Epoch 151 
2025-01-27 03:18:23.663747: Current learning rate: 0.00863 
2025-01-27 03:19:12.502163: train_loss -0.7992 
2025-01-27 03:19:12.507995: val_loss -0.75 
2025-01-27 03:19:12.510680: Pseudo dice [np.float32(0.9528), np.float32(0.863)] 
2025-01-27 03:19:12.513576: Epoch time: 48.84 s 
2025-01-27 03:19:12.516953: Yayy! New best EMA pseudo Dice: 0.9034000039100647 
2025-01-27 03:19:14.265024:  
2025-01-27 03:19:14.268780: Epoch 152 
2025-01-27 03:19:14.271980: Current learning rate: 0.00862 
2025-01-27 03:20:02.923501: train_loss -0.7843 
2025-01-27 03:20:02.930837: val_loss -0.7249 
2025-01-27 03:20:02.933852: Pseudo dice [np.float32(0.9397), np.float32(0.8508)] 
2025-01-27 03:20:02.936606: Epoch time: 48.66 s 
2025-01-27 03:20:04.132663:  
2025-01-27 03:20:04.135522: Epoch 153 
2025-01-27 03:20:04.138492: Current learning rate: 0.00861 
2025-01-27 03:20:53.228451: train_loss -0.7675 
2025-01-27 03:20:53.233088: val_loss -0.7523 
2025-01-27 03:20:53.235962: Pseudo dice [np.float32(0.945), np.float32(0.8674)] 
2025-01-27 03:20:53.238930: Epoch time: 49.1 s 
2025-01-27 03:20:54.500937:  
2025-01-27 03:20:54.504031: Epoch 154 
2025-01-27 03:20:54.506980: Current learning rate: 0.0086 
2025-01-27 03:21:42.706605: train_loss -0.7887 
2025-01-27 03:21:42.734338: val_loss -0.7186 
2025-01-27 03:21:42.737233: Pseudo dice [np.float32(0.9505), np.float32(0.8783)] 
2025-01-27 03:21:42.739781: Epoch time: 48.21 s 
2025-01-27 03:21:42.742316: Yayy! New best EMA pseudo Dice: 0.9041000008583069 
2025-01-27 03:21:44.562661:  
2025-01-27 03:21:44.565767: Epoch 155 
2025-01-27 03:21:44.568657: Current learning rate: 0.00859 
2025-01-27 03:22:33.254095: train_loss -0.7767 
2025-01-27 03:22:33.260990: val_loss -0.7323 
2025-01-27 03:22:33.263757: Pseudo dice [np.float32(0.9484), np.float32(0.8234)] 
2025-01-27 03:22:33.266392: Epoch time: 48.69 s 
2025-01-27 03:22:34.486164:  
2025-01-27 03:22:34.489102: Epoch 156 
2025-01-27 03:22:34.491817: Current learning rate: 0.00858 
2025-01-27 03:23:23.374346: train_loss -0.7923 
2025-01-27 03:23:23.382208: val_loss -0.774 
2025-01-27 03:23:23.385153: Pseudo dice [np.float32(0.9462), np.float32(0.8771)] 
2025-01-27 03:23:23.387803: Epoch time: 48.89 s 
2025-01-27 03:23:24.613608:  
2025-01-27 03:23:24.616895: Epoch 157 
2025-01-27 03:23:24.619850: Current learning rate: 0.00858 
2025-01-27 03:24:13.373120: train_loss -0.7989 
2025-01-27 03:24:13.379138: val_loss -0.7146 
2025-01-27 03:24:13.382147: Pseudo dice [np.float32(0.9471), np.float32(0.8223)] 
2025-01-27 03:24:13.384888: Epoch time: 48.76 s 
2025-01-27 03:24:14.630230:  
2025-01-27 03:24:14.633236: Epoch 158 
2025-01-27 03:24:14.636060: Current learning rate: 0.00857 
2025-01-27 03:25:03.153610: train_loss -0.8133 
2025-01-27 03:25:03.160265: val_loss -0.7767 
2025-01-27 03:25:03.163138: Pseudo dice [np.float32(0.9504), np.float32(0.8627)] 
2025-01-27 03:25:03.166264: Epoch time: 48.52 s 
2025-01-27 03:25:04.373626:  
2025-01-27 03:25:04.377285: Epoch 159 
2025-01-27 03:25:04.380402: Current learning rate: 0.00856 
2025-01-27 03:25:52.906271: train_loss -0.7889 
2025-01-27 03:25:52.913422: val_loss -0.795 
2025-01-27 03:25:52.916360: Pseudo dice [np.float32(0.9518), np.float32(0.8731)] 
2025-01-27 03:25:52.919084: Epoch time: 48.53 s 
2025-01-27 03:25:54.134191:  
2025-01-27 03:25:54.137644: Epoch 160 
2025-01-27 03:25:54.140583: Current learning rate: 0.00855 
2025-01-27 03:26:42.487608: train_loss -0.8036 
2025-01-27 03:26:42.496706: val_loss -0.745 
2025-01-27 03:26:42.499897: Pseudo dice [np.float32(0.9559), np.float32(0.8492)] 
2025-01-27 03:26:42.503249: Epoch time: 48.35 s 
2025-01-27 03:26:43.721321:  
2025-01-27 03:26:43.725487: Epoch 161 
2025-01-27 03:26:43.728458: Current learning rate: 0.00854 
2025-01-27 03:27:32.496821: train_loss -0.8138 
2025-01-27 03:27:32.502154: val_loss -0.7869 
2025-01-27 03:27:32.504664: Pseudo dice [np.float32(0.9509), np.float32(0.8745)] 
2025-01-27 03:27:32.507240: Epoch time: 48.78 s 
2025-01-27 03:27:33.718213:  
2025-01-27 03:27:33.721185: Epoch 162 
2025-01-27 03:27:33.723797: Current learning rate: 0.00853 
2025-01-27 03:28:22.283522: train_loss -0.7996 
2025-01-27 03:28:22.289038: val_loss -0.7638 
2025-01-27 03:28:22.291578: Pseudo dice [np.float32(0.9483), np.float32(0.8429)] 
2025-01-27 03:28:22.294167: Epoch time: 48.57 s 
2025-01-27 03:28:23.522352:  
2025-01-27 03:28:23.525592: Epoch 163 
2025-01-27 03:28:23.528474: Current learning rate: 0.00852 
2025-01-27 03:29:11.940334: train_loss -0.7717 
2025-01-27 03:29:11.947373: val_loss -0.7697 
2025-01-27 03:29:11.950393: Pseudo dice [np.float32(0.9566), np.float32(0.8729)] 
2025-01-27 03:29:11.953319: Epoch time: 48.42 s 
2025-01-27 03:29:11.956075: Yayy! New best EMA pseudo Dice: 0.90420001745224 
2025-01-27 03:29:13.802636:  
2025-01-27 03:29:13.805995: Epoch 164 
2025-01-27 03:29:13.809057: Current learning rate: 0.00851 
2025-01-27 03:30:02.007904: train_loss -0.799 
2025-01-27 03:30:02.014177: val_loss -0.7289 
2025-01-27 03:30:02.016762: Pseudo dice [np.float32(0.9499), np.float32(0.8144)] 
2025-01-27 03:30:02.019362: Epoch time: 48.21 s 
2025-01-27 03:30:03.211037:  
2025-01-27 03:30:03.214685: Epoch 165 
2025-01-27 03:30:03.218020: Current learning rate: 0.0085 
2025-01-27 03:30:51.740757: train_loss -0.7986 
2025-01-27 03:30:51.745795: val_loss -0.7225 
2025-01-27 03:30:51.748510: Pseudo dice [np.float32(0.9445), np.float32(0.8262)] 
2025-01-27 03:30:51.751254: Epoch time: 48.53 s 
2025-01-27 03:30:52.972194:  
2025-01-27 03:30:52.975552: Epoch 166 
2025-01-27 03:30:52.978581: Current learning rate: 0.00849 
2025-01-27 03:31:41.332214: train_loss -0.8029 
2025-01-27 03:31:41.338003: val_loss -0.7528 
2025-01-27 03:31:41.340697: Pseudo dice [np.float32(0.9533), np.float32(0.9067)] 
2025-01-27 03:31:41.343417: Epoch time: 48.36 s 
2025-01-27 03:31:43.090563:  
2025-01-27 03:31:43.093755: Epoch 167 
2025-01-27 03:31:43.096655: Current learning rate: 0.00848 
2025-01-27 03:32:31.543239: train_loss -0.8001 
2025-01-27 03:32:31.547771: val_loss -0.7568 
2025-01-27 03:32:31.550494: Pseudo dice [np.float32(0.9453), np.float32(0.8767)] 
2025-01-27 03:32:31.553209: Epoch time: 48.45 s 
2025-01-27 03:32:32.791891:  
2025-01-27 03:32:32.795051: Epoch 168 
2025-01-27 03:32:32.797968: Current learning rate: 0.00847 
2025-01-27 03:33:21.430625: train_loss -0.8023 
2025-01-27 03:33:21.436832: val_loss -0.7558 
2025-01-27 03:33:21.439917: Pseudo dice [np.float32(0.9473), np.float32(0.8535)] 
2025-01-27 03:33:21.442639: Epoch time: 48.64 s 
2025-01-27 03:33:22.645615:  
2025-01-27 03:33:22.649001: Epoch 169 
2025-01-27 03:33:22.653744: Current learning rate: 0.00847 
2025-01-27 03:34:11.014606: train_loss -0.8064 
2025-01-27 03:34:11.019201: val_loss -0.73 
2025-01-27 03:34:11.022069: Pseudo dice [np.float32(0.9491), np.float32(0.851)] 
2025-01-27 03:34:11.024770: Epoch time: 48.37 s 
2025-01-27 03:34:12.269039:  
2025-01-27 03:34:12.272492: Epoch 170 
2025-01-27 03:34:12.275524: Current learning rate: 0.00846 
2025-01-27 03:35:00.900848: train_loss -0.811 
2025-01-27 03:35:00.907230: val_loss -0.7623 
2025-01-27 03:35:00.910031: Pseudo dice [np.float32(0.9546), np.float32(0.8537)] 
2025-01-27 03:35:00.912812: Epoch time: 48.63 s 
2025-01-27 03:35:02.122191:  
2025-01-27 03:35:02.125828: Epoch 171 
2025-01-27 03:35:02.129080: Current learning rate: 0.00845 
2025-01-27 03:35:51.478119: train_loss -0.8123 
2025-01-27 03:35:51.482374: val_loss -0.7388 
2025-01-27 03:35:51.485056: Pseudo dice [np.float32(0.9548), np.float32(0.8943)] 
2025-01-27 03:35:51.487755: Epoch time: 49.36 s 
2025-01-27 03:35:51.490547: Yayy! New best EMA pseudo Dice: 0.9054999947547913 
2025-01-27 03:35:53.284358:  
2025-01-27 03:35:53.287209: Epoch 172 
2025-01-27 03:35:53.289961: Current learning rate: 0.00844 
2025-01-27 03:36:41.734404: train_loss -0.8103 
2025-01-27 03:36:41.741308: val_loss -0.8014 
2025-01-27 03:36:41.744573: Pseudo dice [np.float32(0.9545), np.float32(0.8992)] 
2025-01-27 03:36:41.747537: Epoch time: 48.45 s 
2025-01-27 03:36:41.750329: Yayy! New best EMA pseudo Dice: 0.9077000021934509 
2025-01-27 03:36:43.550598:  
2025-01-27 03:36:43.554534: Epoch 173 
2025-01-27 03:36:43.557482: Current learning rate: 0.00843 
2025-01-27 03:37:32.693599: train_loss -0.8116 
2025-01-27 03:37:32.698130: val_loss -0.7824 
2025-01-27 03:37:32.700930: Pseudo dice [np.float32(0.9522), np.float32(0.8808)] 
2025-01-27 03:37:32.703392: Epoch time: 49.14 s 
2025-01-27 03:37:32.705777: Yayy! New best EMA pseudo Dice: 0.9085000157356262 
2025-01-27 03:37:34.546781:  
2025-01-27 03:37:34.550122: Epoch 174 
2025-01-27 03:37:34.553496: Current learning rate: 0.00842 
2025-01-27 03:38:23.589075: train_loss -0.8045 
2025-01-27 03:38:23.595390: val_loss -0.7487 
2025-01-27 03:38:23.598791: Pseudo dice [np.float32(0.9523), np.float32(0.8523)] 
2025-01-27 03:38:23.601582: Epoch time: 49.04 s 
2025-01-27 03:38:24.814516:  
2025-01-27 03:38:24.817673: Epoch 175 
2025-01-27 03:38:24.820552: Current learning rate: 0.00841 
2025-01-27 03:39:13.114464: train_loss -0.7975 
2025-01-27 03:39:13.118818: val_loss -0.7946 
2025-01-27 03:39:13.121392: Pseudo dice [np.float32(0.9541), np.float32(0.885)] 
2025-01-27 03:39:13.124392: Epoch time: 48.3 s 
2025-01-27 03:39:13.127048: Yayy! New best EMA pseudo Dice: 0.9090999960899353 
2025-01-27 03:39:14.884702:  
2025-01-27 03:39:14.887449: Epoch 176 
2025-01-27 03:39:14.890182: Current learning rate: 0.0084 
2025-01-27 03:40:03.584097: train_loss -0.8145 
2025-01-27 03:40:03.590375: val_loss -0.7482 
2025-01-27 03:40:03.593447: Pseudo dice [np.float32(0.9506), np.float32(0.8413)] 
2025-01-27 03:40:03.596423: Epoch time: 48.7 s 
2025-01-27 03:40:04.797833:  
2025-01-27 03:40:04.801090: Epoch 177 
2025-01-27 03:40:04.804282: Current learning rate: 0.00839 
2025-01-27 03:40:53.312112: train_loss -0.788 
2025-01-27 03:40:53.316478: val_loss -0.7444 
2025-01-27 03:40:53.319225: Pseudo dice [np.float32(0.9412), np.float32(0.785)] 
2025-01-27 03:40:53.321749: Epoch time: 48.52 s 
2025-01-27 03:40:54.555204:  
2025-01-27 03:40:54.558416: Epoch 178 
2025-01-27 03:40:54.561486: Current learning rate: 0.00838 
2025-01-27 03:41:43.578274: train_loss -0.8046 
2025-01-27 03:41:43.584660: val_loss -0.717 
2025-01-27 03:41:43.587493: Pseudo dice [np.float32(0.9503), np.float32(0.7993)] 
2025-01-27 03:41:43.590423: Epoch time: 49.02 s 
2025-01-27 03:41:44.792908:  
2025-01-27 03:41:44.797440: Epoch 179 
2025-01-27 03:41:44.800151: Current learning rate: 0.00837 
2025-01-27 03:42:33.266612: train_loss -0.7875 
2025-01-27 03:42:33.271433: val_loss -0.7563 
2025-01-27 03:42:33.274508: Pseudo dice [np.float32(0.9395), np.float32(0.8316)] 
2025-01-27 03:42:33.277184: Epoch time: 48.47 s 
2025-01-27 03:42:34.477487:  
2025-01-27 03:42:34.481070: Epoch 180 
2025-01-27 03:42:34.484214: Current learning rate: 0.00836 
2025-01-27 03:43:22.933188: train_loss -0.7771 
2025-01-27 03:43:22.939212: val_loss -0.7378 
2025-01-27 03:43:22.942143: Pseudo dice [np.float32(0.9444), np.float32(0.8073)] 
2025-01-27 03:43:22.945029: Epoch time: 48.46 s 
2025-01-27 03:43:24.160653:  
2025-01-27 03:43:24.164026: Epoch 181 
2025-01-27 03:43:24.167116: Current learning rate: 0.00836 
2025-01-27 03:44:12.941958: train_loss -0.7954 
2025-01-27 03:44:12.948868: val_loss -0.7278 
2025-01-27 03:44:12.951737: Pseudo dice [np.float32(0.9499), np.float32(0.8037)] 
2025-01-27 03:44:12.954651: Epoch time: 48.78 s 
2025-01-27 03:44:14.196345:  
2025-01-27 03:44:14.200357: Epoch 182 
2025-01-27 03:44:14.203960: Current learning rate: 0.00835 
2025-01-27 03:45:02.711037: train_loss -0.8145 
2025-01-27 03:45:02.717483: val_loss -0.7741 
2025-01-27 03:45:02.720451: Pseudo dice [np.float32(0.9511), np.float32(0.8738)] 
2025-01-27 03:45:02.723367: Epoch time: 48.52 s 
2025-01-27 03:45:03.927179:  
2025-01-27 03:45:03.930365: Epoch 183 
2025-01-27 03:45:03.933268: Current learning rate: 0.00834 
2025-01-27 03:45:52.463960: train_loss -0.7901 
2025-01-27 03:45:52.470882: val_loss -0.7659 
2025-01-27 03:45:52.473853: Pseudo dice [np.float32(0.9579), np.float32(0.8755)] 
2025-01-27 03:45:52.476842: Epoch time: 48.54 s 
2025-01-27 03:45:53.686574:  
2025-01-27 03:45:53.689810: Epoch 184 
2025-01-27 03:45:53.692657: Current learning rate: 0.00833 
2025-01-27 03:46:42.280736: train_loss -0.8246 
2025-01-27 03:46:42.286586: val_loss -0.7275 
2025-01-27 03:46:42.289432: Pseudo dice [np.float32(0.9537), np.float32(0.8663)] 
2025-01-27 03:46:42.292219: Epoch time: 48.6 s 
2025-01-27 03:46:44.106443:  
2025-01-27 03:46:44.110000: Epoch 185 
2025-01-27 03:46:44.113007: Current learning rate: 0.00832 
2025-01-27 03:47:32.460857: train_loss -0.8101 
2025-01-27 03:47:32.465365: val_loss -0.753 
2025-01-27 03:47:32.468062: Pseudo dice [np.float32(0.9501), np.float32(0.861)] 
2025-01-27 03:47:32.470733: Epoch time: 48.36 s 
2025-01-27 03:47:33.712648:  
2025-01-27 03:47:33.715783: Epoch 186 
2025-01-27 03:47:33.718920: Current learning rate: 0.00831 
2025-01-27 03:48:23.307052: train_loss -0.7925 
2025-01-27 03:48:23.315090: val_loss -0.7435 
2025-01-27 03:48:23.318201: Pseudo dice [np.float32(0.953), np.float32(0.8742)] 
2025-01-27 03:48:23.321027: Epoch time: 49.6 s 
2025-01-27 03:48:24.565440:  
2025-01-27 03:48:24.568794: Epoch 187 
2025-01-27 03:48:24.572028: Current learning rate: 0.0083 
2025-01-27 03:49:13.391981: train_loss -0.7918 
2025-01-27 03:49:13.396548: val_loss -0.7568 
2025-01-27 03:49:13.399796: Pseudo dice [np.float32(0.9407), np.float32(0.8432)] 
2025-01-27 03:49:13.402663: Epoch time: 48.83 s 
2025-01-27 03:49:14.602089:  
2025-01-27 03:49:14.605406: Epoch 188 
2025-01-27 03:49:14.608262: Current learning rate: 0.00829 
2025-01-27 03:50:03.382101: train_loss -0.8049 
2025-01-27 03:50:03.389149: val_loss -0.7581 
2025-01-27 03:50:03.392028: Pseudo dice [np.float32(0.9538), np.float32(0.8473)] 
2025-01-27 03:50:03.394964: Epoch time: 48.78 s 
2025-01-27 03:50:04.594513:  
2025-01-27 03:50:04.597548: Epoch 189 
2025-01-27 03:50:04.600182: Current learning rate: 0.00828 
2025-01-27 03:50:53.470695: train_loss -0.7883 
2025-01-27 03:50:53.475296: val_loss -0.7263 
2025-01-27 03:50:53.478015: Pseudo dice [np.float32(0.9362), np.float32(0.8525)] 
2025-01-27 03:50:53.480738: Epoch time: 48.88 s 
2025-01-27 03:50:54.694362:  
2025-01-27 03:50:54.697620: Epoch 190 
2025-01-27 03:50:54.700998: Current learning rate: 0.00827 
2025-01-27 03:51:43.145715: train_loss -0.7784 
2025-01-27 03:51:43.150629: val_loss -0.7595 
2025-01-27 03:51:43.153361: Pseudo dice [np.float32(0.9566), np.float32(0.8586)] 
2025-01-27 03:51:43.155860: Epoch time: 48.45 s 
2025-01-27 03:51:44.381623:  
2025-01-27 03:51:44.384580: Epoch 191 
2025-01-27 03:51:44.387464: Current learning rate: 0.00826 
2025-01-27 03:52:32.952659: train_loss -0.8063 
2025-01-27 03:52:32.958023: val_loss -0.7561 
2025-01-27 03:52:32.960967: Pseudo dice [np.float32(0.9529), np.float32(0.8703)] 
2025-01-27 03:52:32.964383: Epoch time: 48.57 s 
2025-01-27 03:52:34.177800:  
2025-01-27 03:52:34.181031: Epoch 192 
2025-01-27 03:52:34.183921: Current learning rate: 0.00825 
2025-01-27 03:53:22.743393: train_loss -0.8072 
2025-01-27 03:53:22.749689: val_loss -0.7709 
2025-01-27 03:53:22.752517: Pseudo dice [np.float32(0.953), np.float32(0.8955)] 
2025-01-27 03:53:22.755555: Epoch time: 48.57 s 
2025-01-27 03:53:24.013809:  
2025-01-27 03:53:24.017577: Epoch 193 
2025-01-27 03:53:24.020447: Current learning rate: 0.00824 
2025-01-27 03:54:12.704987: train_loss -0.8078 
2025-01-27 03:54:12.709542: val_loss -0.768 
2025-01-27 03:54:12.712120: Pseudo dice [np.float32(0.9626), np.float32(0.889)] 
2025-01-27 03:54:12.715128: Epoch time: 48.69 s 
2025-01-27 03:54:13.935839:  
2025-01-27 03:54:13.939106: Epoch 194 
2025-01-27 03:54:13.942303: Current learning rate: 0.00824 
2025-01-27 03:55:03.236011: train_loss -0.8116 
2025-01-27 03:55:03.242275: val_loss -0.7714 
2025-01-27 03:55:03.245189: Pseudo dice [np.float32(0.9554), np.float32(0.8845)] 
2025-01-27 03:55:03.247707: Epoch time: 49.3 s 
2025-01-27 03:55:04.455310:  
2025-01-27 03:55:04.458432: Epoch 195 
2025-01-27 03:55:04.461381: Current learning rate: 0.00823 
2025-01-27 03:55:53.360702: train_loss -0.7933 
2025-01-27 03:55:53.368308: val_loss -0.7876 
2025-01-27 03:55:53.371800: Pseudo dice [np.float32(0.9421), np.float32(0.8635)] 
2025-01-27 03:55:53.374784: Epoch time: 48.91 s 
2025-01-27 03:55:54.616525:  
2025-01-27 03:55:54.619656: Epoch 196 
2025-01-27 03:55:54.622642: Current learning rate: 0.00822 
2025-01-27 03:56:43.524113: train_loss -0.7578 
2025-01-27 03:56:43.530014: val_loss -0.7176 
2025-01-27 03:56:43.533097: Pseudo dice [np.float32(0.9398), np.float32(0.827)] 
2025-01-27 03:56:43.535916: Epoch time: 48.91 s 
2025-01-27 03:56:44.794705:  
2025-01-27 03:56:44.797948: Epoch 197 
2025-01-27 03:56:44.801126: Current learning rate: 0.00821 
2025-01-27 03:57:33.386104: train_loss -0.7685 
2025-01-27 03:57:33.391301: val_loss -0.7732 
2025-01-27 03:57:33.394565: Pseudo dice [np.float32(0.9444), np.float32(0.8392)] 
2025-01-27 03:57:33.397681: Epoch time: 48.59 s 
2025-01-27 03:57:34.618061:  
2025-01-27 03:57:34.621507: Epoch 198 
2025-01-27 03:57:34.624625: Current learning rate: 0.0082 
2025-01-27 03:58:23.161064: train_loss -0.7649 
2025-01-27 03:58:23.166582: val_loss -0.7268 
2025-01-27 03:58:23.169030: Pseudo dice [np.float32(0.9536), np.float32(0.8205)] 
2025-01-27 03:58:23.171658: Epoch time: 48.54 s 
2025-01-27 03:58:24.387136:  
2025-01-27 03:58:24.390187: Epoch 199 
2025-01-27 03:58:24.393042: Current learning rate: 0.00819 
2025-01-27 03:59:13.169217: train_loss -0.7954 
2025-01-27 03:59:13.176022: val_loss -0.7574 
2025-01-27 03:59:13.178950: Pseudo dice [np.float32(0.9532), np.float32(0.8798)] 
2025-01-27 03:59:13.181754: Epoch time: 48.78 s 
2025-01-27 03:59:14.978512:  
2025-01-27 03:59:14.981724: Epoch 200 
2025-01-27 03:59:14.984750: Current learning rate: 0.00818 
2025-01-27 04:00:03.408601: train_loss -0.8071 
2025-01-27 04:00:03.415123: val_loss -0.7534 
2025-01-27 04:00:03.418378: Pseudo dice [np.float32(0.9557), np.float32(0.8499)] 
2025-01-27 04:00:03.421381: Epoch time: 48.43 s 
2025-01-27 04:00:04.671327:  
2025-01-27 04:00:04.674637: Epoch 201 
2025-01-27 04:00:04.677692: Current learning rate: 0.00817 
2025-01-27 04:00:53.082593: train_loss -0.8101 
2025-01-27 04:00:53.086858: val_loss -0.7791 
2025-01-27 04:00:53.089570: Pseudo dice [np.float32(0.9521), np.float32(0.8958)] 
2025-01-27 04:00:53.092516: Epoch time: 48.41 s 
2025-01-27 04:00:54.342892:  
2025-01-27 04:00:54.345541: Epoch 202 
2025-01-27 04:00:54.348170: Current learning rate: 0.00816 
2025-01-27 04:01:42.763265: train_loss -0.8055 
2025-01-27 04:01:42.770730: val_loss -0.695 
2025-01-27 04:01:42.773626: Pseudo dice [np.float32(0.9513), np.float32(0.7904)] 
2025-01-27 04:01:42.776309: Epoch time: 48.42 s 
2025-01-27 04:01:44.599095:  
2025-01-27 04:01:44.602308: Epoch 203 
2025-01-27 04:01:44.604850: Current learning rate: 0.00815 
2025-01-27 04:02:33.224909: train_loss -0.7995 
2025-01-27 04:02:33.231609: val_loss -0.7193 
2025-01-27 04:02:33.234928: Pseudo dice [np.float32(0.9511), np.float32(0.8672)] 
2025-01-27 04:02:33.237743: Epoch time: 48.63 s 
2025-01-27 04:02:34.452876:  
2025-01-27 04:02:34.456390: Epoch 204 
2025-01-27 04:02:34.459177: Current learning rate: 0.00814 
2025-01-27 04:03:22.790550: train_loss -0.8057 
2025-01-27 04:03:22.796689: val_loss -0.7782 
2025-01-27 04:03:22.799475: Pseudo dice [np.float32(0.9597), np.float32(0.8889)] 
2025-01-27 04:03:22.802179: Epoch time: 48.34 s 
2025-01-27 04:03:24.025259:  
2025-01-27 04:03:24.028213: Epoch 205 
2025-01-27 04:03:24.031220: Current learning rate: 0.00813 
2025-01-27 04:04:13.027145: train_loss -0.7951 
2025-01-27 04:04:13.035048: val_loss -0.756 
2025-01-27 04:04:13.038365: Pseudo dice [np.float32(0.9454), np.float32(0.7835)] 
2025-01-27 04:04:13.041382: Epoch time: 49.0 s 
2025-01-27 04:04:14.237808:  
2025-01-27 04:04:14.248102: Epoch 206 
2025-01-27 04:04:14.261757: Current learning rate: 0.00813 
2025-01-27 04:05:02.935915: train_loss -0.7667 
2025-01-27 04:05:02.942717: val_loss -0.7602 
2025-01-27 04:05:02.945718: Pseudo dice [np.float32(0.9516), np.float32(0.7559)] 
2025-01-27 04:05:02.948564: Epoch time: 48.7 s 
2025-01-27 04:05:04.107966:  
2025-01-27 04:05:04.111273: Epoch 207 
2025-01-27 04:05:04.114144: Current learning rate: 0.00812 
2025-01-27 04:05:52.973477: train_loss -0.7856 
2025-01-27 04:05:52.979513: val_loss -0.7417 
2025-01-27 04:05:52.993322: Pseudo dice [np.float32(0.9514), np.float32(0.803)] 
2025-01-27 04:05:53.000353: Epoch time: 48.87 s 
2025-01-27 04:05:54.153356:  
2025-01-27 04:05:54.157579: Epoch 208 
2025-01-27 04:05:54.160972: Current learning rate: 0.00811 
2025-01-27 04:06:43.472979: train_loss -0.795 
2025-01-27 04:06:43.478498: val_loss -0.7863 
2025-01-27 04:06:43.481312: Pseudo dice [np.float32(0.9519), np.float32(0.8655)] 
2025-01-27 04:06:43.483610: Epoch time: 49.32 s 
2025-01-27 04:06:44.674137:  
2025-01-27 04:06:44.677038: Epoch 209 
2025-01-27 04:06:44.679694: Current learning rate: 0.0081 
2025-01-27 04:07:33.629732: train_loss -0.7985 
2025-01-27 04:07:33.636386: val_loss -0.722 
2025-01-27 04:07:33.639048: Pseudo dice [np.float32(0.9517), np.float32(0.8655)] 
2025-01-27 04:07:33.641904: Epoch time: 48.96 s 
2025-01-27 04:07:34.804811:  
2025-01-27 04:07:34.807849: Epoch 210 
2025-01-27 04:07:34.810486: Current learning rate: 0.00809 
2025-01-27 04:08:23.466197: train_loss -0.8079 
2025-01-27 04:08:23.472649: val_loss -0.7609 
2025-01-27 04:08:23.475606: Pseudo dice [np.float32(0.9596), np.float32(0.8986)] 
2025-01-27 04:08:23.478094: Epoch time: 48.66 s 
2025-01-27 04:08:24.633236:  
2025-01-27 04:08:24.636340: Epoch 211 
2025-01-27 04:08:24.639263: Current learning rate: 0.00808 
2025-01-27 04:09:13.624972: train_loss -0.7927 
2025-01-27 04:09:13.629367: val_loss -0.788 
2025-01-27 04:09:13.632010: Pseudo dice [np.float32(0.954), np.float32(0.8627)] 
2025-01-27 04:09:13.634634: Epoch time: 48.99 s 
2025-01-27 04:09:14.796777:  
2025-01-27 04:09:14.800007: Epoch 212 
2025-01-27 04:09:14.803003: Current learning rate: 0.00807 
2025-01-27 04:10:03.489723: train_loss -0.8192 
2025-01-27 04:10:03.496228: val_loss -0.7551 
2025-01-27 04:10:03.499535: Pseudo dice [np.float32(0.9504), np.float32(0.8799)] 
2025-01-27 04:10:03.502433: Epoch time: 48.69 s 
2025-01-27 04:10:04.683986:  
2025-01-27 04:10:04.688162: Epoch 213 
2025-01-27 04:10:04.691420: Current learning rate: 0.00806 
2025-01-27 04:10:53.881428: train_loss -0.8176 
2025-01-27 04:10:53.885894: val_loss -0.7601 
2025-01-27 04:10:53.888881: Pseudo dice [np.float32(0.9525), np.float32(0.8065)] 
2025-01-27 04:10:53.891551: Epoch time: 49.2 s 
2025-01-27 04:10:55.051731:  
2025-01-27 04:10:55.054641: Epoch 214 
2025-01-27 04:10:55.057559: Current learning rate: 0.00805 
2025-01-27 04:11:43.772845: train_loss -0.8001 
2025-01-27 04:11:43.778857: val_loss -0.7266 
2025-01-27 04:11:43.781928: Pseudo dice [np.float32(0.9489), np.float32(0.7995)] 
2025-01-27 04:11:43.784661: Epoch time: 48.72 s 
2025-01-27 04:11:44.973001:  
2025-01-27 04:11:44.976320: Epoch 215 
2025-01-27 04:11:44.979198: Current learning rate: 0.00804 
2025-01-27 04:12:33.813320: train_loss -0.7842 
2025-01-27 04:12:33.817920: val_loss -0.7433 
2025-01-27 04:12:33.820776: Pseudo dice [np.float32(0.9577), np.float32(0.8858)] 
2025-01-27 04:12:33.823751: Epoch time: 48.84 s 
2025-01-27 04:12:34.990241:  
2025-01-27 04:12:34.993106: Epoch 216 
2025-01-27 04:12:34.996010: Current learning rate: 0.00803 
2025-01-27 04:13:23.537883: train_loss -0.792 
2025-01-27 04:13:23.544674: val_loss -0.7585 
2025-01-27 04:13:23.547668: Pseudo dice [np.float32(0.9416), np.float32(0.8268)] 
2025-01-27 04:13:23.550832: Epoch time: 48.55 s 
2025-01-27 04:13:24.704121:  
2025-01-27 04:13:24.707071: Epoch 217 
2025-01-27 04:13:24.709927: Current learning rate: 0.00802 
2025-01-27 04:14:13.594600: train_loss -0.816 
2025-01-27 04:14:13.598969: val_loss -0.7596 
2025-01-27 04:14:13.601510: Pseudo dice [np.float32(0.9552), np.float32(0.88)] 
2025-01-27 04:14:13.604390: Epoch time: 48.89 s 
2025-01-27 04:14:14.798586:  
2025-01-27 04:14:14.801786: Epoch 218 
2025-01-27 04:14:14.805039: Current learning rate: 0.00801 
2025-01-27 04:15:03.721219: train_loss -0.8124 
2025-01-27 04:15:03.726379: val_loss -0.7772 
2025-01-27 04:15:03.728722: Pseudo dice [np.float32(0.9551), np.float32(0.8958)] 
2025-01-27 04:15:03.730956: Epoch time: 48.92 s 
2025-01-27 04:15:04.892836:  
2025-01-27 04:15:04.895835: Epoch 219 
2025-01-27 04:15:04.898624: Current learning rate: 0.00801 
2025-01-27 04:15:53.579286: train_loss -0.8243 
2025-01-27 04:15:53.584286: val_loss -0.7728 
2025-01-27 04:15:53.586973: Pseudo dice [np.float32(0.9508), np.float32(0.8862)] 
2025-01-27 04:15:53.590044: Epoch time: 48.69 s 
2025-01-27 04:15:54.748701:  
2025-01-27 04:15:54.752032: Epoch 220 
2025-01-27 04:15:54.754860: Current learning rate: 0.008 
2025-01-27 04:16:43.854060: train_loss -0.7882 
2025-01-27 04:16:43.859693: val_loss -0.7504 
2025-01-27 04:16:43.862126: Pseudo dice [np.float32(0.9577), np.float32(0.8813)] 
2025-01-27 04:16:43.864583: Epoch time: 49.11 s 
2025-01-27 04:16:45.019886:  
2025-01-27 04:16:45.023170: Epoch 221 
2025-01-27 04:16:45.025915: Current learning rate: 0.00799 
2025-01-27 04:17:33.760317: train_loss -0.7991 
2025-01-27 04:17:33.765369: val_loss -0.7411 
2025-01-27 04:17:33.768291: Pseudo dice [np.float32(0.9594), np.float32(0.8975)] 
2025-01-27 04:17:33.771213: Epoch time: 48.74 s 
2025-01-27 04:17:34.924982:  
2025-01-27 04:17:34.928534: Epoch 222 
2025-01-27 04:17:34.931379: Current learning rate: 0.00798 
2025-01-27 04:18:24.243947: train_loss -0.8076 
2025-01-27 04:18:24.249819: val_loss -0.7818 
2025-01-27 04:18:24.252475: Pseudo dice [np.float32(0.9609), np.float32(0.8681)] 
2025-01-27 04:18:24.255118: Epoch time: 49.32 s 
2025-01-27 04:18:25.404433:  
2025-01-27 04:18:25.408051: Epoch 223 
2025-01-27 04:18:25.410992: Current learning rate: 0.00797 
2025-01-27 04:19:13.992551: train_loss -0.8169 
2025-01-27 04:19:13.997768: val_loss -0.7841 
2025-01-27 04:19:14.000279: Pseudo dice [np.float32(0.9541), np.float32(0.8778)] 
2025-01-27 04:19:14.003125: Epoch time: 48.59 s 
2025-01-27 04:19:14.005979: Yayy! New best EMA pseudo Dice: 0.909500002861023 
2025-01-27 04:19:15.762411:  
2025-01-27 04:19:15.765058: Epoch 224 
2025-01-27 04:19:15.767542: Current learning rate: 0.00796 
2025-01-27 04:20:04.834677: train_loss -0.8025 
2025-01-27 04:20:04.841605: val_loss -0.7417 
2025-01-27 04:20:04.844404: Pseudo dice [np.float32(0.9448), np.float32(0.8298)] 
2025-01-27 04:20:04.846930: Epoch time: 49.07 s 
2025-01-27 04:20:06.014760:  
2025-01-27 04:20:06.017899: Epoch 225 
2025-01-27 04:20:06.020934: Current learning rate: 0.00795 
2025-01-27 04:20:54.781661: train_loss -0.8148 
2025-01-27 04:20:54.786152: val_loss -0.7769 
2025-01-27 04:20:54.788797: Pseudo dice [np.float32(0.9625), np.float32(0.8949)] 
2025-01-27 04:20:54.791515: Epoch time: 48.77 s 
2025-01-27 04:20:55.932890:  
2025-01-27 04:20:55.936298: Epoch 226 
2025-01-27 04:20:55.939503: Current learning rate: 0.00794 
2025-01-27 04:21:44.512990: train_loss -0.8028 
2025-01-27 04:21:44.519199: val_loss -0.7598 
2025-01-27 04:21:44.521947: Pseudo dice [np.float32(0.959), np.float32(0.8865)] 
2025-01-27 04:21:44.524768: Epoch time: 48.58 s 
2025-01-27 04:21:44.527411: Yayy! New best EMA pseudo Dice: 0.9107000231742859 
2025-01-27 04:21:46.228974:  
2025-01-27 04:21:46.231863: Epoch 227 
2025-01-27 04:21:46.234972: Current learning rate: 0.00793 
2025-01-27 04:22:34.551719: train_loss -0.8239 
2025-01-27 04:22:34.556483: val_loss -0.7887 
2025-01-27 04:22:34.559337: Pseudo dice [np.float32(0.955), np.float32(0.8741)] 
2025-01-27 04:22:34.562219: Epoch time: 48.32 s 
2025-01-27 04:22:34.565183: Yayy! New best EMA pseudo Dice: 0.9110999703407288 
2025-01-27 04:22:36.429266:  
2025-01-27 04:22:36.432945: Epoch 228 
2025-01-27 04:22:36.436154: Current learning rate: 0.00792 
2025-01-27 04:23:25.819265: train_loss -0.8072 
2025-01-27 04:23:25.827518: val_loss -0.7244 
2025-01-27 04:23:25.830372: Pseudo dice [np.float32(0.9537), np.float32(0.8542)] 
2025-01-27 04:23:25.833123: Epoch time: 49.39 s 
2025-01-27 04:23:26.972655:  
2025-01-27 04:23:26.975675: Epoch 229 
2025-01-27 04:23:26.978769: Current learning rate: 0.00791 
2025-01-27 04:24:15.487521: train_loss -0.7833 
2025-01-27 04:24:15.493166: val_loss -0.7546 
2025-01-27 04:24:15.496081: Pseudo dice [np.float32(0.9359), np.float32(0.8099)] 
2025-01-27 04:24:15.498955: Epoch time: 48.52 s 
2025-01-27 04:24:16.641337:  
2025-01-27 04:24:16.644389: Epoch 230 
2025-01-27 04:24:16.647784: Current learning rate: 0.0079 
2025-01-27 04:25:05.457987: train_loss -0.7967 
2025-01-27 04:25:05.465992: val_loss -0.7693 
2025-01-27 04:25:05.468602: Pseudo dice [np.float32(0.9555), np.float32(0.8759)] 
2025-01-27 04:25:05.471677: Epoch time: 48.82 s 
2025-01-27 04:25:06.618187:  
2025-01-27 04:25:06.620998: Epoch 231 
2025-01-27 04:25:06.623657: Current learning rate: 0.00789 
2025-01-27 04:25:55.400947: train_loss -0.7812 
2025-01-27 04:25:55.406024: val_loss -0.7625 
2025-01-27 04:25:55.409276: Pseudo dice [np.float32(0.9481), np.float32(0.844)] 
2025-01-27 04:25:55.412467: Epoch time: 48.78 s 
2025-01-27 04:25:56.581446:  
2025-01-27 04:25:56.584494: Epoch 232 
2025-01-27 04:25:56.587526: Current learning rate: 0.00789 
2025-01-27 04:26:45.059477: train_loss -0.7924 
2025-01-27 04:26:45.065479: val_loss -0.7336 
2025-01-27 04:26:45.068003: Pseudo dice [np.float32(0.9383), np.float32(0.7806)] 
2025-01-27 04:26:45.070780: Epoch time: 48.48 s 
2025-01-27 04:26:46.211914:  
2025-01-27 04:26:46.214921: Epoch 233 
2025-01-27 04:26:46.217928: Current learning rate: 0.00788 
2025-01-27 04:27:35.097561: train_loss -0.7783 
2025-01-27 04:27:35.103679: val_loss -0.7406 
2025-01-27 04:27:35.106329: Pseudo dice [np.float32(0.9513), np.float32(0.812)] 
2025-01-27 04:27:35.109003: Epoch time: 48.89 s 
2025-01-27 04:27:36.247945:  
2025-01-27 04:27:36.251130: Epoch 234 
2025-01-27 04:27:36.254304: Current learning rate: 0.00787 
2025-01-27 04:28:25.892973: train_loss -0.7991 
2025-01-27 04:28:25.898634: val_loss -0.7942 
2025-01-27 04:28:25.901265: Pseudo dice [np.float32(0.9481), np.float32(0.8998)] 
2025-01-27 04:28:25.903785: Epoch time: 49.65 s 
2025-01-27 04:28:27.069597:  
2025-01-27 04:28:27.072647: Epoch 235 
2025-01-27 04:28:27.075550: Current learning rate: 0.00786 
2025-01-27 04:29:15.970464: train_loss -0.8089 
2025-01-27 04:29:15.975461: val_loss -0.7767 
2025-01-27 04:29:15.978806: Pseudo dice [np.float32(0.951), np.float32(0.8908)] 
2025-01-27 04:29:15.981731: Epoch time: 48.9 s 
2025-01-27 04:29:17.147508:  
2025-01-27 04:29:17.150856: Epoch 236 
2025-01-27 04:29:17.154269: Current learning rate: 0.00785 
2025-01-27 04:30:05.797746: train_loss -0.7898 
2025-01-27 04:30:05.804821: val_loss -0.714 
2025-01-27 04:30:05.807893: Pseudo dice [np.float32(0.9494), np.float32(0.8291)] 
2025-01-27 04:30:05.810341: Epoch time: 48.65 s 
2025-01-27 04:30:06.974841:  
2025-01-27 04:30:06.977534: Epoch 237 
2025-01-27 04:30:06.980321: Current learning rate: 0.00784 
2025-01-27 04:30:55.246504: train_loss -0.796 
2025-01-27 04:30:55.252962: val_loss -0.7259 
2025-01-27 04:30:55.256063: Pseudo dice [np.float32(0.9521), np.float32(0.8779)] 
2025-01-27 04:30:55.258635: Epoch time: 48.27 s 
2025-01-27 04:30:56.415431:  
2025-01-27 04:30:56.419178: Epoch 238 
2025-01-27 04:30:56.421918: Current learning rate: 0.00783 
2025-01-27 04:31:44.571218: train_loss -0.7933 
2025-01-27 04:31:44.577426: val_loss -0.7722 
2025-01-27 04:31:44.580308: Pseudo dice [np.float32(0.9512), np.float32(0.8378)] 
2025-01-27 04:31:44.582734: Epoch time: 48.16 s 
2025-01-27 04:31:45.741095:  
2025-01-27 04:31:45.744256: Epoch 239 
2025-01-27 04:31:45.747512: Current learning rate: 0.00782 
2025-01-27 04:32:33.963425: train_loss -0.8022 
2025-01-27 04:32:33.967911: val_loss -0.7699 
2025-01-27 04:32:33.970637: Pseudo dice [np.float32(0.9581), np.float32(0.8982)] 
2025-01-27 04:32:33.973479: Epoch time: 48.22 s 
2025-01-27 04:32:35.183611:  
2025-01-27 04:32:35.186768: Epoch 240 
2025-01-27 04:32:35.190300: Current learning rate: 0.00781 
2025-01-27 04:33:23.795972: train_loss -0.807 
2025-01-27 04:33:23.803815: val_loss -0.7791 
2025-01-27 04:33:23.806703: Pseudo dice [np.float32(0.9559), np.float32(0.8643)] 
2025-01-27 04:33:23.809614: Epoch time: 48.61 s 
2025-01-27 04:33:24.986984:  
2025-01-27 04:33:24.989819: Epoch 241 
2025-01-27 04:33:24.992823: Current learning rate: 0.0078 
2025-01-27 04:34:13.484589: train_loss -0.7921 
2025-01-27 04:34:13.490447: val_loss -0.7229 
2025-01-27 04:34:13.492835: Pseudo dice [np.float32(0.9462), np.float32(0.8206)] 
2025-01-27 04:34:13.495740: Epoch time: 48.5 s 
2025-01-27 04:34:15.345106:  
2025-01-27 04:34:15.348421: Epoch 242 
2025-01-27 04:34:15.351312: Current learning rate: 0.00779 
2025-01-27 04:35:03.982413: train_loss -0.7978 
2025-01-27 04:35:03.988455: val_loss -0.7482 
2025-01-27 04:35:03.991438: Pseudo dice [np.float32(0.9475), np.float32(0.8677)] 
2025-01-27 04:35:03.994237: Epoch time: 48.64 s 
2025-01-27 04:35:05.168160:  
2025-01-27 04:35:05.171328: Epoch 243 
2025-01-27 04:35:05.174364: Current learning rate: 0.00778 
2025-01-27 04:35:53.997694: train_loss -0.7912 
2025-01-27 04:35:54.002086: val_loss -0.7616 
2025-01-27 04:35:54.005093: Pseudo dice [np.float32(0.9545), np.float32(0.89)] 
2025-01-27 04:35:54.007823: Epoch time: 48.83 s 
2025-01-27 04:35:55.179400:  
2025-01-27 04:35:55.182767: Epoch 244 
2025-01-27 04:35:55.185776: Current learning rate: 0.00777 
2025-01-27 04:36:44.203183: train_loss -0.7983 
2025-01-27 04:36:44.209707: val_loss -0.7858 
2025-01-27 04:36:44.212516: Pseudo dice [np.float32(0.9538), np.float32(0.8913)] 
2025-01-27 04:36:44.214903: Epoch time: 49.02 s 
2025-01-27 04:36:45.390586:  
2025-01-27 04:36:45.393368: Epoch 245 
2025-01-27 04:36:45.396352: Current learning rate: 0.00777 
2025-01-27 04:37:33.880876: train_loss -0.7973 
2025-01-27 04:37:33.885002: val_loss -0.7216 
2025-01-27 04:37:33.887498: Pseudo dice [np.float32(0.9458), np.float32(0.7815)] 
2025-01-27 04:37:33.890230: Epoch time: 48.49 s 
2025-01-27 04:37:35.064895:  
2025-01-27 04:37:35.068003: Epoch 246 
2025-01-27 04:37:35.071096: Current learning rate: 0.00776 
2025-01-27 04:38:23.373508: train_loss -0.8254 
2025-01-27 04:38:23.380066: val_loss -0.7605 
2025-01-27 04:38:23.382697: Pseudo dice [np.float32(0.9494), np.float32(0.8748)] 
2025-01-27 04:38:23.385534: Epoch time: 48.31 s 
2025-01-27 04:38:24.556884:  
2025-01-27 04:38:24.559988: Epoch 247 
2025-01-27 04:38:24.562635: Current learning rate: 0.00775 
2025-01-27 04:39:13.086908: train_loss -0.8128 
2025-01-27 04:39:13.094660: val_loss -0.7191 
2025-01-27 04:39:13.097638: Pseudo dice [np.float32(0.9433), np.float32(0.8565)] 
2025-01-27 04:39:13.100556: Epoch time: 48.53 s 
2025-01-27 04:39:14.276876:  
2025-01-27 04:39:14.280036: Epoch 248 
2025-01-27 04:39:14.282728: Current learning rate: 0.00774 
2025-01-27 04:40:02.651385: train_loss -0.8058 
2025-01-27 04:40:02.657757: val_loss -0.7345 
2025-01-27 04:40:02.660522: Pseudo dice [np.float32(0.9537), np.float32(0.8455)] 
2025-01-27 04:40:02.663136: Epoch time: 48.38 s 
2025-01-27 04:40:03.833605:  
2025-01-27 04:40:03.836764: Epoch 249 
2025-01-27 04:40:03.839859: Current learning rate: 0.00773 
2025-01-27 04:40:51.865240: train_loss -0.8132 
2025-01-27 04:40:51.872117: val_loss -0.7916 
2025-01-27 04:40:51.874762: Pseudo dice [np.float32(0.9546), np.float32(0.8881)] 
2025-01-27 04:40:51.877534: Epoch time: 48.03 s 
2025-01-27 04:40:53.617391:  
2025-01-27 04:40:53.620768: Epoch 250 
2025-01-27 04:40:53.623836: Current learning rate: 0.00772 
2025-01-27 04:41:41.644382: train_loss -0.8382 
2025-01-27 04:41:41.650383: val_loss -0.7447 
2025-01-27 04:41:41.653204: Pseudo dice [np.float32(0.9521), np.float32(0.8934)] 
2025-01-27 04:41:41.655845: Epoch time: 48.03 s 
2025-01-27 04:41:42.839319:  
2025-01-27 04:41:42.842510: Epoch 251 
2025-01-27 04:41:42.845632: Current learning rate: 0.00771 
2025-01-27 04:42:31.133482: train_loss -0.8038 
2025-01-27 04:42:31.140172: val_loss -0.7914 
2025-01-27 04:42:31.143330: Pseudo dice [np.float32(0.9506), np.float32(0.8822)] 
2025-01-27 04:42:31.146543: Epoch time: 48.3 s 
2025-01-27 04:42:32.333911:  
2025-01-27 04:42:32.337220: Epoch 252 
2025-01-27 04:42:32.340298: Current learning rate: 0.0077 
2025-01-27 04:43:20.558377: train_loss -0.7842 
2025-01-27 04:43:20.564474: val_loss -0.7813 
2025-01-27 04:43:20.567145: Pseudo dice [np.float32(0.9462), np.float32(0.8564)] 
2025-01-27 04:43:20.570232: Epoch time: 48.23 s 
2025-01-27 04:43:21.741705:  
2025-01-27 04:43:21.744775: Epoch 253 
2025-01-27 04:43:21.747740: Current learning rate: 0.00769 
2025-01-27 04:44:10.674494: train_loss -0.8005 
2025-01-27 04:44:10.679350: val_loss -0.7674 
2025-01-27 04:44:10.682459: Pseudo dice [np.float32(0.9538), np.float32(0.8704)] 
2025-01-27 04:44:10.685116: Epoch time: 48.93 s 
2025-01-27 04:44:11.862457:  
2025-01-27 04:44:11.866001: Epoch 254 
2025-01-27 04:44:11.869207: Current learning rate: 0.00768 
2025-01-27 04:45:00.381412: train_loss -0.8254 
2025-01-27 04:45:00.391536: val_loss -0.7727 
2025-01-27 04:45:00.394398: Pseudo dice [np.float32(0.9636), np.float32(0.8683)] 
2025-01-27 04:45:00.396765: Epoch time: 48.52 s 
2025-01-27 04:45:01.564717:  
2025-01-27 04:45:01.567649: Epoch 255 
2025-01-27 04:45:01.570599: Current learning rate: 0.00767 
2025-01-27 04:45:49.763069: train_loss -0.8037 
2025-01-27 04:45:49.767892: val_loss -0.7767 
2025-01-27 04:45:49.770759: Pseudo dice [np.float32(0.9523), np.float32(0.876)] 
2025-01-27 04:45:49.773521: Epoch time: 48.2 s 
2025-01-27 04:45:50.950050:  
2025-01-27 04:45:50.953150: Epoch 256 
2025-01-27 04:45:50.956009: Current learning rate: 0.00766 
2025-01-27 04:46:39.740791: train_loss -0.8028 
2025-01-27 04:46:39.746082: val_loss -0.7648 
2025-01-27 04:46:39.748807: Pseudo dice [np.float32(0.9527), np.float32(0.8409)] 
2025-01-27 04:46:39.751342: Epoch time: 48.79 s 
2025-01-27 04:46:40.922348:  
2025-01-27 04:46:40.926053: Epoch 257 
2025-01-27 04:46:40.928916: Current learning rate: 0.00765 
2025-01-27 04:47:29.772043: train_loss -0.7977 
2025-01-27 04:47:29.776552: val_loss -0.7434 
2025-01-27 04:47:29.779856: Pseudo dice [np.float32(0.9567), np.float32(0.8689)] 
2025-01-27 04:47:29.782680: Epoch time: 48.85 s 
2025-01-27 04:47:30.953826:  
2025-01-27 04:47:30.957118: Epoch 258 
2025-01-27 04:47:30.960203: Current learning rate: 0.00764 
2025-01-27 04:48:19.419294: train_loss -0.8033 
2025-01-27 04:48:19.425189: val_loss -0.7027 
2025-01-27 04:48:19.428153: Pseudo dice [np.float32(0.946), np.float32(0.7457)] 
2025-01-27 04:48:19.430690: Epoch time: 48.47 s 
2025-01-27 04:48:20.594974:  
2025-01-27 04:48:20.597887: Epoch 259 
2025-01-27 04:48:20.600584: Current learning rate: 0.00764 
2025-01-27 04:49:08.625904: train_loss -0.8007 
2025-01-27 04:49:08.630358: val_loss -0.797 
2025-01-27 04:49:08.633117: Pseudo dice [np.float32(0.9615), np.float32(0.8888)] 
2025-01-27 04:49:08.635610: Epoch time: 48.03 s 
2025-01-27 04:49:09.808325:  
2025-01-27 04:49:09.811544: Epoch 260 
2025-01-27 04:49:09.814780: Current learning rate: 0.00763 
2025-01-27 04:49:58.198584: train_loss -0.8134 
2025-01-27 04:49:58.208418: val_loss -0.7718 
2025-01-27 04:49:58.211137: Pseudo dice [np.float32(0.9576), np.float32(0.876)] 
2025-01-27 04:49:58.213794: Epoch time: 48.39 s 
2025-01-27 04:49:59.946709:  
2025-01-27 04:49:59.949932: Epoch 261 
2025-01-27 04:49:59.953099: Current learning rate: 0.00762 
2025-01-27 04:50:48.149636: train_loss -0.7949 
2025-01-27 04:50:48.155680: val_loss -0.7402 
2025-01-27 04:50:48.158377: Pseudo dice [np.float32(0.9564), np.float32(0.8661)] 
2025-01-27 04:50:48.161146: Epoch time: 48.2 s 
2025-01-27 04:50:49.335365:  
2025-01-27 04:50:49.338900: Epoch 262 
2025-01-27 04:50:49.341989: Current learning rate: 0.00761 
2025-01-27 04:51:37.677569: train_loss -0.8129 
2025-01-27 04:51:37.687137: val_loss -0.7392 
2025-01-27 04:51:37.689850: Pseudo dice [np.float32(0.9518), np.float32(0.8807)] 
2025-01-27 04:51:37.692599: Epoch time: 48.34 s 
2025-01-27 04:51:38.867802:  
2025-01-27 04:51:38.870772: Epoch 263 
2025-01-27 04:51:38.873475: Current learning rate: 0.0076 
2025-01-27 04:52:27.669051: train_loss -0.8004 
2025-01-27 04:52:27.675879: val_loss -0.7776 
2025-01-27 04:52:27.678630: Pseudo dice [np.float32(0.9568), np.float32(0.8832)] 
2025-01-27 04:52:27.681550: Epoch time: 48.8 s 
2025-01-27 04:52:28.864476:  
2025-01-27 04:52:28.867296: Epoch 264 
2025-01-27 04:52:28.870218: Current learning rate: 0.00759 
2025-01-27 04:53:17.231088: train_loss -0.8073 
2025-01-27 04:53:17.237196: val_loss -0.8229 
2025-01-27 04:53:17.240015: Pseudo dice [np.float32(0.955), np.float32(0.9064)] 
2025-01-27 04:53:17.242723: Epoch time: 48.37 s 
2025-01-27 04:53:18.430327:  
2025-01-27 04:53:18.433401: Epoch 265 
2025-01-27 04:53:18.436486: Current learning rate: 0.00758 
2025-01-27 04:54:07.219180: train_loss -0.8043 
2025-01-27 04:54:07.223588: val_loss -0.7977 
2025-01-27 04:54:07.226284: Pseudo dice [np.float32(0.957), np.float32(0.8909)] 
2025-01-27 04:54:07.229050: Epoch time: 48.79 s 
2025-01-27 04:54:07.231544: Yayy! New best EMA pseudo Dice: 0.9120000004768372 
2025-01-27 04:54:08.994932:  
2025-01-27 04:54:08.998195: Epoch 266 
2025-01-27 04:54:09.001327: Current learning rate: 0.00757 
2025-01-27 04:54:57.302665: train_loss -0.8176 
2025-01-27 04:54:57.307235: val_loss -0.8124 
2025-01-27 04:54:57.309726: Pseudo dice [np.float32(0.9601), np.float32(0.9031)] 
2025-01-27 04:54:57.311949: Epoch time: 48.31 s 
2025-01-27 04:54:57.314524: Yayy! New best EMA pseudo Dice: 0.9139999747276306 
2025-01-27 04:54:59.048952:  
2025-01-27 04:54:59.051473: Epoch 267 
2025-01-27 04:54:59.053997: Current learning rate: 0.00756 
2025-01-27 04:55:47.445541: train_loss -0.804 
2025-01-27 04:55:47.450237: val_loss -0.7759 
2025-01-27 04:55:47.453053: Pseudo dice [np.float32(0.9519), np.float32(0.8823)] 
2025-01-27 04:55:47.455821: Epoch time: 48.4 s 
2025-01-27 04:55:47.458952: Yayy! New best EMA pseudo Dice: 0.9143000245094299 
2025-01-27 04:55:49.244042:  
2025-01-27 04:55:49.248039: Epoch 268 
2025-01-27 04:55:49.251314: Current learning rate: 0.00755 
2025-01-27 04:56:37.632522: train_loss -0.8201 
2025-01-27 04:56:37.638147: val_loss -0.7774 
2025-01-27 04:56:37.640626: Pseudo dice [np.float32(0.9522), np.float32(0.8712)] 
2025-01-27 04:56:37.643523: Epoch time: 48.39 s 
2025-01-27 04:56:38.817121:  
2025-01-27 04:56:38.820781: Epoch 269 
2025-01-27 04:56:38.823821: Current learning rate: 0.00754 
2025-01-27 04:57:27.137492: train_loss -0.8062 
2025-01-27 04:57:27.141421: val_loss -0.7432 
2025-01-27 04:57:27.143769: Pseudo dice [np.float32(0.955), np.float32(0.8992)] 
2025-01-27 04:57:27.146136: Epoch time: 48.32 s 
2025-01-27 04:57:27.148547: Yayy! New best EMA pseudo Dice: 0.9153000116348267 
2025-01-27 04:57:28.893680:  
2025-01-27 04:57:28.898760: Epoch 270 
2025-01-27 04:57:28.901582: Current learning rate: 0.00753 
2025-01-27 04:58:17.530649: train_loss -0.8043 
2025-01-27 04:58:17.537069: val_loss -0.772 
2025-01-27 04:58:17.540118: Pseudo dice [np.float32(0.9529), np.float32(0.8425)] 
2025-01-27 04:58:17.542738: Epoch time: 48.64 s 
2025-01-27 04:58:18.724309:  
2025-01-27 04:58:18.727281: Epoch 271 
2025-01-27 04:58:18.730063: Current learning rate: 0.00752 
2025-01-27 04:59:07.524190: train_loss -0.808 
2025-01-27 04:59:07.528368: val_loss -0.7548 
2025-01-27 04:59:07.530843: Pseudo dice [np.float32(0.951), np.float32(0.8821)] 
2025-01-27 04:59:07.533414: Epoch time: 48.8 s 
2025-01-27 04:59:08.704920:  
2025-01-27 04:59:08.707884: Epoch 272 
2025-01-27 04:59:08.710603: Current learning rate: 0.00751 
2025-01-27 04:59:56.957518: train_loss -0.8146 
2025-01-27 04:59:56.963621: val_loss -0.7697 
2025-01-27 04:59:56.966207: Pseudo dice [np.float32(0.955), np.float32(0.9012)] 
2025-01-27 04:59:56.968979: Epoch time: 48.25 s 
2025-01-27 04:59:58.144536:  
2025-01-27 04:59:58.148044: Epoch 273 
2025-01-27 04:59:58.150641: Current learning rate: 0.00751 
2025-01-27 05:00:47.262219: train_loss -0.7991 
2025-01-27 05:00:47.267441: val_loss -0.7887 
2025-01-27 05:00:47.270175: Pseudo dice [np.float32(0.9563), np.float32(0.8873)] 
2025-01-27 05:00:47.272913: Epoch time: 49.12 s 
2025-01-27 05:00:47.275846: Yayy! New best EMA pseudo Dice: 0.9158999919891357 
2025-01-27 05:00:49.057079:  
2025-01-27 05:00:49.060310: Epoch 274 
2025-01-27 05:00:49.063244: Current learning rate: 0.0075 
2025-01-27 05:01:37.904149: train_loss -0.8241 
2025-01-27 05:01:37.910986: val_loss -0.7764 
2025-01-27 05:01:37.913611: Pseudo dice [np.float32(0.953), np.float32(0.8957)] 
2025-01-27 05:01:37.916304: Epoch time: 48.85 s 
2025-01-27 05:01:37.918917: Yayy! New best EMA pseudo Dice: 0.9168000221252441 
2025-01-27 05:01:39.658027:  
2025-01-27 05:01:39.661105: Epoch 275 
2025-01-27 05:01:39.663765: Current learning rate: 0.00749 
2025-01-27 05:02:28.208361: train_loss -0.8342 
2025-01-27 05:02:28.214399: val_loss -0.7746 
2025-01-27 05:02:28.217187: Pseudo dice [np.float32(0.9542), np.float32(0.8506)] 
2025-01-27 05:02:28.219864: Epoch time: 48.55 s 
2025-01-27 05:02:29.392359:  
2025-01-27 05:02:29.395634: Epoch 276 
2025-01-27 05:02:29.398515: Current learning rate: 0.00748 
2025-01-27 05:03:17.784683: train_loss -0.8099 
2025-01-27 05:03:17.791090: val_loss -0.7767 
2025-01-27 05:03:17.793792: Pseudo dice [np.float32(0.958), np.float32(0.8413)] 
2025-01-27 05:03:17.796455: Epoch time: 48.39 s 
2025-01-27 05:03:18.980005:  
2025-01-27 05:03:18.983207: Epoch 277 
2025-01-27 05:03:18.985969: Current learning rate: 0.00747 
2025-01-27 05:04:07.628880: train_loss -0.8021 
2025-01-27 05:04:07.636007: val_loss -0.7638 
2025-01-27 05:04:07.639029: Pseudo dice [np.float32(0.954), np.float32(0.8367)] 
2025-01-27 05:04:07.641690: Epoch time: 48.65 s 
2025-01-27 05:04:08.809559:  
2025-01-27 05:04:08.812653: Epoch 278 
2025-01-27 05:04:08.815243: Current learning rate: 0.00746 
2025-01-27 05:04:57.514252: train_loss -0.8077 
2025-01-27 05:04:57.520388: val_loss -0.7578 
2025-01-27 05:04:57.523136: Pseudo dice [np.float32(0.9482), np.float32(0.855)] 
2025-01-27 05:04:57.526045: Epoch time: 48.71 s 
2025-01-27 05:04:58.694030:  
2025-01-27 05:04:58.697330: Epoch 279 
2025-01-27 05:04:58.700278: Current learning rate: 0.00745 
2025-01-27 05:05:47.735513: train_loss -0.8143 
2025-01-27 05:05:47.740047: val_loss -0.7861 
2025-01-27 05:05:47.742878: Pseudo dice [np.float32(0.9565), np.float32(0.8883)] 
2025-01-27 05:05:47.745309: Epoch time: 49.04 s 
2025-01-27 05:05:49.567376:  
2025-01-27 05:05:49.571024: Epoch 280 
2025-01-27 05:05:49.573972: Current learning rate: 0.00744 
2025-01-27 05:06:37.904821: train_loss -0.8048 
2025-01-27 05:06:37.912053: val_loss -0.7857 
2025-01-27 05:06:37.915611: Pseudo dice [np.float32(0.9583), np.float32(0.8744)] 
2025-01-27 05:06:37.919082: Epoch time: 48.34 s 
2025-01-27 05:06:39.106241:  
2025-01-27 05:06:39.109324: Epoch 281 
2025-01-27 05:06:39.112087: Current learning rate: 0.00743 
2025-01-27 05:07:27.705731: train_loss -0.8159 
2025-01-27 05:07:27.710547: val_loss -0.7967 
2025-01-27 05:07:27.713077: Pseudo dice [np.float32(0.9582), np.float32(0.9071)] 
2025-01-27 05:07:27.715889: Epoch time: 48.6 s 
2025-01-27 05:07:28.883720:  
2025-01-27 05:07:28.887116: Epoch 282 
2025-01-27 05:07:28.890091: Current learning rate: 0.00742 
2025-01-27 05:08:17.724206: train_loss -0.8057 
2025-01-27 05:08:17.733105: val_loss -0.7449 
2025-01-27 05:08:17.735925: Pseudo dice [np.float32(0.9482), np.float32(0.8173)] 
2025-01-27 05:08:17.738593: Epoch time: 48.84 s 
2025-01-27 05:08:18.897723:  
2025-01-27 05:08:18.901501: Epoch 283 
2025-01-27 05:08:18.904341: Current learning rate: 0.00741 
2025-01-27 05:09:07.741133: train_loss -0.7764 
2025-01-27 05:09:07.746047: val_loss -0.7677 
2025-01-27 05:09:07.749133: Pseudo dice [np.float32(0.9405), np.float32(0.8312)] 
2025-01-27 05:09:07.751839: Epoch time: 48.84 s 
2025-01-27 05:09:08.922737:  
2025-01-27 05:09:08.926482: Epoch 284 
2025-01-27 05:09:08.929738: Current learning rate: 0.0074 
2025-01-27 05:09:57.276545: train_loss -0.7681 
2025-01-27 05:09:57.282421: val_loss -0.7527 
2025-01-27 05:09:57.285426: Pseudo dice [np.float32(0.9441), np.float32(0.8615)] 
2025-01-27 05:09:57.288373: Epoch time: 48.35 s 
2025-01-27 05:09:58.451622:  
2025-01-27 05:09:58.455079: Epoch 285 
2025-01-27 05:09:58.458107: Current learning rate: 0.00739 
2025-01-27 05:10:46.889705: train_loss -0.7911 
2025-01-27 05:10:46.894896: val_loss -0.7496 
2025-01-27 05:10:46.898000: Pseudo dice [np.float32(0.946), np.float32(0.8778)] 
2025-01-27 05:10:46.901092: Epoch time: 48.44 s 
2025-01-27 05:10:48.068156:  
2025-01-27 05:10:48.070896: Epoch 286 
2025-01-27 05:10:48.074262: Current learning rate: 0.00738 
2025-01-27 05:11:36.454740: train_loss -0.8066 
2025-01-27 05:11:36.461106: val_loss -0.7505 
2025-01-27 05:11:36.464144: Pseudo dice [np.float32(0.9441), np.float32(0.8652)] 
2025-01-27 05:11:36.466745: Epoch time: 48.39 s 
2025-01-27 05:11:37.682351:  
2025-01-27 05:11:37.685504: Epoch 287 
2025-01-27 05:11:37.688910: Current learning rate: 0.00738 
2025-01-27 05:12:25.929726: train_loss -0.7883 
2025-01-27 05:12:25.936486: val_loss -0.7327 
2025-01-27 05:12:25.939492: Pseudo dice [np.float32(0.947), np.float32(0.8593)] 
2025-01-27 05:12:25.942598: Epoch time: 48.25 s 
2025-01-27 05:12:27.130188:  
2025-01-27 05:12:27.133630: Epoch 288 
2025-01-27 05:12:27.137183: Current learning rate: 0.00737 
2025-01-27 05:13:15.809964: train_loss -0.8108 
2025-01-27 05:13:15.817653: val_loss -0.7554 
2025-01-27 05:13:15.820563: Pseudo dice [np.float32(0.9453), np.float32(0.8405)] 
2025-01-27 05:13:15.823537: Epoch time: 48.68 s 
2025-01-27 05:13:17.004140:  
2025-01-27 05:13:17.007140: Epoch 289 
2025-01-27 05:13:17.009701: Current learning rate: 0.00736 
2025-01-27 05:14:05.132396: train_loss -0.8135 
2025-01-27 05:14:05.139481: val_loss -0.7489 
2025-01-27 05:14:05.142318: Pseudo dice [np.float32(0.9494), np.float32(0.8716)] 
2025-01-27 05:14:05.145332: Epoch time: 48.13 s 
2025-01-27 05:14:06.360494:  
2025-01-27 05:14:06.363673: Epoch 290 
2025-01-27 05:14:06.366941: Current learning rate: 0.00735 
2025-01-27 05:14:54.772425: train_loss -0.8021 
2025-01-27 05:14:54.778716: val_loss -0.712 
2025-01-27 05:14:54.781752: Pseudo dice [np.float32(0.939), np.float32(0.8222)] 
2025-01-27 05:14:54.784667: Epoch time: 48.41 s 
2025-01-27 05:14:56.018023:  
2025-01-27 05:14:56.021257: Epoch 291 
2025-01-27 05:14:56.024215: Current learning rate: 0.00734 
2025-01-27 05:15:44.296079: train_loss -0.7863 
2025-01-27 05:15:44.300905: val_loss -0.7697 
2025-01-27 05:15:44.303628: Pseudo dice [np.float32(0.9475), np.float32(0.8891)] 
2025-01-27 05:15:44.306249: Epoch time: 48.28 s 
2025-01-27 05:15:45.527687:  
2025-01-27 05:15:45.532149: Epoch 292 
2025-01-27 05:15:45.534838: Current learning rate: 0.00733 
2025-01-27 05:16:33.942530: train_loss -0.8012 
2025-01-27 05:16:33.957290: val_loss -0.7842 
2025-01-27 05:16:33.960055: Pseudo dice [np.float32(0.9582), np.float32(0.8855)] 
2025-01-27 05:16:33.962534: Epoch time: 48.42 s 
2025-01-27 05:16:35.160274:  
2025-01-27 05:16:35.163336: Epoch 293 
2025-01-27 05:16:35.166200: Current learning rate: 0.00732 
2025-01-27 05:17:23.669129: train_loss -0.8023 
2025-01-27 05:17:23.673231: val_loss -0.7442 
2025-01-27 05:17:23.675996: Pseudo dice [np.float32(0.9433), np.float32(0.8376)] 
2025-01-27 05:17:23.678520: Epoch time: 48.51 s 
2025-01-27 05:17:24.876928:  
2025-01-27 05:17:24.880372: Epoch 294 
2025-01-27 05:17:24.883922: Current learning rate: 0.00731 
2025-01-27 05:18:13.495689: train_loss -0.796 
2025-01-27 05:18:13.501030: val_loss -0.7698 
2025-01-27 05:18:13.503917: Pseudo dice [np.float32(0.9576), np.float32(0.8828)] 
2025-01-27 05:18:13.506592: Epoch time: 48.62 s 
2025-01-27 05:18:14.693501:  
2025-01-27 05:18:14.696610: Epoch 295 
2025-01-27 05:18:14.699846: Current learning rate: 0.0073 
2025-01-27 05:19:03.103044: train_loss -0.8124 
2025-01-27 05:19:03.108073: val_loss -0.7873 
2025-01-27 05:19:03.111504: Pseudo dice [np.float32(0.9505), np.float32(0.8951)] 
2025-01-27 05:19:03.114335: Epoch time: 48.41 s 
2025-01-27 05:19:04.294852:  
2025-01-27 05:19:04.297996: Epoch 296 
2025-01-27 05:19:04.300899: Current learning rate: 0.00729 
2025-01-27 05:19:52.656459: train_loss -0.8051 
2025-01-27 05:19:52.662429: val_loss -0.8079 
2025-01-27 05:19:52.665514: Pseudo dice [np.float32(0.9536), np.float32(0.8977)] 
2025-01-27 05:19:52.668306: Epoch time: 48.36 s 
2025-01-27 05:19:53.850699:  
2025-01-27 05:19:53.854060: Epoch 297 
2025-01-27 05:19:53.857275: Current learning rate: 0.00728 
2025-01-27 05:20:42.776590: train_loss -0.8223 
2025-01-27 05:20:42.783322: val_loss -0.754 
2025-01-27 05:20:42.786122: Pseudo dice [np.float32(0.9534), np.float32(0.8726)] 
2025-01-27 05:20:42.788831: Epoch time: 48.93 s 
2025-01-27 05:20:44.007919:  
2025-01-27 05:20:44.011424: Epoch 298 
2025-01-27 05:20:44.014522: Current learning rate: 0.00727 
2025-01-27 05:21:32.535349: train_loss -0.8167 
2025-01-27 05:21:32.541919: val_loss -0.7581 
2025-01-27 05:21:32.545163: Pseudo dice [np.float32(0.9465), np.float32(0.8469)] 
2025-01-27 05:21:32.548278: Epoch time: 48.53 s 
2025-01-27 05:21:34.375559:  
2025-01-27 05:21:34.379094: Epoch 299 
2025-01-27 05:21:34.382126: Current learning rate: 0.00726 
2025-01-27 05:22:22.925165: train_loss -0.8185 
2025-01-27 05:22:22.930182: val_loss -0.797 
2025-01-27 05:22:22.934076: Pseudo dice [np.float32(0.9543), np.float32(0.9088)] 
2025-01-27 05:22:22.937512: Epoch time: 48.55 s 
2025-01-27 05:22:24.680605:  
2025-01-27 05:22:24.683930: Epoch 300 
2025-01-27 05:22:24.686989: Current learning rate: 0.00725 
2025-01-27 05:23:13.281554: train_loss -0.828 
2025-01-27 05:23:13.288203: val_loss -0.7343 
2025-01-27 05:23:13.291533: Pseudo dice [np.float32(0.9526), np.float32(0.9074)] 
2025-01-27 05:23:13.294459: Epoch time: 48.6 s 
2025-01-27 05:23:14.497102:  
2025-01-27 05:23:14.499754: Epoch 301 
2025-01-27 05:23:14.502574: Current learning rate: 0.00724 
2025-01-27 05:24:02.854495: train_loss -0.8029 
2025-01-27 05:24:02.858914: val_loss -0.7757 
2025-01-27 05:24:02.861957: Pseudo dice [np.float32(0.956), np.float32(0.8657)] 
2025-01-27 05:24:02.864913: Epoch time: 48.36 s 
2025-01-27 05:24:04.040877:  
2025-01-27 05:24:04.044154: Epoch 302 
2025-01-27 05:24:04.046970: Current learning rate: 0.00724 
2025-01-27 05:24:52.590781: train_loss -0.8194 
2025-01-27 05:24:52.597774: val_loss -0.7759 
2025-01-27 05:24:52.600492: Pseudo dice [np.float32(0.9525), np.float32(0.8752)] 
2025-01-27 05:24:52.603376: Epoch time: 48.55 s 
2025-01-27 05:24:53.782924:  
2025-01-27 05:24:53.786038: Epoch 303 
2025-01-27 05:24:53.789163: Current learning rate: 0.00723 
2025-01-27 05:25:42.745116: train_loss -0.799 
2025-01-27 05:25:42.751576: val_loss -0.7907 
2025-01-27 05:25:42.754440: Pseudo dice [np.float32(0.9569), np.float32(0.903)] 
2025-01-27 05:25:42.757239: Epoch time: 48.96 s 
2025-01-27 05:25:43.939973:  
2025-01-27 05:25:43.942986: Epoch 304 
2025-01-27 05:25:43.946720: Current learning rate: 0.00722 
2025-01-27 05:26:32.587719: train_loss -0.8261 
2025-01-27 05:26:32.593729: val_loss -0.784 
2025-01-27 05:26:32.596433: Pseudo dice [np.float32(0.9604), np.float32(0.88)] 
2025-01-27 05:26:32.599171: Epoch time: 48.65 s 
2025-01-27 05:26:33.787833:  
2025-01-27 05:26:33.790672: Epoch 305 
2025-01-27 05:26:33.793464: Current learning rate: 0.00721 
2025-01-27 05:27:22.444419: train_loss -0.8279 
2025-01-27 05:27:22.451793: val_loss -0.8022 
2025-01-27 05:27:22.454562: Pseudo dice [np.float32(0.9569), np.float32(0.8943)] 
2025-01-27 05:27:22.457242: Epoch time: 48.66 s 
2025-01-27 05:27:23.639985:  
2025-01-27 05:27:23.643129: Epoch 306 
2025-01-27 05:27:23.646059: Current learning rate: 0.0072 
2025-01-27 05:28:12.446977: train_loss -0.8241 
2025-01-27 05:28:12.455901: val_loss -0.7487 
2025-01-27 05:28:12.458904: Pseudo dice [np.float32(0.9418), np.float32(0.8812)] 
2025-01-27 05:28:12.461827: Epoch time: 48.81 s 
2025-01-27 05:28:13.651729:  
2025-01-27 05:28:13.655410: Epoch 307 
2025-01-27 05:28:13.658223: Current learning rate: 0.00719 
2025-01-27 05:29:01.811459: train_loss -0.7975 
2025-01-27 05:29:01.816085: val_loss -0.7436 
2025-01-27 05:29:01.819104: Pseudo dice [np.float32(0.9528), np.float32(0.8459)] 
2025-01-27 05:29:01.822065: Epoch time: 48.16 s 
2025-01-27 05:29:03.008648:  
2025-01-27 05:29:03.011966: Epoch 308 
2025-01-27 05:29:03.015280: Current learning rate: 0.00718 
2025-01-27 05:29:51.472623: train_loss -0.7792 
2025-01-27 05:29:51.478777: val_loss -0.7768 
2025-01-27 05:29:51.481972: Pseudo dice [np.float32(0.9496), np.float32(0.8764)] 
2025-01-27 05:29:51.485276: Epoch time: 48.47 s 
2025-01-27 05:29:52.672956:  
2025-01-27 05:29:52.675967: Epoch 309 
2025-01-27 05:29:52.678733: Current learning rate: 0.00717 
2025-01-27 05:30:41.028869: train_loss -0.7965 
2025-01-27 05:30:41.033633: val_loss -0.7582 
2025-01-27 05:30:41.036521: Pseudo dice [np.float32(0.9548), np.float32(0.8783)] 
2025-01-27 05:30:41.039530: Epoch time: 48.36 s 
2025-01-27 05:30:42.222566:  
2025-01-27 05:30:42.225831: Epoch 310 
2025-01-27 05:30:42.228778: Current learning rate: 0.00716 
2025-01-27 05:31:30.801609: train_loss -0.7946 
2025-01-27 05:31:30.807231: val_loss -0.7635 
2025-01-27 05:31:30.810173: Pseudo dice [np.float32(0.9543), np.float32(0.8911)] 
2025-01-27 05:31:30.812989: Epoch time: 48.58 s 
2025-01-27 05:31:31.993986:  
2025-01-27 05:31:31.997771: Epoch 311 
2025-01-27 05:31:32.000977: Current learning rate: 0.00715 
2025-01-27 05:32:20.495885: train_loss -0.8166 
2025-01-27 05:32:20.500940: val_loss -0.8093 
2025-01-27 05:32:20.504000: Pseudo dice [np.float32(0.9559), np.float32(0.893)] 
2025-01-27 05:32:20.506526: Epoch time: 48.5 s 
2025-01-27 05:32:21.688410:  
2025-01-27 05:32:21.691490: Epoch 312 
2025-01-27 05:32:21.694141: Current learning rate: 0.00714 
2025-01-27 05:33:10.150624: train_loss -0.8148 
2025-01-27 05:33:10.156906: val_loss -0.8009 
2025-01-27 05:33:10.159795: Pseudo dice [np.float32(0.9506), np.float32(0.895)] 
2025-01-27 05:33:10.162490: Epoch time: 48.46 s 
2025-01-27 05:33:11.383792:  
2025-01-27 05:33:11.387152: Epoch 313 
2025-01-27 05:33:11.390013: Current learning rate: 0.00713 
2025-01-27 05:34:00.029226: train_loss -0.807 
2025-01-27 05:34:00.035723: val_loss -0.7726 
2025-01-27 05:34:00.038642: Pseudo dice [np.float32(0.9534), np.float32(0.8317)] 
2025-01-27 05:34:00.041153: Epoch time: 48.65 s 
2025-01-27 05:34:01.224051:  
2025-01-27 05:34:01.226868: Epoch 314 
2025-01-27 05:34:01.229890: Current learning rate: 0.00712 
2025-01-27 05:34:49.853817: train_loss -0.803 
2025-01-27 05:34:49.859710: val_loss -0.7262 
2025-01-27 05:34:49.862755: Pseudo dice [np.float32(0.9563), np.float32(0.8633)] 
2025-01-27 05:34:49.865479: Epoch time: 48.63 s 
2025-01-27 05:34:51.063775:  
2025-01-27 05:34:51.067130: Epoch 315 
2025-01-27 05:34:51.070465: Current learning rate: 0.00711 
2025-01-27 05:35:39.935997: train_loss -0.7972 
2025-01-27 05:35:39.940206: val_loss -0.7603 
2025-01-27 05:35:39.942917: Pseudo dice [np.float32(0.9575), np.float32(0.8668)] 
2025-01-27 05:35:39.945590: Epoch time: 48.87 s 
2025-01-27 05:35:41.139829:  
2025-01-27 05:35:41.143094: Epoch 316 
2025-01-27 05:35:41.146355: Current learning rate: 0.0071 
2025-01-27 05:36:29.743590: train_loss -0.8259 
2025-01-27 05:36:29.749722: val_loss -0.7317 
2025-01-27 05:36:29.752642: Pseudo dice [np.float32(0.954), np.float32(0.8409)] 
2025-01-27 05:36:29.755094: Epoch time: 48.6 s 
2025-01-27 05:36:30.949621:  
2025-01-27 05:36:30.952977: Epoch 317 
2025-01-27 05:36:30.955723: Current learning rate: 0.0071 
2025-01-27 05:37:19.426974: train_loss -0.8111 
2025-01-27 05:37:19.433456: val_loss -0.7655 
2025-01-27 05:37:19.436276: Pseudo dice [np.float32(0.9567), np.float32(0.8985)] 
2025-01-27 05:37:19.439302: Epoch time: 48.48 s 
2025-01-27 05:37:21.197362:  
2025-01-27 05:37:21.200790: Epoch 318 
2025-01-27 05:37:21.203581: Current learning rate: 0.00709 
2025-01-27 05:38:09.657453: train_loss -0.824 
2025-01-27 05:38:09.663865: val_loss -0.7864 
2025-01-27 05:38:09.666556: Pseudo dice [np.float32(0.9572), np.float32(0.83)] 
2025-01-27 05:38:09.669395: Epoch time: 48.46 s 
2025-01-27 05:38:10.918768:  
2025-01-27 05:38:10.922195: Epoch 319 
2025-01-27 05:38:10.925225: Current learning rate: 0.00708 
2025-01-27 05:39:00.014114: train_loss -0.8083 
2025-01-27 05:39:00.022318: val_loss -0.7608 
2025-01-27 05:39:00.025485: Pseudo dice [np.float32(0.9577), np.float32(0.8648)] 
2025-01-27 05:39:00.028911: Epoch time: 49.1 s 
2025-01-27 05:39:01.227686:  
2025-01-27 05:39:01.230926: Epoch 320 
2025-01-27 05:39:01.233782: Current learning rate: 0.00707 
2025-01-27 05:39:49.887243: train_loss -0.8027 
2025-01-27 05:39:49.893767: val_loss -0.7341 
2025-01-27 05:39:49.896544: Pseudo dice [np.float32(0.9582), np.float32(0.8616)] 
2025-01-27 05:39:49.899208: Epoch time: 48.66 s 
2025-01-27 05:39:51.095306:  
2025-01-27 05:39:51.098641: Epoch 321 
2025-01-27 05:39:51.101911: Current learning rate: 0.00706 
2025-01-27 05:40:39.928051: train_loss -0.8146 
2025-01-27 05:40:39.934010: val_loss -0.7588 
2025-01-27 05:40:39.936970: Pseudo dice [np.float32(0.9514), np.float32(0.8812)] 
2025-01-27 05:40:39.939616: Epoch time: 48.83 s 
2025-01-27 05:40:41.154717:  
2025-01-27 05:40:41.158137: Epoch 322 
2025-01-27 05:40:41.161277: Current learning rate: 0.00705 
2025-01-27 05:41:29.605041: train_loss -0.8158 
2025-01-27 05:41:29.611874: val_loss -0.749 
2025-01-27 05:41:29.614650: Pseudo dice [np.float32(0.9506), np.float32(0.8456)] 
2025-01-27 05:41:29.617372: Epoch time: 48.45 s 
2025-01-27 05:41:30.816682:  
2025-01-27 05:41:30.820189: Epoch 323 
2025-01-27 05:41:30.823976: Current learning rate: 0.00704 
2025-01-27 05:42:19.794176: train_loss -0.8044 
2025-01-27 05:42:19.801190: val_loss -0.741 
2025-01-27 05:42:19.804412: Pseudo dice [np.float32(0.9478), np.float32(0.8233)] 
2025-01-27 05:42:19.807312: Epoch time: 48.98 s 
2025-01-27 05:42:20.993311:  
2025-01-27 05:42:20.996555: Epoch 324 
2025-01-27 05:42:20.999930: Current learning rate: 0.00703 
2025-01-27 05:43:10.538307: train_loss -0.8025 
2025-01-27 05:43:10.545239: val_loss -0.7375 
2025-01-27 05:43:10.548548: Pseudo dice [np.float32(0.945), np.float32(0.7951)] 
2025-01-27 05:43:10.551461: Epoch time: 49.55 s 
2025-01-27 05:43:11.772537:  
2025-01-27 05:43:11.776131: Epoch 325 
2025-01-27 05:43:11.779410: Current learning rate: 0.00702 
2025-01-27 05:44:00.655980: train_loss -0.8004 
2025-01-27 05:44:00.663908: val_loss -0.7084 
2025-01-27 05:44:00.667056: Pseudo dice [np.float32(0.9361), np.float32(0.7717)] 
2025-01-27 05:44:00.670006: Epoch time: 48.88 s 
2025-01-27 05:44:01.906511:  
2025-01-27 05:44:01.909947: Epoch 326 
2025-01-27 05:44:01.912723: Current learning rate: 0.00701 
2025-01-27 05:44:50.449812: train_loss -0.8209 
2025-01-27 05:44:50.459244: val_loss -0.7707 
2025-01-27 05:44:50.462538: Pseudo dice [np.float32(0.9538), np.float32(0.8717)] 
2025-01-27 05:44:50.466044: Epoch time: 48.54 s 
2025-01-27 05:44:51.655483:  
2025-01-27 05:44:51.658811: Epoch 327 
2025-01-27 05:44:51.662677: Current learning rate: 0.007 
2025-01-27 05:45:40.310492: train_loss -0.8069 
2025-01-27 05:45:40.318901: val_loss -0.7821 
2025-01-27 05:45:40.321752: Pseudo dice [np.float32(0.9534), np.float32(0.872)] 
2025-01-27 05:45:40.324582: Epoch time: 48.66 s 
2025-01-27 05:45:41.523726:  
2025-01-27 05:45:41.526981: Epoch 328 
2025-01-27 05:45:41.530123: Current learning rate: 0.00699 
2025-01-27 05:46:29.974096: train_loss -0.8114 
2025-01-27 05:46:29.980325: val_loss -0.7745 
2025-01-27 05:46:29.983134: Pseudo dice [np.float32(0.9492), np.float32(0.8986)] 
2025-01-27 05:46:29.985826: Epoch time: 48.45 s 
2025-01-27 05:46:31.214319:  
2025-01-27 05:46:31.217223: Epoch 329 
2025-01-27 05:46:31.220386: Current learning rate: 0.00698 
2025-01-27 05:47:19.546458: train_loss -0.8026 
2025-01-27 05:47:19.551344: val_loss -0.7871 
2025-01-27 05:47:19.554412: Pseudo dice [np.float32(0.949), np.float32(0.8932)] 
2025-01-27 05:47:19.557109: Epoch time: 48.33 s 
2025-01-27 05:47:20.734236:  
2025-01-27 05:47:20.737563: Epoch 330 
2025-01-27 05:47:20.740822: Current learning rate: 0.00697 
2025-01-27 05:48:09.315674: train_loss -0.8138 
2025-01-27 05:48:09.322131: val_loss -0.759 
2025-01-27 05:48:09.325070: Pseudo dice [np.float32(0.9537), np.float32(0.8933)] 
2025-01-27 05:48:09.327919: Epoch time: 48.58 s 
2025-01-27 05:48:10.513092:  
2025-01-27 05:48:10.515998: Epoch 331 
2025-01-27 05:48:10.519208: Current learning rate: 0.00696 
2025-01-27 05:48:58.869322: train_loss -0.802 
2025-01-27 05:48:58.873662: val_loss -0.7863 
2025-01-27 05:48:58.876754: Pseudo dice [np.float32(0.9558), np.float32(0.8615)] 
2025-01-27 05:48:58.879349: Epoch time: 48.36 s 
2025-01-27 05:49:00.069415:  
2025-01-27 05:49:00.072623: Epoch 332 
2025-01-27 05:49:00.075523: Current learning rate: 0.00696 
2025-01-27 05:49:48.815280: train_loss -0.8104 
2025-01-27 05:49:48.821992: val_loss -0.7199 
2025-01-27 05:49:48.825027: Pseudo dice [np.float32(0.9588), np.float32(0.838)] 
2025-01-27 05:49:48.827718: Epoch time: 48.75 s 
2025-01-27 05:49:50.053162:  
2025-01-27 05:49:50.056218: Epoch 333 
2025-01-27 05:49:50.059367: Current learning rate: 0.00695 
2025-01-27 05:50:38.550064: train_loss -0.8195 
2025-01-27 05:50:38.554673: val_loss -0.7665 
2025-01-27 05:50:38.557600: Pseudo dice [np.float32(0.955), np.float32(0.875)] 
2025-01-27 05:50:38.560473: Epoch time: 48.5 s 
2025-01-27 05:50:39.752488:  
2025-01-27 05:50:39.755662: Epoch 334 
2025-01-27 05:50:39.758655: Current learning rate: 0.00694 
2025-01-27 05:51:28.616628: train_loss -0.8017 
2025-01-27 05:51:28.623248: val_loss -0.7572 
2025-01-27 05:51:28.626516: Pseudo dice [np.float32(0.9502), np.float32(0.8963)] 
2025-01-27 05:51:28.629904: Epoch time: 48.87 s 
2025-01-27 05:51:29.873881:  
2025-01-27 05:51:29.877369: Epoch 335 
2025-01-27 05:51:29.880754: Current learning rate: 0.00693 
2025-01-27 05:52:19.286194: train_loss -0.8011 
2025-01-27 05:52:19.290549: val_loss -0.7748 
2025-01-27 05:52:19.293331: Pseudo dice [np.float32(0.9529), np.float32(0.8425)] 
2025-01-27 05:52:19.295973: Epoch time: 49.41 s 
2025-01-27 05:52:20.522504:  
2025-01-27 05:52:20.525808: Epoch 336 
2025-01-27 05:52:20.528304: Current learning rate: 0.00692 
2025-01-27 05:53:09.670212: train_loss -0.7612 
2025-01-27 05:53:09.676564: val_loss -0.7031 
2025-01-27 05:53:09.679345: Pseudo dice [np.float32(0.941), np.float32(0.7973)] 
2025-01-27 05:53:09.681798: Epoch time: 49.15 s 
2025-01-27 05:53:11.501845:  
2025-01-27 05:53:11.505095: Epoch 337 
2025-01-27 05:53:11.507876: Current learning rate: 0.00691 
2025-01-27 05:53:59.953380: train_loss -0.7953 
2025-01-27 05:53:59.958151: val_loss -0.7457 
2025-01-27 05:53:59.960799: Pseudo dice [np.float32(0.9407), np.float32(0.8509)] 
2025-01-27 05:53:59.963553: Epoch time: 48.45 s 
2025-01-27 05:54:01.206847:  
2025-01-27 05:54:01.210558: Epoch 338 
2025-01-27 05:54:01.213752: Current learning rate: 0.0069 
2025-01-27 05:54:49.969243: train_loss -0.8035 
2025-01-27 05:54:49.975994: val_loss -0.7259 
2025-01-27 05:54:49.979004: Pseudo dice [np.float32(0.9511), np.float32(0.8529)] 
2025-01-27 05:54:49.981756: Epoch time: 48.76 s 
2025-01-27 05:54:51.176498:  
2025-01-27 05:54:51.179658: Epoch 339 
2025-01-27 05:54:51.182810: Current learning rate: 0.00689 
2025-01-27 05:55:39.507095: train_loss -0.7997 
2025-01-27 05:55:39.511805: val_loss -0.7667 
2025-01-27 05:55:39.514739: Pseudo dice [np.float32(0.9548), np.float32(0.8102)] 
2025-01-27 05:55:39.517299: Epoch time: 48.33 s 
2025-01-27 05:55:40.719250:  
2025-01-27 05:55:40.722445: Epoch 340 
2025-01-27 05:55:40.725549: Current learning rate: 0.00688 
2025-01-27 05:56:29.531819: train_loss -0.797 
2025-01-27 05:56:29.537743: val_loss -0.7271 
2025-01-27 05:56:29.540935: Pseudo dice [np.float32(0.9425), np.float32(0.8169)] 
2025-01-27 05:56:29.543949: Epoch time: 48.81 s 
2025-01-27 05:56:30.754717:  
2025-01-27 05:56:30.758320: Epoch 341 
2025-01-27 05:56:30.761376: Current learning rate: 0.00687 
2025-01-27 05:57:18.729785: train_loss -0.7935 
2025-01-27 05:57:18.734711: val_loss -0.745 
2025-01-27 05:57:18.737547: Pseudo dice [np.float32(0.9573), np.float32(0.8326)] 
2025-01-27 05:57:18.740682: Epoch time: 47.98 s 
2025-01-27 05:57:19.944112:  
2025-01-27 05:57:19.947341: Epoch 342 
2025-01-27 05:57:19.950344: Current learning rate: 0.00686 
2025-01-27 05:58:08.485512: train_loss -0.796 
2025-01-27 05:58:08.491915: val_loss -0.7768 
2025-01-27 05:58:08.494913: Pseudo dice [np.float32(0.9552), np.float32(0.8596)] 
2025-01-27 05:58:08.498013: Epoch time: 48.54 s 
2025-01-27 05:58:09.712112:  
2025-01-27 05:58:09.715707: Epoch 343 
2025-01-27 05:58:09.719195: Current learning rate: 0.00685 
2025-01-27 05:58:58.211049: train_loss -0.8048 
2025-01-27 05:58:58.216123: val_loss -0.7638 
2025-01-27 05:58:58.219089: Pseudo dice [np.float32(0.9502), np.float32(0.8697)] 
2025-01-27 05:58:58.222420: Epoch time: 48.5 s 
2025-01-27 05:58:59.431265:  
2025-01-27 05:58:59.434762: Epoch 344 
2025-01-27 05:58:59.437510: Current learning rate: 0.00684 
2025-01-27 05:59:47.873870: train_loss -0.8132 
2025-01-27 05:59:47.879652: val_loss -0.7516 
2025-01-27 05:59:47.882305: Pseudo dice [np.float32(0.9524), np.float32(0.8788)] 
2025-01-27 05:59:47.884829: Epoch time: 48.44 s 
2025-01-27 05:59:49.116561:  
2025-01-27 05:59:49.119633: Epoch 345 
2025-01-27 05:59:49.123072: Current learning rate: 0.00683 
2025-01-27 06:00:38.240593: train_loss -0.8071 
2025-01-27 06:00:38.244958: val_loss -0.7808 
2025-01-27 06:00:38.247923: Pseudo dice [np.float32(0.9584), np.float32(0.898)] 
2025-01-27 06:00:38.250790: Epoch time: 49.13 s 
2025-01-27 06:00:39.489812:  
2025-01-27 06:00:39.492938: Epoch 346 
2025-01-27 06:00:39.495942: Current learning rate: 0.00682 
2025-01-27 06:01:27.972612: train_loss -0.8237 
2025-01-27 06:01:27.978402: val_loss -0.7788 
2025-01-27 06:01:27.981361: Pseudo dice [np.float32(0.9589), np.float32(0.8851)] 
2025-01-27 06:01:27.983650: Epoch time: 48.48 s 
2025-01-27 06:01:29.182776:  
2025-01-27 06:01:29.185715: Epoch 347 
2025-01-27 06:01:29.188348: Current learning rate: 0.00681 
2025-01-27 06:02:17.602801: train_loss -0.8157 
2025-01-27 06:02:17.609491: val_loss -0.7594 
2025-01-27 06:02:17.612130: Pseudo dice [np.float32(0.9541), np.float32(0.8961)] 
2025-01-27 06:02:17.614632: Epoch time: 48.42 s 
2025-01-27 06:02:18.822866:  
2025-01-27 06:02:18.825869: Epoch 348 
2025-01-27 06:02:18.828979: Current learning rate: 0.0068 
2025-01-27 06:03:07.390348: train_loss -0.8093 
2025-01-27 06:03:07.395538: val_loss -0.7786 
2025-01-27 06:03:07.398024: Pseudo dice [np.float32(0.9542), np.float32(0.8867)] 
2025-01-27 06:03:07.400742: Epoch time: 48.57 s 
2025-01-27 06:03:08.598131:  
2025-01-27 06:03:08.608301: Epoch 349 
2025-01-27 06:03:08.611239: Current learning rate: 0.0068 
2025-01-27 06:03:57.205389: train_loss -0.8058 
2025-01-27 06:03:57.209442: val_loss -0.7872 
2025-01-27 06:03:57.212152: Pseudo dice [np.float32(0.9508), np.float32(0.8677)] 
2025-01-27 06:03:57.214976: Epoch time: 48.61 s 
2025-01-27 06:03:58.999882:  
2025-01-27 06:03:59.002874: Epoch 350 
2025-01-27 06:03:59.005659: Current learning rate: 0.00679 
2025-01-27 06:04:47.447683: train_loss -0.8225 
2025-01-27 06:04:47.454019: val_loss -0.7614 
2025-01-27 06:04:47.457169: Pseudo dice [np.float32(0.9588), np.float32(0.902)] 
2025-01-27 06:04:47.460072: Epoch time: 48.45 s 
2025-01-27 06:04:48.712864:  
2025-01-27 06:04:48.716147: Epoch 351 
2025-01-27 06:04:48.719313: Current learning rate: 0.00678 
2025-01-27 06:05:36.913631: train_loss -0.827 
2025-01-27 06:05:36.918293: val_loss -0.761 
2025-01-27 06:05:36.921239: Pseudo dice [np.float32(0.9606), np.float32(0.8899)] 
2025-01-27 06:05:36.924356: Epoch time: 48.2 s 
2025-01-27 06:05:38.148236:  
2025-01-27 06:05:38.151697: Epoch 352 
2025-01-27 06:05:38.154942: Current learning rate: 0.00677 
2025-01-27 06:06:27.148216: train_loss -0.8093 
2025-01-27 06:06:27.154642: val_loss -0.7985 
2025-01-27 06:06:27.157339: Pseudo dice [np.float32(0.9592), np.float32(0.8914)] 
2025-01-27 06:06:27.159824: Epoch time: 49.0 s 
2025-01-27 06:06:28.371913:  
2025-01-27 06:06:28.374958: Epoch 353 
2025-01-27 06:06:28.377683: Current learning rate: 0.00676 
2025-01-27 06:07:16.805485: train_loss -0.8232 
2025-01-27 06:07:16.810597: val_loss -0.7796 
2025-01-27 06:07:16.813656: Pseudo dice [np.float32(0.9547), np.float32(0.8734)] 
2025-01-27 06:07:16.816781: Epoch time: 48.43 s 
2025-01-27 06:07:18.027494:  
2025-01-27 06:07:18.030406: Epoch 354 
2025-01-27 06:07:18.033264: Current learning rate: 0.00675 
2025-01-27 06:08:06.335292: train_loss -0.8281 
2025-01-27 06:08:06.341102: val_loss -0.7547 
2025-01-27 06:08:06.344118: Pseudo dice [np.float32(0.9571), np.float32(0.8956)] 
2025-01-27 06:08:06.347158: Epoch time: 48.31 s 
2025-01-27 06:08:08.114830:  
2025-01-27 06:08:08.117944: Epoch 355 
2025-01-27 06:08:08.120784: Current learning rate: 0.00674 
2025-01-27 06:08:56.396039: train_loss -0.8132 
2025-01-27 06:08:56.401120: val_loss -0.7441 
2025-01-27 06:08:56.404019: Pseudo dice [np.float32(0.9562), np.float32(0.8629)] 
2025-01-27 06:08:56.406826: Epoch time: 48.28 s 
2025-01-27 06:08:57.618190:  
2025-01-27 06:08:57.621823: Epoch 356 
2025-01-27 06:08:57.624709: Current learning rate: 0.00673 
2025-01-27 06:09:46.640337: train_loss -0.7843 
2025-01-27 06:09:46.646593: val_loss -0.7765 
2025-01-27 06:09:46.649483: Pseudo dice [np.float32(0.9483), np.float32(0.8582)] 
2025-01-27 06:09:46.652143: Epoch time: 49.02 s 
2025-01-27 06:09:47.859689:  
2025-01-27 06:09:47.863174: Epoch 357 
2025-01-27 06:09:47.866155: Current learning rate: 0.00672 
2025-01-27 06:10:36.772741: train_loss -0.7954 
2025-01-27 06:10:36.777666: val_loss -0.7592 
2025-01-27 06:10:36.780699: Pseudo dice [np.float32(0.9479), np.float32(0.8482)] 
2025-01-27 06:10:36.783292: Epoch time: 48.91 s 
2025-01-27 06:10:37.981563:  
2025-01-27 06:10:37.984495: Epoch 358 
2025-01-27 06:10:37.987650: Current learning rate: 0.00671 
2025-01-27 06:11:26.749293: train_loss -0.8173 
2025-01-27 06:11:26.755216: val_loss -0.7928 
2025-01-27 06:11:26.758198: Pseudo dice [np.float32(0.9596), np.float32(0.88)] 
2025-01-27 06:11:26.761079: Epoch time: 48.77 s 
2025-01-27 06:11:27.963333:  
2025-01-27 06:11:27.966586: Epoch 359 
2025-01-27 06:11:27.969853: Current learning rate: 0.0067 
2025-01-27 06:12:16.273517: train_loss -0.804 
2025-01-27 06:12:16.278150: val_loss -0.7415 
2025-01-27 06:12:16.281026: Pseudo dice [np.float32(0.9582), np.float32(0.8743)] 
2025-01-27 06:12:16.283542: Epoch time: 48.31 s 
2025-01-27 06:12:17.488785:  
2025-01-27 06:12:17.492062: Epoch 360 
2025-01-27 06:12:17.495141: Current learning rate: 0.00669 
2025-01-27 06:13:06.217236: train_loss -0.8165 
2025-01-27 06:13:06.223325: val_loss -0.7555 
2025-01-27 06:13:06.225989: Pseudo dice [np.float32(0.957), np.float32(0.863)] 
2025-01-27 06:13:06.228919: Epoch time: 48.73 s 
2025-01-27 06:13:07.434960:  
2025-01-27 06:13:07.438215: Epoch 361 
2025-01-27 06:13:07.441183: Current learning rate: 0.00668 
2025-01-27 06:13:55.791055: train_loss -0.819 
2025-01-27 06:13:55.795940: val_loss -0.7287 
2025-01-27 06:13:55.799003: Pseudo dice [np.float32(0.9367), np.float32(0.7715)] 
2025-01-27 06:13:55.801821: Epoch time: 48.36 s 
2025-01-27 06:13:57.052321:  
2025-01-27 06:13:57.055515: Epoch 362 
2025-01-27 06:13:57.058595: Current learning rate: 0.00667 
2025-01-27 06:14:45.548640: train_loss -0.821 
2025-01-27 06:14:45.554896: val_loss -0.7824 
2025-01-27 06:14:45.558077: Pseudo dice [np.float32(0.9607), np.float32(0.8694)] 
2025-01-27 06:14:45.560762: Epoch time: 48.5 s 
2025-01-27 06:14:46.768402:  
2025-01-27 06:14:46.771573: Epoch 363 
2025-01-27 06:14:46.774636: Current learning rate: 0.00666 
2025-01-27 06:15:35.868758: train_loss -0.8151 
2025-01-27 06:15:35.873651: val_loss -0.7067 
2025-01-27 06:15:35.876821: Pseudo dice [np.float32(0.9523), np.float32(0.868)] 
2025-01-27 06:15:35.879791: Epoch time: 49.1 s 
2025-01-27 06:15:37.095519:  
2025-01-27 06:15:37.098659: Epoch 364 
2025-01-27 06:15:37.101891: Current learning rate: 0.00665 
2025-01-27 06:16:25.767744: train_loss -0.814 
2025-01-27 06:16:25.773440: val_loss -0.7625 
2025-01-27 06:16:25.776279: Pseudo dice [np.float32(0.9485), np.float32(0.8618)] 
2025-01-27 06:16:25.778851: Epoch time: 48.67 s 
2025-01-27 06:16:26.984290:  
2025-01-27 06:16:26.987378: Epoch 365 
2025-01-27 06:16:26.990124: Current learning rate: 0.00665 
2025-01-27 06:17:15.637428: train_loss -0.7987 
2025-01-27 06:17:15.642297: val_loss -0.7519 
2025-01-27 06:17:15.645224: Pseudo dice [np.float32(0.9542), np.float32(0.8647)] 
2025-01-27 06:17:15.648147: Epoch time: 48.65 s 
2025-01-27 06:17:16.878593:  
2025-01-27 06:17:16.882308: Epoch 366 
2025-01-27 06:17:16.885504: Current learning rate: 0.00664 
2025-01-27 06:18:05.514580: train_loss -0.7867 
2025-01-27 06:18:05.520456: val_loss -0.7755 
2025-01-27 06:18:05.523266: Pseudo dice [np.float32(0.9475), np.float32(0.8755)] 
2025-01-27 06:18:05.525819: Epoch time: 48.64 s 
2025-01-27 06:18:06.734577:  
2025-01-27 06:18:06.738456: Epoch 367 
2025-01-27 06:18:06.741861: Current learning rate: 0.00663 
2025-01-27 06:18:55.631993: train_loss -0.8071 
2025-01-27 06:18:55.638493: val_loss -0.7637 
2025-01-27 06:18:55.641264: Pseudo dice [np.float32(0.952), np.float32(0.8567)] 
2025-01-27 06:18:55.644348: Epoch time: 48.9 s 
2025-01-27 06:18:56.876016:  
2025-01-27 06:18:56.880059: Epoch 368 
2025-01-27 06:18:56.883330: Current learning rate: 0.00662 
2025-01-27 06:19:46.248044: train_loss -0.8115 
2025-01-27 06:19:46.254136: val_loss -0.765 
2025-01-27 06:19:46.256697: Pseudo dice [np.float32(0.9526), np.float32(0.87)] 
2025-01-27 06:19:46.259501: Epoch time: 49.37 s 
2025-01-27 06:19:47.503033:  
2025-01-27 06:19:47.507029: Epoch 369 
2025-01-27 06:19:47.510268: Current learning rate: 0.00661 
2025-01-27 06:20:36.568429: train_loss -0.8074 
2025-01-27 06:20:36.573590: val_loss -0.7753 
2025-01-27 06:20:36.576572: Pseudo dice [np.float32(0.9536), np.float32(0.9031)] 
2025-01-27 06:20:36.579524: Epoch time: 49.07 s 
2025-01-27 06:20:37.790429:  
2025-01-27 06:20:37.793612: Epoch 370 
2025-01-27 06:20:37.796864: Current learning rate: 0.0066 
2025-01-27 06:21:26.362082: train_loss -0.8002 
2025-01-27 06:21:26.368027: val_loss -0.7615 
2025-01-27 06:21:26.371104: Pseudo dice [np.float32(0.954), np.float32(0.8886)] 
2025-01-27 06:21:26.373953: Epoch time: 48.57 s 
2025-01-27 06:21:27.578500:  
2025-01-27 06:21:27.583609: Epoch 371 
2025-01-27 06:21:27.587204: Current learning rate: 0.00659 
2025-01-27 06:22:16.307454: train_loss -0.8217 
2025-01-27 06:22:16.311665: val_loss -0.8215 
2025-01-27 06:22:16.314218: Pseudo dice [np.float32(0.9592), np.float32(0.9032)] 
2025-01-27 06:22:16.316794: Epoch time: 48.73 s 
2025-01-27 06:22:17.527588:  
2025-01-27 06:22:17.530795: Epoch 372 
2025-01-27 06:22:17.533865: Current learning rate: 0.00658 
2025-01-27 06:23:05.996827: train_loss -0.8122 
2025-01-27 06:23:06.002381: val_loss -0.7614 
2025-01-27 06:23:06.005157: Pseudo dice [np.float32(0.9531), np.float32(0.9024)] 
2025-01-27 06:23:06.008053: Epoch time: 48.47 s 
2025-01-27 06:23:07.250608:  
2025-01-27 06:23:07.253948: Epoch 373 
2025-01-27 06:23:07.256647: Current learning rate: 0.00657 
2025-01-27 06:23:55.924324: train_loss -0.808 
2025-01-27 06:23:55.928605: val_loss -0.7438 
2025-01-27 06:23:55.931192: Pseudo dice [np.float32(0.9516), np.float32(0.8282)] 
2025-01-27 06:23:55.933899: Epoch time: 48.67 s 
2025-01-27 06:23:57.733847:  
2025-01-27 06:23:57.737684: Epoch 374 
2025-01-27 06:23:57.740857: Current learning rate: 0.00656 
2025-01-27 06:24:46.638879: train_loss -0.7971 
2025-01-27 06:24:46.645585: val_loss -0.7509 
2025-01-27 06:24:46.648665: Pseudo dice [np.float32(0.9478), np.float32(0.8659)] 
2025-01-27 06:24:46.651460: Epoch time: 48.91 s 
2025-01-27 06:24:47.864476:  
2025-01-27 06:24:47.867827: Epoch 375 
2025-01-27 06:24:47.870918: Current learning rate: 0.00655 
2025-01-27 06:25:36.702927: train_loss -0.7963 
2025-01-27 06:25:36.708838: val_loss -0.7343 
2025-01-27 06:25:36.711768: Pseudo dice [np.float32(0.9549), np.float32(0.8445)] 
2025-01-27 06:25:36.714272: Epoch time: 48.84 s 
2025-01-27 06:25:37.922243:  
2025-01-27 06:25:37.925608: Epoch 376 
2025-01-27 06:25:37.928607: Current learning rate: 0.00654 
2025-01-27 06:26:26.833475: train_loss -0.8145 
2025-01-27 06:26:26.840049: val_loss -0.7711 
2025-01-27 06:26:26.842798: Pseudo dice [np.float32(0.9593), np.float32(0.8987)] 
2025-01-27 06:26:26.845567: Epoch time: 48.91 s 
2025-01-27 06:26:28.102793:  
2025-01-27 06:26:28.106167: Epoch 377 
2025-01-27 06:26:28.109217: Current learning rate: 0.00653 
2025-01-27 06:27:16.826739: train_loss -0.803 
2025-01-27 06:27:16.830965: val_loss -0.7696 
2025-01-27 06:27:16.833654: Pseudo dice [np.float32(0.9559), np.float32(0.8658)] 
2025-01-27 06:27:16.836293: Epoch time: 48.72 s 
2025-01-27 06:27:18.072128:  
2025-01-27 06:27:18.076363: Epoch 378 
2025-01-27 06:27:18.079425: Current learning rate: 0.00652 
2025-01-27 06:28:06.840066: train_loss -0.7954 
2025-01-27 06:28:06.846922: val_loss -0.7588 
2025-01-27 06:28:06.849826: Pseudo dice [np.float32(0.9457), np.float32(0.8543)] 
2025-01-27 06:28:06.852745: Epoch time: 48.77 s 
2025-01-27 06:28:08.086595:  
2025-01-27 06:28:08.089654: Epoch 379 
2025-01-27 06:28:08.092631: Current learning rate: 0.00651 
2025-01-27 06:28:56.456265: train_loss -0.8226 
2025-01-27 06:28:56.460728: val_loss -0.7431 
2025-01-27 06:28:56.463477: Pseudo dice [np.float32(0.9554), np.float32(0.8624)] 
2025-01-27 06:28:56.466363: Epoch time: 48.37 s 
2025-01-27 06:28:57.699477:  
2025-01-27 06:28:57.703085: Epoch 380 
2025-01-27 06:28:57.706203: Current learning rate: 0.0065 
2025-01-27 06:29:46.733492: train_loss -0.8205 
2025-01-27 06:29:46.738970: val_loss -0.7938 
2025-01-27 06:29:46.741658: Pseudo dice [np.float32(0.9561), np.float32(0.8943)] 
2025-01-27 06:29:46.744766: Epoch time: 49.04 s 
2025-01-27 06:29:47.980663:  
2025-01-27 06:29:47.984104: Epoch 381 
2025-01-27 06:29:47.987412: Current learning rate: 0.00649 
2025-01-27 06:30:36.534564: train_loss -0.8362 
2025-01-27 06:30:36.538791: val_loss -0.7899 
2025-01-27 06:30:36.541281: Pseudo dice [np.float32(0.9615), np.float32(0.8788)] 
2025-01-27 06:30:36.543885: Epoch time: 48.56 s 
2025-01-27 06:30:37.775189:  
2025-01-27 06:30:37.778774: Epoch 382 
2025-01-27 06:30:37.781759: Current learning rate: 0.00648 
2025-01-27 06:31:26.311929: train_loss -0.7971 
2025-01-27 06:31:26.318866: val_loss -0.7553 
2025-01-27 06:31:26.321928: Pseudo dice [np.float32(0.9572), np.float32(0.8999)] 
2025-01-27 06:31:26.324614: Epoch time: 48.54 s 
2025-01-27 06:31:27.569472:  
2025-01-27 06:31:27.572682: Epoch 383 
2025-01-27 06:31:27.575713: Current learning rate: 0.00648 
2025-01-27 06:32:16.155256: train_loss -0.8263 
2025-01-27 06:32:16.159415: val_loss -0.7592 
2025-01-27 06:32:16.162279: Pseudo dice [np.float32(0.9587), np.float32(0.8343)] 
2025-01-27 06:32:16.165138: Epoch time: 48.59 s 
2025-01-27 06:32:17.404218:  
2025-01-27 06:32:17.407357: Epoch 384 
2025-01-27 06:32:17.410092: Current learning rate: 0.00647 
2025-01-27 06:33:06.034688: train_loss -0.8206 
2025-01-27 06:33:06.040733: val_loss -0.7888 
2025-01-27 06:33:06.043432: Pseudo dice [np.float32(0.9636), np.float32(0.8965)] 
2025-01-27 06:33:06.046118: Epoch time: 48.63 s 
2025-01-27 06:33:07.272575:  
2025-01-27 06:33:07.275609: Epoch 385 
2025-01-27 06:33:07.278472: Current learning rate: 0.00646 
2025-01-27 06:33:55.664888: train_loss -0.796 
2025-01-27 06:33:55.670493: val_loss -0.8005 
2025-01-27 06:33:55.673273: Pseudo dice [np.float32(0.9563), np.float32(0.9007)] 
2025-01-27 06:33:55.677382: Epoch time: 48.39 s 
2025-01-27 06:33:56.908271:  
2025-01-27 06:33:56.911584: Epoch 386 
2025-01-27 06:33:56.914405: Current learning rate: 0.00645 
2025-01-27 06:34:45.185445: train_loss -0.8325 
2025-01-27 06:34:45.191390: val_loss -0.7974 
2025-01-27 06:34:45.194140: Pseudo dice [np.float32(0.9556), np.float32(0.8535)] 
2025-01-27 06:34:45.196800: Epoch time: 48.28 s 
2025-01-27 06:34:46.432734:  
2025-01-27 06:34:46.435620: Epoch 387 
2025-01-27 06:34:46.438244: Current learning rate: 0.00644 
2025-01-27 06:35:35.179875: train_loss -0.8356 
2025-01-27 06:35:35.184593: val_loss -0.7805 
2025-01-27 06:35:35.187320: Pseudo dice [np.float32(0.9579), np.float32(0.9035)] 
2025-01-27 06:35:35.189891: Epoch time: 48.75 s 
2025-01-27 06:35:36.425901:  
2025-01-27 06:35:36.428892: Epoch 388 
2025-01-27 06:35:36.432186: Current learning rate: 0.00643 
2025-01-27 06:36:24.907158: train_loss -0.8029 
2025-01-27 06:36:24.912929: val_loss -0.7768 
2025-01-27 06:36:24.915975: Pseudo dice [np.float32(0.9593), np.float32(0.903)] 
2025-01-27 06:36:24.918957: Epoch time: 48.48 s 
2025-01-27 06:36:24.921381: Yayy! New best EMA pseudo Dice: 0.9178000092506409 
2025-01-27 06:36:26.733543:  
2025-01-27 06:36:26.736591: Epoch 389 
2025-01-27 06:36:26.739279: Current learning rate: 0.00642 
2025-01-27 06:37:15.625683: train_loss -0.8112 
2025-01-27 06:37:15.630045: val_loss -0.7751 
2025-01-27 06:37:15.632970: Pseudo dice [np.float32(0.9531), np.float32(0.8898)] 
2025-01-27 06:37:15.635388: Epoch time: 48.89 s 
2025-01-27 06:37:15.637806: Yayy! New best EMA pseudo Dice: 0.9182000160217285 
2025-01-27 06:37:17.466788:  
2025-01-27 06:37:17.469940: Epoch 390 
2025-01-27 06:37:17.473394: Current learning rate: 0.00641 
2025-01-27 06:38:05.884280: train_loss -0.8114 
2025-01-27 06:38:05.889998: val_loss -0.788 
2025-01-27 06:38:05.892668: Pseudo dice [np.float32(0.9565), np.float32(0.8903)] 
2025-01-27 06:38:05.895396: Epoch time: 48.42 s 
2025-01-27 06:38:05.898109: Yayy! New best EMA pseudo Dice: 0.9186999797821045 
2025-01-27 06:38:07.696553:  
2025-01-27 06:38:07.700268: Epoch 391 
2025-01-27 06:38:07.703693: Current learning rate: 0.0064 
2025-01-27 06:38:56.268912: train_loss -0.8331 
2025-01-27 06:38:56.273804: val_loss -0.7587 
2025-01-27 06:38:56.276816: Pseudo dice [np.float32(0.9507), np.float32(0.8763)] 
2025-01-27 06:38:56.279562: Epoch time: 48.57 s 
2025-01-27 06:38:58.204234:  
2025-01-27 06:38:58.207851: Epoch 392 
2025-01-27 06:38:58.210741: Current learning rate: 0.00639 
2025-01-27 06:39:47.163812: train_loss -0.8239 
2025-01-27 06:39:47.170055: val_loss -0.7558 
2025-01-27 06:39:47.172799: Pseudo dice [np.float32(0.9547), np.float32(0.8965)] 
2025-01-27 06:39:47.175355: Epoch time: 48.96 s 
2025-01-27 06:39:47.177840: Yayy! New best EMA pseudo Dice: 0.9189000129699707 
2025-01-27 06:39:48.992896:  
2025-01-27 06:39:48.996536: Epoch 393 
2025-01-27 06:39:48.999319: Current learning rate: 0.00638 
2025-01-27 06:40:37.895209: train_loss -0.8125 
2025-01-27 06:40:37.901570: val_loss -0.7939 
2025-01-27 06:40:37.904732: Pseudo dice [np.float32(0.9591), np.float32(0.8907)] 
2025-01-27 06:40:37.907505: Epoch time: 48.9 s 
2025-01-27 06:40:37.910312: Yayy! New best EMA pseudo Dice: 0.9194999933242798 
2025-01-27 06:40:39.794139:  
2025-01-27 06:40:39.799628: Epoch 394 
2025-01-27 06:40:39.802953: Current learning rate: 0.00637 
2025-01-27 06:41:28.737039: train_loss -0.832 
2025-01-27 06:41:28.742576: val_loss -0.7414 
2025-01-27 06:41:28.745160: Pseudo dice [np.float32(0.9528), np.float32(0.8413)] 
2025-01-27 06:41:28.747617: Epoch time: 48.95 s 
2025-01-27 06:41:29.977698:  
2025-01-27 06:41:29.980656: Epoch 395 
2025-01-27 06:41:29.983685: Current learning rate: 0.00636 
2025-01-27 06:42:18.769149: train_loss -0.8208 
2025-01-27 06:42:18.774767: val_loss -0.7941 
2025-01-27 06:42:18.777687: Pseudo dice [np.float32(0.9575), np.float32(0.8998)] 
2025-01-27 06:42:18.780731: Epoch time: 48.79 s 
2025-01-27 06:42:20.017837:  
2025-01-27 06:42:20.021361: Epoch 396 
2025-01-27 06:42:20.024529: Current learning rate: 0.00635 
2025-01-27 06:43:08.598443: train_loss -0.8157 
2025-01-27 06:43:08.603990: val_loss -0.7643 
2025-01-27 06:43:08.606710: Pseudo dice [np.float32(0.9537), np.float32(0.8977)] 
2025-01-27 06:43:08.609363: Epoch time: 48.58 s 
2025-01-27 06:43:09.837323:  
2025-01-27 06:43:09.840432: Epoch 397 
2025-01-27 06:43:09.843248: Current learning rate: 0.00634 
2025-01-27 06:43:58.974560: train_loss -0.8075 
2025-01-27 06:43:58.981788: val_loss -0.7711 
2025-01-27 06:43:58.985172: Pseudo dice [np.float32(0.9544), np.float32(0.8771)] 
2025-01-27 06:43:58.988502: Epoch time: 49.14 s 
2025-01-27 06:44:00.220520:  
2025-01-27 06:44:00.223706: Epoch 398 
2025-01-27 06:44:00.226686: Current learning rate: 0.00633 
2025-01-27 06:44:48.888778: train_loss -0.8193 
2025-01-27 06:44:48.895215: val_loss -0.7621 
2025-01-27 06:44:48.897869: Pseudo dice [np.float32(0.949), np.float32(0.8455)] 
2025-01-27 06:44:48.900648: Epoch time: 48.67 s 
2025-01-27 06:44:50.171235:  
2025-01-27 06:44:50.176053: Epoch 399 
2025-01-27 06:44:50.179111: Current learning rate: 0.00632 
2025-01-27 06:45:38.809840: train_loss -0.8093 
2025-01-27 06:45:38.814781: val_loss -0.7507 
2025-01-27 06:45:38.817655: Pseudo dice [np.float32(0.9533), np.float32(0.8482)] 
2025-01-27 06:45:38.820524: Epoch time: 48.64 s 
2025-01-27 06:45:40.674989:  
2025-01-27 06:45:40.678238: Epoch 400 
2025-01-27 06:45:40.681205: Current learning rate: 0.00631 
2025-01-27 06:46:29.337265: train_loss -0.8359 
2025-01-27 06:46:29.342584: val_loss -0.7315 
2025-01-27 06:46:29.345230: Pseudo dice [np.float32(0.9547), np.float32(0.8785)] 
2025-01-27 06:46:29.348194: Epoch time: 48.66 s 
2025-01-27 06:46:30.580132:  
2025-01-27 06:46:30.583536: Epoch 401 
2025-01-27 06:46:30.586699: Current learning rate: 0.0063 
2025-01-27 06:47:19.821888: train_loss -0.8191 
2025-01-27 06:47:19.826407: val_loss -0.7285 
2025-01-27 06:47:19.829168: Pseudo dice [np.float32(0.9543), np.float32(0.8687)] 
2025-01-27 06:47:19.831672: Epoch time: 49.24 s 
2025-01-27 06:47:21.053515:  
2025-01-27 06:47:21.056639: Epoch 402 
2025-01-27 06:47:21.059566: Current learning rate: 0.0063 
2025-01-27 06:48:09.546906: train_loss -0.8165 
2025-01-27 06:48:09.552592: val_loss -0.774 
2025-01-27 06:48:09.555059: Pseudo dice [np.float32(0.9555), np.float32(0.8976)] 
2025-01-27 06:48:09.557822: Epoch time: 48.49 s 
2025-01-27 06:48:10.791716:  
2025-01-27 06:48:10.795168: Epoch 403 
2025-01-27 06:48:10.798305: Current learning rate: 0.00629 
2025-01-27 06:48:59.395024: train_loss -0.7993 
2025-01-27 06:48:59.400361: val_loss -0.7378 
2025-01-27 06:48:59.403260: Pseudo dice [np.float32(0.9553), np.float32(0.8681)] 
2025-01-27 06:48:59.406035: Epoch time: 48.6 s 
2025-01-27 06:49:00.657490:  
2025-01-27 06:49:00.660712: Epoch 404 
2025-01-27 06:49:00.664013: Current learning rate: 0.00628 
2025-01-27 06:49:49.267373: train_loss -0.8101 
2025-01-27 06:49:49.274973: val_loss -0.8195 
2025-01-27 06:49:49.278143: Pseudo dice [np.float32(0.9525), np.float32(0.9004)] 
2025-01-27 06:49:49.281131: Epoch time: 48.61 s 
2025-01-27 06:49:50.510932:  
2025-01-27 06:49:50.515366: Epoch 405 
2025-01-27 06:49:50.518250: Current learning rate: 0.00627 
2025-01-27 06:50:39.306314: train_loss -0.8286 
2025-01-27 06:50:39.311455: val_loss -0.779 
2025-01-27 06:50:39.314344: Pseudo dice [np.float32(0.9575), np.float32(0.8818)] 
2025-01-27 06:50:39.317924: Epoch time: 48.8 s 
2025-01-27 06:50:40.576281:  
2025-01-27 06:50:40.579873: Epoch 406 
2025-01-27 06:50:40.582685: Current learning rate: 0.00626 
2025-01-27 06:51:28.839887: train_loss -0.8156 
2025-01-27 06:51:28.846536: val_loss -0.7745 
2025-01-27 06:51:28.849275: Pseudo dice [np.float32(0.9589), np.float32(0.8863)] 
2025-01-27 06:51:28.852015: Epoch time: 48.26 s 
2025-01-27 06:51:30.104100:  
2025-01-27 06:51:30.106858: Epoch 407 
2025-01-27 06:51:30.109361: Current learning rate: 0.00625 
2025-01-27 06:52:18.359685: train_loss -0.8112 
2025-01-27 06:52:18.364707: val_loss -0.7606 
2025-01-27 06:52:18.367447: Pseudo dice [np.float32(0.9447), np.float32(0.861)] 
2025-01-27 06:52:18.370599: Epoch time: 48.26 s 
2025-01-27 06:52:19.625142:  
2025-01-27 06:52:19.628467: Epoch 408 
2025-01-27 06:52:19.630950: Current learning rate: 0.00624 
2025-01-27 06:53:07.710993: train_loss -0.8254 
2025-01-27 06:53:07.717125: val_loss -0.7957 
2025-01-27 06:53:07.720021: Pseudo dice [np.float32(0.9563), np.float32(0.9098)] 
2025-01-27 06:53:07.722595: Epoch time: 48.09 s 
2025-01-27 06:53:09.614757:  
2025-01-27 06:53:09.617877: Epoch 409 
2025-01-27 06:53:09.620678: Current learning rate: 0.00623 
2025-01-27 06:53:58.711347: train_loss -0.8077 
2025-01-27 06:53:58.715585: val_loss -0.7402 
2025-01-27 06:53:58.718505: Pseudo dice [np.float32(0.9581), np.float32(0.7897)] 
2025-01-27 06:53:58.721147: Epoch time: 49.1 s 
2025-01-27 06:53:59.969420:  
2025-01-27 06:53:59.972500: Epoch 410 
2025-01-27 06:53:59.975219: Current learning rate: 0.00622 
2025-01-27 06:54:48.719660: train_loss -0.7972 
2025-01-27 06:54:48.725412: val_loss -0.7649 
2025-01-27 06:54:48.728073: Pseudo dice [np.float32(0.9537), np.float32(0.8778)] 
2025-01-27 06:54:48.730526: Epoch time: 48.75 s 
2025-01-27 06:54:49.901157:  
2025-01-27 06:54:49.904320: Epoch 411 
2025-01-27 06:54:49.906880: Current learning rate: 0.00621 
2025-01-27 06:55:37.975574: train_loss -0.8136 
2025-01-27 06:55:37.981473: val_loss -0.7274 
2025-01-27 06:55:37.983837: Pseudo dice [np.float32(0.9558), np.float32(0.8327)] 
2025-01-27 06:55:37.986310: Epoch time: 48.08 s 
2025-01-27 06:55:39.161377:  
2025-01-27 06:55:39.164365: Epoch 412 
2025-01-27 06:55:39.167533: Current learning rate: 0.0062 
2025-01-27 06:56:28.197626: train_loss -0.7986 
2025-01-27 06:56:28.203728: val_loss -0.7641 
2025-01-27 06:56:28.206277: Pseudo dice [np.float32(0.9594), np.float32(0.8844)] 
2025-01-27 06:56:28.209134: Epoch time: 49.04 s 
2025-01-27 06:56:29.388572:  
2025-01-27 06:56:29.391787: Epoch 413 
2025-01-27 06:56:29.394737: Current learning rate: 0.00619 
2025-01-27 06:57:17.479621: train_loss -0.813 
2025-01-27 06:57:17.483860: val_loss -0.7872 
2025-01-27 06:57:17.486512: Pseudo dice [np.float32(0.9554), np.float32(0.865)] 
2025-01-27 06:57:17.489167: Epoch time: 48.09 s 
2025-01-27 06:57:18.669771:  
2025-01-27 06:57:18.673063: Epoch 414 
2025-01-27 06:57:18.675821: Current learning rate: 0.00618 
2025-01-27 06:58:07.563174: train_loss -0.8301 
2025-01-27 06:58:07.571261: val_loss -0.7786 
2025-01-27 06:58:07.574442: Pseudo dice [np.float32(0.9574), np.float32(0.8997)] 
2025-01-27 06:58:07.577393: Epoch time: 48.89 s 
2025-01-27 06:58:08.757407:  
2025-01-27 06:58:08.760777: Epoch 415 
2025-01-27 06:58:08.763935: Current learning rate: 0.00617 
2025-01-27 06:58:57.452270: train_loss -0.7921 
2025-01-27 06:58:57.457082: val_loss -0.7929 
2025-01-27 06:58:57.459685: Pseudo dice [np.float32(0.9556), np.float32(0.8609)] 
2025-01-27 06:58:57.462235: Epoch time: 48.7 s 
2025-01-27 06:58:58.647858:  
2025-01-27 06:58:58.650874: Epoch 416 
2025-01-27 06:58:58.653665: Current learning rate: 0.00616 
2025-01-27 06:59:47.060190: train_loss -0.8131 
2025-01-27 06:59:47.067662: val_loss -0.7433 
2025-01-27 06:59:47.070019: Pseudo dice [np.float32(0.9518), np.float32(0.882)] 
2025-01-27 06:59:47.072515: Epoch time: 48.41 s 
2025-01-27 06:59:48.255129:  
2025-01-27 06:59:48.258277: Epoch 417 
2025-01-27 06:59:48.261150: Current learning rate: 0.00615 
2025-01-27 07:00:36.420348: train_loss -0.8346 
2025-01-27 07:00:36.425488: val_loss -0.8058 
2025-01-27 07:00:36.428608: Pseudo dice [np.float32(0.9582), np.float32(0.9036)] 
2025-01-27 07:00:36.431771: Epoch time: 48.17 s 
2025-01-27 07:00:37.615586:  
2025-01-27 07:00:37.618854: Epoch 418 
2025-01-27 07:00:37.622281: Current learning rate: 0.00614 
2025-01-27 07:01:25.739155: train_loss -0.8159 
2025-01-27 07:01:25.744640: val_loss -0.7064 
2025-01-27 07:01:25.747343: Pseudo dice [np.float32(0.9484), np.float32(0.8528)] 
2025-01-27 07:01:25.749811: Epoch time: 48.12 s 
2025-01-27 07:01:26.925948:  
2025-01-27 07:01:26.928660: Epoch 419 
2025-01-27 07:01:26.931294: Current learning rate: 0.00613 
2025-01-27 07:02:15.580099: train_loss -0.7956 
2025-01-27 07:02:15.584467: val_loss -0.7329 
2025-01-27 07:02:15.587211: Pseudo dice [np.float32(0.9538), np.float32(0.8719)] 
2025-01-27 07:02:15.589777: Epoch time: 48.66 s 
2025-01-27 07:02:16.767844:  
2025-01-27 07:02:16.770609: Epoch 420 
2025-01-27 07:02:16.773892: Current learning rate: 0.00612 
2025-01-27 07:03:05.851999: train_loss -0.8073 
2025-01-27 07:03:05.858315: val_loss -0.787 
2025-01-27 07:03:05.861005: Pseudo dice [np.float32(0.9549), np.float32(0.899)] 
2025-01-27 07:03:05.863798: Epoch time: 49.09 s 
2025-01-27 07:03:07.042369:  
2025-01-27 07:03:07.045283: Epoch 421 
2025-01-27 07:03:07.047898: Current learning rate: 0.00612 
2025-01-27 07:03:55.506002: train_loss -0.8148 
2025-01-27 07:03:55.511749: val_loss -0.7829 
2025-01-27 07:03:55.514646: Pseudo dice [np.float32(0.9494), np.float32(0.883)] 
2025-01-27 07:03:55.517287: Epoch time: 48.46 s 
2025-01-27 07:03:56.699687:  
2025-01-27 07:03:56.702521: Epoch 422 
2025-01-27 07:03:56.705273: Current learning rate: 0.00611 
2025-01-27 07:04:44.914250: train_loss -0.8147 
2025-01-27 07:04:44.923248: val_loss -0.7679 
2025-01-27 07:04:44.926219: Pseudo dice [np.float32(0.9552), np.float32(0.8808)] 
2025-01-27 07:04:44.929099: Epoch time: 48.22 s 
2025-01-27 07:04:46.105943:  
2025-01-27 07:04:46.108984: Epoch 423 
2025-01-27 07:04:46.112015: Current learning rate: 0.0061 
2025-01-27 07:05:34.697148: train_loss -0.8075 
2025-01-27 07:05:34.701652: val_loss -0.7725 
2025-01-27 07:05:34.704466: Pseudo dice [np.float32(0.9518), np.float32(0.8992)] 
2025-01-27 07:05:34.707256: Epoch time: 48.59 s 
2025-01-27 07:05:35.891886:  
2025-01-27 07:05:35.894682: Epoch 424 
2025-01-27 07:05:35.897838: Current learning rate: 0.00609 
2025-01-27 07:06:24.015354: train_loss -0.8043 
2025-01-27 07:06:24.021077: val_loss -0.7244 
2025-01-27 07:06:24.024170: Pseudo dice [np.float32(0.9418), np.float32(0.7575)] 
2025-01-27 07:06:24.026904: Epoch time: 48.12 s 
2025-01-27 07:06:25.203697:  
2025-01-27 07:06:25.206699: Epoch 425 
2025-01-27 07:06:25.209555: Current learning rate: 0.00608 
2025-01-27 07:07:13.459174: train_loss -0.8069 
2025-01-27 07:07:13.463714: val_loss -0.7589 
2025-01-27 07:07:13.466676: Pseudo dice [np.float32(0.9517), np.float32(0.8884)] 
2025-01-27 07:07:13.469467: Epoch time: 48.26 s 
2025-01-27 07:07:14.644580:  
2025-01-27 07:07:14.647556: Epoch 426 
2025-01-27 07:07:14.650677: Current learning rate: 0.00607 
2025-01-27 07:08:02.898999: train_loss -0.8105 
2025-01-27 07:08:02.905248: val_loss -0.7503 
2025-01-27 07:08:02.908309: Pseudo dice [np.float32(0.9603), np.float32(0.8965)] 
2025-01-27 07:08:02.911247: Epoch time: 48.26 s 
2025-01-27 07:08:04.085188:  
2025-01-27 07:08:04.088334: Epoch 427 
2025-01-27 07:08:04.091030: Current learning rate: 0.00606 
2025-01-27 07:08:52.399095: train_loss -0.8307 
2025-01-27 07:08:52.404176: val_loss -0.7509 
2025-01-27 07:08:52.407260: Pseudo dice [np.float32(0.9607), np.float32(0.8919)] 
2025-01-27 07:08:52.410204: Epoch time: 48.31 s 
2025-01-27 07:08:54.164769:  
2025-01-27 07:08:54.168330: Epoch 428 
2025-01-27 07:08:54.170942: Current learning rate: 0.00605 
2025-01-27 07:09:42.754896: train_loss -0.8168 
2025-01-27 07:09:42.762773: val_loss -0.7724 
2025-01-27 07:09:42.765537: Pseudo dice [np.float32(0.9581), np.float32(0.9135)] 
2025-01-27 07:09:42.768168: Epoch time: 48.59 s 
2025-01-27 07:09:43.948162:  
2025-01-27 07:09:43.951552: Epoch 429 
2025-01-27 07:09:43.954367: Current learning rate: 0.00604 
2025-01-27 07:10:32.192514: train_loss -0.8152 
2025-01-27 07:10:32.198126: val_loss -0.7378 
2025-01-27 07:10:32.201636: Pseudo dice [np.float32(0.9489), np.float32(0.877)] 
2025-01-27 07:10:32.204466: Epoch time: 48.25 s 
2025-01-27 07:10:33.379511:  
2025-01-27 07:10:33.382524: Epoch 430 
2025-01-27 07:10:33.385524: Current learning rate: 0.00603 
2025-01-27 07:11:22.105608: train_loss -0.8101 
2025-01-27 07:11:22.114659: val_loss -0.7666 
2025-01-27 07:11:22.117602: Pseudo dice [np.float32(0.9561), np.float32(0.8399)] 
2025-01-27 07:11:22.120208: Epoch time: 48.73 s 
2025-01-27 07:11:23.290681:  
2025-01-27 07:11:23.293564: Epoch 431 
2025-01-27 07:11:23.296561: Current learning rate: 0.00602 
2025-01-27 07:12:12.114514: train_loss -0.8184 
2025-01-27 07:12:12.118762: val_loss -0.8015 
2025-01-27 07:12:12.121325: Pseudo dice [np.float32(0.9605), np.float32(0.8747)] 
2025-01-27 07:12:12.124092: Epoch time: 48.82 s 
2025-01-27 07:12:13.304465:  
2025-01-27 07:12:13.308273: Epoch 432 
2025-01-27 07:12:13.311478: Current learning rate: 0.00601 
2025-01-27 07:13:01.710779: train_loss -0.8157 
2025-01-27 07:13:01.717354: val_loss -0.7705 
2025-01-27 07:13:01.720324: Pseudo dice [np.float32(0.9621), np.float32(0.896)] 
2025-01-27 07:13:01.722973: Epoch time: 48.41 s 
2025-01-27 07:13:02.901470:  
2025-01-27 07:13:02.905335: Epoch 433 
2025-01-27 07:13:02.908886: Current learning rate: 0.006 
2025-01-27 07:13:51.354849: train_loss -0.8136 
2025-01-27 07:13:51.358803: val_loss -0.7661 
2025-01-27 07:13:51.361412: Pseudo dice [np.float32(0.9485), np.float32(0.882)] 
2025-01-27 07:13:51.364079: Epoch time: 48.45 s 
2025-01-27 07:13:52.542087:  
2025-01-27 07:13:52.545110: Epoch 434 
2025-01-27 07:13:52.548144: Current learning rate: 0.00599 
2025-01-27 07:14:40.757710: train_loss -0.8237 
2025-01-27 07:14:40.763968: val_loss -0.7639 
2025-01-27 07:14:40.766834: Pseudo dice [np.float32(0.9548), np.float32(0.8619)] 
2025-01-27 07:14:40.769480: Epoch time: 48.22 s 
2025-01-27 07:14:41.943736:  
2025-01-27 07:14:41.947403: Epoch 435 
2025-01-27 07:14:41.950254: Current learning rate: 0.00598 
2025-01-27 07:15:30.658412: train_loss -0.8198 
2025-01-27 07:15:30.668340: val_loss -0.7582 
2025-01-27 07:15:30.671375: Pseudo dice [np.float32(0.9546), np.float32(0.898)] 
2025-01-27 07:15:30.674496: Epoch time: 48.72 s 
2025-01-27 07:15:31.854801:  
2025-01-27 07:15:31.858010: Epoch 436 
2025-01-27 07:15:31.861024: Current learning rate: 0.00597 
2025-01-27 07:16:20.355316: train_loss -0.8249 
2025-01-27 07:16:20.360389: val_loss -0.7725 
2025-01-27 07:16:20.363237: Pseudo dice [np.float32(0.9642), np.float32(0.9026)] 
2025-01-27 07:16:20.365605: Epoch time: 48.5 s 
2025-01-27 07:16:21.537847:  
2025-01-27 07:16:21.541082: Epoch 437 
2025-01-27 07:16:21.544263: Current learning rate: 0.00596 
2025-01-27 07:17:10.082864: train_loss -0.8349 
2025-01-27 07:17:10.089312: val_loss -0.8004 
2025-01-27 07:17:10.092112: Pseudo dice [np.float32(0.9593), np.float32(0.8779)] 
2025-01-27 07:17:10.094997: Epoch time: 48.55 s 
2025-01-27 07:17:11.278457:  
2025-01-27 07:17:11.281792: Epoch 438 
2025-01-27 07:17:11.284741: Current learning rate: 0.00595 
2025-01-27 07:17:59.668248: train_loss -0.8196 
2025-01-27 07:17:59.674244: val_loss -0.7995 
2025-01-27 07:17:59.677126: Pseudo dice [np.float32(0.9608), np.float32(0.883)] 
2025-01-27 07:17:59.680053: Epoch time: 48.39 s 
2025-01-27 07:18:00.851318:  
2025-01-27 07:18:00.854523: Epoch 439 
2025-01-27 07:18:00.857478: Current learning rate: 0.00594 
2025-01-27 07:18:49.641113: train_loss -0.8382 
2025-01-27 07:18:49.645777: val_loss -0.7345 
2025-01-27 07:18:49.648809: Pseudo dice [np.float32(0.9592), np.float32(0.8308)] 
2025-01-27 07:18:49.651573: Epoch time: 48.79 s 
2025-01-27 07:18:50.825477:  
2025-01-27 07:18:50.828194: Epoch 440 
2025-01-27 07:18:50.831171: Current learning rate: 0.00593 
2025-01-27 07:19:38.932992: train_loss -0.8233 
2025-01-27 07:19:38.938176: val_loss -0.7553 
2025-01-27 07:19:38.940981: Pseudo dice [np.float32(0.9579), np.float32(0.9116)] 
2025-01-27 07:19:38.943625: Epoch time: 48.11 s 
2025-01-27 07:19:40.113946:  
2025-01-27 07:19:40.117040: Epoch 441 
2025-01-27 07:19:40.119750: Current learning rate: 0.00592 
2025-01-27 07:20:28.721042: train_loss -0.8333 
2025-01-27 07:20:28.725268: val_loss -0.7501 
2025-01-27 07:20:28.727874: Pseudo dice [np.float32(0.9525), np.float32(0.8529)] 
2025-01-27 07:20:28.730230: Epoch time: 48.61 s 
2025-01-27 07:20:29.901197:  
2025-01-27 07:20:29.906468: Epoch 442 
2025-01-27 07:20:29.909448: Current learning rate: 0.00592 
2025-01-27 07:21:18.565827: train_loss -0.8227 
2025-01-27 07:21:18.574174: val_loss -0.7671 
2025-01-27 07:21:18.577501: Pseudo dice [np.float32(0.9566), np.float32(0.8839)] 
2025-01-27 07:21:18.580225: Epoch time: 48.67 s 
2025-01-27 07:21:19.759422:  
2025-01-27 07:21:19.762812: Epoch 443 
2025-01-27 07:21:19.765803: Current learning rate: 0.00591 
2025-01-27 07:22:07.955684: train_loss -0.8195 
2025-01-27 07:22:07.968682: val_loss -0.7851 
2025-01-27 07:22:07.971596: Pseudo dice [np.float32(0.9523), np.float32(0.9045)] 
2025-01-27 07:22:07.974159: Epoch time: 48.2 s 
2025-01-27 07:22:09.139892:  
2025-01-27 07:22:09.142463: Epoch 444 
2025-01-27 07:22:09.145381: Current learning rate: 0.0059 
2025-01-27 07:22:57.406275: train_loss -0.8085 
2025-01-27 07:22:57.412834: val_loss -0.7606 
2025-01-27 07:22:57.415936: Pseudo dice [np.float32(0.9482), np.float32(0.8608)] 
2025-01-27 07:22:57.418992: Epoch time: 48.27 s 
2025-01-27 07:22:58.570422:  
2025-01-27 07:22:58.573522: Epoch 445 
2025-01-27 07:22:58.576611: Current learning rate: 0.00589 
2025-01-27 07:23:46.862523: train_loss -0.8114 
2025-01-27 07:23:46.866702: val_loss -0.7964 
2025-01-27 07:23:46.869503: Pseudo dice [np.float32(0.9522), np.float32(0.8987)] 
2025-01-27 07:23:46.872276: Epoch time: 48.29 s 
2025-01-27 07:23:48.038219:  
2025-01-27 07:23:48.041194: Epoch 446 
2025-01-27 07:23:48.044223: Current learning rate: 0.00588 
2025-01-27 07:24:36.167870: train_loss -0.8234 
2025-01-27 07:24:36.173413: val_loss -0.7702 
2025-01-27 07:24:36.176183: Pseudo dice [np.float32(0.9599), np.float32(0.9003)] 
2025-01-27 07:24:36.178994: Epoch time: 48.13 s 
2025-01-27 07:24:37.332718:  
2025-01-27 07:24:37.335532: Epoch 447 
2025-01-27 07:24:37.338455: Current learning rate: 0.00587 
2025-01-27 07:25:26.185629: train_loss -0.7976 
2025-01-27 07:25:26.191569: val_loss -0.7941 
2025-01-27 07:25:26.194201: Pseudo dice [np.float32(0.9495), np.float32(0.8669)] 
2025-01-27 07:25:26.196988: Epoch time: 48.85 s 
2025-01-27 07:25:27.928517:  
2025-01-27 07:25:27.931397: Epoch 448 
2025-01-27 07:25:27.934159: Current learning rate: 0.00586 
2025-01-27 07:26:16.690336: train_loss -0.8143 
2025-01-27 07:26:16.697132: val_loss -0.7342 
2025-01-27 07:26:16.700177: Pseudo dice [np.float32(0.9592), np.float32(0.8881)] 
2025-01-27 07:26:16.703271: Epoch time: 48.76 s 
2025-01-27 07:26:17.875443:  
2025-01-27 07:26:17.878624: Epoch 449 
2025-01-27 07:26:17.881581: Current learning rate: 0.00585 
2025-01-27 07:27:06.533254: train_loss -0.8125 
2025-01-27 07:27:06.537484: val_loss -0.755 
2025-01-27 07:27:06.540330: Pseudo dice [np.float32(0.9527), np.float32(0.863)] 
2025-01-27 07:27:06.542746: Epoch time: 48.66 s 
2025-01-27 07:27:08.475822:  
2025-01-27 07:27:08.479582: Epoch 450 
2025-01-27 07:27:08.482311: Current learning rate: 0.00584 
2025-01-27 07:27:57.607161: train_loss -0.7972 
2025-01-27 07:27:57.615155: val_loss -0.7194 
2025-01-27 07:27:57.617949: Pseudo dice [np.float32(0.9511), np.float32(0.8699)] 
2025-01-27 07:27:57.620610: Epoch time: 49.13 s 
2025-01-27 07:27:58.767745:  
2025-01-27 07:27:58.771001: Epoch 451 
2025-01-27 07:27:58.774208: Current learning rate: 0.00583 
2025-01-27 07:28:47.497616: train_loss -0.8187 
2025-01-27 07:28:47.502147: val_loss -0.7485 
2025-01-27 07:28:47.505185: Pseudo dice [np.float32(0.9562), np.float32(0.8589)] 
2025-01-27 07:28:47.508104: Epoch time: 48.73 s 
2025-01-27 07:28:48.692763:  
2025-01-27 07:28:48.696025: Epoch 452 
2025-01-27 07:28:48.699606: Current learning rate: 0.00582 
2025-01-27 07:29:37.879020: train_loss -0.8158 
2025-01-27 07:29:37.885518: val_loss -0.7842 
2025-01-27 07:29:37.888641: Pseudo dice [np.float32(0.9507), np.float32(0.8877)] 
2025-01-27 07:29:37.891410: Epoch time: 49.19 s 
2025-01-27 07:29:39.053110:  
2025-01-27 07:29:39.056240: Epoch 453 
2025-01-27 07:29:39.059345: Current learning rate: 0.00581 
2025-01-27 07:30:28.093423: train_loss -0.8213 
2025-01-27 07:30:28.099321: val_loss -0.7982 
2025-01-27 07:30:28.102537: Pseudo dice [np.float32(0.9538), np.float32(0.8939)] 
2025-01-27 07:30:28.105348: Epoch time: 49.04 s 
2025-01-27 07:30:29.261029:  
2025-01-27 07:30:29.264494: Epoch 454 
2025-01-27 07:30:29.267600: Current learning rate: 0.0058 
2025-01-27 07:31:17.598638: train_loss -0.8069 
2025-01-27 07:31:17.605175: val_loss -0.7558 
2025-01-27 07:31:17.608080: Pseudo dice [np.float32(0.9569), np.float32(0.9059)] 
2025-01-27 07:31:17.610516: Epoch time: 48.34 s 
2025-01-27 07:31:18.781536:  
2025-01-27 07:31:18.784842: Epoch 455 
2025-01-27 07:31:18.788292: Current learning rate: 0.00579 
2025-01-27 07:32:07.828641: train_loss -0.8074 
2025-01-27 07:32:07.835997: val_loss -0.7625 
2025-01-27 07:32:07.839534: Pseudo dice [np.float32(0.9619), np.float32(0.8992)] 
2025-01-27 07:32:07.842776: Epoch time: 49.05 s 
2025-01-27 07:32:08.998965:  
2025-01-27 07:32:09.001951: Epoch 456 
2025-01-27 07:32:09.007926: Current learning rate: 0.00578 
2025-01-27 07:32:57.593792: train_loss -0.8305 
2025-01-27 07:32:57.600680: val_loss -0.7828 
2025-01-27 07:32:57.603751: Pseudo dice [np.float32(0.9569), np.float32(0.8833)] 
2025-01-27 07:32:57.606313: Epoch time: 48.6 s 
2025-01-27 07:32:57.609116: Yayy! New best EMA pseudo Dice: 0.9194999933242798 
2025-01-27 07:32:59.375789:  
2025-01-27 07:32:59.393418: Epoch 457 
2025-01-27 07:32:59.403883: Current learning rate: 0.00577 
2025-01-27 07:33:48.351951: train_loss -0.8205 
2025-01-27 07:33:48.356455: val_loss -0.7502 
2025-01-27 07:33:48.359349: Pseudo dice [np.float32(0.9583), np.float32(0.8962)] 
2025-01-27 07:33:48.362809: Epoch time: 48.98 s 
2025-01-27 07:33:48.365670: Yayy! New best EMA pseudo Dice: 0.9203000068664551 
2025-01-27 07:33:50.086051:  
2025-01-27 07:33:50.089622: Epoch 458 
2025-01-27 07:33:50.092745: Current learning rate: 0.00576 
2025-01-27 07:34:38.599996: train_loss -0.8211 
2025-01-27 07:34:38.607388: val_loss -0.7651 
2025-01-27 07:34:38.610144: Pseudo dice [np.float32(0.9555), np.float32(0.915)] 
2025-01-27 07:34:38.613457: Epoch time: 48.51 s 
2025-01-27 07:34:38.616194: Yayy! New best EMA pseudo Dice: 0.9218000173568726 
2025-01-27 07:34:40.327382:  
2025-01-27 07:34:40.330845: Epoch 459 
2025-01-27 07:34:40.333788: Current learning rate: 0.00575 
2025-01-27 07:35:28.933331: train_loss -0.8296 
2025-01-27 07:35:28.938122: val_loss -0.7629 
2025-01-27 07:35:28.940952: Pseudo dice [np.float32(0.9548), np.float32(0.8694)] 
2025-01-27 07:35:28.943638: Epoch time: 48.61 s 
2025-01-27 07:35:30.128483:  
2025-01-27 07:35:30.131685: Epoch 460 
2025-01-27 07:35:30.134608: Current learning rate: 0.00574 
2025-01-27 07:36:19.119641: train_loss -0.8094 
2025-01-27 07:36:19.126698: val_loss -0.7325 
2025-01-27 07:36:19.129565: Pseudo dice [np.float32(0.9524), np.float32(0.8256)] 
2025-01-27 07:36:19.132030: Epoch time: 48.99 s 
2025-01-27 07:36:20.272007:  
2025-01-27 07:36:20.275100: Epoch 461 
2025-01-27 07:36:20.277807: Current learning rate: 0.00573 
2025-01-27 07:37:08.981529: train_loss -0.8121 
2025-01-27 07:37:08.988081: val_loss -0.7818 
2025-01-27 07:37:08.991186: Pseudo dice [np.float32(0.9556), np.float32(0.8693)] 
2025-01-27 07:37:08.994110: Epoch time: 48.71 s 
2025-01-27 07:37:10.148316:  
2025-01-27 07:37:10.151336: Epoch 462 
2025-01-27 07:37:10.154251: Current learning rate: 0.00572 
2025-01-27 07:37:58.520551: train_loss -0.8287 
2025-01-27 07:37:58.527710: val_loss -0.7731 
2025-01-27 07:37:58.530599: Pseudo dice [np.float32(0.9564), np.float32(0.8765)] 
2025-01-27 07:37:58.534060: Epoch time: 48.37 s 
2025-01-27 07:37:59.700967:  
2025-01-27 07:37:59.704337: Epoch 463 
2025-01-27 07:37:59.707357: Current learning rate: 0.00571 
2025-01-27 07:38:48.498315: train_loss -0.8228 
2025-01-27 07:38:48.502338: val_loss -0.7899 
2025-01-27 07:38:48.504971: Pseudo dice [np.float32(0.9538), np.float32(0.8424)] 
2025-01-27 07:38:48.507660: Epoch time: 48.8 s 
2025-01-27 07:38:49.683827:  
2025-01-27 07:38:49.686937: Epoch 464 
2025-01-27 07:38:49.690080: Current learning rate: 0.0057 
2025-01-27 07:39:38.228720: train_loss -0.8293 
2025-01-27 07:39:38.234636: val_loss -0.77 
2025-01-27 07:39:38.237488: Pseudo dice [np.float32(0.949), np.float32(0.8887)] 
2025-01-27 07:39:38.240185: Epoch time: 48.55 s 
2025-01-27 07:39:39.467854:  
2025-01-27 07:39:39.471229: Epoch 465 
2025-01-27 07:39:39.474308: Current learning rate: 0.0057 
2025-01-27 07:40:27.940322: train_loss -0.809 
2025-01-27 07:40:27.944939: val_loss -0.7538 
2025-01-27 07:40:27.947813: Pseudo dice [np.float32(0.9533), np.float32(0.8818)] 
2025-01-27 07:40:27.950668: Epoch time: 48.47 s 
2025-01-27 07:40:29.111752:  
2025-01-27 07:40:29.115206: Epoch 466 
2025-01-27 07:40:29.118090: Current learning rate: 0.00569 
2025-01-27 07:41:17.897891: train_loss -0.8123 
2025-01-27 07:41:17.906017: val_loss -0.7896 
2025-01-27 07:41:17.908853: Pseudo dice [np.float32(0.9569), np.float32(0.8927)] 
2025-01-27 07:41:17.911707: Epoch time: 48.79 s 
2025-01-27 07:41:19.707372:  
2025-01-27 07:41:19.711198: Epoch 467 
2025-01-27 07:41:19.713950: Current learning rate: 0.00568 
2025-01-27 07:42:08.625847: train_loss -0.8182 
2025-01-27 07:42:08.630990: val_loss -0.7431 
2025-01-27 07:42:08.634087: Pseudo dice [np.float32(0.9597), np.float32(0.8751)] 
2025-01-27 07:42:08.636900: Epoch time: 48.92 s 
2025-01-27 07:42:09.800242:  
2025-01-27 07:42:09.804096: Epoch 468 
2025-01-27 07:42:09.807605: Current learning rate: 0.00567 
2025-01-27 07:42:59.522108: train_loss -0.8117 
2025-01-27 07:42:59.528888: val_loss -0.7584 
2025-01-27 07:42:59.531822: Pseudo dice [np.float32(0.9597), np.float32(0.8833)] 
2025-01-27 07:42:59.534909: Epoch time: 49.72 s 
2025-01-27 07:43:00.688847:  
2025-01-27 07:43:00.692243: Epoch 469 
2025-01-27 07:43:00.695579: Current learning rate: 0.00566 
2025-01-27 07:43:49.562918: train_loss -0.8102 
2025-01-27 07:43:49.567947: val_loss -0.798 
2025-01-27 07:43:49.571313: Pseudo dice [np.float32(0.9533), np.float32(0.869)] 
2025-01-27 07:43:49.574469: Epoch time: 48.88 s 
2025-01-27 07:43:50.731804:  
2025-01-27 07:43:50.735549: Epoch 470 
2025-01-27 07:43:50.738819: Current learning rate: 0.00565 
2025-01-27 07:44:39.619358: train_loss -0.8425 
2025-01-27 07:44:39.625431: val_loss -0.7734 
2025-01-27 07:44:39.628114: Pseudo dice [np.float32(0.9598), np.float32(0.886)] 
2025-01-27 07:44:39.630913: Epoch time: 48.89 s 
2025-01-27 07:44:40.787741:  
2025-01-27 07:44:40.791305: Epoch 471 
2025-01-27 07:44:40.794194: Current learning rate: 0.00564 
2025-01-27 07:45:29.137227: train_loss -0.8177 
2025-01-27 07:45:29.142123: val_loss -0.8136 
2025-01-27 07:45:29.145114: Pseudo dice [np.float32(0.9637), np.float32(0.8907)] 
2025-01-27 07:45:29.147778: Epoch time: 48.35 s 
2025-01-27 07:45:30.305421:  
2025-01-27 07:45:30.308766: Epoch 472 
2025-01-27 07:45:30.311660: Current learning rate: 0.00563 
2025-01-27 07:46:18.862662: train_loss -0.8261 
2025-01-27 07:46:18.868627: val_loss -0.737 
2025-01-27 07:46:18.871406: Pseudo dice [np.float32(0.9579), np.float32(0.9107)] 
2025-01-27 07:46:18.874384: Epoch time: 48.56 s 
2025-01-27 07:46:20.035396:  
2025-01-27 07:46:20.039317: Epoch 473 
2025-01-27 07:46:20.042475: Current learning rate: 0.00562 
2025-01-27 07:47:08.491802: train_loss -0.8269 
2025-01-27 07:47:08.496196: val_loss -0.7687 
2025-01-27 07:47:08.498852: Pseudo dice [np.float32(0.9607), np.float32(0.8982)] 
2025-01-27 07:47:08.501582: Epoch time: 48.46 s 
2025-01-27 07:47:09.655908:  
2025-01-27 07:47:09.659417: Epoch 474 
2025-01-27 07:47:09.662556: Current learning rate: 0.00561 
2025-01-27 07:47:58.320847: train_loss -0.8161 
2025-01-27 07:47:58.326987: val_loss -0.796 
2025-01-27 07:47:58.329830: Pseudo dice [np.float32(0.9591), np.float32(0.8778)] 
2025-01-27 07:47:58.333018: Epoch time: 48.67 s 
2025-01-27 07:47:59.500570:  
2025-01-27 07:47:59.504026: Epoch 475 
2025-01-27 07:47:59.507380: Current learning rate: 0.0056 
2025-01-27 07:48:48.509247: train_loss -0.8232 
2025-01-27 07:48:48.515964: val_loss -0.7998 
2025-01-27 07:48:48.519155: Pseudo dice [np.float32(0.9615), np.float32(0.9036)] 
2025-01-27 07:48:48.521862: Epoch time: 49.01 s 
2025-01-27 07:48:49.706324:  
2025-01-27 07:48:49.710862: Epoch 476 
2025-01-27 07:48:49.714513: Current learning rate: 0.00559 
2025-01-27 07:49:38.041151: train_loss -0.8188 
2025-01-27 07:49:38.046380: val_loss -0.7455 
2025-01-27 07:49:38.048971: Pseudo dice [np.float32(0.9613), np.float32(0.8936)] 
2025-01-27 07:49:38.051607: Epoch time: 48.34 s 
2025-01-27 07:49:38.054214: Yayy! New best EMA pseudo Dice: 0.9222999811172485 
2025-01-27 07:49:39.773660:  
2025-01-27 07:49:39.776708: Epoch 477 
2025-01-27 07:49:39.779305: Current learning rate: 0.00558 
2025-01-27 07:50:27.740240: train_loss -0.8303 
2025-01-27 07:50:27.745769: val_loss -0.7965 
2025-01-27 07:50:27.749213: Pseudo dice [np.float32(0.9589), np.float32(0.877)] 
2025-01-27 07:50:27.753779: Epoch time: 47.97 s 
2025-01-27 07:50:28.918985:  
2025-01-27 07:50:28.922609: Epoch 478 
2025-01-27 07:50:28.926517: Current learning rate: 0.00557 
2025-01-27 07:51:17.333329: train_loss -0.8261 
2025-01-27 07:51:17.340557: val_loss -0.7552 
2025-01-27 07:51:17.343388: Pseudo dice [np.float32(0.9552), np.float32(0.8812)] 
2025-01-27 07:51:17.346083: Epoch time: 48.42 s 
2025-01-27 07:51:18.508873:  
2025-01-27 07:51:18.512103: Epoch 479 
2025-01-27 07:51:18.514953: Current learning rate: 0.00556 
2025-01-27 07:52:06.900830: train_loss -0.8362 
2025-01-27 07:52:06.906261: val_loss -0.7541 
2025-01-27 07:52:06.909396: Pseudo dice [np.float32(0.955), np.float32(0.8726)] 
2025-01-27 07:52:06.912327: Epoch time: 48.39 s 
2025-01-27 07:52:08.089706:  
2025-01-27 07:52:08.093276: Epoch 480 
2025-01-27 07:52:08.096488: Current learning rate: 0.00555 
2025-01-27 07:52:56.336113: train_loss -0.8391 
2025-01-27 07:52:56.343424: val_loss -0.7716 
2025-01-27 07:52:56.346286: Pseudo dice [np.float32(0.9559), np.float32(0.8959)] 
2025-01-27 07:52:56.348905: Epoch time: 48.25 s 
2025-01-27 07:52:57.513537:  
2025-01-27 07:52:57.516706: Epoch 481 
2025-01-27 07:52:57.519430: Current learning rate: 0.00554 
2025-01-27 07:53:45.851836: train_loss -0.8236 
2025-01-27 07:53:45.857258: val_loss -0.7863 
2025-01-27 07:53:45.860543: Pseudo dice [np.float32(0.9537), np.float32(0.8871)] 
2025-01-27 07:53:45.863486: Epoch time: 48.34 s 
2025-01-27 07:53:47.034067:  
2025-01-27 07:53:47.037673: Epoch 482 
2025-01-27 07:53:47.040929: Current learning rate: 0.00553 
2025-01-27 07:54:36.082875: train_loss -0.8152 
2025-01-27 07:54:36.091062: val_loss -0.7323 
2025-01-27 07:54:36.094415: Pseudo dice [np.float32(0.9534), np.float32(0.8646)] 
2025-01-27 07:54:36.097193: Epoch time: 49.05 s 
2025-01-27 07:54:37.254009:  
2025-01-27 07:54:37.257034: Epoch 483 
2025-01-27 07:54:37.259769: Current learning rate: 0.00552 
2025-01-27 07:55:25.876776: train_loss -0.8101 
2025-01-27 07:55:25.881519: val_loss -0.7554 
2025-01-27 07:55:25.884262: Pseudo dice [np.float32(0.9429), np.float32(0.8152)] 
2025-01-27 07:55:25.886977: Epoch time: 48.62 s 
2025-01-27 07:55:27.060521:  
2025-01-27 07:55:27.063583: Epoch 484 
2025-01-27 07:55:27.066534: Current learning rate: 0.00551 
2025-01-27 07:56:15.444519: train_loss -0.7914 
2025-01-27 07:56:15.450469: val_loss -0.7391 
2025-01-27 07:56:15.453512: Pseudo dice [np.float32(0.9538), np.float32(0.8522)] 
2025-01-27 07:56:15.456243: Epoch time: 48.38 s 
2025-01-27 07:56:16.621797:  
2025-01-27 07:56:16.624599: Epoch 485 
2025-01-27 07:56:16.627097: Current learning rate: 0.0055 
2025-01-27 07:57:05.430373: train_loss -0.8016 
2025-01-27 07:57:05.434995: val_loss -0.7338 
2025-01-27 07:57:05.437853: Pseudo dice [np.float32(0.95), np.float32(0.8358)] 
2025-01-27 07:57:05.440683: Epoch time: 48.81 s 
2025-01-27 07:57:06.604167:  
2025-01-27 07:57:06.607517: Epoch 486 
2025-01-27 07:57:06.610491: Current learning rate: 0.00549 
2025-01-27 07:57:55.218068: train_loss -0.8092 
2025-01-27 07:57:55.224882: val_loss -0.77 
2025-01-27 07:57:55.227657: Pseudo dice [np.float32(0.9495), np.float32(0.8641)] 
2025-01-27 07:57:55.230762: Epoch time: 48.62 s 
2025-01-27 07:57:57.011896:  
2025-01-27 07:57:57.015193: Epoch 487 
2025-01-27 07:57:57.018057: Current learning rate: 0.00548 
2025-01-27 07:58:45.349717: train_loss -0.8278 
2025-01-27 07:58:45.354013: val_loss -0.7688 
2025-01-27 07:58:45.356855: Pseudo dice [np.float32(0.9605), np.float32(0.866)] 
2025-01-27 07:58:45.359667: Epoch time: 48.34 s 
2025-01-27 07:58:46.525730:  
2025-01-27 07:58:46.528949: Epoch 488 
2025-01-27 07:58:46.531872: Current learning rate: 0.00547 
2025-01-27 07:59:34.969535: train_loss -0.8054 
2025-01-27 07:59:34.977410: val_loss -0.7651 
2025-01-27 07:59:34.980535: Pseudo dice [np.float32(0.9471), np.float32(0.8518)] 
2025-01-27 07:59:34.983071: Epoch time: 48.44 s 
2025-01-27 07:59:36.175310:  
2025-01-27 07:59:36.178320: Epoch 489 
2025-01-27 07:59:36.181606: Current learning rate: 0.00546 
2025-01-27 08:00:24.273481: train_loss -0.8155 
2025-01-27 08:00:24.278171: val_loss -0.7539 
2025-01-27 08:00:24.280864: Pseudo dice [np.float32(0.9552), np.float32(0.8458)] 
2025-01-27 08:00:24.283672: Epoch time: 48.1 s 
2025-01-27 08:00:25.448775:  
2025-01-27 08:00:25.452524: Epoch 490 
2025-01-27 08:00:25.455589: Current learning rate: 0.00546 
2025-01-27 08:01:13.915929: train_loss -0.8142 
2025-01-27 08:01:13.923265: val_loss -0.787 
2025-01-27 08:01:13.926192: Pseudo dice [np.float32(0.9535), np.float32(0.8964)] 
2025-01-27 08:01:13.929475: Epoch time: 48.47 s 
2025-01-27 08:01:15.083889:  
2025-01-27 08:01:15.086886: Epoch 491 
2025-01-27 08:01:15.089602: Current learning rate: 0.00545 
2025-01-27 08:02:04.064153: train_loss -0.8175 
2025-01-27 08:02:04.071568: val_loss -0.7312 
2025-01-27 08:02:04.074914: Pseudo dice [np.float32(0.951), np.float32(0.8736)] 
2025-01-27 08:02:04.077600: Epoch time: 48.98 s 
2025-01-27 08:02:05.242766:  
2025-01-27 08:02:05.245703: Epoch 492 
2025-01-27 08:02:05.248602: Current learning rate: 0.00544 
2025-01-27 08:02:53.843283: train_loss -0.8235 
2025-01-27 08:02:53.849481: val_loss -0.7852 
2025-01-27 08:02:53.852337: Pseudo dice [np.float32(0.9552), np.float32(0.8601)] 
2025-01-27 08:02:53.854709: Epoch time: 48.6 s 
2025-01-27 08:02:55.009589:  
2025-01-27 08:02:55.012558: Epoch 493 
2025-01-27 08:02:55.015109: Current learning rate: 0.00543 
2025-01-27 08:03:43.416998: train_loss -0.8364 
2025-01-27 08:03:43.425036: val_loss -0.7821 
2025-01-27 08:03:43.428013: Pseudo dice [np.float32(0.9558), np.float32(0.8659)] 
2025-01-27 08:03:43.430698: Epoch time: 48.41 s 
2025-01-27 08:03:44.598857:  
2025-01-27 08:03:44.601753: Epoch 494 
2025-01-27 08:03:44.604327: Current learning rate: 0.00542 
2025-01-27 08:04:33.531129: train_loss -0.8114 
2025-01-27 08:04:33.537895: val_loss -0.7896 
2025-01-27 08:04:33.540934: Pseudo dice [np.float32(0.9608), np.float32(0.9004)] 
2025-01-27 08:04:33.543892: Epoch time: 48.93 s 
2025-01-27 08:04:34.712195:  
2025-01-27 08:04:34.715387: Epoch 495 
2025-01-27 08:04:34.718033: Current learning rate: 0.00541 
2025-01-27 08:05:23.441099: train_loss -0.8058 
2025-01-27 08:05:23.445996: val_loss -0.7548 
2025-01-27 08:05:23.449267: Pseudo dice [np.float32(0.9492), np.float32(0.8759)] 
2025-01-27 08:05:23.452138: Epoch time: 48.73 s 
2025-01-27 08:05:24.615559:  
2025-01-27 08:05:24.618888: Epoch 496 
2025-01-27 08:05:24.622088: Current learning rate: 0.0054 
2025-01-27 08:06:13.166847: train_loss -0.8204 
2025-01-27 08:06:13.172786: val_loss -0.8143 
2025-01-27 08:06:13.175673: Pseudo dice [np.float32(0.9595), np.float32(0.887)] 
2025-01-27 08:06:13.178657: Epoch time: 48.55 s 
2025-01-27 08:06:14.344075:  
2025-01-27 08:06:14.347321: Epoch 497 
2025-01-27 08:06:14.350440: Current learning rate: 0.00539 
2025-01-27 08:07:02.986669: train_loss -0.8094 
2025-01-27 08:07:02.993350: val_loss -0.7588 
2025-01-27 08:07:02.996535: Pseudo dice [np.float32(0.9547), np.float32(0.8649)] 
2025-01-27 08:07:02.999176: Epoch time: 48.64 s 
2025-01-27 08:07:04.162361:  
2025-01-27 08:07:04.165347: Epoch 498 
2025-01-27 08:07:04.168168: Current learning rate: 0.00538 
2025-01-27 08:07:53.108126: train_loss -0.8049 
2025-01-27 08:07:53.114413: val_loss -0.7405 
2025-01-27 08:07:53.117331: Pseudo dice [np.float32(0.9531), np.float32(0.8804)] 
2025-01-27 08:07:53.120066: Epoch time: 48.95 s 
2025-01-27 08:07:54.276372:  
2025-01-27 08:07:54.279970: Epoch 499 
2025-01-27 08:07:54.283085: Current learning rate: 0.00537 
2025-01-27 08:08:42.962194: train_loss -0.8338 
2025-01-27 08:08:42.966903: val_loss -0.7735 
2025-01-27 08:08:42.970102: Pseudo dice [np.float32(0.9575), np.float32(0.8882)] 
2025-01-27 08:08:42.972643: Epoch time: 48.69 s 
2025-01-27 08:08:44.733717:  
2025-01-27 08:08:44.736801: Epoch 500 
2025-01-27 08:08:44.739731: Current learning rate: 0.00536 
2025-01-27 08:09:33.078945: train_loss -0.8056 
2025-01-27 08:09:33.086261: val_loss -0.7823 
2025-01-27 08:09:33.089403: Pseudo dice [np.float32(0.9547), np.float32(0.8822)] 
2025-01-27 08:09:33.092288: Epoch time: 48.35 s 
2025-01-27 08:09:34.253644:  
2025-01-27 08:09:34.256888: Epoch 501 
2025-01-27 08:09:34.259929: Current learning rate: 0.00535 
2025-01-27 08:10:22.732138: train_loss -0.8273 
2025-01-27 08:10:22.736739: val_loss -0.7577 
2025-01-27 08:10:22.739297: Pseudo dice [np.float32(0.9614), np.float32(0.9031)] 
2025-01-27 08:10:22.742029: Epoch time: 48.48 s 
2025-01-27 08:10:23.902585:  
2025-01-27 08:10:23.905875: Epoch 502 
2025-01-27 08:10:23.908472: Current learning rate: 0.00534 
2025-01-27 08:11:12.805084: train_loss -0.8197 
2025-01-27 08:11:12.811177: val_loss -0.7803 
2025-01-27 08:11:12.815788: Pseudo dice [np.float32(0.9654), np.float32(0.9124)] 
2025-01-27 08:11:12.818905: Epoch time: 48.9 s 
2025-01-27 08:11:13.980517:  
2025-01-27 08:11:13.983819: Epoch 503 
2025-01-27 08:11:13.986743: Current learning rate: 0.00533 
2025-01-27 08:12:02.417208: train_loss -0.836 
2025-01-27 08:12:02.424293: val_loss -0.774 
2025-01-27 08:12:02.427179: Pseudo dice [np.float32(0.9533), np.float32(0.9118)] 
2025-01-27 08:12:02.429973: Epoch time: 48.44 s 
2025-01-27 08:12:03.598692:  
2025-01-27 08:12:03.602045: Epoch 504 
2025-01-27 08:12:03.605165: Current learning rate: 0.00532 
2025-01-27 08:12:51.509851: train_loss -0.826 
2025-01-27 08:12:51.516092: val_loss -0.7903 
2025-01-27 08:12:51.519206: Pseudo dice [np.float32(0.9495), np.float32(0.8874)] 
2025-01-27 08:12:51.522212: Epoch time: 47.91 s 
2025-01-27 08:12:52.723835:  
2025-01-27 08:12:52.727030: Epoch 505 
2025-01-27 08:12:52.730034: Current learning rate: 0.00531 
2025-01-27 08:13:41.121244: train_loss -0.8196 
2025-01-27 08:13:41.127063: val_loss -0.7755 
2025-01-27 08:13:41.129822: Pseudo dice [np.float32(0.9549), np.float32(0.9138)] 
2025-01-27 08:13:41.132592: Epoch time: 48.4 s 
2025-01-27 08:13:42.857240:  
2025-01-27 08:13:42.860787: Epoch 506 
2025-01-27 08:13:42.863831: Current learning rate: 0.0053 
2025-01-27 08:14:32.137560: train_loss -0.8272 
2025-01-27 08:14:32.143741: val_loss -0.753 
2025-01-27 08:14:32.146602: Pseudo dice [np.float32(0.9609), np.float32(0.8904)] 
2025-01-27 08:14:32.149611: Epoch time: 49.28 s 
2025-01-27 08:14:33.304525:  
2025-01-27 08:14:33.307003: Epoch 507 
2025-01-27 08:14:33.309632: Current learning rate: 0.00529 
2025-01-27 08:15:21.791584: train_loss -0.8333 
2025-01-27 08:15:21.796009: val_loss -0.762 
2025-01-27 08:15:21.798879: Pseudo dice [np.float32(0.9502), np.float32(0.8692)] 
2025-01-27 08:15:21.801772: Epoch time: 48.49 s 
2025-01-27 08:15:22.974353:  
2025-01-27 08:15:22.978084: Epoch 508 
2025-01-27 08:15:22.981076: Current learning rate: 0.00528 
2025-01-27 08:16:11.456917: train_loss -0.8308 
2025-01-27 08:16:11.463108: val_loss -0.7773 
2025-01-27 08:16:11.465980: Pseudo dice [np.float32(0.9508), np.float32(0.8601)] 
2025-01-27 08:16:11.468706: Epoch time: 48.48 s 
2025-01-27 08:16:12.638362:  
2025-01-27 08:16:12.641526: Epoch 509 
2025-01-27 08:16:12.644445: Current learning rate: 0.00527 
2025-01-27 08:17:01.214148: train_loss -0.8359 
2025-01-27 08:17:01.218894: val_loss -0.7909 
2025-01-27 08:17:01.221626: Pseudo dice [np.float32(0.9582), np.float32(0.8721)] 
2025-01-27 08:17:01.224470: Epoch time: 48.58 s 
2025-01-27 08:17:02.388467:  
2025-01-27 08:17:02.391652: Epoch 510 
2025-01-27 08:17:02.394606: Current learning rate: 0.00526 
2025-01-27 08:17:50.826764: train_loss -0.8175 
2025-01-27 08:17:50.832398: val_loss -0.7975 
2025-01-27 08:17:50.835203: Pseudo dice [np.float32(0.962), np.float32(0.9195)] 
2025-01-27 08:17:50.838210: Epoch time: 48.44 s 
2025-01-27 08:17:52.007564:  
2025-01-27 08:17:52.010823: Epoch 511 
2025-01-27 08:17:52.014031: Current learning rate: 0.00525 
2025-01-27 08:18:40.325711: train_loss -0.8308 
2025-01-27 08:18:40.330396: val_loss -0.8065 
2025-01-27 08:18:40.332943: Pseudo dice [np.float32(0.9588), np.float32(0.8869)] 
2025-01-27 08:18:40.335379: Epoch time: 48.32 s 
2025-01-27 08:18:41.504413:  
2025-01-27 08:18:41.507749: Epoch 512 
2025-01-27 08:18:41.510786: Current learning rate: 0.00524 
2025-01-27 08:19:30.155779: train_loss -0.8152 
2025-01-27 08:19:30.162281: val_loss -0.769 
2025-01-27 08:19:30.165293: Pseudo dice [np.float32(0.9535), np.float32(0.8852)] 
2025-01-27 08:19:30.168207: Epoch time: 48.65 s 
2025-01-27 08:19:31.331591:  
2025-01-27 08:19:31.334677: Epoch 513 
2025-01-27 08:19:31.337613: Current learning rate: 0.00523 
2025-01-27 08:20:19.892478: train_loss -0.8147 
2025-01-27 08:20:19.897092: val_loss -0.7764 
2025-01-27 08:20:19.900113: Pseudo dice [np.float32(0.9521), np.float32(0.8876)] 
2025-01-27 08:20:19.902777: Epoch time: 48.56 s 
2025-01-27 08:20:21.071487:  
2025-01-27 08:20:21.074589: Epoch 514 
2025-01-27 08:20:21.077544: Current learning rate: 0.00522 
2025-01-27 08:21:10.063952: train_loss -0.8249 
2025-01-27 08:21:10.071740: val_loss -0.7477 
2025-01-27 08:21:10.074798: Pseudo dice [np.float32(0.9581), np.float32(0.8758)] 
2025-01-27 08:21:10.077528: Epoch time: 48.99 s 
2025-01-27 08:21:11.251490:  
2025-01-27 08:21:11.254608: Epoch 515 
2025-01-27 08:21:11.257583: Current learning rate: 0.00521 
2025-01-27 08:21:59.892991: train_loss -0.8249 
2025-01-27 08:21:59.897341: val_loss -0.7591 
2025-01-27 08:21:59.900147: Pseudo dice [np.float32(0.9559), np.float32(0.8878)] 
2025-01-27 08:21:59.902640: Epoch time: 48.64 s 
2025-01-27 08:22:01.081550:  
2025-01-27 08:22:01.084783: Epoch 516 
2025-01-27 08:22:01.087762: Current learning rate: 0.0052 
2025-01-27 08:22:49.810370: train_loss -0.824 
2025-01-27 08:22:49.818287: val_loss -0.7705 
2025-01-27 08:22:49.821255: Pseudo dice [np.float32(0.9624), np.float32(0.8935)] 
2025-01-27 08:22:49.824352: Epoch time: 48.73 s 
2025-01-27 08:22:50.998523:  
2025-01-27 08:22:51.001768: Epoch 517 
2025-01-27 08:22:51.004971: Current learning rate: 0.00519 
2025-01-27 08:23:39.732196: train_loss -0.8275 
2025-01-27 08:23:39.737099: val_loss -0.7687 
2025-01-27 08:23:39.739897: Pseudo dice [np.float32(0.9509), np.float32(0.8845)] 
2025-01-27 08:23:39.742471: Epoch time: 48.73 s 
2025-01-27 08:23:40.948536:  
2025-01-27 08:23:40.951749: Epoch 518 
2025-01-27 08:23:40.954690: Current learning rate: 0.00518 
2025-01-27 08:24:29.523408: train_loss -0.8037 
2025-01-27 08:24:29.529420: val_loss -0.7368 
2025-01-27 08:24:29.532516: Pseudo dice [np.float32(0.9455), np.float32(0.8576)] 
2025-01-27 08:24:29.535366: Epoch time: 48.58 s 
2025-01-27 08:24:30.707401:  
2025-01-27 08:24:30.710901: Epoch 519 
2025-01-27 08:24:30.713821: Current learning rate: 0.00518 
2025-01-27 08:25:19.122741: train_loss -0.8157 
2025-01-27 08:25:19.127484: val_loss -0.7598 
2025-01-27 08:25:19.130228: Pseudo dice [np.float32(0.9536), np.float32(0.8784)] 
2025-01-27 08:25:19.132735: Epoch time: 48.42 s 
2025-01-27 08:25:20.302300:  
2025-01-27 08:25:20.305593: Epoch 520 
2025-01-27 08:25:20.308393: Current learning rate: 0.00517 
2025-01-27 08:26:09.183132: train_loss -0.8297 
2025-01-27 08:26:09.189109: val_loss -0.7569 
2025-01-27 08:26:09.192105: Pseudo dice [np.float32(0.9611), np.float32(0.883)] 
2025-01-27 08:26:09.194863: Epoch time: 48.88 s 
2025-01-27 08:26:10.358501:  
2025-01-27 08:26:10.362154: Epoch 521 
2025-01-27 08:26:10.365234: Current learning rate: 0.00516 
2025-01-27 08:26:58.791172: train_loss -0.8108 
2025-01-27 08:26:58.795614: val_loss -0.7435 
2025-01-27 08:26:58.798600: Pseudo dice [np.float32(0.9532), np.float32(0.8745)] 
2025-01-27 08:26:58.801291: Epoch time: 48.43 s 
2025-01-27 08:26:59.974724:  
2025-01-27 08:26:59.983254: Epoch 522 
2025-01-27 08:26:59.986198: Current learning rate: 0.00515 
2025-01-27 08:27:48.048329: train_loss -0.8219 
2025-01-27 08:27:48.054579: val_loss -0.7805 
2025-01-27 08:27:48.058084: Pseudo dice [np.float32(0.9583), np.float32(0.8904)] 
2025-01-27 08:27:48.060837: Epoch time: 48.07 s 
2025-01-27 08:27:49.242201:  
2025-01-27 08:27:49.245443: Epoch 523 
2025-01-27 08:27:49.248182: Current learning rate: 0.00514 
2025-01-27 08:28:38.186247: train_loss -0.8329 
2025-01-27 08:28:38.190639: val_loss -0.7681 
2025-01-27 08:28:38.193619: Pseudo dice [np.float32(0.9614), np.float32(0.8984)] 
2025-01-27 08:28:38.196247: Epoch time: 48.95 s 
2025-01-27 08:28:39.366611:  
2025-01-27 08:28:39.369807: Epoch 524 
2025-01-27 08:28:39.372609: Current learning rate: 0.00513 
2025-01-27 08:29:28.071771: train_loss -0.8287 
2025-01-27 08:29:28.077620: val_loss -0.7788 
2025-01-27 08:29:28.080595: Pseudo dice [np.float32(0.9525), np.float32(0.8896)] 
2025-01-27 08:29:28.083209: Epoch time: 48.71 s 
2025-01-27 08:29:29.325582:  
2025-01-27 08:29:29.328954: Epoch 525 
2025-01-27 08:29:29.332172: Current learning rate: 0.00512 
2025-01-27 08:30:18.275401: train_loss -0.8135 
2025-01-27 08:30:18.279902: val_loss -0.7458 
2025-01-27 08:30:18.283123: Pseudo dice [np.float32(0.9559), np.float32(0.8767)] 
2025-01-27 08:30:18.285886: Epoch time: 48.95 s 
2025-01-27 08:30:20.042836:  
2025-01-27 08:30:20.047115: Epoch 526 
2025-01-27 08:30:20.050390: Current learning rate: 0.00511 
2025-01-27 08:31:08.736228: train_loss -0.821 
2025-01-27 08:31:08.743556: val_loss -0.7646 
2025-01-27 08:31:08.746122: Pseudo dice [np.float32(0.957), np.float32(0.8971)] 
2025-01-27 08:31:08.748560: Epoch time: 48.69 s 
2025-01-27 08:31:09.943893:  
2025-01-27 08:31:09.947143: Epoch 527 
2025-01-27 08:31:09.950430: Current learning rate: 0.0051 
2025-01-27 08:31:58.272291: train_loss -0.8255 
2025-01-27 08:31:58.279232: val_loss -0.7476 
2025-01-27 08:31:58.282365: Pseudo dice [np.float32(0.9447), np.float32(0.7923)] 
2025-01-27 08:31:58.285131: Epoch time: 48.33 s 
2025-01-27 08:31:59.460108:  
2025-01-27 08:31:59.463691: Epoch 528 
2025-01-27 08:31:59.466872: Current learning rate: 0.00509 
2025-01-27 08:32:48.240190: train_loss -0.8283 
2025-01-27 08:32:48.245424: val_loss -0.775 
2025-01-27 08:32:48.248155: Pseudo dice [np.float32(0.9601), np.float32(0.909)] 
2025-01-27 08:32:48.250619: Epoch time: 48.78 s 
2025-01-27 08:32:49.454730:  
2025-01-27 08:32:49.458067: Epoch 529 
2025-01-27 08:32:49.460953: Current learning rate: 0.00508 
2025-01-27 08:33:38.072775: train_loss -0.8211 
2025-01-27 08:33:38.077554: val_loss -0.7924 
2025-01-27 08:33:38.080788: Pseudo dice [np.float32(0.9616), np.float32(0.9069)] 
2025-01-27 08:33:38.083734: Epoch time: 48.62 s 
2025-01-27 08:33:39.285754:  
2025-01-27 08:33:39.289215: Epoch 530 
2025-01-27 08:33:39.292568: Current learning rate: 0.00507 
2025-01-27 08:34:27.998886: train_loss -0.8139 
2025-01-27 08:34:28.006098: val_loss -0.7692 
2025-01-27 08:34:28.009120: Pseudo dice [np.float32(0.9533), np.float32(0.8915)] 
2025-01-27 08:34:28.011887: Epoch time: 48.71 s 
2025-01-27 08:34:29.182510:  
2025-01-27 08:34:29.185735: Epoch 531 
2025-01-27 08:34:29.188922: Current learning rate: 0.00506 
2025-01-27 08:35:18.160886: train_loss -0.8193 
2025-01-27 08:35:18.165572: val_loss -0.7689 
2025-01-27 08:35:18.168552: Pseudo dice [np.float32(0.9566), np.float32(0.868)] 
2025-01-27 08:35:18.171361: Epoch time: 48.98 s 
2025-01-27 08:35:19.345150:  
2025-01-27 08:35:19.348488: Epoch 532 
2025-01-27 08:35:19.351530: Current learning rate: 0.00505 
2025-01-27 08:36:07.741606: train_loss -0.8288 
2025-01-27 08:36:07.747612: val_loss -0.8124 
2025-01-27 08:36:07.750375: Pseudo dice [np.float32(0.9555), np.float32(0.8923)] 
2025-01-27 08:36:07.753132: Epoch time: 48.4 s 
2025-01-27 08:36:08.952220:  
2025-01-27 08:36:08.955341: Epoch 533 
2025-01-27 08:36:08.958153: Current learning rate: 0.00504 
2025-01-27 08:36:57.993627: train_loss -0.8307 
2025-01-27 08:36:57.998267: val_loss -0.77 
2025-01-27 08:36:58.001171: Pseudo dice [np.float32(0.9588), np.float32(0.8845)] 
2025-01-27 08:36:58.004082: Epoch time: 49.04 s 
2025-01-27 08:36:59.202652:  
2025-01-27 08:36:59.205993: Epoch 534 
2025-01-27 08:36:59.209257: Current learning rate: 0.00503 
2025-01-27 08:37:47.491546: train_loss -0.8115 
2025-01-27 08:37:47.497350: val_loss -0.815 
2025-01-27 08:37:47.500125: Pseudo dice [np.float32(0.9574), np.float32(0.8966)] 
2025-01-27 08:37:47.502913: Epoch time: 48.29 s 
2025-01-27 08:37:48.671340:  
2025-01-27 08:37:48.674294: Epoch 535 
2025-01-27 08:37:48.677189: Current learning rate: 0.00502 
2025-01-27 08:38:37.849847: train_loss -0.8224 
2025-01-27 08:38:37.854114: val_loss -0.7865 
2025-01-27 08:38:37.857010: Pseudo dice [np.float32(0.946), np.float32(0.8757)] 
2025-01-27 08:38:37.859712: Epoch time: 49.18 s 
2025-01-27 08:38:39.023949:  
2025-01-27 08:38:39.026772: Epoch 536 
2025-01-27 08:38:39.029588: Current learning rate: 0.00501 
2025-01-27 08:39:27.501588: train_loss -0.8178 
2025-01-27 08:39:27.507662: val_loss -0.7816 
2025-01-27 08:39:27.510822: Pseudo dice [np.float32(0.9644), np.float32(0.8885)] 
2025-01-27 08:39:27.513994: Epoch time: 48.48 s 
2025-01-27 08:39:28.715315:  
2025-01-27 08:39:28.719380: Epoch 537 
2025-01-27 08:39:28.722533: Current learning rate: 0.005 
2025-01-27 08:40:17.231559: train_loss -0.8286 
2025-01-27 08:40:17.237706: val_loss -0.7873 
2025-01-27 08:40:17.240798: Pseudo dice [np.float32(0.9561), np.float32(0.8909)] 
2025-01-27 08:40:17.243780: Epoch time: 48.52 s 
2025-01-27 08:40:18.414019:  
2025-01-27 08:40:18.417062: Epoch 538 
2025-01-27 08:40:18.420336: Current learning rate: 0.00499 
2025-01-27 08:41:06.756413: train_loss -0.8285 
2025-01-27 08:41:06.762026: val_loss -0.7587 
2025-01-27 08:41:06.764936: Pseudo dice [np.float32(0.9593), np.float32(0.8666)] 
2025-01-27 08:41:06.767465: Epoch time: 48.34 s 
2025-01-27 08:41:07.966787:  
2025-01-27 08:41:07.970316: Epoch 539 
2025-01-27 08:41:07.973539: Current learning rate: 0.00498 
2025-01-27 08:41:56.876700: train_loss -0.8394 
2025-01-27 08:41:56.881299: val_loss -0.7968 
2025-01-27 08:41:56.883768: Pseudo dice [np.float32(0.9629), np.float32(0.899)] 
2025-01-27 08:41:56.886543: Epoch time: 48.91 s 
2025-01-27 08:41:58.048154:  
2025-01-27 08:41:58.051360: Epoch 540 
2025-01-27 08:41:58.054145: Current learning rate: 0.00497 
2025-01-27 08:42:46.501424: train_loss -0.8172 
2025-01-27 08:42:46.507981: val_loss -0.7775 
2025-01-27 08:42:46.510550: Pseudo dice [np.float32(0.9544), np.float32(0.8799)] 
2025-01-27 08:42:46.513341: Epoch time: 48.45 s 
2025-01-27 08:42:47.702635:  
2025-01-27 08:42:47.706003: Epoch 541 
2025-01-27 08:42:47.708894: Current learning rate: 0.00496 
2025-01-27 08:43:36.279984: train_loss -0.8163 
2025-01-27 08:43:36.284854: val_loss -0.7843 
2025-01-27 08:43:36.287744: Pseudo dice [np.float32(0.9548), np.float32(0.9017)] 
2025-01-27 08:43:36.290448: Epoch time: 48.58 s 
2025-01-27 08:43:37.450765:  
2025-01-27 08:43:37.453879: Epoch 542 
2025-01-27 08:43:37.456925: Current learning rate: 0.00495 
2025-01-27 08:44:26.583688: train_loss -0.8346 
2025-01-27 08:44:26.589333: val_loss -0.7521 
2025-01-27 08:44:26.592238: Pseudo dice [np.float32(0.9604), np.float32(0.907)] 
2025-01-27 08:44:26.594952: Epoch time: 49.13 s 
2025-01-27 08:44:26.597592: Yayy! New best EMA pseudo Dice: 0.9223999977111816 
2025-01-27 08:44:28.354171:  
2025-01-27 08:44:28.357268: Epoch 543 
2025-01-27 08:44:28.360452: Current learning rate: 0.00494 
2025-01-27 08:45:16.712474: train_loss -0.8261 
2025-01-27 08:45:16.717745: val_loss -0.8014 
2025-01-27 08:45:16.720615: Pseudo dice [np.float32(0.9564), np.float32(0.916)] 
2025-01-27 08:45:16.723253: Epoch time: 48.36 s 
2025-01-27 08:45:16.725877: Yayy! New best EMA pseudo Dice: 0.923799991607666 
2025-01-27 08:45:18.526769:  
2025-01-27 08:45:18.530091: Epoch 544 
2025-01-27 08:45:18.532840: Current learning rate: 0.00493 
2025-01-27 08:46:06.852919: train_loss -0.8211 
2025-01-27 08:46:06.859586: val_loss -0.7805 
2025-01-27 08:46:06.862286: Pseudo dice [np.float32(0.9527), np.float32(0.8856)] 
2025-01-27 08:46:06.865318: Epoch time: 48.33 s 
2025-01-27 08:46:08.583091:  
2025-01-27 08:46:08.586064: Epoch 545 
2025-01-27 08:46:08.588959: Current learning rate: 0.00492 
2025-01-27 08:46:57.296919: train_loss -0.8244 
2025-01-27 08:46:57.301733: val_loss -0.789 
2025-01-27 08:46:57.304735: Pseudo dice [np.float32(0.9566), np.float32(0.8906)] 
2025-01-27 08:46:57.307715: Epoch time: 48.71 s 
2025-01-27 08:46:58.501000:  
2025-01-27 08:46:58.504147: Epoch 546 
2025-01-27 08:46:58.507215: Current learning rate: 0.00491 
2025-01-27 08:47:47.473870: train_loss -0.8433 
2025-01-27 08:47:47.479866: val_loss -0.8026 
2025-01-27 08:47:47.482930: Pseudo dice [np.float32(0.9532), np.float32(0.8945)] 
2025-01-27 08:47:47.485819: Epoch time: 48.97 s 
2025-01-27 08:47:48.650426:  
2025-01-27 08:47:48.653810: Epoch 547 
2025-01-27 08:47:48.656594: Current learning rate: 0.0049 
2025-01-27 08:48:37.143379: train_loss -0.8301 
2025-01-27 08:48:37.148188: val_loss -0.7836 
2025-01-27 08:48:37.151381: Pseudo dice [np.float32(0.9583), np.float32(0.8953)] 
2025-01-27 08:48:37.154166: Epoch time: 48.49 s 
2025-01-27 08:48:38.316495:  
2025-01-27 08:48:38.320366: Epoch 548 
2025-01-27 08:48:38.323504: Current learning rate: 0.00489 
2025-01-27 08:49:26.752202: train_loss -0.8164 
2025-01-27 08:49:26.758214: val_loss -0.803 
2025-01-27 08:49:26.760823: Pseudo dice [np.float32(0.9575), np.float32(0.8933)] 
2025-01-27 08:49:26.763465: Epoch time: 48.44 s 
2025-01-27 08:49:26.766037: Yayy! New best EMA pseudo Dice: 0.9239000082015991 
2025-01-27 08:49:28.541856:  
2025-01-27 08:49:28.545478: Epoch 549 
2025-01-27 08:49:28.548415: Current learning rate: 0.00488 
2025-01-27 08:50:17.639796: train_loss -0.8156 
2025-01-27 08:50:17.644556: val_loss -0.7566 
2025-01-27 08:50:17.647897: Pseudo dice [np.float32(0.9528), np.float32(0.8971)] 
2025-01-27 08:50:17.650999: Epoch time: 49.1 s 
2025-01-27 08:50:18.257161: Yayy! New best EMA pseudo Dice: 0.9240000247955322 
2025-01-27 08:50:20.037358:  
2025-01-27 08:50:20.040920: Epoch 550 
2025-01-27 08:50:20.044164: Current learning rate: 0.00487 
2025-01-27 08:51:09.182987: train_loss -0.825 
2025-01-27 08:51:09.188618: val_loss -0.7585 
2025-01-27 08:51:09.191554: Pseudo dice [np.float32(0.954), np.float32(0.8871)] 
2025-01-27 08:51:09.194114: Epoch time: 49.15 s 
2025-01-27 08:51:10.366256:  
2025-01-27 08:51:10.369502: Epoch 551 
2025-01-27 08:51:10.372549: Current learning rate: 0.00486 
2025-01-27 08:51:58.767119: train_loss -0.8023 
2025-01-27 08:51:58.771533: val_loss -0.7615 
2025-01-27 08:51:58.774319: Pseudo dice [np.float32(0.9544), np.float32(0.8714)] 
2025-01-27 08:51:58.776964: Epoch time: 48.4 s 
2025-01-27 08:51:59.983815:  
2025-01-27 08:51:59.986824: Epoch 552 
2025-01-27 08:51:59.989690: Current learning rate: 0.00485 
2025-01-27 08:52:48.985055: train_loss -0.8154 
2025-01-27 08:52:48.992032: val_loss -0.7996 
2025-01-27 08:52:48.995165: Pseudo dice [np.float32(0.9571), np.float32(0.894)] 
2025-01-27 08:52:48.998432: Epoch time: 49.0 s 
2025-01-27 08:52:50.164244:  
2025-01-27 08:52:50.167195: Epoch 553 
2025-01-27 08:52:50.169992: Current learning rate: 0.00484 
2025-01-27 08:53:38.526133: train_loss -0.839 
2025-01-27 08:53:38.531259: val_loss -0.759 
2025-01-27 08:53:38.534095: Pseudo dice [np.float32(0.9614), np.float32(0.8839)] 
2025-01-27 08:53:38.536864: Epoch time: 48.36 s 
2025-01-27 08:53:39.706078:  
2025-01-27 08:53:39.709229: Epoch 554 
2025-01-27 08:53:39.712322: Current learning rate: 0.00484 
2025-01-27 08:54:28.790040: train_loss -0.819 
2025-01-27 08:54:28.797634: val_loss -0.7944 
2025-01-27 08:54:28.800547: Pseudo dice [np.float32(0.9572), np.float32(0.8961)] 
2025-01-27 08:54:28.802936: Epoch time: 49.08 s 
2025-01-27 08:54:29.976576:  
2025-01-27 08:54:29.979401: Epoch 555 
2025-01-27 08:54:29.982628: Current learning rate: 0.00483 
2025-01-27 08:55:18.662527: train_loss -0.8198 
2025-01-27 08:55:18.669047: val_loss -0.7977 
2025-01-27 08:55:18.671903: Pseudo dice [np.float32(0.9618), np.float32(0.9036)] 
2025-01-27 08:55:18.674142: Epoch time: 48.69 s 
2025-01-27 08:55:18.676776: Yayy! New best EMA pseudo Dice: 0.9241999983787537 
2025-01-27 08:55:20.449360:  
2025-01-27 08:55:20.452574: Epoch 556 
2025-01-27 08:55:20.455254: Current learning rate: 0.00482 
2025-01-27 08:56:09.234412: train_loss -0.8392 
2025-01-27 08:56:09.242565: val_loss -0.7809 
2025-01-27 08:56:09.245370: Pseudo dice [np.float32(0.9623), np.float32(0.8862)] 
2025-01-27 08:56:09.248086: Epoch time: 48.79 s 
2025-01-27 08:56:09.250542: Yayy! New best EMA pseudo Dice: 0.9241999983787537 
2025-01-27 08:56:11.042675:  
2025-01-27 08:56:11.045980: Epoch 557 
2025-01-27 08:56:11.048922: Current learning rate: 0.00481 
2025-01-27 08:57:00.134623: train_loss -0.8263 
2025-01-27 08:57:00.138833: val_loss -0.8086 
2025-01-27 08:57:00.141406: Pseudo dice [np.float32(0.9559), np.float32(0.8963)] 
2025-01-27 08:57:00.144218: Epoch time: 49.09 s 
2025-01-27 08:57:00.146822: Yayy! New best EMA pseudo Dice: 0.9243999719619751 
2025-01-27 08:57:02.038846:  
2025-01-27 08:57:02.043871: Epoch 558 
2025-01-27 08:57:02.046942: Current learning rate: 0.0048 
2025-01-27 08:57:50.802299: train_loss -0.8211 
2025-01-27 08:57:50.808599: val_loss -0.7282 
2025-01-27 08:57:50.811529: Pseudo dice [np.float32(0.9439), np.float32(0.8655)] 
2025-01-27 08:57:50.814356: Epoch time: 48.76 s 
2025-01-27 08:57:51.986350:  
2025-01-27 08:57:51.989546: Epoch 559 
2025-01-27 08:57:51.992787: Current learning rate: 0.00479 
2025-01-27 08:58:40.876064: train_loss -0.8053 
2025-01-27 08:58:40.880329: val_loss -0.7441 
2025-01-27 08:58:40.883260: Pseudo dice [np.float32(0.9451), np.float32(0.882)] 
2025-01-27 08:58:40.885737: Epoch time: 48.89 s 
2025-01-27 08:58:42.050092:  
2025-01-27 08:58:42.053684: Epoch 560 
2025-01-27 08:58:42.056960: Current learning rate: 0.00478 
2025-01-27 08:59:30.880533: train_loss -0.8382 
2025-01-27 08:59:30.888400: val_loss -0.7794 
2025-01-27 08:59:30.891429: Pseudo dice [np.float32(0.9572), np.float32(0.9068)] 
2025-01-27 08:59:30.894454: Epoch time: 48.83 s 
2025-01-27 08:59:32.057895:  
2025-01-27 08:59:32.061468: Epoch 561 
2025-01-27 08:59:32.064770: Current learning rate: 0.00477 
2025-01-27 09:00:20.703187: train_loss -0.8359 
2025-01-27 09:00:20.707861: val_loss -0.7444 
2025-01-27 09:00:20.711048: Pseudo dice [np.float32(0.9527), np.float32(0.8689)] 
2025-01-27 09:00:20.714188: Epoch time: 48.65 s 
2025-01-27 09:00:21.924572:  
2025-01-27 09:00:21.928073: Epoch 562 
2025-01-27 09:00:21.931260: Current learning rate: 0.00476 
2025-01-27 09:01:10.316254: train_loss -0.8098 
2025-01-27 09:01:10.323480: val_loss -0.7685 
2025-01-27 09:01:10.326081: Pseudo dice [np.float32(0.9437), np.float32(0.8751)] 
2025-01-27 09:01:10.328803: Epoch time: 48.39 s 
2025-01-27 09:01:11.505630:  
2025-01-27 09:01:11.508541: Epoch 563 
2025-01-27 09:01:11.511408: Current learning rate: 0.00475 
2025-01-27 09:02:00.164785: train_loss -0.8252 
2025-01-27 09:02:00.168993: val_loss -0.7588 
2025-01-27 09:02:00.171534: Pseudo dice [np.float32(0.9571), np.float32(0.8601)] 
2025-01-27 09:02:00.174119: Epoch time: 48.66 s 
2025-01-27 09:02:01.954718:  
2025-01-27 09:02:01.958118: Epoch 564 
2025-01-27 09:02:01.960539: Current learning rate: 0.00474 
2025-01-27 09:02:50.852797: train_loss -0.8025 
2025-01-27 09:02:50.859878: val_loss -0.7555 
2025-01-27 09:02:50.862414: Pseudo dice [np.float32(0.9571), np.float32(0.8962)] 
2025-01-27 09:02:50.864867: Epoch time: 48.9 s 
2025-01-27 09:02:52.068980:  
2025-01-27 09:02:52.072074: Epoch 565 
2025-01-27 09:02:52.074886: Current learning rate: 0.00473 
2025-01-27 09:03:41.165703: train_loss -0.8156 
2025-01-27 09:03:41.171349: val_loss -0.7446 
2025-01-27 09:03:41.174247: Pseudo dice [np.float32(0.9574), np.float32(0.8704)] 
2025-01-27 09:03:41.176418: Epoch time: 49.1 s 
2025-01-27 09:03:42.361125:  
2025-01-27 09:03:42.363793: Epoch 566 
2025-01-27 09:03:42.366593: Current learning rate: 0.00472 
2025-01-27 09:04:31.274207: train_loss -0.8113 
2025-01-27 09:04:31.281770: val_loss -0.755 
2025-01-27 09:04:31.284474: Pseudo dice [np.float32(0.9465), np.float32(0.856)] 
2025-01-27 09:04:31.287273: Epoch time: 48.91 s 
2025-01-27 09:04:32.479615:  
2025-01-27 09:04:32.482571: Epoch 567 
2025-01-27 09:04:32.485602: Current learning rate: 0.00471 
2025-01-27 09:05:21.656579: train_loss -0.8168 
2025-01-27 09:05:21.661143: val_loss -0.7714 
2025-01-27 09:05:21.663986: Pseudo dice [np.float32(0.948), np.float32(0.8754)] 
2025-01-27 09:05:21.666536: Epoch time: 49.18 s 
2025-01-27 09:05:22.861660:  
2025-01-27 09:05:22.864592: Epoch 568 
2025-01-27 09:05:22.867360: Current learning rate: 0.0047 
2025-01-27 09:06:11.459279: train_loss -0.8211 
2025-01-27 09:06:11.464931: val_loss -0.7749 
2025-01-27 09:06:11.467381: Pseudo dice [np.float32(0.9555), np.float32(0.9094)] 
2025-01-27 09:06:11.469631: Epoch time: 48.6 s 
2025-01-27 09:06:12.645855:  
2025-01-27 09:06:12.648792: Epoch 569 
2025-01-27 09:06:12.651818: Current learning rate: 0.00469 
2025-01-27 09:07:01.612349: train_loss -0.8193 
2025-01-27 09:07:01.616800: val_loss -0.7684 
2025-01-27 09:07:01.619610: Pseudo dice [np.float32(0.9577), np.float32(0.9082)] 
2025-01-27 09:07:01.622518: Epoch time: 48.97 s 
2025-01-27 09:07:02.825159:  
2025-01-27 09:07:02.829399: Epoch 570 
2025-01-27 09:07:02.832535: Current learning rate: 0.00468 
2025-01-27 09:07:51.494927: train_loss -0.8158 
2025-01-27 09:07:51.503044: val_loss -0.795 
2025-01-27 09:07:51.505932: Pseudo dice [np.float32(0.9551), np.float32(0.8748)] 
2025-01-27 09:07:51.508850: Epoch time: 48.67 s 
2025-01-27 09:07:52.708216:  
2025-01-27 09:07:52.711609: Epoch 571 
2025-01-27 09:07:52.714576: Current learning rate: 0.00467 
2025-01-27 09:08:41.361407: train_loss -0.7783 
2025-01-27 09:08:41.366786: val_loss -0.7579 
2025-01-27 09:08:41.369620: Pseudo dice [np.float32(0.9566), np.float32(0.8794)] 
2025-01-27 09:08:41.372257: Epoch time: 48.65 s 
2025-01-27 09:08:42.544634:  
2025-01-27 09:08:42.547971: Epoch 572 
2025-01-27 09:08:42.551411: Current learning rate: 0.00466 
2025-01-27 09:09:31.145015: train_loss -0.8045 
2025-01-27 09:09:31.151709: val_loss -0.7493 
2025-01-27 09:09:31.154733: Pseudo dice [np.float32(0.955), np.float32(0.8717)] 
2025-01-27 09:09:31.157938: Epoch time: 48.6 s 
2025-01-27 09:09:32.377897:  
2025-01-27 09:09:32.380880: Epoch 573 
2025-01-27 09:09:32.383657: Current learning rate: 0.00465 
2025-01-27 09:10:21.042232: train_loss -0.8221 
2025-01-27 09:10:21.046736: val_loss -0.7762 
2025-01-27 09:10:21.049562: Pseudo dice [np.float32(0.957), np.float32(0.8822)] 
2025-01-27 09:10:21.052289: Epoch time: 48.67 s 
2025-01-27 09:10:22.239428:  
2025-01-27 09:10:22.242633: Epoch 574 
2025-01-27 09:10:22.245164: Current learning rate: 0.00464 
2025-01-27 09:11:10.452079: train_loss -0.8053 
2025-01-27 09:11:10.458323: val_loss -0.7976 
2025-01-27 09:11:10.460942: Pseudo dice [np.float32(0.9602), np.float32(0.9038)] 
2025-01-27 09:11:10.463772: Epoch time: 48.21 s 
2025-01-27 09:11:11.678604:  
2025-01-27 09:11:11.682174: Epoch 575 
2025-01-27 09:11:11.685458: Current learning rate: 0.00463 
2025-01-27 09:12:00.497595: train_loss -0.8262 
2025-01-27 09:12:00.502396: val_loss -0.7423 
2025-01-27 09:12:00.505194: Pseudo dice [np.float32(0.9586), np.float32(0.8802)] 
2025-01-27 09:12:00.507962: Epoch time: 48.82 s 
2025-01-27 09:12:01.691536:  
2025-01-27 09:12:01.694855: Epoch 576 
2025-01-27 09:12:01.698283: Current learning rate: 0.00462 
2025-01-27 09:12:49.768645: train_loss -0.8182 
2025-01-27 09:12:49.774794: val_loss -0.7788 
2025-01-27 09:12:49.777673: Pseudo dice [np.float32(0.9474), np.float32(0.864)] 
2025-01-27 09:12:49.780662: Epoch time: 48.08 s 
2025-01-27 09:12:50.962789:  
2025-01-27 09:12:50.965604: Epoch 577 
2025-01-27 09:12:50.968304: Current learning rate: 0.00461 
2025-01-27 09:13:39.682638: train_loss -0.7983 
2025-01-27 09:13:39.686763: val_loss -0.7208 
2025-01-27 09:13:39.689651: Pseudo dice [np.float32(0.9532), np.float32(0.8747)] 
2025-01-27 09:13:39.692242: Epoch time: 48.72 s 
2025-01-27 09:13:40.892008:  
2025-01-27 09:13:40.895371: Epoch 578 
2025-01-27 09:13:40.898399: Current learning rate: 0.0046 
2025-01-27 09:14:29.490278: train_loss -0.8344 
2025-01-27 09:14:29.496779: val_loss -0.8062 
2025-01-27 09:14:29.499958: Pseudo dice [np.float32(0.9635), np.float32(0.9174)] 
2025-01-27 09:14:29.502815: Epoch time: 48.6 s 
2025-01-27 09:14:30.689627:  
2025-01-27 09:14:30.692756: Epoch 579 
2025-01-27 09:14:30.695872: Current learning rate: 0.00459 
2025-01-27 09:15:19.243906: train_loss -0.831 
2025-01-27 09:15:19.248531: val_loss -0.8303 
2025-01-27 09:15:19.251168: Pseudo dice [np.float32(0.9591), np.float32(0.8926)] 
2025-01-27 09:15:19.253726: Epoch time: 48.56 s 
2025-01-27 09:15:20.482005:  
2025-01-27 09:15:20.485801: Epoch 580 
2025-01-27 09:15:20.488897: Current learning rate: 0.00458 
2025-01-27 09:16:09.060350: train_loss -0.8207 
2025-01-27 09:16:09.066342: val_loss -0.784 
2025-01-27 09:16:09.068934: Pseudo dice [np.float32(0.9572), np.float32(0.9064)] 
2025-01-27 09:16:09.071971: Epoch time: 48.58 s 
2025-01-27 09:16:10.257414:  
2025-01-27 09:16:10.260383: Epoch 581 
2025-01-27 09:16:10.263245: Current learning rate: 0.00457 
2025-01-27 09:16:58.741715: train_loss -0.8273 
2025-01-27 09:16:58.746665: val_loss -0.74 
2025-01-27 09:16:58.749614: Pseudo dice [np.float32(0.9533), np.float32(0.8976)] 
2025-01-27 09:16:58.752288: Epoch time: 48.49 s 
2025-01-27 09:17:00.499094:  
2025-01-27 09:17:00.502870: Epoch 582 
2025-01-27 09:17:00.505706: Current learning rate: 0.00456 
2025-01-27 09:17:49.509227: train_loss -0.794 
2025-01-27 09:17:49.515827: val_loss -0.7342 
2025-01-27 09:17:49.518961: Pseudo dice [np.float32(0.9553), np.float32(0.847)] 
2025-01-27 09:17:49.522037: Epoch time: 49.01 s 
2025-01-27 09:17:50.730986:  
2025-01-27 09:17:50.734173: Epoch 583 
2025-01-27 09:17:50.736678: Current learning rate: 0.00455 
2025-01-27 09:18:39.043690: train_loss -0.8023 
2025-01-27 09:18:39.048668: val_loss -0.8222 
2025-01-27 09:18:39.051448: Pseudo dice [np.float32(0.959), np.float32(0.8944)] 
2025-01-27 09:18:39.054011: Epoch time: 48.31 s 
2025-01-27 09:18:40.242851:  
2025-01-27 09:18:40.245814: Epoch 584 
2025-01-27 09:18:40.248599: Current learning rate: 0.00454 
2025-01-27 09:19:28.826269: train_loss -0.8399 
2025-01-27 09:19:28.832272: val_loss -0.8147 
2025-01-27 09:19:28.835288: Pseudo dice [np.float32(0.9609), np.float32(0.9107)] 
2025-01-27 09:19:28.839662: Epoch time: 48.58 s 
2025-01-27 09:19:30.015687:  
2025-01-27 09:19:30.018865: Epoch 585 
2025-01-27 09:19:30.021953: Current learning rate: 0.00453 
2025-01-27 09:20:18.907743: train_loss -0.8237 
2025-01-27 09:20:18.912759: val_loss -0.7711 
2025-01-27 09:20:18.916138: Pseudo dice [np.float32(0.9567), np.float32(0.8586)] 
2025-01-27 09:20:18.919259: Epoch time: 48.89 s 
2025-01-27 09:20:20.117891:  
2025-01-27 09:20:20.120866: Epoch 586 
2025-01-27 09:20:20.123667: Current learning rate: 0.00452 
2025-01-27 09:21:08.612670: train_loss -0.8459 
2025-01-27 09:21:08.618676: val_loss -0.8035 
2025-01-27 09:21:08.621648: Pseudo dice [np.float32(0.958), np.float32(0.9096)] 
2025-01-27 09:21:08.625622: Epoch time: 48.5 s 
2025-01-27 09:21:09.813067:  
2025-01-27 09:21:09.816158: Epoch 587 
2025-01-27 09:21:09.819263: Current learning rate: 0.00451 
2025-01-27 09:21:58.500419: train_loss -0.8277 
2025-01-27 09:21:58.505331: val_loss -0.7654 
2025-01-27 09:21:58.508401: Pseudo dice [np.float32(0.9544), np.float32(0.8958)] 
2025-01-27 09:21:58.511020: Epoch time: 48.69 s 
2025-01-27 09:21:59.704921:  
2025-01-27 09:21:59.707997: Epoch 588 
2025-01-27 09:21:59.710643: Current learning rate: 0.0045 
2025-01-27 09:22:48.545319: train_loss -0.8347 
2025-01-27 09:22:48.551476: val_loss -0.7799 
2025-01-27 09:22:48.554420: Pseudo dice [np.float32(0.9619), np.float32(0.9104)] 
2025-01-27 09:22:48.557223: Epoch time: 48.84 s 
2025-01-27 09:22:49.758700:  
2025-01-27 09:22:49.762105: Epoch 589 
2025-01-27 09:22:49.765012: Current learning rate: 0.00449 
2025-01-27 09:23:38.629657: train_loss -0.8257 
2025-01-27 09:23:38.634672: val_loss -0.7739 
2025-01-27 09:23:38.637532: Pseudo dice [np.float32(0.9653), np.float32(0.9145)] 
2025-01-27 09:23:38.640293: Epoch time: 48.87 s 
2025-01-27 09:23:38.643274: Yayy! New best EMA pseudo Dice: 0.9254000186920166 
2025-01-27 09:23:40.440847:  
2025-01-27 09:23:40.443821: Epoch 590 
2025-01-27 09:23:40.446584: Current learning rate: 0.00448 
2025-01-27 09:24:28.767144: train_loss -0.8297 
2025-01-27 09:24:28.774331: val_loss -0.81 
2025-01-27 09:24:28.776967: Pseudo dice [np.float32(0.9638), np.float32(0.9074)] 
2025-01-27 09:24:28.779863: Epoch time: 48.33 s 
2025-01-27 09:24:28.782454: Yayy! New best EMA pseudo Dice: 0.9265000224113464 
2025-01-27 09:24:30.640243:  
2025-01-27 09:24:30.643186: Epoch 591 
2025-01-27 09:24:30.645939: Current learning rate: 0.00447 
2025-01-27 09:25:19.177157: train_loss -0.847 
2025-01-27 09:25:19.181476: val_loss -0.8289 
2025-01-27 09:25:19.184994: Pseudo dice [np.float32(0.9635), np.float32(0.9163)] 
2025-01-27 09:25:19.187667: Epoch time: 48.54 s 
2025-01-27 09:25:19.190956: Yayy! New best EMA pseudo Dice: 0.9277999997138977 
2025-01-27 09:25:20.944317:  
2025-01-27 09:25:20.947517: Epoch 592 
2025-01-27 09:25:20.953716: Current learning rate: 0.00446 
2025-01-27 09:26:09.741378: train_loss -0.8378 
2025-01-27 09:26:09.747760: val_loss -0.7937 
2025-01-27 09:26:09.750724: Pseudo dice [np.float32(0.9587), np.float32(0.9142)] 
2025-01-27 09:26:09.753304: Epoch time: 48.8 s 
2025-01-27 09:26:09.755922: Yayy! New best EMA pseudo Dice: 0.9286999702453613 
2025-01-27 09:26:11.569633:  
2025-01-27 09:26:11.573071: Epoch 593 
2025-01-27 09:26:11.575933: Current learning rate: 0.00445 
2025-01-27 09:27:00.174685: train_loss -0.8146 
2025-01-27 09:27:00.179152: val_loss -0.7599 
2025-01-27 09:27:00.182051: Pseudo dice [np.float32(0.9481), np.float32(0.8318)] 
2025-01-27 09:27:00.184968: Epoch time: 48.61 s 
2025-01-27 09:27:01.417981:  
2025-01-27 09:27:01.421266: Epoch 594 
2025-01-27 09:27:01.424413: Current learning rate: 0.00444 
2025-01-27 09:27:49.586228: train_loss -0.8306 
2025-01-27 09:27:49.591743: val_loss -0.7654 
2025-01-27 09:27:49.594799: Pseudo dice [np.float32(0.9537), np.float32(0.901)] 
2025-01-27 09:27:49.597838: Epoch time: 48.17 s 
2025-01-27 09:27:50.777817:  
2025-01-27 09:27:50.780922: Epoch 595 
2025-01-27 09:27:50.783735: Current learning rate: 0.00443 
2025-01-27 09:28:39.396634: train_loss -0.792 
2025-01-27 09:28:39.400632: val_loss -0.7577 
2025-01-27 09:28:39.403525: Pseudo dice [np.float32(0.9538), np.float32(0.7818)] 
2025-01-27 09:28:39.406376: Epoch time: 48.62 s 
2025-01-27 09:28:40.600648:  
2025-01-27 09:28:40.603595: Epoch 596 
2025-01-27 09:28:40.606427: Current learning rate: 0.00442 
2025-01-27 09:29:29.171473: train_loss -0.7998 
2025-01-27 09:29:29.178960: val_loss -0.7968 
2025-01-27 09:29:29.181768: Pseudo dice [np.float32(0.9563), np.float32(0.9029)] 
2025-01-27 09:29:29.184622: Epoch time: 48.57 s 
2025-01-27 09:29:30.398917:  
2025-01-27 09:29:30.402141: Epoch 597 
2025-01-27 09:29:30.405359: Current learning rate: 0.00441 
2025-01-27 09:30:18.952817: train_loss -0.7968 
2025-01-27 09:30:18.956880: val_loss -0.751 
2025-01-27 09:30:18.959837: Pseudo dice [np.float32(0.9531), np.float32(0.8693)] 
2025-01-27 09:30:18.962348: Epoch time: 48.55 s 
2025-01-27 09:30:20.176614:  
2025-01-27 09:30:20.179772: Epoch 598 
2025-01-27 09:30:20.182787: Current learning rate: 0.0044 
2025-01-27 09:31:08.881901: train_loss -0.8183 
2025-01-27 09:31:08.888398: val_loss -0.7627 
2025-01-27 09:31:08.891601: Pseudo dice [np.float32(0.9592), np.float32(0.8893)] 
2025-01-27 09:31:08.894287: Epoch time: 48.71 s 
2025-01-27 09:31:10.117984:  
2025-01-27 09:31:10.121290: Epoch 599 
2025-01-27 09:31:10.124128: Current learning rate: 0.00439 
2025-01-27 09:31:58.649305: train_loss -0.8165 
2025-01-27 09:31:58.653788: val_loss -0.7525 
2025-01-27 09:31:58.656968: Pseudo dice [np.float32(0.9536), np.float32(0.8739)] 
2025-01-27 09:31:58.659885: Epoch time: 48.53 s 
2025-01-27 09:32:00.537584:  
2025-01-27 09:32:00.540510: Epoch 600 
2025-01-27 09:32:00.543541: Current learning rate: 0.00438 
2025-01-27 09:32:49.344521: train_loss -0.8303 
2025-01-27 09:32:49.350560: val_loss -0.797 
2025-01-27 09:32:49.353490: Pseudo dice [np.float32(0.9605), np.float32(0.9088)] 
2025-01-27 09:32:49.356180: Epoch time: 48.81 s 
2025-01-27 09:32:51.251188:  
2025-01-27 09:32:51.254112: Epoch 601 
2025-01-27 09:32:51.256724: Current learning rate: 0.00437 
2025-01-27 09:33:39.501832: train_loss -0.8142 
2025-01-27 09:33:39.507264: val_loss -0.8099 
2025-01-27 09:33:39.510412: Pseudo dice [np.float32(0.9538), np.float32(0.8952)] 
2025-01-27 09:33:39.513202: Epoch time: 48.25 s 
2025-01-27 09:33:40.736181:  
2025-01-27 09:33:40.739088: Epoch 602 
2025-01-27 09:33:40.741912: Current learning rate: 0.00436 
2025-01-27 09:34:29.398952: train_loss -0.8174 
2025-01-27 09:34:29.406951: val_loss -0.7901 
2025-01-27 09:34:29.409564: Pseudo dice [np.float32(0.9566), np.float32(0.8709)] 
2025-01-27 09:34:29.412484: Epoch time: 48.66 s 
2025-01-27 09:34:30.611277:  
2025-01-27 09:34:30.613980: Epoch 603 
2025-01-27 09:34:30.617170: Current learning rate: 0.00435 
2025-01-27 09:35:19.608065: train_loss -0.8297 
2025-01-27 09:35:19.612008: val_loss -0.7832 
2025-01-27 09:35:19.614620: Pseudo dice [np.float32(0.9648), np.float32(0.8973)] 
2025-01-27 09:35:19.617011: Epoch time: 49.0 s 
2025-01-27 09:35:20.815245:  
2025-01-27 09:35:20.818350: Epoch 604 
2025-01-27 09:35:20.820990: Current learning rate: 0.00434 
2025-01-27 09:36:08.916348: train_loss -0.8257 
2025-01-27 09:36:08.921973: val_loss -0.7688 
2025-01-27 09:36:08.925031: Pseudo dice [np.float32(0.9587), np.float32(0.9115)] 
2025-01-27 09:36:08.927873: Epoch time: 48.1 s 
2025-01-27 09:36:10.124830:  
2025-01-27 09:36:10.127645: Epoch 605 
2025-01-27 09:36:10.130476: Current learning rate: 0.00433 
2025-01-27 09:36:58.950088: train_loss -0.834 
2025-01-27 09:36:58.954373: val_loss -0.7827 
2025-01-27 09:36:58.957131: Pseudo dice [np.float32(0.9557), np.float32(0.9148)] 
2025-01-27 09:36:58.959521: Epoch time: 48.83 s 
2025-01-27 09:37:00.170634:  
2025-01-27 09:37:00.174913: Epoch 606 
2025-01-27 09:37:00.177846: Current learning rate: 0.00432 
2025-01-27 09:37:48.351111: train_loss -0.8177 
2025-01-27 09:37:48.356970: val_loss -0.7531 
2025-01-27 09:37:48.360281: Pseudo dice [np.float32(0.9615), np.float32(0.8577)] 
2025-01-27 09:37:48.362997: Epoch time: 48.18 s 
2025-01-27 09:37:49.559258:  
2025-01-27 09:37:49.562753: Epoch 607 
2025-01-27 09:37:49.565517: Current learning rate: 0.00431 
2025-01-27 09:38:38.643693: train_loss -0.8279 
2025-01-27 09:38:38.647902: val_loss -0.7826 
2025-01-27 09:38:38.650911: Pseudo dice [np.float32(0.9544), np.float32(0.8765)] 
2025-01-27 09:38:38.653720: Epoch time: 49.09 s 
2025-01-27 09:38:39.855321:  
2025-01-27 09:38:39.858219: Epoch 608 
2025-01-27 09:38:39.861063: Current learning rate: 0.0043 
2025-01-27 09:39:28.594334: train_loss -0.819 
2025-01-27 09:39:28.620077: val_loss -0.7771 
2025-01-27 09:39:28.623222: Pseudo dice [np.float32(0.959), np.float32(0.8815)] 
2025-01-27 09:39:28.626179: Epoch time: 48.74 s 
2025-01-27 09:39:29.824734:  
2025-01-27 09:39:29.827355: Epoch 609 
2025-01-27 09:39:29.830109: Current learning rate: 0.00429 
2025-01-27 09:40:18.286153: train_loss -0.8197 
2025-01-27 09:40:18.290566: val_loss -0.7839 
2025-01-27 09:40:18.293067: Pseudo dice [np.float32(0.951), np.float32(0.8764)] 
2025-01-27 09:40:18.295623: Epoch time: 48.46 s 
2025-01-27 09:40:19.499393:  
2025-01-27 09:40:19.502186: Epoch 610 
2025-01-27 09:40:19.505116: Current learning rate: 0.00429 
2025-01-27 09:41:07.779496: train_loss -0.8186 
2025-01-27 09:41:07.785666: val_loss -0.7883 
2025-01-27 09:41:07.788468: Pseudo dice [np.float32(0.9589), np.float32(0.881)] 
2025-01-27 09:41:07.791844: Epoch time: 48.28 s 
2025-01-27 09:41:08.994674:  
2025-01-27 09:41:08.997941: Epoch 611 
2025-01-27 09:41:09.000650: Current learning rate: 0.00428 
2025-01-27 09:41:57.309331: train_loss -0.8403 
2025-01-27 09:41:57.314866: val_loss -0.8107 
2025-01-27 09:41:57.317392: Pseudo dice [np.float32(0.9611), np.float32(0.9072)] 
2025-01-27 09:41:57.319675: Epoch time: 48.32 s 
2025-01-27 09:41:58.516490:  
2025-01-27 09:41:58.519777: Epoch 612 
2025-01-27 09:41:58.522606: Current learning rate: 0.00427 
2025-01-27 09:42:46.879790: train_loss -0.8334 
2025-01-27 09:42:46.886248: val_loss -0.7765 
2025-01-27 09:42:46.888963: Pseudo dice [np.float32(0.9496), np.float32(0.9059)] 
2025-01-27 09:42:46.891826: Epoch time: 48.36 s 
2025-01-27 09:42:48.085407:  
2025-01-27 09:42:48.088487: Epoch 613 
2025-01-27 09:42:48.091659: Current learning rate: 0.00426 
2025-01-27 09:43:36.057409: train_loss -0.8291 
2025-01-27 09:43:36.062031: val_loss -0.7779 
2025-01-27 09:43:36.064806: Pseudo dice [np.float32(0.9639), np.float32(0.9087)] 
2025-01-27 09:43:36.067629: Epoch time: 47.97 s 
2025-01-27 09:43:37.269626:  
2025-01-27 09:43:37.272527: Epoch 614 
2025-01-27 09:43:37.275051: Current learning rate: 0.00425 
2025-01-27 09:44:25.980580: train_loss -0.8218 
2025-01-27 09:44:25.986237: val_loss -0.7662 
2025-01-27 09:44:25.989343: Pseudo dice [np.float32(0.9619), np.float32(0.8924)] 
2025-01-27 09:44:25.992015: Epoch time: 48.71 s 
2025-01-27 09:44:27.193231:  
2025-01-27 09:44:27.196117: Epoch 615 
2025-01-27 09:44:27.198931: Current learning rate: 0.00424 
2025-01-27 09:45:15.354419: train_loss -0.8267 
2025-01-27 09:45:15.359275: val_loss -0.7552 
2025-01-27 09:45:15.362291: Pseudo dice [np.float32(0.9652), np.float32(0.8911)] 
2025-01-27 09:45:15.365079: Epoch time: 48.16 s 
2025-01-27 09:45:16.575961:  
2025-01-27 09:45:16.579886: Epoch 616 
2025-01-27 09:45:16.583403: Current learning rate: 0.00423 
2025-01-27 09:46:04.978406: train_loss -0.8335 
2025-01-27 09:46:04.984548: val_loss -0.7565 
2025-01-27 09:46:04.987016: Pseudo dice [np.float32(0.965), np.float32(0.9051)] 
2025-01-27 09:46:04.989473: Epoch time: 48.4 s 
2025-01-27 09:46:06.194571:  
2025-01-27 09:46:06.197698: Epoch 617 
2025-01-27 09:46:06.200424: Current learning rate: 0.00422 
2025-01-27 09:46:54.808668: train_loss -0.8313 
2025-01-27 09:46:54.812823: val_loss -0.7842 
2025-01-27 09:46:54.816112: Pseudo dice [np.float32(0.9627), np.float32(0.8996)] 
2025-01-27 09:46:54.818659: Epoch time: 48.62 s 
2025-01-27 09:46:56.028423:  
2025-01-27 09:46:56.031419: Epoch 618 
2025-01-27 09:46:56.034212: Current learning rate: 0.00421 
2025-01-27 09:47:44.099321: train_loss -0.8276 
2025-01-27 09:47:44.105417: val_loss -0.7791 
2025-01-27 09:47:44.109307: Pseudo dice [np.float32(0.9593), np.float32(0.876)] 
2025-01-27 09:47:44.113344: Epoch time: 48.07 s 
2025-01-27 09:47:45.973682:  
2025-01-27 09:47:45.976772: Epoch 619 
2025-01-27 09:47:45.979941: Current learning rate: 0.0042 
2025-01-27 09:48:34.472554: train_loss -0.8251 
2025-01-27 09:48:34.476990: val_loss -0.7736 
2025-01-27 09:48:34.479807: Pseudo dice [np.float32(0.9571), np.float32(0.8893)] 
2025-01-27 09:48:34.482504: Epoch time: 48.5 s 
2025-01-27 09:48:35.678674:  
2025-01-27 09:48:35.681670: Epoch 620 
2025-01-27 09:48:35.684412: Current learning rate: 0.00419 
2025-01-27 09:49:24.213199: train_loss -0.8302 
2025-01-27 09:49:24.219664: val_loss -0.7766 
2025-01-27 09:49:24.222699: Pseudo dice [np.float32(0.9662), np.float32(0.9002)] 
2025-01-27 09:49:24.225789: Epoch time: 48.54 s 
2025-01-27 09:49:25.427053:  
2025-01-27 09:49:25.430301: Epoch 621 
2025-01-27 09:49:25.433180: Current learning rate: 0.00418 
2025-01-27 09:50:14.418216: train_loss -0.8489 
2025-01-27 09:50:14.422371: val_loss -0.7744 
2025-01-27 09:50:14.424947: Pseudo dice [np.float32(0.9604), np.float32(0.9003)] 
2025-01-27 09:50:14.427673: Epoch time: 48.99 s 
2025-01-27 09:50:15.638497:  
2025-01-27 09:50:15.641128: Epoch 622 
2025-01-27 09:50:15.643885: Current learning rate: 0.00417 
2025-01-27 09:51:04.229444: train_loss -0.8476 
2025-01-27 09:51:04.236168: val_loss -0.7719 
2025-01-27 09:51:04.239315: Pseudo dice [np.float32(0.9621), np.float32(0.9058)] 
2025-01-27 09:51:04.242474: Epoch time: 48.59 s 
2025-01-27 09:51:05.438956:  
2025-01-27 09:51:05.443035: Epoch 623 
2025-01-27 09:51:05.446166: Current learning rate: 0.00416 
2025-01-27 09:51:53.811264: train_loss -0.834 
2025-01-27 09:51:53.815624: val_loss -0.8157 
2025-01-27 09:51:53.818572: Pseudo dice [np.float32(0.962), np.float32(0.9043)] 
2025-01-27 09:51:53.821517: Epoch time: 48.37 s 
2025-01-27 09:51:55.024749:  
2025-01-27 09:51:55.027965: Epoch 624 
2025-01-27 09:51:55.030680: Current learning rate: 0.00415 
2025-01-27 09:52:43.877138: train_loss -0.8154 
2025-01-27 09:52:43.882665: val_loss -0.7899 
2025-01-27 09:52:43.885340: Pseudo dice [np.float32(0.9572), np.float32(0.8965)] 
2025-01-27 09:52:43.887715: Epoch time: 48.85 s 
2025-01-27 09:52:45.083247:  
2025-01-27 09:52:45.086673: Epoch 625 
2025-01-27 09:52:45.089490: Current learning rate: 0.00414 
2025-01-27 09:53:33.634237: train_loss -0.8309 
2025-01-27 09:53:33.638140: val_loss -0.7889 
2025-01-27 09:53:33.640800: Pseudo dice [np.float32(0.9597), np.float32(0.8897)] 
2025-01-27 09:53:33.643604: Epoch time: 48.55 s 
2025-01-27 09:53:34.842521:  
2025-01-27 09:53:34.845745: Epoch 626 
2025-01-27 09:53:34.848401: Current learning rate: 0.00413 
2025-01-27 09:54:23.244390: train_loss -0.8449 
2025-01-27 09:54:23.250641: val_loss -0.7639 
2025-01-27 09:54:23.253502: Pseudo dice [np.float32(0.9587), np.float32(0.8825)] 
2025-01-27 09:54:23.255896: Epoch time: 48.4 s 
2025-01-27 09:54:24.453797:  
2025-01-27 09:54:24.456780: Epoch 627 
2025-01-27 09:54:24.459841: Current learning rate: 0.00412 
2025-01-27 09:55:12.830025: train_loss -0.8276 
2025-01-27 09:55:12.834009: val_loss -0.7651 
2025-01-27 09:55:12.836788: Pseudo dice [np.float32(0.9633), np.float32(0.9095)] 
2025-01-27 09:55:12.839468: Epoch time: 48.38 s 
2025-01-27 09:55:14.038072:  
2025-01-27 09:55:14.041191: Epoch 628 
2025-01-27 09:55:14.044130: Current learning rate: 0.00411 
2025-01-27 09:56:02.542331: train_loss -0.84 
2025-01-27 09:56:02.549952: val_loss -0.7849 
2025-01-27 09:56:02.552685: Pseudo dice [np.float32(0.9584), np.float32(0.9105)] 
2025-01-27 09:56:02.555259: Epoch time: 48.51 s 
2025-01-27 09:56:03.752666:  
2025-01-27 09:56:03.755914: Epoch 629 
2025-01-27 09:56:03.758972: Current learning rate: 0.0041 
2025-01-27 09:56:51.844206: train_loss -0.8395 
2025-01-27 09:56:51.848887: val_loss -0.7636 
2025-01-27 09:56:51.851913: Pseudo dice [np.float32(0.9549), np.float32(0.8833)] 
2025-01-27 09:56:51.854360: Epoch time: 48.09 s 
2025-01-27 09:56:53.058754:  
2025-01-27 09:56:53.061961: Epoch 630 
2025-01-27 09:56:53.064877: Current learning rate: 0.00409 
2025-01-27 09:57:41.384513: train_loss -0.8272 
2025-01-27 09:57:41.392075: val_loss -0.7589 
2025-01-27 09:57:41.394772: Pseudo dice [np.float32(0.9623), np.float32(0.8998)] 
2025-01-27 09:57:41.397602: Epoch time: 48.33 s 
2025-01-27 09:57:42.595960:  
2025-01-27 09:57:42.598800: Epoch 631 
2025-01-27 09:57:42.601675: Current learning rate: 0.00408 
2025-01-27 09:58:30.486745: train_loss -0.8106 
2025-01-27 09:58:30.490552: val_loss -0.7859 
2025-01-27 09:58:30.493527: Pseudo dice [np.float32(0.9554), np.float32(0.9064)] 
2025-01-27 09:58:30.496101: Epoch time: 47.89 s 
2025-01-27 09:58:31.692450:  
2025-01-27 09:58:31.695511: Epoch 632 
2025-01-27 09:58:31.698069: Current learning rate: 0.00407 
2025-01-27 09:59:20.064456: train_loss -0.8256 
2025-01-27 09:59:20.070448: val_loss -0.8189 
2025-01-27 09:59:20.073142: Pseudo dice [np.float32(0.9622), np.float32(0.9194)] 
2025-01-27 09:59:20.075722: Epoch time: 48.37 s 
2025-01-27 09:59:20.078396: Yayy! New best EMA pseudo Dice: 0.9294000267982483 
2025-01-27 09:59:21.831246:  
2025-01-27 09:59:21.834823: Epoch 633 
2025-01-27 09:59:21.838083: Current learning rate: 0.00406 
2025-01-27 10:00:10.235068: train_loss -0.8345 
2025-01-27 10:00:10.241491: val_loss -0.7746 
2025-01-27 10:00:10.244344: Pseudo dice [np.float32(0.9491), np.float32(0.8707)] 
2025-01-27 10:00:10.246941: Epoch time: 48.4 s 
2025-01-27 10:00:11.465321:  
2025-01-27 10:00:11.468525: Epoch 634 
2025-01-27 10:00:11.471553: Current learning rate: 0.00405 
2025-01-27 10:00:59.931367: train_loss -0.8174 
2025-01-27 10:00:59.937338: val_loss -0.8167 
2025-01-27 10:00:59.939831: Pseudo dice [np.float32(0.9532), np.float32(0.9071)] 
2025-01-27 10:00:59.942307: Epoch time: 48.47 s 
2025-01-27 10:01:01.152351:  
2025-01-27 10:01:01.154986: Epoch 635 
2025-01-27 10:01:01.157588: Current learning rate: 0.00404 
2025-01-27 10:01:49.454418: train_loss -0.8246 
2025-01-27 10:01:49.461695: val_loss -0.8028 
2025-01-27 10:01:49.464497: Pseudo dice [np.float32(0.9565), np.float32(0.904)] 
2025-01-27 10:01:49.467295: Epoch time: 48.3 s 
2025-01-27 10:01:50.668594:  
2025-01-27 10:01:50.671326: Epoch 636 
2025-01-27 10:01:50.673904: Current learning rate: 0.00403 
2025-01-27 10:02:39.706567: train_loss -0.8246 
2025-01-27 10:02:39.713143: val_loss -0.7876 
2025-01-27 10:02:39.715710: Pseudo dice [np.float32(0.9602), np.float32(0.9007)] 
2025-01-27 10:02:39.718160: Epoch time: 49.04 s 
2025-01-27 10:02:40.923590:  
2025-01-27 10:02:40.926491: Epoch 637 
2025-01-27 10:02:40.929338: Current learning rate: 0.00402 
2025-01-27 10:03:29.396405: train_loss -0.8417 
2025-01-27 10:03:29.400990: val_loss -0.8024 
2025-01-27 10:03:29.403571: Pseudo dice [np.float32(0.9635), np.float32(0.9117)] 
2025-01-27 10:03:29.406586: Epoch time: 48.47 s 
2025-01-27 10:03:31.168253:  
2025-01-27 10:03:31.171375: Epoch 638 
2025-01-27 10:03:31.174380: Current learning rate: 0.00401 
2025-01-27 10:04:19.317816: train_loss -0.834 
2025-01-27 10:04:19.326013: val_loss -0.7789 
2025-01-27 10:04:19.328656: Pseudo dice [np.float32(0.9591), np.float32(0.8946)] 
2025-01-27 10:04:19.331296: Epoch time: 48.15 s 
2025-01-27 10:04:20.529925:  
2025-01-27 10:04:20.533086: Epoch 639 
2025-01-27 10:04:20.535777: Current learning rate: 0.004 
2025-01-27 10:05:08.875699: train_loss -0.8315 
2025-01-27 10:05:08.880717: val_loss -0.786 
2025-01-27 10:05:08.883809: Pseudo dice [np.float32(0.9582), np.float32(0.9058)] 
2025-01-27 10:05:08.886944: Epoch time: 48.35 s 
2025-01-27 10:05:10.094184:  
2025-01-27 10:05:10.097444: Epoch 640 
2025-01-27 10:05:10.100418: Current learning rate: 0.00399 
2025-01-27 10:05:59.265248: train_loss -0.8151 
2025-01-27 10:05:59.270478: val_loss -0.7938 
2025-01-27 10:05:59.273082: Pseudo dice [np.float32(0.9591), np.float32(0.8734)] 
2025-01-27 10:05:59.275500: Epoch time: 49.17 s 
2025-01-27 10:06:00.469785:  
2025-01-27 10:06:00.472528: Epoch 641 
2025-01-27 10:06:00.475529: Current learning rate: 0.00398 
2025-01-27 10:06:48.542268: train_loss -0.8405 
2025-01-27 10:06:48.548546: val_loss -0.8096 
2025-01-27 10:06:48.551218: Pseudo dice [np.float32(0.9631), np.float32(0.9157)] 
2025-01-27 10:06:48.554235: Epoch time: 48.07 s 
2025-01-27 10:06:49.759102:  
2025-01-27 10:06:49.762149: Epoch 642 
2025-01-27 10:06:49.765082: Current learning rate: 0.00397 
2025-01-27 10:07:37.867201: train_loss -0.8279 
2025-01-27 10:07:37.873220: val_loss -0.7766 
2025-01-27 10:07:37.876070: Pseudo dice [np.float32(0.9508), np.float32(0.9014)] 
2025-01-27 10:07:37.878425: Epoch time: 48.11 s 
2025-01-27 10:07:39.117184:  
2025-01-27 10:07:39.120170: Epoch 643 
2025-01-27 10:07:39.122760: Current learning rate: 0.00396 
2025-01-27 10:08:27.598571: train_loss -0.8269 
2025-01-27 10:08:27.602648: val_loss -0.7711 
2025-01-27 10:08:27.605175: Pseudo dice [np.float32(0.9544), np.float32(0.8667)] 
2025-01-27 10:08:27.607482: Epoch time: 48.48 s 
2025-01-27 10:08:28.869525:  
2025-01-27 10:08:28.872421: Epoch 644 
2025-01-27 10:08:28.875245: Current learning rate: 0.00395 
2025-01-27 10:09:17.483660: train_loss -0.822 
2025-01-27 10:09:17.489415: val_loss -0.7947 
2025-01-27 10:09:17.492002: Pseudo dice [np.float32(0.959), np.float32(0.8783)] 
2025-01-27 10:09:17.494469: Epoch time: 48.62 s 
2025-01-27 10:09:18.721127:  
2025-01-27 10:09:18.724027: Epoch 645 
2025-01-27 10:09:18.726969: Current learning rate: 0.00394 
2025-01-27 10:10:07.879859: train_loss -0.8306 
2025-01-27 10:10:07.884755: val_loss -0.7672 
2025-01-27 10:10:07.887770: Pseudo dice [np.float32(0.9607), np.float32(0.8278)] 
2025-01-27 10:10:07.890591: Epoch time: 49.16 s 
2025-01-27 10:10:09.090456:  
2025-01-27 10:10:09.093825: Epoch 646 
2025-01-27 10:10:09.096475: Current learning rate: 0.00393 
2025-01-27 10:10:58.366019: train_loss -0.8266 
2025-01-27 10:10:58.372373: val_loss -0.7618 
2025-01-27 10:10:58.374893: Pseudo dice [np.float32(0.956), np.float32(0.9045)] 
2025-01-27 10:10:58.377662: Epoch time: 49.28 s 
2025-01-27 10:10:59.588380:  
2025-01-27 10:10:59.591706: Epoch 647 
2025-01-27 10:10:59.594315: Current learning rate: 0.00392 
2025-01-27 10:11:48.506102: train_loss -0.822 
2025-01-27 10:11:48.510472: val_loss -0.7681 
2025-01-27 10:11:48.513347: Pseudo dice [np.float32(0.9594), np.float32(0.8666)] 
2025-01-27 10:11:48.515944: Epoch time: 48.92 s 
2025-01-27 10:11:49.746071:  
2025-01-27 10:11:49.749059: Epoch 648 
2025-01-27 10:11:49.752071: Current learning rate: 0.00391 
2025-01-27 10:12:38.462203: train_loss -0.8273 
2025-01-27 10:12:38.468172: val_loss -0.8033 
2025-01-27 10:12:38.470840: Pseudo dice [np.float32(0.961), np.float32(0.8948)] 
2025-01-27 10:12:38.473478: Epoch time: 48.72 s 
2025-01-27 10:12:39.665041:  
2025-01-27 10:12:39.669188: Epoch 649 
2025-01-27 10:12:39.672328: Current learning rate: 0.0039 
2025-01-27 10:13:28.186735: train_loss -0.8367 
2025-01-27 10:13:28.191234: val_loss -0.7603 
2025-01-27 10:13:28.194252: Pseudo dice [np.float32(0.9604), np.float32(0.9107)] 
2025-01-27 10:13:28.197131: Epoch time: 48.52 s 
2025-01-27 10:13:30.007115:  
2025-01-27 10:13:30.009966: Epoch 650 
2025-01-27 10:13:30.012658: Current learning rate: 0.00389 
2025-01-27 10:14:18.502555: train_loss -0.828 
2025-01-27 10:14:18.508371: val_loss -0.7702 
2025-01-27 10:14:18.511215: Pseudo dice [np.float32(0.9534), np.float32(0.8787)] 
2025-01-27 10:14:18.513877: Epoch time: 48.5 s 
2025-01-27 10:14:19.706496:  
2025-01-27 10:14:19.709777: Epoch 651 
2025-01-27 10:14:19.713012: Current learning rate: 0.00388 
2025-01-27 10:15:08.774951: train_loss -0.8444 
2025-01-27 10:15:08.779580: val_loss -0.7515 
2025-01-27 10:15:08.782302: Pseudo dice [np.float32(0.9572), np.float32(0.8918)] 
2025-01-27 10:15:08.784824: Epoch time: 49.07 s 
2025-01-27 10:15:09.975175:  
2025-01-27 10:15:09.978250: Epoch 652 
2025-01-27 10:15:09.981180: Current learning rate: 0.00387 
2025-01-27 10:15:58.873219: train_loss -0.8321 
2025-01-27 10:15:58.878713: val_loss -0.7842 
2025-01-27 10:15:58.881262: Pseudo dice [np.float32(0.961), np.float32(0.9139)] 
2025-01-27 10:15:58.883858: Epoch time: 48.9 s 
2025-01-27 10:16:00.079851:  
2025-01-27 10:16:00.082920: Epoch 653 
2025-01-27 10:16:00.085697: Current learning rate: 0.00386 
2025-01-27 10:16:48.831357: train_loss -0.839 
2025-01-27 10:16:48.836263: val_loss -0.7682 
2025-01-27 10:16:48.839122: Pseudo dice [np.float32(0.9537), np.float32(0.8749)] 
2025-01-27 10:16:48.842215: Epoch time: 48.75 s 
2025-01-27 10:16:50.075680:  
2025-01-27 10:16:50.078984: Epoch 654 
2025-01-27 10:16:50.081945: Current learning rate: 0.00385 
2025-01-27 10:17:38.581061: train_loss -0.8199 
2025-01-27 10:17:38.587466: val_loss -0.7718 
2025-01-27 10:17:38.590287: Pseudo dice [np.float32(0.9562), np.float32(0.8954)] 
2025-01-27 10:17:38.592852: Epoch time: 48.51 s 
2025-01-27 10:17:39.814775:  
2025-01-27 10:17:39.818121: Epoch 655 
2025-01-27 10:17:39.820870: Current learning rate: 0.00384 
2025-01-27 10:18:28.209531: train_loss -0.8107 
2025-01-27 10:18:28.214865: val_loss -0.8143 
2025-01-27 10:18:28.218213: Pseudo dice [np.float32(0.957), np.float32(0.9121)] 
2025-01-27 10:18:28.220855: Epoch time: 48.4 s 
2025-01-27 10:18:29.437332:  
2025-01-27 10:18:29.440556: Epoch 656 
2025-01-27 10:18:29.443117: Current learning rate: 0.00383 
2025-01-27 10:19:18.127146: train_loss -0.8276 
2025-01-27 10:19:18.133981: val_loss -0.7889 
2025-01-27 10:19:18.137199: Pseudo dice [np.float32(0.9613), np.float32(0.8902)] 
2025-01-27 10:19:18.140291: Epoch time: 48.69 s 
2025-01-27 10:19:19.995390:  
2025-01-27 10:19:19.998620: Epoch 657 
2025-01-27 10:19:20.001145: Current learning rate: 0.00382 
2025-01-27 10:20:08.648415: train_loss -0.8265 
2025-01-27 10:20:08.653342: val_loss -0.7647 
2025-01-27 10:20:08.656126: Pseudo dice [np.float32(0.9358), np.float32(0.8884)] 
2025-01-27 10:20:08.658994: Epoch time: 48.65 s 
2025-01-27 10:20:09.897169:  
2025-01-27 10:20:09.900523: Epoch 658 
2025-01-27 10:20:09.903217: Current learning rate: 0.00381 
2025-01-27 10:20:58.345393: train_loss -0.8235 
2025-01-27 10:20:58.353431: val_loss -0.7848 
2025-01-27 10:20:58.356625: Pseudo dice [np.float32(0.9587), np.float32(0.8946)] 
2025-01-27 10:20:58.359083: Epoch time: 48.45 s 
2025-01-27 10:20:59.587229:  
2025-01-27 10:20:59.590524: Epoch 659 
2025-01-27 10:20:59.593576: Current learning rate: 0.0038 
2025-01-27 10:21:48.372298: train_loss -0.8256 
2025-01-27 10:21:48.376798: val_loss -0.7832 
2025-01-27 10:21:48.379495: Pseudo dice [np.float32(0.9633), np.float32(0.9056)] 
2025-01-27 10:21:48.381982: Epoch time: 48.79 s 
2025-01-27 10:21:49.573511:  
2025-01-27 10:21:49.576789: Epoch 660 
2025-01-27 10:21:49.579660: Current learning rate: 0.00379 
2025-01-27 10:22:38.276114: train_loss -0.8352 
2025-01-27 10:22:38.281963: val_loss -0.765 
2025-01-27 10:22:38.284824: Pseudo dice [np.float32(0.9614), np.float32(0.8785)] 
2025-01-27 10:22:38.287285: Epoch time: 48.7 s 
2025-01-27 10:22:39.479574:  
2025-01-27 10:22:39.482675: Epoch 661 
2025-01-27 10:22:39.485737: Current learning rate: 0.00378 
2025-01-27 10:23:27.972677: train_loss -0.8221 
2025-01-27 10:23:27.977322: val_loss -0.7486 
2025-01-27 10:23:27.980382: Pseudo dice [np.float32(0.9559), np.float32(0.8966)] 
2025-01-27 10:23:27.983084: Epoch time: 48.49 s 
2025-01-27 10:23:29.170038:  
2025-01-27 10:23:29.173713: Epoch 662 
2025-01-27 10:23:29.176883: Current learning rate: 0.00377 
2025-01-27 10:24:18.177126: train_loss -0.8177 
2025-01-27 10:24:18.183126: val_loss -0.7815 
2025-01-27 10:24:18.186139: Pseudo dice [np.float32(0.9579), np.float32(0.8944)] 
2025-01-27 10:24:18.188773: Epoch time: 49.01 s 
2025-01-27 10:24:19.378996:  
2025-01-27 10:24:19.381982: Epoch 663 
2025-01-27 10:24:19.384746: Current learning rate: 0.00376 
2025-01-27 10:25:08.121864: train_loss -0.8347 
2025-01-27 10:25:08.128504: val_loss -0.769 
2025-01-27 10:25:08.131695: Pseudo dice [np.float32(0.9607), np.float32(0.8858)] 
2025-01-27 10:25:08.134594: Epoch time: 48.74 s 
2025-01-27 10:25:09.338898:  
2025-01-27 10:25:09.342741: Epoch 664 
2025-01-27 10:25:09.345639: Current learning rate: 0.00375 
2025-01-27 10:25:58.661693: train_loss -0.8302 
2025-01-27 10:25:58.668099: val_loss -0.7495 
2025-01-27 10:25:58.671397: Pseudo dice [np.float32(0.9644), np.float32(0.9027)] 
2025-01-27 10:25:58.674515: Epoch time: 49.33 s 
2025-01-27 10:25:59.880554:  
2025-01-27 10:25:59.883907: Epoch 665 
2025-01-27 10:25:59.886768: Current learning rate: 0.00374 
2025-01-27 10:26:48.848395: train_loss -0.8156 
2025-01-27 10:26:48.852781: val_loss -0.7733 
2025-01-27 10:26:48.855999: Pseudo dice [np.float32(0.9615), np.float32(0.9037)] 
2025-01-27 10:26:48.858896: Epoch time: 48.97 s 
2025-01-27 10:26:50.049552:  
2025-01-27 10:26:50.053214: Epoch 666 
2025-01-27 10:26:50.056102: Current learning rate: 0.00373 
2025-01-27 10:27:39.147812: train_loss -0.8352 
2025-01-27 10:27:39.155162: val_loss -0.727 
2025-01-27 10:27:39.157776: Pseudo dice [np.float32(0.963), np.float32(0.9077)] 
2025-01-27 10:27:39.160422: Epoch time: 49.1 s 
2025-01-27 10:27:40.380948:  
2025-01-27 10:27:40.383710: Epoch 667 
2025-01-27 10:27:40.386577: Current learning rate: 0.00372 
2025-01-27 10:28:29.205368: train_loss -0.8361 
2025-01-27 10:28:29.209863: val_loss -0.7852 
2025-01-27 10:28:29.212711: Pseudo dice [np.float32(0.9613), np.float32(0.909)] 
2025-01-27 10:28:29.215266: Epoch time: 48.83 s 
2025-01-27 10:28:30.425245:  
2025-01-27 10:28:30.428152: Epoch 668 
2025-01-27 10:28:30.430986: Current learning rate: 0.00371 
2025-01-27 10:29:18.691161: train_loss -0.8346 
2025-01-27 10:29:18.697396: val_loss -0.7811 
2025-01-27 10:29:18.700781: Pseudo dice [np.float32(0.9653), np.float32(0.9163)] 
2025-01-27 10:29:18.703569: Epoch time: 48.27 s 
2025-01-27 10:29:19.907909:  
2025-01-27 10:29:19.911283: Epoch 669 
2025-01-27 10:29:19.914444: Current learning rate: 0.0037 
2025-01-27 10:30:09.506845: train_loss -0.8351 
2025-01-27 10:30:09.511158: val_loss -0.7855 
2025-01-27 10:30:09.514071: Pseudo dice [np.float32(0.9636), np.float32(0.8848)] 
2025-01-27 10:30:09.516711: Epoch time: 49.6 s 
2025-01-27 10:30:10.731042:  
2025-01-27 10:30:10.734376: Epoch 670 
2025-01-27 10:30:10.737829: Current learning rate: 0.00369 
2025-01-27 10:30:59.825352: train_loss -0.83 
2025-01-27 10:30:59.831258: val_loss -0.8 
2025-01-27 10:30:59.833795: Pseudo dice [np.float32(0.9583), np.float32(0.9101)] 
2025-01-27 10:30:59.836755: Epoch time: 49.1 s 
2025-01-27 10:31:01.039949:  
2025-01-27 10:31:01.045164: Epoch 671 
2025-01-27 10:31:01.048301: Current learning rate: 0.00368 
2025-01-27 10:31:49.954121: train_loss -0.8446 
2025-01-27 10:31:49.958613: val_loss -0.834 
2025-01-27 10:31:49.961702: Pseudo dice [np.float32(0.9655), np.float32(0.9135)] 
2025-01-27 10:31:49.964190: Epoch time: 48.92 s 
2025-01-27 10:31:49.966866: Yayy! New best EMA pseudo Dice: 0.930400013923645 
2025-01-27 10:31:51.740762:  
2025-01-27 10:31:51.744486: Epoch 672 
2025-01-27 10:31:51.747981: Current learning rate: 0.00367 
2025-01-27 10:32:40.887771: train_loss -0.8431 
2025-01-27 10:32:40.894171: val_loss -0.8016 
2025-01-27 10:32:40.896950: Pseudo dice [np.float32(0.9572), np.float32(0.9125)] 
2025-01-27 10:32:40.899834: Epoch time: 49.15 s 
2025-01-27 10:32:40.902362: Yayy! New best EMA pseudo Dice: 0.9308000206947327 
2025-01-27 10:32:42.715102:  
2025-01-27 10:32:42.718061: Epoch 673 
2025-01-27 10:32:42.721340: Current learning rate: 0.00366 
2025-01-27 10:33:31.024696: train_loss -0.8486 
2025-01-27 10:33:31.030562: val_loss -0.773 
2025-01-27 10:33:31.033294: Pseudo dice [np.float32(0.9584), np.float32(0.8882)] 
2025-01-27 10:33:31.035925: Epoch time: 48.31 s 
2025-01-27 10:33:32.252630:  
2025-01-27 10:33:32.255948: Epoch 674 
2025-01-27 10:33:32.259497: Current learning rate: 0.00365 
2025-01-27 10:34:21.292729: train_loss -0.8387 
2025-01-27 10:34:21.298635: val_loss -0.7696 
2025-01-27 10:34:21.301725: Pseudo dice [np.float32(0.9587), np.float32(0.9001)] 
2025-01-27 10:34:21.304593: Epoch time: 49.04 s 
2025-01-27 10:34:23.122506:  
2025-01-27 10:34:23.125786: Epoch 675 
2025-01-27 10:34:23.128757: Current learning rate: 0.00364 
2025-01-27 10:35:12.050642: train_loss -0.8247 
2025-01-27 10:35:12.055933: val_loss -0.7469 
2025-01-27 10:35:12.059128: Pseudo dice [np.float32(0.9635), np.float32(0.9111)] 
2025-01-27 10:35:12.061960: Epoch time: 48.93 s 
2025-01-27 10:35:13.295371:  
2025-01-27 10:35:13.298836: Epoch 676 
2025-01-27 10:35:13.301964: Current learning rate: 0.00363 
2025-01-27 10:36:02.050818: train_loss -0.842 
2025-01-27 10:36:02.057251: val_loss -0.7956 
2025-01-27 10:36:02.060667: Pseudo dice [np.float32(0.9594), np.float32(0.9082)] 
2025-01-27 10:36:02.063466: Epoch time: 48.76 s 
2025-01-27 10:36:02.066206: Yayy! New best EMA pseudo Dice: 0.9309999942779541 
2025-01-27 10:36:03.926311:  
2025-01-27 10:36:03.930110: Epoch 677 
2025-01-27 10:36:03.933350: Current learning rate: 0.00362 
2025-01-27 10:36:53.176772: train_loss -0.8427 
2025-01-27 10:36:53.181343: val_loss -0.7993 
2025-01-27 10:36:53.184161: Pseudo dice [np.float32(0.9539), np.float32(0.9076)] 
2025-01-27 10:36:53.186893: Epoch time: 49.25 s 
2025-01-27 10:36:54.389341:  
2025-01-27 10:36:54.392270: Epoch 678 
2025-01-27 10:36:54.395250: Current learning rate: 0.00361 
2025-01-27 10:37:43.742204: train_loss -0.8433 
2025-01-27 10:37:43.747998: val_loss -0.7961 
2025-01-27 10:37:43.750748: Pseudo dice [np.float32(0.9641), np.float32(0.9031)] 
2025-01-27 10:37:43.753659: Epoch time: 49.35 s 
2025-01-27 10:37:43.756259: Yayy! New best EMA pseudo Dice: 0.9312999844551086 
2025-01-27 10:37:45.590577:  
2025-01-27 10:37:45.593909: Epoch 679 
2025-01-27 10:37:45.596881: Current learning rate: 0.0036 
2025-01-27 10:38:34.264621: train_loss -0.8455 
2025-01-27 10:38:34.271403: val_loss -0.7965 
2025-01-27 10:38:34.274126: Pseudo dice [np.float32(0.9571), np.float32(0.8942)] 
2025-01-27 10:38:34.276763: Epoch time: 48.67 s 
2025-01-27 10:38:35.486459:  
2025-01-27 10:38:35.489922: Epoch 680 
2025-01-27 10:38:35.493301: Current learning rate: 0.00359 
2025-01-27 10:39:24.533810: train_loss -0.8346 
2025-01-27 10:39:24.540101: val_loss -0.7306 
2025-01-27 10:39:24.543411: Pseudo dice [np.float32(0.9608), np.float32(0.8843)] 
2025-01-27 10:39:24.545991: Epoch time: 49.05 s 
2025-01-27 10:39:25.755671:  
2025-01-27 10:39:25.758558: Epoch 681 
2025-01-27 10:39:25.761493: Current learning rate: 0.00358 
2025-01-27 10:40:14.671022: train_loss -0.8412 
2025-01-27 10:40:14.675546: val_loss -0.8109 
2025-01-27 10:40:14.678453: Pseudo dice [np.float32(0.9569), np.float32(0.9119)] 
2025-01-27 10:40:14.681152: Epoch time: 48.92 s 
2025-01-27 10:40:15.891790:  
2025-01-27 10:40:15.894889: Epoch 682 
2025-01-27 10:40:15.897906: Current learning rate: 0.00357 
2025-01-27 10:41:05.070053: train_loss -0.8309 
2025-01-27 10:41:05.076190: val_loss -0.759 
2025-01-27 10:41:05.079042: Pseudo dice [np.float32(0.9627), np.float32(0.8575)] 
2025-01-27 10:41:05.081582: Epoch time: 49.18 s 
2025-01-27 10:41:06.296136:  
2025-01-27 10:41:06.299505: Epoch 683 
2025-01-27 10:41:06.302624: Current learning rate: 0.00356 
2025-01-27 10:41:55.667318: train_loss -0.8379 
2025-01-27 10:41:55.672232: val_loss -0.7785 
2025-01-27 10:41:55.675529: Pseudo dice [np.float32(0.9652), np.float32(0.7498)] 
2025-01-27 10:41:55.678551: Epoch time: 49.37 s 
2025-01-27 10:41:56.891357:  
2025-01-27 10:41:56.894823: Epoch 684 
2025-01-27 10:41:56.898058: Current learning rate: 0.00355 
2025-01-27 10:42:46.051966: train_loss -0.8306 
2025-01-27 10:42:46.059842: val_loss -0.8063 
2025-01-27 10:42:46.062578: Pseudo dice [np.float32(0.9606), np.float32(0.9189)] 
2025-01-27 10:42:46.065290: Epoch time: 49.16 s 
2025-01-27 10:42:47.274886:  
2025-01-27 10:42:47.278247: Epoch 685 
2025-01-27 10:42:47.281315: Current learning rate: 0.00354 
2025-01-27 10:43:36.052524: train_loss -0.8467 
2025-01-27 10:43:36.057546: val_loss -0.7914 
2025-01-27 10:43:36.060496: Pseudo dice [np.float32(0.9603), np.float32(0.8983)] 
2025-01-27 10:43:36.063554: Epoch time: 48.78 s 
2025-01-27 10:43:37.269059:  
2025-01-27 10:43:37.272198: Epoch 686 
2025-01-27 10:43:37.275426: Current learning rate: 0.00353 
2025-01-27 10:44:26.238035: train_loss -0.8427 
2025-01-27 10:44:26.243788: val_loss -0.7725 
2025-01-27 10:44:26.246868: Pseudo dice [np.float32(0.9655), np.float32(0.9175)] 
2025-01-27 10:44:26.249745: Epoch time: 48.97 s 
2025-01-27 10:44:27.462952:  
2025-01-27 10:44:27.466309: Epoch 687 
2025-01-27 10:44:27.468917: Current learning rate: 0.00352 
2025-01-27 10:45:16.511376: train_loss -0.8336 
2025-01-27 10:45:16.515851: val_loss -0.7773 
2025-01-27 10:45:16.518401: Pseudo dice [np.float32(0.9627), np.float32(0.9222)] 
2025-01-27 10:45:16.521079: Epoch time: 49.05 s 
2025-01-27 10:45:17.727390:  
2025-01-27 10:45:17.730623: Epoch 688 
2025-01-27 10:45:17.733784: Current learning rate: 0.00351 
2025-01-27 10:46:06.700505: train_loss -0.8334 
2025-01-27 10:46:06.706527: val_loss -0.7128 
2025-01-27 10:46:06.709320: Pseudo dice [np.float32(0.9607), np.float32(0.8707)] 
2025-01-27 10:46:06.711893: Epoch time: 48.97 s 
2025-01-27 10:46:07.918466:  
2025-01-27 10:46:07.921578: Epoch 689 
2025-01-27 10:46:07.924378: Current learning rate: 0.0035 
2025-01-27 10:46:56.899342: train_loss -0.8094 
2025-01-27 10:46:56.905231: val_loss -0.7522 
2025-01-27 10:46:56.908018: Pseudo dice [np.float32(0.9586), np.float32(0.8845)] 
2025-01-27 10:46:56.910533: Epoch time: 48.98 s 
2025-01-27 10:46:58.157473:  
2025-01-27 10:46:58.161207: Epoch 690 
2025-01-27 10:46:58.164176: Current learning rate: 0.00349 
2025-01-27 10:47:46.912854: train_loss -0.8245 
2025-01-27 10:47:46.919108: val_loss -0.7913 
2025-01-27 10:47:46.921886: Pseudo dice [np.float32(0.9549), np.float32(0.9048)] 
2025-01-27 10:47:46.924662: Epoch time: 48.76 s 
2025-01-27 10:47:48.145680:  
2025-01-27 10:47:48.148548: Epoch 691 
2025-01-27 10:47:48.151562: Current learning rate: 0.00348 
2025-01-27 10:48:37.422834: train_loss -0.8299 
2025-01-27 10:48:37.427715: val_loss -0.7922 
2025-01-27 10:48:37.430764: Pseudo dice [np.float32(0.9633), np.float32(0.9158)] 
2025-01-27 10:48:37.433632: Epoch time: 49.28 s 
2025-01-27 10:48:38.700598:  
2025-01-27 10:48:38.704504: Epoch 692 
2025-01-27 10:48:38.707841: Current learning rate: 0.00346 
2025-01-27 10:49:28.173081: train_loss -0.8464 
2025-01-27 10:49:28.179674: val_loss -0.7808 
2025-01-27 10:49:28.182369: Pseudo dice [np.float32(0.9593), np.float32(0.8084)] 
2025-01-27 10:49:28.185218: Epoch time: 49.48 s 
2025-01-27 10:49:29.382612:  
2025-01-27 10:49:29.385547: Epoch 693 
2025-01-27 10:49:29.388491: Current learning rate: 0.00345 
2025-01-27 10:50:18.297270: train_loss -0.8389 
2025-01-27 10:50:18.301937: val_loss -0.7683 
2025-01-27 10:50:18.304677: Pseudo dice [np.float32(0.9671), np.float32(0.9184)] 
2025-01-27 10:50:18.307448: Epoch time: 48.92 s 
2025-01-27 10:50:19.517100:  
2025-01-27 10:50:19.520084: Epoch 694 
2025-01-27 10:50:19.523198: Current learning rate: 0.00344 
2025-01-27 10:51:08.408113: train_loss -0.839 
2025-01-27 10:51:08.414550: val_loss -0.8027 
2025-01-27 10:51:08.417622: Pseudo dice [np.float32(0.9612), np.float32(0.9106)] 
2025-01-27 10:51:08.420476: Epoch time: 48.89 s 
2025-01-27 10:51:09.627605:  
2025-01-27 10:51:09.630808: Epoch 695 
2025-01-27 10:51:09.633852: Current learning rate: 0.00343 
2025-01-27 10:51:58.828395: train_loss -0.8045 
2025-01-27 10:51:58.832782: val_loss -0.7192 
2025-01-27 10:51:58.835497: Pseudo dice [np.float32(0.9608), np.float32(0.8741)] 
2025-01-27 10:51:58.838002: Epoch time: 49.2 s 
2025-01-27 10:52:00.085332:  
2025-01-27 10:52:00.088765: Epoch 696 
2025-01-27 10:52:00.091762: Current learning rate: 0.00342 
2025-01-27 10:52:49.510137: train_loss -0.8216 
2025-01-27 10:52:49.516678: val_loss -0.7882 
2025-01-27 10:52:49.519362: Pseudo dice [np.float32(0.9563), np.float32(0.9114)] 
2025-01-27 10:52:49.522175: Epoch time: 49.43 s 
2025-01-27 10:52:50.812596:  
2025-01-27 10:52:50.815949: Epoch 697 
2025-01-27 10:52:50.818912: Current learning rate: 0.00341 
2025-01-27 10:53:40.300121: train_loss -0.8239 
2025-01-27 10:53:40.305094: val_loss -0.8254 
2025-01-27 10:53:40.308261: Pseudo dice [np.float32(0.9587), np.float32(0.9076)] 
2025-01-27 10:53:40.311192: Epoch time: 49.49 s 
2025-01-27 10:53:41.562318:  
2025-01-27 10:53:41.566777: Epoch 698 
2025-01-27 10:53:41.570285: Current learning rate: 0.0034 
2025-01-27 10:54:30.227293: train_loss -0.8248 
2025-01-27 10:54:30.233321: val_loss -0.8016 
2025-01-27 10:54:30.236168: Pseudo dice [np.float32(0.9564), np.float32(0.9074)] 
2025-01-27 10:54:30.239189: Epoch time: 48.67 s 
2025-01-27 10:54:31.527922:  
2025-01-27 10:54:31.531195: Epoch 699 
2025-01-27 10:54:31.533779: Current learning rate: 0.00339 
2025-01-27 10:55:20.114159: train_loss -0.8449 
2025-01-27 10:55:20.119069: val_loss -0.767 
2025-01-27 10:55:20.122127: Pseudo dice [np.float32(0.9651), np.float32(0.8948)] 
2025-01-27 10:55:20.124632: Epoch time: 48.59 s 
2025-01-27 10:55:21.994960:  
2025-01-27 10:55:21.998380: Epoch 700 
2025-01-27 10:55:22.001278: Current learning rate: 0.00338 
2025-01-27 10:56:10.365700: train_loss -0.8279 
2025-01-27 10:56:10.370799: val_loss -0.7983 
2025-01-27 10:56:10.373515: Pseudo dice [np.float32(0.9628), np.float32(0.9187)] 
2025-01-27 10:56:10.375794: Epoch time: 48.37 s 
2025-01-27 10:56:11.671076:  
2025-01-27 10:56:11.674402: Epoch 701 
2025-01-27 10:56:11.677662: Current learning rate: 0.00337 
2025-01-27 10:57:00.378322: train_loss -0.8392 
2025-01-27 10:57:00.384373: val_loss -0.7856 
2025-01-27 10:57:00.387115: Pseudo dice [np.float32(0.9613), np.float32(0.9137)] 
2025-01-27 10:57:00.389655: Epoch time: 48.71 s 
2025-01-27 10:57:01.676636:  
2025-01-27 10:57:01.679928: Epoch 702 
2025-01-27 10:57:01.682839: Current learning rate: 0.00336 
2025-01-27 10:57:51.141712: train_loss -0.8309 
2025-01-27 10:57:51.147875: val_loss -0.7831 
2025-01-27 10:57:51.150888: Pseudo dice [np.float32(0.9618), np.float32(0.9203)] 
2025-01-27 10:57:51.153641: Epoch time: 49.47 s 
2025-01-27 10:57:52.443995:  
2025-01-27 10:57:52.447082: Epoch 703 
2025-01-27 10:57:52.449701: Current learning rate: 0.00335 
2025-01-27 10:58:40.951196: train_loss -0.8334 
2025-01-27 10:58:40.955740: val_loss -0.818 
2025-01-27 10:58:40.958563: Pseudo dice [np.float32(0.9646), np.float32(0.9013)] 
2025-01-27 10:58:40.961367: Epoch time: 48.51 s 
2025-01-27 10:58:42.249201:  
2025-01-27 10:58:42.252371: Epoch 704 
2025-01-27 10:58:42.255352: Current learning rate: 0.00334 
2025-01-27 10:59:31.137728: train_loss -0.832 
2025-01-27 10:59:31.143538: val_loss -0.7875 
2025-01-27 10:59:31.146252: Pseudo dice [np.float32(0.9653), np.float32(0.9206)] 
2025-01-27 10:59:31.148854: Epoch time: 48.89 s 
2025-01-27 10:59:31.151742: Yayy! New best EMA pseudo Dice: 0.9322999715805054 
2025-01-27 10:59:33.035758:  
2025-01-27 10:59:33.038750: Epoch 705 
2025-01-27 10:59:33.041505: Current learning rate: 0.00333 
2025-01-27 11:00:21.821841: train_loss -0.832 
2025-01-27 11:00:21.828693: val_loss -0.8076 
2025-01-27 11:00:21.831526: Pseudo dice [np.float32(0.9607), np.float32(0.915)] 
2025-01-27 11:00:21.834548: Epoch time: 48.79 s 
2025-01-27 11:00:21.837097: Yayy! New best EMA pseudo Dice: 0.9327999949455261 
2025-01-27 11:00:23.725275:  
2025-01-27 11:00:23.728203: Epoch 706 
2025-01-27 11:00:23.731131: Current learning rate: 0.00332 
2025-01-27 11:01:12.397293: train_loss -0.8475 
2025-01-27 11:01:12.402544: val_loss -0.7949 
2025-01-27 11:01:12.405349: Pseudo dice [np.float32(0.9618), np.float32(0.8974)] 
2025-01-27 11:01:12.408021: Epoch time: 48.67 s 
2025-01-27 11:01:13.694538:  
2025-01-27 11:01:13.697316: Epoch 707 
2025-01-27 11:01:13.699939: Current learning rate: 0.00331 
2025-01-27 11:02:02.298107: train_loss -0.8424 
2025-01-27 11:02:02.304422: val_loss -0.8118 
2025-01-27 11:02:02.307350: Pseudo dice [np.float32(0.966), np.float32(0.8842)] 
2025-01-27 11:02:02.309962: Epoch time: 48.6 s 
2025-01-27 11:02:03.580402:  
2025-01-27 11:02:03.583409: Epoch 708 
2025-01-27 11:02:03.586190: Current learning rate: 0.0033 
2025-01-27 11:02:52.345065: train_loss -0.8361 
2025-01-27 11:02:52.350969: val_loss -0.7701 
2025-01-27 11:02:52.353774: Pseudo dice [np.float32(0.9551), np.float32(0.883)] 
2025-01-27 11:02:52.356510: Epoch time: 48.77 s 
2025-01-27 11:02:53.650891:  
2025-01-27 11:02:53.653800: Epoch 709 
2025-01-27 11:02:53.656609: Current learning rate: 0.00329 
2025-01-27 11:03:42.883483: train_loss -0.8359 
2025-01-27 11:03:42.887751: val_loss -0.7786 
2025-01-27 11:03:42.890523: Pseudo dice [np.float32(0.9636), np.float32(0.9082)] 
2025-01-27 11:03:42.893041: Epoch time: 49.23 s 
2025-01-27 11:03:44.843175:  
2025-01-27 11:03:44.846397: Epoch 710 
2025-01-27 11:03:44.849414: Current learning rate: 0.00328 
2025-01-27 11:04:33.252305: train_loss -0.8299 
2025-01-27 11:04:33.258931: val_loss -0.8096 
2025-01-27 11:04:33.261475: Pseudo dice [np.float32(0.9597), np.float32(0.9148)] 
2025-01-27 11:04:33.263755: Epoch time: 48.41 s 
2025-01-27 11:04:34.543278:  
2025-01-27 11:04:34.546230: Epoch 711 
2025-01-27 11:04:34.549241: Current learning rate: 0.00327 
2025-01-27 11:05:23.446644: train_loss -0.8426 
2025-01-27 11:05:23.450944: val_loss -0.7992 
2025-01-27 11:05:23.453981: Pseudo dice [np.float32(0.9592), np.float32(0.9048)] 
2025-01-27 11:05:23.456672: Epoch time: 48.9 s 
2025-01-27 11:05:24.740188:  
2025-01-27 11:05:24.743341: Epoch 712 
2025-01-27 11:05:24.746404: Current learning rate: 0.00326 
2025-01-27 11:06:13.673210: train_loss -0.8264 
2025-01-27 11:06:13.680024: val_loss -0.7961 
2025-01-27 11:06:13.682408: Pseudo dice [np.float32(0.9575), np.float32(0.8957)] 
2025-01-27 11:06:13.684779: Epoch time: 48.93 s 
2025-01-27 11:06:14.965089:  
2025-01-27 11:06:14.968017: Epoch 713 
2025-01-27 11:06:14.970416: Current learning rate: 0.00325 
2025-01-27 11:07:04.087051: train_loss -0.8363 
2025-01-27 11:07:04.091505: val_loss -0.7955 
2025-01-27 11:07:04.094192: Pseudo dice [np.float32(0.9619), np.float32(0.9027)] 
2025-01-27 11:07:04.097122: Epoch time: 49.12 s 
2025-01-27 11:07:05.379315:  
2025-01-27 11:07:05.382988: Epoch 714 
2025-01-27 11:07:05.385960: Current learning rate: 0.00324 
2025-01-27 11:07:54.107262: train_loss -0.8248 
2025-01-27 11:07:54.112546: val_loss -0.8092 
2025-01-27 11:07:54.115442: Pseudo dice [np.float32(0.9569), np.float32(0.9072)] 
2025-01-27 11:07:54.118208: Epoch time: 48.73 s 
2025-01-27 11:07:55.401571:  
2025-01-27 11:07:55.404268: Epoch 715 
2025-01-27 11:07:55.406928: Current learning rate: 0.00323 
2025-01-27 11:08:44.352305: train_loss -0.8473 
2025-01-27 11:08:44.356844: val_loss -0.7896 
2025-01-27 11:08:44.359739: Pseudo dice [np.float32(0.9593), np.float32(0.9087)] 
2025-01-27 11:08:44.362712: Epoch time: 48.95 s 
2025-01-27 11:08:45.598452:  
2025-01-27 11:08:45.602150: Epoch 716 
2025-01-27 11:08:45.605185: Current learning rate: 0.00322 
2025-01-27 11:09:34.539992: train_loss -0.8396 
2025-01-27 11:09:34.546155: val_loss -0.7788 
2025-01-27 11:09:34.548964: Pseudo dice [np.float32(0.9644), np.float32(0.9095)] 
2025-01-27 11:09:34.551432: Epoch time: 48.94 s 
2025-01-27 11:09:35.776689:  
2025-01-27 11:09:35.779983: Epoch 717 
2025-01-27 11:09:35.783025: Current learning rate: 0.00321 
2025-01-27 11:10:24.606793: train_loss -0.8265 
2025-01-27 11:10:24.611128: val_loss -0.7817 
2025-01-27 11:10:24.614231: Pseudo dice [np.float32(0.9564), np.float32(0.8988)] 
2025-01-27 11:10:24.617029: Epoch time: 48.83 s 
2025-01-27 11:10:25.849413:  
2025-01-27 11:10:25.852495: Epoch 718 
2025-01-27 11:10:25.855424: Current learning rate: 0.0032 
2025-01-27 11:11:14.437431: train_loss -0.8334 
2025-01-27 11:11:14.443179: val_loss -0.7805 
2025-01-27 11:11:14.445616: Pseudo dice [np.float32(0.9602), np.float32(0.8985)] 
2025-01-27 11:11:14.448479: Epoch time: 48.59 s 
2025-01-27 11:11:15.676486:  
2025-01-27 11:11:15.680026: Epoch 719 
2025-01-27 11:11:15.683264: Current learning rate: 0.00319 
2025-01-27 11:12:04.870866: train_loss -0.8376 
2025-01-27 11:12:04.875535: val_loss -0.7633 
2025-01-27 11:12:04.878670: Pseudo dice [np.float32(0.9546), np.float32(0.9034)] 
2025-01-27 11:12:04.881727: Epoch time: 49.2 s 
2025-01-27 11:12:06.104779:  
2025-01-27 11:12:06.107944: Epoch 720 
2025-01-27 11:12:06.110847: Current learning rate: 0.00318 
2025-01-27 11:12:55.068619: train_loss -0.821 
2025-01-27 11:12:55.074550: val_loss -0.7746 
2025-01-27 11:12:55.077637: Pseudo dice [np.float32(0.9596), np.float32(0.8981)] 
2025-01-27 11:12:55.080540: Epoch time: 48.97 s 
2025-01-27 11:12:56.302241:  
2025-01-27 11:12:56.305606: Epoch 721 
2025-01-27 11:12:56.308887: Current learning rate: 0.00317 
2025-01-27 11:13:45.449849: train_loss -0.8477 
2025-01-27 11:13:45.455728: val_loss -0.799 
2025-01-27 11:13:45.458588: Pseudo dice [np.float32(0.9614), np.float32(0.9166)] 
2025-01-27 11:13:45.461163: Epoch time: 49.15 s 
2025-01-27 11:13:46.706516:  
2025-01-27 11:13:46.709572: Epoch 722 
2025-01-27 11:13:46.712609: Current learning rate: 0.00316 
2025-01-27 11:14:35.483078: train_loss -0.845 
2025-01-27 11:14:35.488882: val_loss -0.7773 
2025-01-27 11:14:35.491751: Pseudo dice [np.float32(0.9602), np.float32(0.9106)] 
2025-01-27 11:14:35.494371: Epoch time: 48.78 s 
2025-01-27 11:14:36.749562:  
2025-01-27 11:14:36.753085: Epoch 723 
2025-01-27 11:14:36.756338: Current learning rate: 0.00315 
2025-01-27 11:15:25.687363: train_loss -0.8291 
2025-01-27 11:15:25.692472: val_loss -0.8142 
2025-01-27 11:15:25.694989: Pseudo dice [np.float32(0.967), np.float32(0.9109)] 
2025-01-27 11:15:25.697495: Epoch time: 48.94 s 
2025-01-27 11:15:26.929586:  
2025-01-27 11:15:26.933037: Epoch 724 
2025-01-27 11:15:26.936201: Current learning rate: 0.00314 
2025-01-27 11:16:16.368400: train_loss -0.8441 
2025-01-27 11:16:16.374275: val_loss -0.7935 
2025-01-27 11:16:16.376927: Pseudo dice [np.float32(0.9586), np.float32(0.8835)] 
2025-01-27 11:16:16.379763: Epoch time: 49.44 s 
2025-01-27 11:16:17.605298:  
2025-01-27 11:16:17.608264: Epoch 725 
2025-01-27 11:16:17.611244: Current learning rate: 0.00313 
2025-01-27 11:17:06.130981: train_loss -0.8458 
2025-01-27 11:17:06.135470: val_loss -0.785 
2025-01-27 11:17:06.138222: Pseudo dice [np.float32(0.957), np.float32(0.9043)] 
2025-01-27 11:17:06.140802: Epoch time: 48.53 s 
2025-01-27 11:17:07.355266:  
2025-01-27 11:17:07.358202: Epoch 726 
2025-01-27 11:17:07.360966: Current learning rate: 0.00312 
2025-01-27 11:17:56.452301: train_loss -0.8482 
2025-01-27 11:17:56.459577: val_loss -0.7714 
2025-01-27 11:17:56.462550: Pseudo dice [np.float32(0.9609), np.float32(0.8986)] 
2025-01-27 11:17:56.465065: Epoch time: 49.1 s 
2025-01-27 11:17:57.736526:  
2025-01-27 11:17:57.740781: Epoch 727 
2025-01-27 11:17:57.743974: Current learning rate: 0.00311 
2025-01-27 11:18:46.590980: train_loss -0.82 
2025-01-27 11:18:46.595671: val_loss -0.7825 
2025-01-27 11:18:46.598380: Pseudo dice [np.float32(0.96), np.float32(0.9149)] 
2025-01-27 11:18:46.600886: Epoch time: 48.86 s 
2025-01-27 11:18:48.391086:  
2025-01-27 11:18:48.393857: Epoch 728 
2025-01-27 11:18:48.396614: Current learning rate: 0.0031 
2025-01-27 11:19:37.501494: train_loss -0.8459 
2025-01-27 11:19:37.507421: val_loss -0.8111 
2025-01-27 11:19:37.510487: Pseudo dice [np.float32(0.9653), np.float32(0.9145)] 
2025-01-27 11:19:37.513519: Epoch time: 49.11 s 
2025-01-27 11:19:38.770151:  
2025-01-27 11:19:38.773166: Epoch 729 
2025-01-27 11:19:38.776035: Current learning rate: 0.00309 
2025-01-27 11:20:27.285287: train_loss -0.8493 
2025-01-27 11:20:27.290319: val_loss -0.7754 
2025-01-27 11:20:27.293335: Pseudo dice [np.float32(0.9577), np.float32(0.8623)] 
2025-01-27 11:20:27.296357: Epoch time: 48.52 s 
2025-01-27 11:20:28.543545:  
2025-01-27 11:20:28.546787: Epoch 730 
2025-01-27 11:20:28.549726: Current learning rate: 0.00308 
2025-01-27 11:21:17.600207: train_loss -0.8477 
2025-01-27 11:21:17.605706: val_loss -0.7895 
2025-01-27 11:21:17.608433: Pseudo dice [np.float32(0.9578), np.float32(0.902)] 
2025-01-27 11:21:17.611014: Epoch time: 49.06 s 
2025-01-27 11:21:18.865716:  
2025-01-27 11:21:18.868524: Epoch 731 
2025-01-27 11:21:18.871251: Current learning rate: 0.00307 
2025-01-27 11:22:07.833631: train_loss -0.8339 
2025-01-27 11:22:07.838087: val_loss -0.7494 
2025-01-27 11:22:07.840937: Pseudo dice [np.float32(0.9588), np.float32(0.8989)] 
2025-01-27 11:22:07.843637: Epoch time: 48.97 s 
2025-01-27 11:22:09.062931:  
2025-01-27 11:22:09.065897: Epoch 732 
2025-01-27 11:22:09.068753: Current learning rate: 0.00306 
2025-01-27 11:22:58.375247: train_loss -0.8298 
2025-01-27 11:22:58.381622: val_loss -0.7981 
2025-01-27 11:22:58.384414: Pseudo dice [np.float32(0.9665), np.float32(0.9204)] 
2025-01-27 11:22:58.387411: Epoch time: 49.31 s 
2025-01-27 11:22:59.644599:  
2025-01-27 11:22:59.647729: Epoch 733 
2025-01-27 11:22:59.650553: Current learning rate: 0.00305 
2025-01-27 11:23:48.769929: train_loss -0.8451 
2025-01-27 11:23:48.775234: val_loss -0.7969 
2025-01-27 11:23:48.778602: Pseudo dice [np.float32(0.9622), np.float32(0.7881)] 
2025-01-27 11:23:48.781550: Epoch time: 49.13 s 
2025-01-27 11:23:49.999167:  
2025-01-27 11:23:50.002137: Epoch 734 
2025-01-27 11:23:50.004976: Current learning rate: 0.00304 
2025-01-27 11:24:39.203867: train_loss -0.828 
2025-01-27 11:24:39.211742: val_loss -0.808 
2025-01-27 11:24:39.214877: Pseudo dice [np.float32(0.9656), np.float32(0.9162)] 
2025-01-27 11:24:39.217771: Epoch time: 49.21 s 
2025-01-27 11:24:40.431965:  
2025-01-27 11:24:40.434968: Epoch 735 
2025-01-27 11:24:40.437502: Current learning rate: 0.00303 
2025-01-27 11:25:29.238078: train_loss -0.8243 
2025-01-27 11:25:29.242841: val_loss -0.8019 
2025-01-27 11:25:29.245400: Pseudo dice [np.float32(0.9561), np.float32(0.8856)] 
2025-01-27 11:25:29.248267: Epoch time: 48.81 s 
2025-01-27 11:25:30.470720:  
2025-01-27 11:25:30.473883: Epoch 736 
2025-01-27 11:25:30.476295: Current learning rate: 0.00302 
2025-01-27 11:26:19.711119: train_loss -0.8119 
2025-01-27 11:26:19.719647: val_loss -0.7997 
2025-01-27 11:26:19.722736: Pseudo dice [np.float32(0.9613), np.float32(0.9197)] 
2025-01-27 11:26:19.725571: Epoch time: 49.24 s 
2025-01-27 11:26:20.941504:  
2025-01-27 11:26:20.944602: Epoch 737 
2025-01-27 11:26:20.947624: Current learning rate: 0.00301 
2025-01-27 11:27:09.607243: train_loss -0.8305 
2025-01-27 11:27:09.611345: val_loss -0.7634 
2025-01-27 11:27:09.614234: Pseudo dice [np.float32(0.9599), np.float32(0.8841)] 
2025-01-27 11:27:09.617064: Epoch time: 48.67 s 
2025-01-27 11:27:10.832591:  
2025-01-27 11:27:10.836896: Epoch 738 
2025-01-27 11:27:10.840071: Current learning rate: 0.003 
2025-01-27 11:27:59.535199: train_loss -0.8298 
2025-01-27 11:27:59.541132: val_loss -0.7925 
2025-01-27 11:27:59.543870: Pseudo dice [np.float32(0.9653), np.float32(0.8661)] 
2025-01-27 11:27:59.546274: Epoch time: 48.7 s 
2025-01-27 11:28:00.758470:  
2025-01-27 11:28:00.762898: Epoch 739 
2025-01-27 11:28:00.765932: Current learning rate: 0.00299 
2025-01-27 11:28:49.046683: train_loss -0.8293 
2025-01-27 11:28:49.050801: val_loss -0.7793 
2025-01-27 11:28:49.053703: Pseudo dice [np.float32(0.9531), np.float32(0.8857)] 
2025-01-27 11:28:49.056170: Epoch time: 48.29 s 
2025-01-27 11:28:50.277978:  
2025-01-27 11:28:50.281116: Epoch 740 
2025-01-27 11:28:50.284364: Current learning rate: 0.00297 
2025-01-27 11:29:39.040297: train_loss -0.8328 
2025-01-27 11:29:39.046942: val_loss -0.7711 
2025-01-27 11:29:39.050424: Pseudo dice [np.float32(0.9627), np.float32(0.8966)] 
2025-01-27 11:29:39.053571: Epoch time: 48.76 s 
2025-01-27 11:29:40.310210:  
2025-01-27 11:29:40.313814: Epoch 741 
2025-01-27 11:29:40.317381: Current learning rate: 0.00296 
2025-01-27 11:30:28.767669: train_loss -0.8363 
2025-01-27 11:30:28.773871: val_loss -0.7921 
2025-01-27 11:30:28.776786: Pseudo dice [np.float32(0.9581), np.float32(0.8907)] 
2025-01-27 11:30:28.779762: Epoch time: 48.46 s 
2025-01-27 11:30:30.037193:  
2025-01-27 11:30:30.040314: Epoch 742 
2025-01-27 11:30:30.043425: Current learning rate: 0.00295 
2025-01-27 11:31:18.417846: train_loss -0.8307 
2025-01-27 11:31:18.423307: val_loss -0.7877 
2025-01-27 11:31:18.425912: Pseudo dice [np.float32(0.9619), np.float32(0.8945)] 
2025-01-27 11:31:18.428807: Epoch time: 48.38 s 
2025-01-27 11:31:19.653422:  
2025-01-27 11:31:19.657005: Epoch 743 
2025-01-27 11:31:19.660102: Current learning rate: 0.00294 
2025-01-27 11:32:08.181757: train_loss -0.8472 
2025-01-27 11:32:08.186658: val_loss -0.7617 
2025-01-27 11:32:08.190086: Pseudo dice [np.float32(0.9561), np.float32(0.8981)] 
2025-01-27 11:32:08.193042: Epoch time: 48.53 s 
2025-01-27 11:32:09.418740:  
2025-01-27 11:32:09.422296: Epoch 744 
2025-01-27 11:32:09.425402: Current learning rate: 0.00293 
2025-01-27 11:32:58.219589: train_loss -0.8388 
2025-01-27 11:32:58.225570: val_loss -0.7621 
2025-01-27 11:32:58.228147: Pseudo dice [np.float32(0.9606), np.float32(0.9059)] 
2025-01-27 11:32:58.230999: Epoch time: 48.8 s 
2025-01-27 11:32:59.478523:  
2025-01-27 11:32:59.481886: Epoch 745 
2025-01-27 11:32:59.484955: Current learning rate: 0.00292 
2025-01-27 11:33:48.214109: train_loss -0.8467 
2025-01-27 11:33:48.218441: val_loss -0.8241 
2025-01-27 11:33:48.220894: Pseudo dice [np.float32(0.9616), np.float32(0.9142)] 
2025-01-27 11:33:48.223511: Epoch time: 48.74 s 
2025-01-27 11:33:49.997653:  
2025-01-27 11:33:50.000715: Epoch 746 
2025-01-27 11:33:50.003509: Current learning rate: 0.00291 
2025-01-27 11:34:38.837599: train_loss -0.8444 
2025-01-27 11:34:38.843910: val_loss -0.7831 
2025-01-27 11:34:38.846880: Pseudo dice [np.float32(0.9591), np.float32(0.914)] 
2025-01-27 11:34:38.849615: Epoch time: 48.84 s 
2025-01-27 11:34:40.051131:  
2025-01-27 11:34:40.054185: Epoch 747 
2025-01-27 11:34:40.056858: Current learning rate: 0.0029 
2025-01-27 11:35:28.713722: train_loss -0.8335 
2025-01-27 11:35:28.718356: val_loss -0.8301 
2025-01-27 11:35:28.721399: Pseudo dice [np.float32(0.9598), np.float32(0.9208)] 
2025-01-27 11:35:28.724105: Epoch time: 48.66 s 
2025-01-27 11:35:29.946965:  
2025-01-27 11:35:29.950086: Epoch 748 
2025-01-27 11:35:29.952960: Current learning rate: 0.00289 
2025-01-27 11:36:18.560129: train_loss -0.8419 
2025-01-27 11:36:18.566108: val_loss -0.7641 
2025-01-27 11:36:18.569010: Pseudo dice [np.float32(0.9571), np.float32(0.9087)] 
2025-01-27 11:36:18.572136: Epoch time: 48.61 s 
2025-01-27 11:36:19.817379:  
2025-01-27 11:36:19.820343: Epoch 749 
2025-01-27 11:36:19.823103: Current learning rate: 0.00288 
2025-01-27 11:37:08.723136: train_loss -0.8274 
2025-01-27 11:37:08.727366: val_loss -0.8123 
2025-01-27 11:37:08.730710: Pseudo dice [np.float32(0.9599), np.float32(0.9185)] 
2025-01-27 11:37:08.733594: Epoch time: 48.91 s 
2025-01-27 11:37:10.576141:  
2025-01-27 11:37:10.579665: Epoch 750 
2025-01-27 11:37:10.582703: Current learning rate: 0.00287 
2025-01-27 11:37:59.478204: train_loss -0.844 
2025-01-27 11:37:59.484266: val_loss -0.7679 
2025-01-27 11:37:59.487183: Pseudo dice [np.float32(0.9565), np.float32(0.8913)] 
2025-01-27 11:37:59.489909: Epoch time: 48.9 s 
2025-01-27 11:38:00.733589:  
2025-01-27 11:38:00.737446: Epoch 751 
2025-01-27 11:38:00.740450: Current learning rate: 0.00286 
2025-01-27 11:38:49.172602: train_loss -0.8456 
2025-01-27 11:38:49.177294: val_loss -0.779 
2025-01-27 11:38:49.180428: Pseudo dice [np.float32(0.9604), np.float32(0.9126)] 
2025-01-27 11:38:49.183336: Epoch time: 48.44 s 
2025-01-27 11:38:50.439651:  
2025-01-27 11:38:50.442506: Epoch 752 
2025-01-27 11:38:50.445478: Current learning rate: 0.00285 
2025-01-27 11:39:38.920151: train_loss -0.8416 
2025-01-27 11:39:38.926701: val_loss -0.8041 
2025-01-27 11:39:38.929583: Pseudo dice [np.float32(0.9638), np.float32(0.8937)] 
2025-01-27 11:39:38.932353: Epoch time: 48.48 s 
2025-01-27 11:39:40.148570:  
2025-01-27 11:39:40.151556: Epoch 753 
2025-01-27 11:39:40.154440: Current learning rate: 0.00284 
2025-01-27 11:40:28.647187: train_loss -0.8412 
2025-01-27 11:40:28.651577: val_loss -0.8105 
2025-01-27 11:40:28.654161: Pseudo dice [np.float32(0.9608), np.float32(0.8974)] 
2025-01-27 11:40:28.656984: Epoch time: 48.5 s 
2025-01-27 11:40:29.920627:  
2025-01-27 11:40:29.923586: Epoch 754 
2025-01-27 11:40:29.926582: Current learning rate: 0.00283 
2025-01-27 11:41:18.580385: train_loss -0.8349 
2025-01-27 11:41:18.586384: val_loss -0.8121 
2025-01-27 11:41:18.589616: Pseudo dice [np.float32(0.9634), np.float32(0.9154)] 
2025-01-27 11:41:18.592694: Epoch time: 48.66 s 
2025-01-27 11:41:19.802820:  
2025-01-27 11:41:19.805989: Epoch 755 
2025-01-27 11:41:19.808837: Current learning rate: 0.00282 
2025-01-27 11:42:08.304245: train_loss -0.8388 
2025-01-27 11:42:08.312247: val_loss -0.7734 
2025-01-27 11:42:08.314865: Pseudo dice [np.float32(0.9594), np.float32(0.9141)] 
2025-01-27 11:42:08.317475: Epoch time: 48.5 s 
2025-01-27 11:42:09.561115:  
2025-01-27 11:42:09.564578: Epoch 756 
2025-01-27 11:42:09.567459: Current learning rate: 0.00281 
2025-01-27 11:42:57.964973: train_loss -0.8402 
2025-01-27 11:42:57.971970: val_loss -0.7857 
2025-01-27 11:42:57.974880: Pseudo dice [np.float32(0.9619), np.float32(0.8891)] 
2025-01-27 11:42:57.977838: Epoch time: 48.4 s 
2025-01-27 11:42:59.199123:  
2025-01-27 11:42:59.202466: Epoch 757 
2025-01-27 11:42:59.205824: Current learning rate: 0.0028 
2025-01-27 11:43:47.911774: train_loss -0.8397 
2025-01-27 11:43:47.916800: val_loss -0.7985 
2025-01-27 11:43:47.919723: Pseudo dice [np.float32(0.9603), np.float32(0.913)] 
2025-01-27 11:43:47.922176: Epoch time: 48.71 s 
2025-01-27 11:43:49.134671:  
2025-01-27 11:43:49.137517: Epoch 758 
2025-01-27 11:43:49.140295: Current learning rate: 0.00279 
2025-01-27 11:44:37.975171: train_loss -0.8419 
2025-01-27 11:44:37.980741: val_loss -0.7932 
2025-01-27 11:44:37.983500: Pseudo dice [np.float32(0.9643), np.float32(0.8982)] 
2025-01-27 11:44:37.986116: Epoch time: 48.84 s 
2025-01-27 11:44:39.194870:  
2025-01-27 11:44:39.197957: Epoch 759 
2025-01-27 11:44:39.201205: Current learning rate: 0.00278 
2025-01-27 11:45:27.649832: train_loss -0.8471 
2025-01-27 11:45:27.654384: val_loss -0.8406 
2025-01-27 11:45:27.657506: Pseudo dice [np.float32(0.9615), np.float32(0.9025)] 
2025-01-27 11:45:27.660660: Epoch time: 48.46 s 
2025-01-27 11:45:28.873944:  
2025-01-27 11:45:28.876777: Epoch 760 
2025-01-27 11:45:28.879881: Current learning rate: 0.00277 
2025-01-27 11:46:17.461121: train_loss -0.8488 
2025-01-27 11:46:17.467149: val_loss -0.7623 
2025-01-27 11:46:17.470070: Pseudo dice [np.float32(0.9627), np.float32(0.9138)] 
2025-01-27 11:46:17.472728: Epoch time: 48.59 s 
2025-01-27 11:46:18.724370:  
2025-01-27 11:46:18.727484: Epoch 761 
2025-01-27 11:46:18.730609: Current learning rate: 0.00276 
2025-01-27 11:47:07.703012: train_loss -0.8582 
2025-01-27 11:47:07.707201: val_loss -0.8054 
2025-01-27 11:47:07.710277: Pseudo dice [np.float32(0.9673), np.float32(0.919)] 
2025-01-27 11:47:07.713514: Epoch time: 48.98 s 
2025-01-27 11:47:07.716591: Yayy! New best EMA pseudo Dice: 0.9336000084877014 
2025-01-27 11:47:09.644967:  
2025-01-27 11:47:09.647930: Epoch 762 
2025-01-27 11:47:09.651050: Current learning rate: 0.00275 
2025-01-27 11:47:58.003596: train_loss -0.8486 
2025-01-27 11:47:58.009319: val_loss -0.7656 
2025-01-27 11:47:58.012165: Pseudo dice [np.float32(0.9567), np.float32(0.8813)] 
2025-01-27 11:47:58.015015: Epoch time: 48.36 s 
2025-01-27 11:47:59.274395:  
2025-01-27 11:47:59.277946: Epoch 763 
2025-01-27 11:47:59.280753: Current learning rate: 0.00274 
2025-01-27 11:48:47.878097: train_loss -0.8458 
2025-01-27 11:48:47.882882: val_loss -0.7847 
2025-01-27 11:48:47.885873: Pseudo dice [np.float32(0.9693), np.float32(0.9118)] 
2025-01-27 11:48:47.888535: Epoch time: 48.6 s 
2025-01-27 11:48:49.169041:  
2025-01-27 11:48:49.172345: Epoch 764 
2025-01-27 11:48:49.175047: Current learning rate: 0.00273 
2025-01-27 11:49:38.611919: train_loss -0.8482 
2025-01-27 11:49:38.617946: val_loss -0.7866 
2025-01-27 11:49:38.620877: Pseudo dice [np.float32(0.9613), np.float32(0.9025)] 
2025-01-27 11:49:38.623598: Epoch time: 49.44 s 
2025-01-27 11:49:39.905622:  
2025-01-27 11:49:39.909182: Epoch 765 
2025-01-27 11:49:39.912350: Current learning rate: 0.00272 
2025-01-27 11:50:28.867051: train_loss -0.8254 
2025-01-27 11:50:28.872844: val_loss -0.7743 
2025-01-27 11:50:28.875856: Pseudo dice [np.float32(0.9631), np.float32(0.9076)] 
2025-01-27 11:50:28.878678: Epoch time: 48.96 s 
2025-01-27 11:50:30.140570:  
2025-01-27 11:50:30.143574: Epoch 766 
2025-01-27 11:50:30.146667: Current learning rate: 0.00271 
2025-01-27 11:51:18.834009: train_loss -0.8647 
2025-01-27 11:51:18.839995: val_loss -0.8148 
2025-01-27 11:51:18.842894: Pseudo dice [np.float32(0.9631), np.float32(0.9152)] 
2025-01-27 11:51:18.845636: Epoch time: 48.7 s 
2025-01-27 11:51:18.848391: Yayy! New best EMA pseudo Dice: 0.9337000250816345 
2025-01-27 11:51:20.685538:  
2025-01-27 11:51:20.689957: Epoch 767 
2025-01-27 11:51:20.693106: Current learning rate: 0.0027 
2025-01-27 11:52:09.157386: train_loss -0.8377 
2025-01-27 11:52:09.162139: val_loss -0.8205 
2025-01-27 11:52:09.165195: Pseudo dice [np.float32(0.9595), np.float32(0.9174)] 
2025-01-27 11:52:09.167842: Epoch time: 48.47 s 
2025-01-27 11:52:09.170443: Yayy! New best EMA pseudo Dice: 0.9341999888420105 
2025-01-27 11:52:11.113927:  
2025-01-27 11:52:11.117317: Epoch 768 
2025-01-27 11:52:11.120173: Current learning rate: 0.00268 
2025-01-27 11:52:59.725491: train_loss -0.8355 
2025-01-27 11:52:59.731468: val_loss -0.8278 
2025-01-27 11:52:59.734556: Pseudo dice [np.float32(0.9628), np.float32(0.9133)] 
2025-01-27 11:52:59.737061: Epoch time: 48.61 s 
2025-01-27 11:52:59.739743: Yayy! New best EMA pseudo Dice: 0.9345999956130981 
2025-01-27 11:53:01.573118:  
2025-01-27 11:53:01.576164: Epoch 769 
2025-01-27 11:53:01.579154: Current learning rate: 0.00267 
2025-01-27 11:53:49.722342: train_loss -0.8561 
2025-01-27 11:53:49.728433: val_loss -0.7842 
2025-01-27 11:53:49.731153: Pseudo dice [np.float32(0.9657), np.float32(0.8893)] 
2025-01-27 11:53:49.733887: Epoch time: 48.15 s 
2025-01-27 11:53:51.009406:  
2025-01-27 11:53:51.012602: Epoch 770 
2025-01-27 11:53:51.015559: Current learning rate: 0.00266 
2025-01-27 11:54:39.646268: train_loss -0.8483 
2025-01-27 11:54:39.652946: val_loss -0.7879 
2025-01-27 11:54:39.655918: Pseudo dice [np.float32(0.9626), np.float32(0.9174)] 
2025-01-27 11:54:39.658787: Epoch time: 48.64 s 
2025-01-27 11:54:40.898248:  
2025-01-27 11:54:40.901418: Epoch 771 
2025-01-27 11:54:40.904490: Current learning rate: 0.00265 
2025-01-27 11:55:29.426408: train_loss -0.8469 
2025-01-27 11:55:29.430973: val_loss -0.7912 
2025-01-27 11:55:29.434217: Pseudo dice [np.float32(0.9546), np.float32(0.892)] 
2025-01-27 11:55:29.437346: Epoch time: 48.53 s 
2025-01-27 11:55:30.671429:  
2025-01-27 11:55:30.674385: Epoch 772 
2025-01-27 11:55:30.677382: Current learning rate: 0.00264 
2025-01-27 11:56:19.172818: train_loss -0.8219 
2025-01-27 11:56:19.179120: val_loss -0.7767 
2025-01-27 11:56:19.182260: Pseudo dice [np.float32(0.9484), np.float32(0.8602)] 
2025-01-27 11:56:19.185137: Epoch time: 48.5 s 
2025-01-27 11:56:20.455878:  
2025-01-27 11:56:20.459327: Epoch 773 
2025-01-27 11:56:20.462672: Current learning rate: 0.00263 
2025-01-27 11:57:09.005861: train_loss -0.8051 
2025-01-27 11:57:09.010990: val_loss -0.7883 
2025-01-27 11:57:09.013782: Pseudo dice [np.float32(0.9474), np.float32(0.8841)] 
2025-01-27 11:57:09.016410: Epoch time: 48.55 s 
2025-01-27 11:57:10.243420:  
2025-01-27 11:57:10.246820: Epoch 774 
2025-01-27 11:57:10.249889: Current learning rate: 0.00262 
2025-01-27 11:57:59.408710: train_loss -0.8335 
2025-01-27 11:57:59.415491: val_loss -0.7866 
2025-01-27 11:57:59.418194: Pseudo dice [np.float32(0.9627), np.float32(0.9067)] 
2025-01-27 11:57:59.420891: Epoch time: 49.17 s 
2025-01-27 11:58:00.658176:  
2025-01-27 11:58:00.661320: Epoch 775 
2025-01-27 11:58:00.664138: Current learning rate: 0.00261 
2025-01-27 11:58:49.506252: train_loss -0.8284 
2025-01-27 11:58:49.510675: val_loss -0.78 
2025-01-27 11:58:49.514019: Pseudo dice [np.float32(0.9574), np.float32(0.8947)] 
2025-01-27 11:58:49.516851: Epoch time: 48.85 s 
2025-01-27 11:58:50.746528:  
2025-01-27 11:58:50.749694: Epoch 776 
2025-01-27 11:58:50.752464: Current learning rate: 0.0026 
2025-01-27 11:59:39.564082: train_loss -0.8469 
2025-01-27 11:59:39.570390: val_loss -0.7489 
2025-01-27 11:59:39.573693: Pseudo dice [np.float32(0.9627), np.float32(0.8956)] 
2025-01-27 11:59:39.576607: Epoch time: 48.82 s 
2025-01-27 11:59:40.811366:  
2025-01-27 11:59:40.814356: Epoch 777 
2025-01-27 11:59:40.817190: Current learning rate: 0.00259 
2025-01-27 12:00:29.224476: train_loss -0.8332 
2025-01-27 12:00:29.229335: val_loss -0.755 
2025-01-27 12:00:29.232162: Pseudo dice [np.float32(0.9645), np.float32(0.8908)] 
2025-01-27 12:00:29.234785: Epoch time: 48.41 s 
2025-01-27 12:00:30.472229:  
2025-01-27 12:00:30.475563: Epoch 778 
2025-01-27 12:00:30.478834: Current learning rate: 0.00258 
2025-01-27 12:01:18.914335: train_loss -0.8425 
2025-01-27 12:01:18.920231: val_loss -0.8012 
2025-01-27 12:01:18.923236: Pseudo dice [np.float32(0.9588), np.float32(0.8686)] 
2025-01-27 12:01:18.926169: Epoch time: 48.44 s 
2025-01-27 12:01:20.193246:  
2025-01-27 12:01:20.196638: Epoch 779 
2025-01-27 12:01:20.199594: Current learning rate: 0.00257 
2025-01-27 12:02:08.811848: train_loss -0.828 
2025-01-27 12:02:08.818590: val_loss -0.7816 
2025-01-27 12:02:08.837949: Pseudo dice [np.float32(0.9529), np.float32(0.8723)] 
2025-01-27 12:02:08.840883: Epoch time: 48.62 s 
2025-01-27 12:02:10.073670:  
2025-01-27 12:02:10.076580: Epoch 780 
2025-01-27 12:02:10.079408: Current learning rate: 0.00256 
2025-01-27 12:02:58.697470: train_loss -0.8528 
2025-01-27 12:02:58.702563: val_loss -0.8236 
2025-01-27 12:02:58.705615: Pseudo dice [np.float32(0.9594), np.float32(0.9031)] 
2025-01-27 12:02:58.708016: Epoch time: 48.62 s 
2025-01-27 12:02:59.993897:  
2025-01-27 12:02:59.996550: Epoch 781 
2025-01-27 12:02:59.999159: Current learning rate: 0.00255 
2025-01-27 12:03:48.970316: train_loss -0.8309 
2025-01-27 12:03:48.976086: val_loss -0.8067 
2025-01-27 12:03:48.978779: Pseudo dice [np.float32(0.9551), np.float32(0.8934)] 
2025-01-27 12:03:48.981580: Epoch time: 48.98 s 
2025-01-27 12:03:50.799384:  
2025-01-27 12:03:50.802319: Epoch 782 
2025-01-27 12:03:50.804780: Current learning rate: 0.00254 
2025-01-27 12:04:39.559245: train_loss -0.8375 
2025-01-27 12:04:39.564675: val_loss -0.7812 
2025-01-27 12:04:39.567544: Pseudo dice [np.float32(0.9552), np.float32(0.906)] 
2025-01-27 12:04:39.570112: Epoch time: 48.76 s 
2025-01-27 12:04:40.790907:  
2025-01-27 12:04:40.793987: Epoch 783 
2025-01-27 12:04:40.796738: Current learning rate: 0.00253 
2025-01-27 12:05:29.377048: train_loss -0.8319 
2025-01-27 12:05:29.383190: val_loss -0.8028 
2025-01-27 12:05:29.385800: Pseudo dice [np.float32(0.9604), np.float32(0.9009)] 
2025-01-27 12:05:29.388031: Epoch time: 48.59 s 
2025-01-27 12:05:30.610849:  
2025-01-27 12:05:30.614072: Epoch 784 
2025-01-27 12:05:30.617615: Current learning rate: 0.00252 
2025-01-27 12:06:19.637830: train_loss -0.8484 
2025-01-27 12:06:19.643519: val_loss -0.7922 
2025-01-27 12:06:19.646413: Pseudo dice [np.float32(0.964), np.float32(0.9128)] 
2025-01-27 12:06:19.649146: Epoch time: 49.03 s 
2025-01-27 12:06:20.917849:  
2025-01-27 12:06:20.921576: Epoch 785 
2025-01-27 12:06:20.924552: Current learning rate: 0.00251 
2025-01-27 12:07:09.641176: train_loss -0.8355 
2025-01-27 12:07:09.646044: val_loss -0.8137 
2025-01-27 12:07:09.648800: Pseudo dice [np.float32(0.9568), np.float32(0.895)] 
2025-01-27 12:07:09.651341: Epoch time: 48.72 s 
2025-01-27 12:07:10.879442:  
2025-01-27 12:07:10.883457: Epoch 786 
2025-01-27 12:07:10.886352: Current learning rate: 0.0025 
2025-01-27 12:08:00.261839: train_loss -0.8479 
2025-01-27 12:08:00.268271: val_loss -0.7691 
2025-01-27 12:08:00.271318: Pseudo dice [np.float32(0.9568), np.float32(0.8836)] 
2025-01-27 12:08:00.274658: Epoch time: 49.38 s 
2025-01-27 12:08:01.506092:  
2025-01-27 12:08:01.509169: Epoch 787 
2025-01-27 12:08:01.512005: Current learning rate: 0.00249 
2025-01-27 12:08:50.088698: train_loss -0.8318 
2025-01-27 12:08:50.094414: val_loss -0.7364 
2025-01-27 12:08:50.097918: Pseudo dice [np.float32(0.9596), np.float32(0.8718)] 
2025-01-27 12:08:50.101222: Epoch time: 48.58 s 
2025-01-27 12:08:51.334737:  
2025-01-27 12:08:51.337531: Epoch 788 
2025-01-27 12:08:51.340581: Current learning rate: 0.00248 
2025-01-27 12:09:39.874774: train_loss -0.8366 
2025-01-27 12:09:39.880724: val_loss -0.7675 
2025-01-27 12:09:39.883638: Pseudo dice [np.float32(0.9607), np.float32(0.8992)] 
2025-01-27 12:09:39.886648: Epoch time: 48.54 s 
2025-01-27 12:09:41.108905:  
2025-01-27 12:09:41.112037: Epoch 789 
2025-01-27 12:09:41.115338: Current learning rate: 0.00247 
2025-01-27 12:10:30.312251: train_loss -0.8348 
2025-01-27 12:10:30.316922: val_loss -0.7839 
2025-01-27 12:10:30.320215: Pseudo dice [np.float32(0.9588), np.float32(0.8659)] 
2025-01-27 12:10:30.323133: Epoch time: 49.2 s 
2025-01-27 12:10:31.584880:  
2025-01-27 12:10:31.587924: Epoch 790 
2025-01-27 12:10:31.591064: Current learning rate: 0.00245 
2025-01-27 12:11:20.501373: train_loss -0.8391 
2025-01-27 12:11:20.507166: val_loss -0.8171 
2025-01-27 12:11:20.509998: Pseudo dice [np.float32(0.9596), np.float32(0.9165)] 
2025-01-27 12:11:20.512603: Epoch time: 48.92 s 
2025-01-27 12:11:21.745450:  
2025-01-27 12:11:21.748370: Epoch 791 
2025-01-27 12:11:21.750761: Current learning rate: 0.00244 
2025-01-27 12:12:10.678508: train_loss -0.8447 
2025-01-27 12:12:10.683348: val_loss -0.7939 
2025-01-27 12:12:10.686059: Pseudo dice [np.float32(0.9653), np.float32(0.8983)] 
2025-01-27 12:12:10.688668: Epoch time: 48.93 s 
2025-01-27 12:12:11.946184:  
2025-01-27 12:12:11.949500: Epoch 792 
2025-01-27 12:12:11.952328: Current learning rate: 0.00243 
2025-01-27 12:13:00.708586: train_loss -0.843 
2025-01-27 12:13:00.714948: val_loss -0.7901 
2025-01-27 12:13:00.718005: Pseudo dice [np.float32(0.9609), np.float32(0.9064)] 
2025-01-27 12:13:00.720682: Epoch time: 48.76 s 
2025-01-27 12:13:01.988347:  
2025-01-27 12:13:01.991615: Epoch 793 
2025-01-27 12:13:01.994878: Current learning rate: 0.00242 
2025-01-27 12:13:50.386260: train_loss -0.8298 
2025-01-27 12:13:50.391024: val_loss -0.7804 
2025-01-27 12:13:50.394141: Pseudo dice [np.float32(0.9602), np.float32(0.8899)] 
2025-01-27 12:13:50.396854: Epoch time: 48.4 s 
2025-01-27 12:13:51.616267:  
2025-01-27 12:13:51.619390: Epoch 794 
2025-01-27 12:13:51.622316: Current learning rate: 0.00241 
2025-01-27 12:14:40.372357: train_loss -0.8421 
2025-01-27 12:14:40.378736: val_loss -0.8098 
2025-01-27 12:14:40.381495: Pseudo dice [np.float32(0.9639), np.float32(0.9143)] 
2025-01-27 12:14:40.384411: Epoch time: 48.76 s 
2025-01-27 12:14:41.611305:  
2025-01-27 12:14:41.614688: Epoch 795 
2025-01-27 12:14:41.617543: Current learning rate: 0.0024 
2025-01-27 12:15:30.533339: train_loss -0.8349 
2025-01-27 12:15:30.537894: val_loss -0.781 
2025-01-27 12:15:30.540625: Pseudo dice [np.float32(0.9613), np.float32(0.8933)] 
2025-01-27 12:15:30.543509: Epoch time: 48.92 s 
2025-01-27 12:15:31.764370:  
2025-01-27 12:15:31.767684: Epoch 796 
2025-01-27 12:15:31.770668: Current learning rate: 0.00239 
2025-01-27 12:16:19.945227: train_loss -0.8421 
2025-01-27 12:16:19.951303: val_loss -0.7526 
2025-01-27 12:16:19.953955: Pseudo dice [np.float32(0.9626), np.float32(0.9099)] 
2025-01-27 12:16:19.956806: Epoch time: 48.18 s 
2025-01-27 12:16:21.226030:  
2025-01-27 12:16:21.229185: Epoch 797 
2025-01-27 12:16:21.232183: Current learning rate: 0.00238 
2025-01-27 12:17:10.023357: train_loss -0.8398 
2025-01-27 12:17:10.028054: val_loss -0.8176 
2025-01-27 12:17:10.031159: Pseudo dice [np.float32(0.9636), np.float32(0.8972)] 
2025-01-27 12:17:10.033836: Epoch time: 48.8 s 
2025-01-27 12:17:11.301712:  
2025-01-27 12:17:11.304897: Epoch 798 
2025-01-27 12:17:11.313420: Current learning rate: 0.00237 
2025-01-27 12:18:00.013325: train_loss -0.8197 
2025-01-27 12:18:00.019720: val_loss -0.7924 
2025-01-27 12:18:00.022587: Pseudo dice [np.float32(0.955), np.float32(0.9011)] 
2025-01-27 12:18:00.025974: Epoch time: 48.71 s 
2025-01-27 12:18:01.255870:  
2025-01-27 12:18:01.261683: Epoch 799 
2025-01-27 12:18:01.264570: Current learning rate: 0.00236 
2025-01-27 12:18:49.772830: train_loss -0.8499 
2025-01-27 12:18:49.776914: val_loss -0.7846 
2025-01-27 12:18:49.779426: Pseudo dice [np.float32(0.9564), np.float32(0.9079)] 
2025-01-27 12:18:49.782087: Epoch time: 48.52 s 
2025-01-27 12:18:52.239206:  
2025-01-27 12:18:52.242610: Epoch 800 
2025-01-27 12:18:52.250076: Current learning rate: 0.00235 
2025-01-27 12:19:41.005109: train_loss -0.847 
2025-01-27 12:19:41.010981: val_loss -0.78 
2025-01-27 12:19:41.013824: Pseudo dice [np.float32(0.9558), np.float32(0.8925)] 
2025-01-27 12:19:41.016512: Epoch time: 48.77 s 
2025-01-27 12:19:42.292132:  
2025-01-27 12:19:42.295208: Epoch 801 
2025-01-27 12:19:42.304745: Current learning rate: 0.00234 
2025-01-27 12:20:30.779464: train_loss -0.8476 
2025-01-27 12:20:30.784596: val_loss -0.8203 
2025-01-27 12:20:30.787948: Pseudo dice [np.float32(0.956), np.float32(0.9065)] 
2025-01-27 12:20:30.790992: Epoch time: 48.49 s 
2025-01-27 12:20:32.022470:  
2025-01-27 12:20:32.028735: Epoch 802 
2025-01-27 12:20:32.031784: Current learning rate: 0.00233 
2025-01-27 12:21:20.669633: train_loss -0.8364 
2025-01-27 12:21:20.675587: val_loss -0.781 
2025-01-27 12:21:20.678647: Pseudo dice [np.float32(0.9598), np.float32(0.8988)] 
2025-01-27 12:21:20.681333: Epoch time: 48.65 s 
2025-01-27 12:21:21.935645:  
2025-01-27 12:21:21.939075: Epoch 803 
2025-01-27 12:21:21.947211: Current learning rate: 0.00232 
2025-01-27 12:22:10.491865: train_loss -0.8498 
2025-01-27 12:22:10.496703: val_loss -0.768 
2025-01-27 12:22:10.499764: Pseudo dice [np.float32(0.9604), np.float32(0.9077)] 
2025-01-27 12:22:10.502391: Epoch time: 48.56 s 
2025-01-27 12:22:11.730742:  
2025-01-27 12:22:11.736996: Epoch 804 
2025-01-27 12:22:11.740272: Current learning rate: 0.00231 
2025-01-27 12:22:59.933471: train_loss -0.8125 
2025-01-27 12:22:59.940032: val_loss -0.8034 
2025-01-27 12:22:59.943180: Pseudo dice [np.float32(0.9621), np.float32(0.8912)] 
2025-01-27 12:22:59.946263: Epoch time: 48.2 s 
2025-01-27 12:23:01.217654:  
2025-01-27 12:23:01.220937: Epoch 805 
2025-01-27 12:23:01.230235: Current learning rate: 0.0023 
2025-01-27 12:23:49.980326: train_loss -0.8393 
2025-01-27 12:23:49.984457: val_loss -0.7822 
2025-01-27 12:23:49.987019: Pseudo dice [np.float32(0.9554), np.float32(0.9155)] 
2025-01-27 12:23:49.989644: Epoch time: 48.76 s 
2025-01-27 12:23:51.221895:  
2025-01-27 12:23:51.225164: Epoch 806 
2025-01-27 12:23:51.234567: Current learning rate: 0.00229 
2025-01-27 12:24:39.767313: train_loss -0.8564 
2025-01-27 12:24:39.774137: val_loss -0.8116 
2025-01-27 12:24:39.777213: Pseudo dice [np.float32(0.9661), np.float32(0.9215)] 
2025-01-27 12:24:39.779722: Epoch time: 48.55 s 
2025-01-27 12:24:41.051686:  
2025-01-27 12:24:41.054956: Epoch 807 
2025-01-27 12:24:41.063869: Current learning rate: 0.00228 
2025-01-27 12:25:29.266635: train_loss -0.8465 
2025-01-27 12:25:29.270694: val_loss -0.7994 
2025-01-27 12:25:29.273576: Pseudo dice [np.float32(0.9617), np.float32(0.9089)] 
2025-01-27 12:25:29.276076: Epoch time: 48.22 s 
2025-01-27 12:25:30.508154:  
2025-01-27 12:25:30.514747: Epoch 808 
2025-01-27 12:25:30.517796: Current learning rate: 0.00226 
2025-01-27 12:26:19.214306: train_loss -0.8356 
2025-01-27 12:26:19.220848: val_loss -0.793 
2025-01-27 12:26:19.223636: Pseudo dice [np.float32(0.9607), np.float32(0.9064)] 
2025-01-27 12:26:19.226452: Epoch time: 48.71 s 
2025-01-27 12:26:20.498031:  
2025-01-27 12:26:20.501148: Epoch 809 
2025-01-27 12:26:20.509794: Current learning rate: 0.00225 
2025-01-27 12:27:09.170389: train_loss -0.8432 
2025-01-27 12:27:09.174637: val_loss -0.7879 
2025-01-27 12:27:09.177428: Pseudo dice [np.float32(0.9494), np.float32(0.8806)] 
2025-01-27 12:27:09.179924: Epoch time: 48.67 s 
2025-01-27 12:27:10.410712:  
2025-01-27 12:27:10.413953: Epoch 810 
2025-01-27 12:27:10.422428: Current learning rate: 0.00224 
2025-01-27 12:27:59.288047: train_loss -0.8429 
2025-01-27 12:27:59.294132: val_loss -0.7163 
2025-01-27 12:27:59.297002: Pseudo dice [np.float32(0.9503), np.float32(0.8892)] 
2025-01-27 12:27:59.299916: Epoch time: 48.88 s 
2025-01-27 12:28:00.528193:  
2025-01-27 12:28:00.531531: Epoch 811 
2025-01-27 12:28:00.540196: Current learning rate: 0.00223 
2025-01-27 12:28:49.455924: train_loss -0.8316 
2025-01-27 12:28:49.460823: val_loss -0.7749 
2025-01-27 12:28:49.463956: Pseudo dice [np.float32(0.9639), np.float32(0.9125)] 
2025-01-27 12:28:49.466801: Epoch time: 48.93 s 
2025-01-27 12:28:50.741147:  
2025-01-27 12:28:50.744711: Epoch 812 
2025-01-27 12:28:50.752993: Current learning rate: 0.00222 
2025-01-27 12:29:39.298113: train_loss -0.8331 
2025-01-27 12:29:39.306400: val_loss -0.7936 
2025-01-27 12:29:39.309165: Pseudo dice [np.float32(0.9558), np.float32(0.9097)] 
2025-01-27 12:29:39.312065: Epoch time: 48.56 s 
2025-01-27 12:29:40.548385:  
2025-01-27 12:29:40.554504: Epoch 813 
2025-01-27 12:29:40.557353: Current learning rate: 0.00221 
2025-01-27 12:30:29.025295: train_loss -0.8509 
2025-01-27 12:30:29.030022: val_loss -0.7917 
2025-01-27 12:30:29.032940: Pseudo dice [np.float32(0.958), np.float32(0.9202)] 
2025-01-27 12:30:29.035747: Epoch time: 48.48 s 
2025-01-27 12:30:30.264251:  
2025-01-27 12:30:30.267424: Epoch 814 
2025-01-27 12:30:30.275705: Current learning rate: 0.0022 
2025-01-27 12:31:19.047690: train_loss -0.8564 
2025-01-27 12:31:19.053900: val_loss -0.8173 
2025-01-27 12:31:19.056661: Pseudo dice [np.float32(0.9618), np.float32(0.9155)] 
2025-01-27 12:31:19.059379: Epoch time: 48.78 s 
2025-01-27 12:31:20.287802:  
2025-01-27 12:31:20.291216: Epoch 815 
2025-01-27 12:31:20.300259: Current learning rate: 0.00219 
2025-01-27 12:32:08.834990: train_loss -0.8572 
2025-01-27 12:32:08.839952: val_loss -0.7964 
2025-01-27 12:32:08.843121: Pseudo dice [np.float32(0.9606), np.float32(0.9128)] 
2025-01-27 12:32:08.846041: Epoch time: 48.55 s 
2025-01-27 12:32:10.083589:  
2025-01-27 12:32:10.086287: Epoch 816 
2025-01-27 12:32:10.094862: Current learning rate: 0.00218 
2025-01-27 12:32:58.362550: train_loss -0.8537 
2025-01-27 12:32:58.368179: val_loss -0.7877 
2025-01-27 12:32:58.370776: Pseudo dice [np.float32(0.9592), np.float32(0.9107)] 
2025-01-27 12:32:58.373248: Epoch time: 48.28 s 
2025-01-27 12:33:00.135327:  
2025-01-27 12:33:00.138254: Epoch 817 
2025-01-27 12:33:00.145164: Current learning rate: 0.00217 
2025-01-27 12:33:48.521291: train_loss -0.86 
2025-01-27 12:33:48.526208: val_loss -0.7711 
2025-01-27 12:33:48.529286: Pseudo dice [np.float32(0.9647), np.float32(0.9153)] 
2025-01-27 12:33:48.532362: Epoch time: 48.39 s 
2025-01-27 12:33:49.749773:  
2025-01-27 12:33:49.755303: Epoch 818 
2025-01-27 12:33:49.758019: Current learning rate: 0.00216 
2025-01-27 12:34:38.232627: train_loss -0.8536 
2025-01-27 12:34:38.240359: val_loss -0.829 
2025-01-27 12:34:38.243098: Pseudo dice [np.float32(0.9636), np.float32(0.9212)] 
2025-01-27 12:34:38.245638: Epoch time: 48.48 s 
2025-01-27 12:34:39.520741:  
2025-01-27 12:34:39.523809: Epoch 819 
2025-01-27 12:34:39.531091: Current learning rate: 0.00215 
2025-01-27 12:35:28.580484: train_loss -0.8374 
2025-01-27 12:35:28.585131: val_loss -0.7847 
2025-01-27 12:35:28.588196: Pseudo dice [np.float32(0.9547), np.float32(0.8877)] 
2025-01-27 12:35:28.591053: Epoch time: 49.06 s 
2025-01-27 12:35:29.768730:  
2025-01-27 12:35:29.771787: Epoch 820 
2025-01-27 12:35:29.780987: Current learning rate: 0.00214 
2025-01-27 12:36:18.416952: train_loss -0.8324 
2025-01-27 12:36:18.422145: val_loss -0.8014 
2025-01-27 12:36:18.424866: Pseudo dice [np.float32(0.9574), np.float32(0.9022)] 
2025-01-27 12:36:18.427499: Epoch time: 48.65 s 
2025-01-27 12:36:19.591905:  
2025-01-27 12:36:19.595243: Epoch 821 
2025-01-27 12:36:19.604512: Current learning rate: 0.00213 
2025-01-27 12:37:08.472710: train_loss -0.8234 
2025-01-27 12:37:08.477139: val_loss -0.8113 
2025-01-27 12:37:08.479851: Pseudo dice [np.float32(0.9596), np.float32(0.9085)] 
2025-01-27 12:37:08.482536: Epoch time: 48.88 s 
2025-01-27 12:37:09.646541:  
2025-01-27 12:37:09.653252: Epoch 822 
2025-01-27 12:37:09.656471: Current learning rate: 0.00212 
2025-01-27 12:37:57.961231: train_loss -0.8452 
2025-01-27 12:37:57.967193: val_loss -0.8339 
2025-01-27 12:37:57.970481: Pseudo dice [np.float32(0.9638), np.float32(0.9251)] 
2025-01-27 12:37:57.973423: Epoch time: 48.32 s 
2025-01-27 12:37:59.172114:  
2025-01-27 12:37:59.178266: Epoch 823 
2025-01-27 12:37:59.181384: Current learning rate: 0.0021 
2025-01-27 12:38:47.864323: train_loss -0.8325 
2025-01-27 12:38:47.868921: val_loss -0.7993 
2025-01-27 12:38:47.871818: Pseudo dice [np.float32(0.9611), np.float32(0.9078)] 
2025-01-27 12:38:47.874473: Epoch time: 48.69 s 
2025-01-27 12:38:49.054128:  
2025-01-27 12:38:49.057554: Epoch 824 
2025-01-27 12:38:49.066801: Current learning rate: 0.00209 
2025-01-27 12:39:37.488409: train_loss -0.8617 
2025-01-27 12:39:37.494292: val_loss -0.7865 
2025-01-27 12:39:37.497092: Pseudo dice [np.float32(0.9648), np.float32(0.9233)] 
2025-01-27 12:39:37.499878: Epoch time: 48.44 s 
2025-01-27 12:39:37.502357: Yayy! New best EMA pseudo Dice: 0.9350000023841858 
2025-01-27 12:39:39.253273:  
2025-01-27 12:39:39.259882: Epoch 825 
2025-01-27 12:39:39.262969: Current learning rate: 0.00208 
2025-01-27 12:40:27.672755: train_loss -0.8477 
2025-01-27 12:40:27.677301: val_loss -0.774 
2025-01-27 12:40:27.680245: Pseudo dice [np.float32(0.9625), np.float32(0.8753)] 
2025-01-27 12:40:27.683138: Epoch time: 48.42 s 
2025-01-27 12:40:28.878537:  
2025-01-27 12:40:28.884157: Epoch 826 
2025-01-27 12:40:28.886993: Current learning rate: 0.00207 
2025-01-27 12:41:17.585729: train_loss -0.8543 
2025-01-27 12:41:17.592919: val_loss -0.7875 
2025-01-27 12:41:17.595988: Pseudo dice [np.float32(0.9563), np.float32(0.8971)] 
2025-01-27 12:41:17.598721: Epoch time: 48.71 s 
2025-01-27 12:41:18.763598:  
2025-01-27 12:41:18.770591: Epoch 827 
2025-01-27 12:41:18.773137: Current learning rate: 0.00206 
2025-01-27 12:42:07.007115: train_loss -0.8472 
2025-01-27 12:42:07.012682: val_loss -0.7856 
2025-01-27 12:42:07.016623: Pseudo dice [np.float32(0.9594), np.float32(0.9184)] 
2025-01-27 12:42:07.020346: Epoch time: 48.24 s 
2025-01-27 12:42:08.221902:  
2025-01-27 12:42:08.225160: Epoch 828 
2025-01-27 12:42:08.234613: Current learning rate: 0.00205 
2025-01-27 12:42:56.923099: train_loss -0.8301 
2025-01-27 12:42:56.928856: val_loss -0.7767 
2025-01-27 12:42:56.931700: Pseudo dice [np.float32(0.9576), np.float32(0.8847)] 
2025-01-27 12:42:56.934333: Epoch time: 48.7 s 
2025-01-27 12:42:58.100455:  
2025-01-27 12:42:58.103570: Epoch 829 
2025-01-27 12:42:58.112267: Current learning rate: 0.00204 
2025-01-27 12:43:46.681635: train_loss -0.8452 
2025-01-27 12:43:46.686123: val_loss -0.8047 
2025-01-27 12:43:46.689158: Pseudo dice [np.float32(0.9594), np.float32(0.9158)] 
2025-01-27 12:43:46.691908: Epoch time: 48.58 s 
2025-01-27 12:43:47.869288:  
2025-01-27 12:43:47.872535: Epoch 830 
2025-01-27 12:43:47.881278: Current learning rate: 0.00203 
2025-01-27 12:44:36.241112: train_loss -0.8265 
2025-01-27 12:44:36.247512: val_loss -0.7897 
2025-01-27 12:44:36.250421: Pseudo dice [np.float32(0.9579), np.float32(0.9007)] 
2025-01-27 12:44:36.253022: Epoch time: 48.37 s 
2025-01-27 12:44:37.415646:  
2025-01-27 12:44:37.421177: Epoch 831 
2025-01-27 12:44:37.424058: Current learning rate: 0.00202 
2025-01-27 12:45:26.251944: train_loss -0.8324 
2025-01-27 12:45:26.256891: val_loss -0.8033 
2025-01-27 12:45:26.259990: Pseudo dice [np.float32(0.9584), np.float32(0.9147)] 
2025-01-27 12:45:26.262762: Epoch time: 48.84 s 
2025-01-27 12:45:27.431715:  
2025-01-27 12:45:27.435431: Epoch 832 
2025-01-27 12:45:27.443809: Current learning rate: 0.00201 
2025-01-27 12:46:15.893899: train_loss -0.8343 
2025-01-27 12:46:15.899659: val_loss -0.8026 
2025-01-27 12:46:15.902375: Pseudo dice [np.float32(0.9629), np.float32(0.9177)] 
2025-01-27 12:46:15.905125: Epoch time: 48.46 s 
2025-01-27 12:46:17.074914:  
2025-01-27 12:46:17.078335: Epoch 833 
2025-01-27 12:46:17.086357: Current learning rate: 0.002 
2025-01-27 12:47:05.272954: train_loss -0.8301 
2025-01-27 12:47:05.279339: val_loss -0.7811 
2025-01-27 12:47:05.282594: Pseudo dice [np.float32(0.9687), np.float32(0.9221)] 
2025-01-27 12:47:05.285593: Epoch time: 48.2 s 
2025-01-27 12:47:06.456886:  
2025-01-27 12:47:06.460668: Epoch 834 
2025-01-27 12:47:06.469271: Current learning rate: 0.00199 
2025-01-27 12:47:54.898846: train_loss -0.8367 
2025-01-27 12:47:54.904861: val_loss -0.8171 
2025-01-27 12:47:54.907395: Pseudo dice [np.float32(0.9617), np.float32(0.9074)] 
2025-01-27 12:47:54.910278: Epoch time: 48.44 s 
2025-01-27 12:47:56.069630:  
2025-01-27 12:47:56.074479: Epoch 835 
2025-01-27 12:47:56.077700: Current learning rate: 0.00198 
2025-01-27 12:48:44.447794: train_loss -0.8221 
2025-01-27 12:48:44.452808: val_loss -0.7934 
2025-01-27 12:48:44.455882: Pseudo dice [np.float32(0.9587), np.float32(0.9165)] 
2025-01-27 12:48:44.458755: Epoch time: 48.38 s 
2025-01-27 12:48:46.191550:  
2025-01-27 12:48:46.194839: Epoch 836 
2025-01-27 12:48:46.204034: Current learning rate: 0.00196 
2025-01-27 12:49:34.509701: train_loss -0.8494 
2025-01-27 12:49:34.515940: val_loss -0.7878 
2025-01-27 12:49:34.518808: Pseudo dice [np.float32(0.9575), np.float32(0.9072)] 
2025-01-27 12:49:34.521510: Epoch time: 48.32 s 
2025-01-27 12:49:35.709017:  
2025-01-27 12:49:35.715234: Epoch 837 
2025-01-27 12:49:35.718430: Current learning rate: 0.00195 
2025-01-27 12:50:24.411141: train_loss -0.8305 
2025-01-27 12:50:24.416330: val_loss -0.7654 
2025-01-27 12:50:24.419203: Pseudo dice [np.float32(0.9596), np.float32(0.9007)] 
2025-01-27 12:50:24.421804: Epoch time: 48.7 s 
2025-01-27 12:50:25.589722:  
2025-01-27 12:50:25.593156: Epoch 838 
2025-01-27 12:50:25.601478: Current learning rate: 0.00194 
2025-01-27 12:51:14.575152: train_loss -0.8309 
2025-01-27 12:51:14.581107: val_loss -0.8056 
2025-01-27 12:51:14.584441: Pseudo dice [np.float32(0.9633), np.float32(0.9213)] 
2025-01-27 12:51:14.587215: Epoch time: 48.99 s 
2025-01-27 12:51:14.590133: Yayy! New best EMA pseudo Dice: 0.9351000189781189 
2025-01-27 12:51:16.703114:  
2025-01-27 12:51:16.707766: Epoch 839 
2025-01-27 12:51:16.710454: Current learning rate: 0.00193 
2025-01-27 12:52:05.264103: train_loss -0.8467 
2025-01-27 12:52:05.268412: val_loss -0.7739 
2025-01-27 12:52:05.270853: Pseudo dice [np.float32(0.9624), np.float32(0.9109)] 
2025-01-27 12:52:05.273591: Epoch time: 48.56 s 
2025-01-27 12:52:05.276341: Yayy! New best EMA pseudo Dice: 0.9351999759674072 
2025-01-27 12:52:07.126236:  
2025-01-27 12:52:07.131930: Epoch 840 
2025-01-27 12:52:07.134797: Current learning rate: 0.00192 
2025-01-27 12:52:55.779063: train_loss -0.8407 
2025-01-27 12:52:55.785357: val_loss -0.7511 
2025-01-27 12:52:55.788400: Pseudo dice [np.float32(0.9633), np.float32(0.9072)] 
2025-01-27 12:52:55.791198: Epoch time: 48.65 s 
2025-01-27 12:52:55.794090: Yayy! New best EMA pseudo Dice: 0.9351999759674072 
2025-01-27 12:52:57.740872:  
2025-01-27 12:52:57.746695: Epoch 841 
2025-01-27 12:52:57.749710: Current learning rate: 0.00191 
2025-01-27 12:53:46.109847: train_loss -0.8321 
2025-01-27 12:53:46.116294: val_loss -0.8001 
2025-01-27 12:53:46.119059: Pseudo dice [np.float32(0.9643), np.float32(0.9114)] 
2025-01-27 12:53:46.121778: Epoch time: 48.37 s 
2025-01-27 12:53:46.124063: Yayy! New best EMA pseudo Dice: 0.9355000257492065 
2025-01-27 12:53:47.891888:  
2025-01-27 12:53:47.897864: Epoch 842 
2025-01-27 12:53:47.900949: Current learning rate: 0.0019 
2025-01-27 12:54:36.474714: train_loss -0.8407 
2025-01-27 12:54:36.480648: val_loss -0.7885 
2025-01-27 12:54:36.483573: Pseudo dice [np.float32(0.9636), np.float32(0.9326)] 
2025-01-27 12:54:36.486446: Epoch time: 48.58 s 
2025-01-27 12:54:36.489601: Yayy! New best EMA pseudo Dice: 0.9366999864578247 
2025-01-27 12:54:38.288020:  
2025-01-27 12:54:38.292454: Epoch 843 
2025-01-27 12:54:38.295311: Current learning rate: 0.00189 
2025-01-27 12:55:26.779996: train_loss -0.8402 
2025-01-27 12:55:26.784779: val_loss -0.7943 
2025-01-27 12:55:26.787605: Pseudo dice [np.float32(0.9579), np.float32(0.9118)] 
2025-01-27 12:55:26.790213: Epoch time: 48.49 s 
2025-01-27 12:55:27.965120:  
2025-01-27 12:55:27.967945: Epoch 844 
2025-01-27 12:55:27.976411: Current learning rate: 0.00188 
2025-01-27 12:56:16.800809: train_loss -0.8541 
2025-01-27 12:56:16.806936: val_loss -0.8217 
2025-01-27 12:56:16.810006: Pseudo dice [np.float32(0.9543), np.float32(0.9133)] 
2025-01-27 12:56:16.812912: Epoch time: 48.84 s 
2025-01-27 12:56:18.016796:  
2025-01-27 12:56:18.023647: Epoch 845 
2025-01-27 12:56:18.026775: Current learning rate: 0.00187 
2025-01-27 12:57:06.535381: train_loss -0.8413 
2025-01-27 12:57:06.540001: val_loss -0.791 
2025-01-27 12:57:06.543104: Pseudo dice [np.float32(0.9566), np.float32(0.9114)] 
2025-01-27 12:57:06.546161: Epoch time: 48.52 s 
2025-01-27 12:57:07.723982:  
2025-01-27 12:57:07.727168: Epoch 846 
2025-01-27 12:57:07.736366: Current learning rate: 0.00186 
2025-01-27 12:57:56.489734: train_loss -0.8423 
2025-01-27 12:57:56.496248: val_loss -0.7835 
2025-01-27 12:57:56.498955: Pseudo dice [np.float32(0.9638), np.float32(0.9078)] 
2025-01-27 12:57:56.501871: Epoch time: 48.77 s 
2025-01-27 12:57:57.676262:  
2025-01-27 12:57:57.679352: Epoch 847 
2025-01-27 12:57:57.687964: Current learning rate: 0.00185 
2025-01-27 12:58:45.780429: train_loss -0.8483 
2025-01-27 12:58:45.785145: val_loss -0.7956 
2025-01-27 12:58:45.787748: Pseudo dice [np.float32(0.9612), np.float32(0.9228)] 
2025-01-27 12:58:45.790385: Epoch time: 48.11 s 
2025-01-27 12:58:46.961044:  
2025-01-27 12:58:46.964548: Epoch 848 
2025-01-27 12:58:46.973520: Current learning rate: 0.00184 
