
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2024-11-10 12:59:01.352509: Using torch.compile... 
2024-11-10 12:59:15.425566: do_dummy_2d_data_aug: False 
2024-11-10 12:59:15.541352: Using splits from existing split file: /srv/scratch/z5362216/kits19/nnUNet_db/nnUNet_preprocessed/Dataset001_Kits19/splits_final.json 
2024-11-10 12:59:15.811552: The split file contains 5 splits. 
2024-11-10 12:59:15.814114: Desired fold for training: 2 
2024-11-10 12:59:15.816456: This split has 80 training and 20 validation cases. 

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 12, 'patch_size': [512, 512], 'median_image_size_in_voxels': [512.0, 512.0], 'spacing': [0.7939453125, 0.7939453125], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 8, 'features_per_stage': [32, 64, 128, 256, 512, 512, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset001_Kits19', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [3.0, 0.7939453125, 0.7939453125], 'original_median_shape_after_transp': [104, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [2, 0, 1], 'transpose_backward': [1, 2, 0], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 2553.0, 'mean': 104.46720886230469, 'median': 104.0, 'min': -277.0, 'percentile_00_5': -73.0, 'percentile_99_5': 292.0, 'std': 74.68063354492188}}} 
 
2024-11-10 12:59:26.416056: unpacking dataset... 
2024-11-10 12:59:45.364861: unpacking done... 
2024-11-10 12:59:45.483932: Unable to plot network architecture: nnUNet_compile is enabled! 
2024-11-10 12:59:45.575838:  
2024-11-10 12:59:45.578326: Epoch 850 
2024-11-10 12:59:45.580832: Current learning rate: 0.00181 
2024-11-10 13:02:46.997440: train_loss -0.9497 
2024-11-10 13:02:47.006342: val_loss -0.8534 
2024-11-10 13:02:47.026227: Pseudo dice [np.float32(0.9593), np.float32(0.8632)] 
2024-11-10 13:02:47.030208: Epoch time: 181.42 s 
2024-11-10 13:02:49.094669:  
2024-11-10 13:02:49.097595: Epoch 851 
2024-11-10 13:02:49.100303: Current learning rate: 0.0018 
2024-11-10 13:03:28.965245: train_loss -0.951 
2024-11-10 13:03:28.968010: val_loss -0.8808 
2024-11-10 13:03:28.970310: Pseudo dice [np.float32(0.9582), np.float32(0.8767)] 
2024-11-10 13:03:28.972821: Epoch time: 39.87 s 
2024-11-10 13:03:30.262422:  
2024-11-10 13:03:30.265136: Epoch 852 
2024-11-10 13:03:30.267746: Current learning rate: 0.00179 
2024-11-10 13:04:10.257833: train_loss -0.9454 
2024-11-10 13:04:10.265218: val_loss -0.8855 
2024-11-10 13:04:10.267333: Pseudo dice [np.float32(0.9612), np.float32(0.887)] 
2024-11-10 13:04:10.269416: Epoch time: 40.0 s 
2024-11-10 13:04:12.072558:  
2024-11-10 13:04:12.075353: Epoch 853 
2024-11-10 13:04:12.078128: Current learning rate: 0.00178 
2024-11-10 13:04:52.073418: train_loss -0.943 
2024-11-10 13:04:52.077764: val_loss -0.8731 
2024-11-10 13:04:52.080092: Pseudo dice [np.float32(0.958), np.float32(0.8575)] 
2024-11-10 13:04:52.082684: Epoch time: 40.0 s 
2024-11-10 13:04:53.353764:  
2024-11-10 13:04:53.356203: Epoch 854 
2024-11-10 13:04:53.359020: Current learning rate: 0.00177 
2024-11-10 13:05:33.352190: train_loss -0.9371 
2024-11-10 13:05:33.357439: val_loss -0.8567 
2024-11-10 13:05:33.359751: Pseudo dice [np.float32(0.9523), np.float32(0.8468)] 
2024-11-10 13:05:33.362008: Epoch time: 40.0 s 
2024-11-10 13:05:34.672560:  
2024-11-10 13:05:34.675254: Epoch 855 
2024-11-10 13:05:34.677575: Current learning rate: 0.00176 
2024-11-10 13:06:14.704681: train_loss -0.9401 
2024-11-10 13:06:14.707824: val_loss -0.8409 
2024-11-10 13:06:14.710328: Pseudo dice [np.float32(0.9596), np.float32(0.8224)] 
2024-11-10 13:06:14.712798: Epoch time: 40.03 s 
2024-11-10 13:06:15.989356:  
2024-11-10 13:06:15.992143: Epoch 856 
2024-11-10 13:06:15.995316: Current learning rate: 0.00175 
2024-11-10 13:06:55.989751: train_loss -0.9529 
2024-11-10 13:06:55.995833: val_loss -0.8601 
2024-11-10 13:06:55.998376: Pseudo dice [np.float32(0.9601), np.float32(0.8538)] 
2024-11-10 13:06:56.000780: Epoch time: 40.0 s 
2024-11-10 13:06:57.275388:  
2024-11-10 13:06:57.278175: Epoch 857 
2024-11-10 13:06:57.280670: Current learning rate: 0.00174 
2024-11-10 13:07:37.216524: train_loss -0.9533 
2024-11-10 13:07:37.219378: val_loss -0.8515 
2024-11-10 13:07:37.221885: Pseudo dice [np.float32(0.9596), np.float32(0.8622)] 
2024-11-10 13:07:37.224135: Epoch time: 39.94 s 
2024-11-10 13:07:38.492127:  
2024-11-10 13:07:38.494902: Epoch 858 
2024-11-10 13:07:38.497619: Current learning rate: 0.00173 
2024-11-10 13:08:18.416423: train_loss -0.9542 
2024-11-10 13:08:18.422314: val_loss -0.8714 
2024-11-10 13:08:18.424996: Pseudo dice [np.float32(0.9568), np.float32(0.8709)] 
2024-11-10 13:08:18.427393: Epoch time: 39.93 s 
2024-11-10 13:08:19.703069:  
2024-11-10 13:08:19.705801: Epoch 859 
2024-11-10 13:08:19.708447: Current learning rate: 0.00172 
2024-11-10 13:08:59.659283: train_loss -0.9517 
2024-11-10 13:08:59.662824: val_loss -0.8763 
2024-11-10 13:08:59.665297: Pseudo dice [np.float32(0.9578), np.float32(0.8854)] 
2024-11-10 13:08:59.667796: Epoch time: 39.96 s 
2024-11-10 13:09:00.934773:  
2024-11-10 13:09:00.937542: Epoch 860 
2024-11-10 13:09:00.940457: Current learning rate: 0.0017 
2024-11-10 13:09:40.887835: train_loss -0.9525 
2024-11-10 13:09:40.893446: val_loss -0.8554 
2024-11-10 13:09:40.896215: Pseudo dice [np.float32(0.9605), np.float32(0.8722)] 
2024-11-10 13:09:40.898815: Epoch time: 39.95 s 
2024-11-10 13:09:42.165164:  
2024-11-10 13:09:42.167719: Epoch 861 
2024-11-10 13:09:42.170195: Current learning rate: 0.00169 
2024-11-10 13:10:22.110916: train_loss -0.9496 
2024-11-10 13:10:22.113723: val_loss -0.8905 
2024-11-10 13:10:22.116158: Pseudo dice [np.float32(0.958), np.float32(0.8854)] 
2024-11-10 13:10:22.118639: Epoch time: 39.95 s 
2024-11-10 13:10:23.392144:  
2024-11-10 13:10:23.395092: Epoch 862 
2024-11-10 13:10:23.397950: Current learning rate: 0.00168 
2024-11-10 13:11:03.345860: train_loss -0.9518 
2024-11-10 13:11:03.353531: val_loss -0.87 
2024-11-10 13:11:03.355800: Pseudo dice [np.float32(0.9634), np.float32(0.8863)] 
2024-11-10 13:11:03.358016: Epoch time: 39.96 s 
2024-11-10 13:11:04.661905:  
2024-11-10 13:11:04.664513: Epoch 863 
2024-11-10 13:11:04.667186: Current learning rate: 0.00167 
2024-11-10 13:11:44.627510: train_loss -0.9522 
2024-11-10 13:11:44.630617: val_loss -0.8673 
2024-11-10 13:11:44.633016: Pseudo dice [np.float32(0.9526), np.float32(0.8446)] 
2024-11-10 13:11:44.635355: Epoch time: 39.97 s 
2024-11-10 13:11:45.901995:  
2024-11-10 13:11:45.904657: Epoch 864 
2024-11-10 13:11:45.907139: Current learning rate: 0.00166 
2024-11-10 13:12:25.874685: train_loss -0.9366 
2024-11-10 13:12:25.880704: val_loss -0.8811 
2024-11-10 13:12:25.884103: Pseudo dice [np.float32(0.9597), np.float32(0.8809)] 
2024-11-10 13:12:25.886601: Epoch time: 39.97 s 
2024-11-10 13:12:27.159852:  
2024-11-10 13:12:27.162495: Epoch 865 
2024-11-10 13:12:27.165148: Current learning rate: 0.00165 
2024-11-10 13:13:07.141977: train_loss -0.9518 
2024-11-10 13:13:07.145258: val_loss -0.8919 
2024-11-10 13:13:07.147796: Pseudo dice [np.float32(0.9625), np.float32(0.8765)] 
2024-11-10 13:13:07.150053: Epoch time: 39.98 s 
2024-11-10 13:13:08.414696:  
2024-11-10 13:13:08.417286: Epoch 866 
2024-11-10 13:13:08.419627: Current learning rate: 0.00164 
2024-11-10 13:13:48.403404: train_loss -0.9446 
2024-11-10 13:13:48.408591: val_loss -0.8912 
2024-11-10 13:13:48.410911: Pseudo dice [np.float32(0.9612), np.float32(0.8772)] 
2024-11-10 13:13:48.413155: Epoch time: 39.99 s 
2024-11-10 13:13:49.682240:  
2024-11-10 13:13:49.684669: Epoch 867 
2024-11-10 13:13:49.686985: Current learning rate: 0.00163 
2024-11-10 13:14:29.660448: train_loss -0.9508 
2024-11-10 13:14:29.664863: val_loss -0.8857 
2024-11-10 13:14:29.668092: Pseudo dice [np.float32(0.9549), np.float32(0.8598)] 
2024-11-10 13:14:29.670491: Epoch time: 39.98 s 
2024-11-10 13:14:30.939530:  
2024-11-10 13:14:30.942042: Epoch 868 
2024-11-10 13:14:30.944529: Current learning rate: 0.00162 
2024-11-10 13:15:10.934669: train_loss -0.9499 
2024-11-10 13:15:10.939961: val_loss -0.8627 
2024-11-10 13:15:10.942415: Pseudo dice [np.float32(0.9592), np.float32(0.8756)] 
2024-11-10 13:15:10.944982: Epoch time: 40.0 s 
2024-11-10 13:15:12.222008:  
2024-11-10 13:15:12.224934: Epoch 869 
2024-11-10 13:15:12.227605: Current learning rate: 0.00161 
2024-11-10 13:15:52.216779: train_loss -0.9496 
2024-11-10 13:15:52.219638: val_loss -0.8321 
2024-11-10 13:15:52.221865: Pseudo dice [np.float32(0.9532), np.float32(0.7995)] 
2024-11-10 13:15:52.224415: Epoch time: 40.0 s 
2024-11-10 13:15:53.490543:  
2024-11-10 13:15:53.493195: Epoch 870 
2024-11-10 13:15:53.496032: Current learning rate: 0.00159 
2024-11-10 13:16:33.479136: train_loss -0.949 
2024-11-10 13:16:33.484290: val_loss -0.8983 
2024-11-10 13:16:33.486429: Pseudo dice [np.float32(0.962), np.float32(0.9057)] 
2024-11-10 13:16:33.488715: Epoch time: 39.99 s 
2024-11-10 13:16:34.757564:  
2024-11-10 13:16:34.760484: Epoch 871 
2024-11-10 13:16:34.763170: Current learning rate: 0.00158 
2024-11-10 13:17:14.797909: train_loss -0.9492 
2024-11-10 13:17:14.802401: val_loss -0.8872 
2024-11-10 13:17:14.804893: Pseudo dice [np.float32(0.9577), np.float32(0.8909)] 
2024-11-10 13:17:14.807197: Epoch time: 40.04 s 
2024-11-10 13:17:16.109105:  
2024-11-10 13:17:16.112004: Epoch 872 
2024-11-10 13:17:16.114739: Current learning rate: 0.00157 
2024-11-10 13:17:56.128771: train_loss -0.946 
2024-11-10 13:17:56.134493: val_loss -0.854 
2024-11-10 13:17:56.136786: Pseudo dice [np.float32(0.958), np.float32(0.8657)] 
2024-11-10 13:17:56.139071: Epoch time: 40.02 s 
2024-11-10 13:17:58.109302:  
2024-11-10 13:17:58.112192: Epoch 873 
2024-11-10 13:17:58.114752: Current learning rate: 0.00156 
2024-11-10 13:18:38.098440: train_loss -0.9498 
2024-11-10 13:18:38.101272: val_loss -0.8604 
2024-11-10 13:18:38.103710: Pseudo dice [np.float32(0.9571), np.float32(0.8836)] 
2024-11-10 13:18:38.105924: Epoch time: 39.99 s 
2024-11-10 13:18:38.108291: Yayy! New best EMA pseudo Dice: 0.9133999943733215 
2024-11-10 13:18:40.251396:  
2024-11-10 13:18:40.254014: Epoch 874 
2024-11-10 13:18:40.256473: Current learning rate: 0.00155 
2024-11-10 13:19:20.255002: train_loss -0.9575 
2024-11-10 13:19:20.260043: val_loss -0.8976 
2024-11-10 13:19:20.262661: Pseudo dice [np.float32(0.9638), np.float32(0.8882)] 
2024-11-10 13:19:20.265131: Epoch time: 40.0 s 
2024-11-10 13:19:20.268513: Yayy! New best EMA pseudo Dice: 0.9146999716758728 
2024-11-10 13:19:22.378827:  
2024-11-10 13:19:22.381648: Epoch 875 
2024-11-10 13:19:22.384115: Current learning rate: 0.00154 
2024-11-10 13:20:02.360104: train_loss -0.952 
2024-11-10 13:20:02.363494: val_loss -0.8755 
2024-11-10 13:20:02.366187: Pseudo dice [np.float32(0.9578), np.float32(0.8602)] 
2024-11-10 13:20:02.368471: Epoch time: 39.98 s 
2024-11-10 13:20:03.672785:  
2024-11-10 13:20:03.676033: Epoch 876 
2024-11-10 13:20:03.678659: Current learning rate: 0.00153 
2024-11-10 13:20:43.689681: train_loss -0.9535 
2024-11-10 13:20:43.694260: val_loss -0.8824 
2024-11-10 13:20:43.696438: Pseudo dice [np.float32(0.9546), np.float32(0.8804)] 
2024-11-10 13:20:43.699065: Epoch time: 40.02 s 
2024-11-10 13:20:44.961440:  
2024-11-10 13:20:44.963953: Epoch 877 
2024-11-10 13:20:44.966530: Current learning rate: 0.00152 
2024-11-10 13:21:24.982650: train_loss -0.9552 
2024-11-10 13:21:24.986258: val_loss -0.9087 
2024-11-10 13:21:24.988731: Pseudo dice [np.float32(0.9635), np.float32(0.9206)] 
2024-11-10 13:21:24.991106: Epoch time: 40.02 s 
2024-11-10 13:21:24.993348: Yayy! New best EMA pseudo Dice: 0.9172000288963318 
2024-11-10 13:21:27.067447:  
2024-11-10 13:21:27.070097: Epoch 878 
2024-11-10 13:21:27.072520: Current learning rate: 0.00151 
2024-11-10 13:22:07.055190: train_loss -0.9563 
2024-11-10 13:22:07.060613: val_loss -0.8761 
2024-11-10 13:22:07.063117: Pseudo dice [np.float32(0.9585), np.float32(0.8745)] 
2024-11-10 13:22:07.065682: Epoch time: 39.99 s 
2024-11-10 13:22:08.367983:  
2024-11-10 13:22:08.370398: Epoch 879 
2024-11-10 13:22:08.372638: Current learning rate: 0.00149 
2024-11-10 13:22:48.376182: train_loss -0.9554 
2024-11-10 13:22:48.379433: val_loss -0.8819 
2024-11-10 13:22:48.381824: Pseudo dice [np.float32(0.9596), np.float32(0.8815)] 
2024-11-10 13:22:48.384186: Epoch time: 40.01 s 
2024-11-10 13:22:48.386520: Yayy! New best EMA pseudo Dice: 0.9175000190734863 
2024-11-10 13:22:50.549922:  
2024-11-10 13:22:50.552644: Epoch 880 
2024-11-10 13:22:50.555258: Current learning rate: 0.00148 
2024-11-10 13:23:30.569604: train_loss -0.9546 
2024-11-10 13:23:30.574481: val_loss -0.8617 
2024-11-10 13:23:30.576936: Pseudo dice [np.float32(0.959), np.float32(0.8597)] 
2024-11-10 13:23:30.579407: Epoch time: 40.02 s 
2024-11-10 13:23:31.881692:  
2024-11-10 13:23:31.884483: Epoch 881 
2024-11-10 13:23:31.887195: Current learning rate: 0.00147 
2024-11-10 13:24:11.919156: train_loss -0.9541 
2024-11-10 13:24:11.922777: val_loss -0.8866 
2024-11-10 13:24:11.925344: Pseudo dice [np.float32(0.9582), np.float32(0.8737)] 
2024-11-10 13:24:11.927811: Epoch time: 40.04 s 
2024-11-10 13:24:13.227775:  
2024-11-10 13:24:13.230477: Epoch 882 
2024-11-10 13:24:13.233110: Current learning rate: 0.00146 
2024-11-10 13:24:53.274907: train_loss -0.9556 
2024-11-10 13:24:53.279798: val_loss -0.8562 
2024-11-10 13:24:53.282148: Pseudo dice [np.float32(0.9609), np.float32(0.8768)] 
2024-11-10 13:24:53.284605: Epoch time: 40.05 s 
2024-11-10 13:24:54.561715:  
2024-11-10 13:24:54.564109: Epoch 883 
2024-11-10 13:24:54.566478: Current learning rate: 0.00145 
2024-11-10 13:25:34.592205: train_loss -0.9469 
2024-11-10 13:25:34.595656: val_loss -0.8802 
2024-11-10 13:25:34.598291: Pseudo dice [np.float32(0.9612), np.float32(0.8528)] 
2024-11-10 13:25:34.600599: Epoch time: 40.03 s 
2024-11-10 13:25:35.872297:  
2024-11-10 13:25:35.875583: Epoch 884 
2024-11-10 13:25:35.878318: Current learning rate: 0.00144 
2024-11-10 13:26:15.912198: train_loss -0.9467 
2024-11-10 13:26:15.917008: val_loss -0.8946 
2024-11-10 13:26:15.919497: Pseudo dice [np.float32(0.9595), np.float32(0.9001)] 
2024-11-10 13:26:15.922192: Epoch time: 40.04 s 
2024-11-10 13:26:17.201954:  
2024-11-10 13:26:17.204790: Epoch 885 
2024-11-10 13:26:17.207656: Current learning rate: 0.00143 
2024-11-10 13:26:57.243292: train_loss -0.9502 
2024-11-10 13:26:57.248187: val_loss -0.9028 
2024-11-10 13:26:57.250769: Pseudo dice [np.float32(0.9649), np.float32(0.9047)] 
2024-11-10 13:26:57.256106: Epoch time: 40.04 s 
2024-11-10 13:26:57.258399: Yayy! New best EMA pseudo Dice: 0.9190000295639038 
2024-11-10 13:26:59.362643:  
2024-11-10 13:26:59.365479: Epoch 886 
2024-11-10 13:26:59.368206: Current learning rate: 0.00142 
2024-11-10 13:27:39.363325: train_loss -0.9514 
2024-11-10 13:27:39.368374: val_loss -0.8796 
2024-11-10 13:27:39.370733: Pseudo dice [np.float32(0.9617), np.float32(0.8809)] 
2024-11-10 13:27:39.373039: Epoch time: 40.0 s 
2024-11-10 13:27:39.375385: Yayy! New best EMA pseudo Dice: 0.9192000031471252 
2024-11-10 13:27:41.454475:  
2024-11-10 13:27:41.456921: Epoch 887 
2024-11-10 13:27:41.459507: Current learning rate: 0.00141 
2024-11-10 13:28:21.445449: train_loss -0.9553 
2024-11-10 13:28:21.448840: val_loss -0.8893 
2024-11-10 13:28:21.453623: Pseudo dice [np.float32(0.9589), np.float32(0.8894)] 
2024-11-10 13:28:21.455869: Epoch time: 39.99 s 
2024-11-10 13:28:21.458014: Yayy! New best EMA pseudo Dice: 0.919700026512146 
2024-11-10 13:28:23.560486:  
2024-11-10 13:28:23.563179: Epoch 888 
2024-11-10 13:28:23.566872: Current learning rate: 0.00139 
2024-11-10 13:29:03.546082: train_loss -0.9544 
2024-11-10 13:29:03.551120: val_loss -0.8717 
2024-11-10 13:29:03.553587: Pseudo dice [np.float32(0.962), np.float32(0.8629)] 
2024-11-10 13:29:03.555820: Epoch time: 39.99 s 
2024-11-10 13:29:04.822845:  
2024-11-10 13:29:04.825512: Epoch 889 
2024-11-10 13:29:04.828368: Current learning rate: 0.00138 
2024-11-10 13:29:44.819757: train_loss -0.9528 
2024-11-10 13:29:44.822992: val_loss -0.8626 
2024-11-10 13:29:44.825343: Pseudo dice [np.float32(0.961), np.float32(0.8658)] 
2024-11-10 13:29:44.827513: Epoch time: 40.0 s 
2024-11-10 13:29:46.097305:  
2024-11-10 13:29:46.099962: Epoch 890 
2024-11-10 13:29:46.102331: Current learning rate: 0.00137 
2024-11-10 13:30:26.095263: train_loss -0.9548 
2024-11-10 13:30:26.099977: val_loss -0.9117 
2024-11-10 13:30:26.102218: Pseudo dice [np.float32(0.9658), np.float32(0.913)] 
2024-11-10 13:30:26.104476: Epoch time: 40.0 s 
2024-11-10 13:30:26.106809: Yayy! New best EMA pseudo Dice: 0.9204999804496765 
2024-11-10 13:30:28.181263:  
2024-11-10 13:30:28.184050: Epoch 891 
2024-11-10 13:30:28.186601: Current learning rate: 0.00136 
2024-11-10 13:31:08.730847: train_loss -0.9551 
2024-11-10 13:31:08.767951: val_loss -0.8748 
2024-11-10 13:31:08.770372: Pseudo dice [np.float32(0.9606), np.float32(0.873)] 
2024-11-10 13:31:08.772770: Epoch time: 40.55 s 
2024-11-10 13:31:10.074605:  
2024-11-10 13:31:10.077517: Epoch 892 
2024-11-10 13:31:10.080243: Current learning rate: 0.00135 
2024-11-10 13:31:50.052742: train_loss -0.9501 
2024-11-10 13:31:50.058185: val_loss -0.8713 
2024-11-10 13:31:50.063133: Pseudo dice [np.float32(0.9588), np.float32(0.8619)] 
2024-11-10 13:31:50.072628: Epoch time: 39.98 s 
2024-11-10 13:31:51.342432:  
2024-11-10 13:31:51.345062: Epoch 893 
2024-11-10 13:31:51.347603: Current learning rate: 0.00134 
2024-11-10 13:32:31.336188: train_loss -0.9576 
2024-11-10 13:32:31.339703: val_loss -0.8925 
2024-11-10 13:32:31.342046: Pseudo dice [np.float32(0.9625), np.float32(0.8869)] 
2024-11-10 13:32:31.345017: Epoch time: 39.99 s 
2024-11-10 13:32:32.621361:  
2024-11-10 13:32:32.625455: Epoch 894 
2024-11-10 13:32:32.628638: Current learning rate: 0.00133 
2024-11-10 13:33:12.638657: train_loss -0.9516 
2024-11-10 13:33:12.643308: val_loss -0.8679 
2024-11-10 13:33:12.645911: Pseudo dice [np.float32(0.9596), np.float32(0.8661)] 
2024-11-10 13:33:12.648371: Epoch time: 40.02 s 
2024-11-10 13:33:13.954876:  
2024-11-10 13:33:13.957744: Epoch 895 
2024-11-10 13:33:13.960581: Current learning rate: 0.00132 
2024-11-10 13:33:53.991947: train_loss -0.9536 
2024-11-10 13:33:53.995450: val_loss -0.8613 
2024-11-10 13:33:53.998149: Pseudo dice [np.float32(0.9562), np.float32(0.8674)] 
2024-11-10 13:33:54.000698: Epoch time: 40.04 s 
2024-11-10 13:33:55.275629:  
2024-11-10 13:33:55.278485: Epoch 896 
2024-11-10 13:33:55.281008: Current learning rate: 0.0013 
2024-11-10 13:34:35.308520: train_loss -0.9482 
2024-11-10 13:34:35.313521: val_loss -0.8421 
2024-11-10 13:34:35.316221: Pseudo dice [np.float32(0.9543), np.float32(0.8475)] 
2024-11-10 13:34:35.319166: Epoch time: 40.03 s 
2024-11-10 13:34:36.595025:  
2024-11-10 13:34:36.598164: Epoch 897 
2024-11-10 13:34:36.601076: Current learning rate: 0.00129 
2024-11-10 13:35:16.630875: train_loss -0.9487 
2024-11-10 13:35:16.634759: val_loss -0.8881 
2024-11-10 13:35:16.637044: Pseudo dice [np.float32(0.9575), np.float32(0.8797)] 
2024-11-10 13:35:16.639448: Epoch time: 40.04 s 
2024-11-10 13:35:17.912328:  
2024-11-10 13:35:17.915163: Epoch 898 
2024-11-10 13:35:17.917505: Current learning rate: 0.00128 
2024-11-10 13:35:57.963353: train_loss -0.9525 
2024-11-10 13:35:57.968428: val_loss -0.8972 
2024-11-10 13:35:57.970760: Pseudo dice [np.float32(0.9624), np.float32(0.8965)] 
2024-11-10 13:35:57.972963: Epoch time: 40.05 s 
2024-11-10 13:35:59.248162:  
2024-11-10 13:35:59.250943: Epoch 899 
2024-11-10 13:35:59.253720: Current learning rate: 0.00127 
2024-11-10 13:36:39.263371: train_loss -0.954 
2024-11-10 13:36:39.267007: val_loss -0.8653 
2024-11-10 13:36:39.269805: Pseudo dice [np.float32(0.9644), np.float32(0.889)] 
2024-11-10 13:36:39.272388: Epoch time: 40.02 s 
2024-11-10 13:36:41.382157:  
2024-11-10 13:36:41.384831: Epoch 900 
2024-11-10 13:36:41.387354: Current learning rate: 0.00126 
2024-11-10 13:37:21.421936: train_loss -0.9531 
2024-11-10 13:37:21.426572: val_loss -0.8902 
2024-11-10 13:37:21.429011: Pseudo dice [np.float32(0.9606), np.float32(0.8813)] 
2024-11-10 13:37:21.431349: Epoch time: 40.04 s 
2024-11-10 13:37:22.699088:  
2024-11-10 13:37:22.701741: Epoch 901 
2024-11-10 13:37:22.704317: Current learning rate: 0.00125 
2024-11-10 13:38:02.733675: train_loss -0.9521 
2024-11-10 13:38:02.737179: val_loss -0.8772 
2024-11-10 13:38:02.739638: Pseudo dice [np.float32(0.956), np.float32(0.8777)] 
2024-11-10 13:38:02.742242: Epoch time: 40.04 s 
2024-11-10 13:38:04.017723:  
2024-11-10 13:38:04.020171: Epoch 902 
2024-11-10 13:38:04.022774: Current learning rate: 0.00124 
2024-11-10 13:38:44.058595: train_loss -0.955 
2024-11-10 13:38:44.063991: val_loss -0.8627 
2024-11-10 13:38:44.066544: Pseudo dice [np.float32(0.9596), np.float32(0.8488)] 
2024-11-10 13:38:44.069028: Epoch time: 40.04 s 
2024-11-10 13:38:45.334761:  
2024-11-10 13:38:45.337240: Epoch 903 
2024-11-10 13:38:45.339671: Current learning rate: 0.00122 
2024-11-10 13:39:25.394077: train_loss -0.9558 
2024-11-10 13:39:25.397534: val_loss -0.8811 
2024-11-10 13:39:25.400549: Pseudo dice [np.float32(0.9604), np.float32(0.8706)] 
2024-11-10 13:39:25.403102: Epoch time: 40.06 s 
2024-11-10 13:39:26.669989:  
2024-11-10 13:39:26.672610: Epoch 904 
2024-11-10 13:39:26.674992: Current learning rate: 0.00121 
2024-11-10 13:40:06.742157: train_loss -0.9565 
2024-11-10 13:40:06.747115: val_loss -0.8748 
2024-11-10 13:40:06.749615: Pseudo dice [np.float32(0.9604), np.float32(0.8508)] 
2024-11-10 13:40:06.752073: Epoch time: 40.07 s 
2024-11-10 13:40:08.023809:  
2024-11-10 13:40:08.026492: Epoch 905 
2024-11-10 13:40:08.029089: Current learning rate: 0.0012 
2024-11-10 13:40:48.070219: train_loss -0.9593 
2024-11-10 13:40:48.073837: val_loss -0.8599 
2024-11-10 13:40:48.076292: Pseudo dice [np.float32(0.9553), np.float32(0.8569)] 
2024-11-10 13:40:48.079083: Epoch time: 40.05 s 
2024-11-10 13:40:49.350936:  
2024-11-10 13:40:49.353888: Epoch 906 
2024-11-10 13:40:49.356568: Current learning rate: 0.00119 
2024-11-10 13:41:29.416935: train_loss -0.9588 
2024-11-10 13:41:29.421984: val_loss -0.8729 
2024-11-10 13:41:29.424523: Pseudo dice [np.float32(0.9593), np.float32(0.8713)] 
2024-11-10 13:41:29.426935: Epoch time: 40.07 s 
2024-11-10 13:41:30.696979:  
2024-11-10 13:41:30.699467: Epoch 907 
2024-11-10 13:41:30.701867: Current learning rate: 0.00118 
2024-11-10 13:42:10.746666: train_loss -0.9556 
2024-11-10 13:42:10.750364: val_loss -0.8925 
2024-11-10 13:42:10.752774: Pseudo dice [np.float32(0.963), np.float32(0.8899)] 
2024-11-10 13:42:10.755057: Epoch time: 40.05 s 
2024-11-10 13:42:12.059180:  
2024-11-10 13:42:12.061920: Epoch 908 
2024-11-10 13:42:12.064480: Current learning rate: 0.00117 
2024-11-10 13:42:52.133141: train_loss -0.9549 
2024-11-10 13:42:52.138129: val_loss -0.8873 
2024-11-10 13:42:52.140534: Pseudo dice [np.float32(0.961), np.float32(0.8968)] 
2024-11-10 13:42:52.143023: Epoch time: 40.08 s 
2024-11-10 13:42:53.412130:  
2024-11-10 13:42:53.414888: Epoch 909 
2024-11-10 13:42:53.417535: Current learning rate: 0.00116 
2024-11-10 13:43:33.451320: train_loss -0.9582 
2024-11-10 13:43:33.454653: val_loss -0.8864 
2024-11-10 13:43:33.457002: Pseudo dice [np.float32(0.9603), np.float32(0.884)] 
2024-11-10 13:43:33.459251: Epoch time: 40.04 s 
2024-11-10 13:43:34.730624:  
2024-11-10 13:43:34.733229: Epoch 910 
2024-11-10 13:43:34.735718: Current learning rate: 0.00115 
2024-11-10 13:44:14.788455: train_loss -0.9526 
2024-11-10 13:44:14.793510: val_loss -0.8667 
2024-11-10 13:44:14.796229: Pseudo dice [np.float32(0.9601), np.float32(0.8754)] 
2024-11-10 13:44:14.798729: Epoch time: 40.06 s 
2024-11-10 13:44:16.766596:  
2024-11-10 13:44:16.769174: Epoch 911 
2024-11-10 13:44:16.771738: Current learning rate: 0.00113 
2024-11-10 13:44:56.853635: train_loss -0.9497 
2024-11-10 13:44:56.856871: val_loss -0.8526 
2024-11-10 13:44:56.859334: Pseudo dice [np.float32(0.9579), np.float32(0.8523)] 
2024-11-10 13:44:56.861555: Epoch time: 40.09 s 
2024-11-10 13:44:58.165167:  
2024-11-10 13:44:58.167780: Epoch 912 
2024-11-10 13:44:58.170370: Current learning rate: 0.00112 
2024-11-10 13:45:38.230619: train_loss -0.95 
2024-11-10 13:45:38.235195: val_loss -0.8487 
2024-11-10 13:45:38.237550: Pseudo dice [np.float32(0.9571), np.float32(0.8319)] 
2024-11-10 13:45:38.240001: Epoch time: 40.07 s 
2024-11-10 13:45:39.544728:  
2024-11-10 13:45:39.547171: Epoch 913 
2024-11-10 13:45:39.549601: Current learning rate: 0.00111 
2024-11-10 13:46:19.637294: train_loss -0.9556 
2024-11-10 13:46:19.640981: val_loss -0.8868 
2024-11-10 13:46:19.643527: Pseudo dice [np.float32(0.959), np.float32(0.8841)] 
2024-11-10 13:46:19.645733: Epoch time: 40.09 s 
2024-11-10 13:46:20.915048:  
2024-11-10 13:46:20.917669: Epoch 914 
2024-11-10 13:46:20.920456: Current learning rate: 0.0011 
2024-11-10 13:47:00.996913: train_loss -0.9535 
2024-11-10 13:47:01.002210: val_loss -0.8764 
2024-11-10 13:47:01.004714: Pseudo dice [np.float32(0.9566), np.float32(0.868)] 
2024-11-10 13:47:01.007005: Epoch time: 40.08 s 
2024-11-10 13:47:02.280540:  
2024-11-10 13:47:02.283165: Epoch 915 
2024-11-10 13:47:02.285760: Current learning rate: 0.00109 
2024-11-10 13:47:42.383912: train_loss -0.9549 
2024-11-10 13:47:42.387512: val_loss -0.8977 
2024-11-10 13:47:42.389884: Pseudo dice [np.float32(0.9615), np.float32(0.8905)] 
2024-11-10 13:47:42.392191: Epoch time: 40.1 s 
2024-11-10 13:47:43.659469:  
2024-11-10 13:47:43.662158: Epoch 916 
2024-11-10 13:47:43.664770: Current learning rate: 0.00108 
2024-11-10 13:48:23.745449: train_loss -0.9584 
2024-11-10 13:48:23.754717: val_loss -0.8662 
2024-11-10 13:48:23.757264: Pseudo dice [np.float32(0.9587), np.float32(0.8733)] 
2024-11-10 13:48:23.759858: Epoch time: 40.09 s 
2024-11-10 13:48:25.033310:  
2024-11-10 13:48:25.035882: Epoch 917 
2024-11-10 13:48:25.038490: Current learning rate: 0.00106 
2024-11-10 13:49:05.113399: train_loss -0.956 
2024-11-10 13:49:05.116860: val_loss -0.8728 
2024-11-10 13:49:05.119511: Pseudo dice [np.float32(0.9574), np.float32(0.8741)] 
2024-11-10 13:49:05.121794: Epoch time: 40.08 s 
2024-11-10 13:49:06.382389:  
2024-11-10 13:49:06.385446: Epoch 918 
2024-11-10 13:49:06.388013: Current learning rate: 0.00105 
2024-11-10 13:49:46.485097: train_loss -0.9605 
2024-11-10 13:49:46.489684: val_loss -0.8956 
2024-11-10 13:49:46.492087: Pseudo dice [np.float32(0.9617), np.float32(0.8725)] 
2024-11-10 13:49:46.494452: Epoch time: 40.1 s 
2024-11-10 13:49:47.766151:  
2024-11-10 13:49:47.768862: Epoch 919 
2024-11-10 13:49:47.771462: Current learning rate: 0.00104 
2024-11-10 13:50:27.874746: train_loss -0.9579 
2024-11-10 13:50:27.878400: val_loss -0.8934 
2024-11-10 13:50:27.880917: Pseudo dice [np.float32(0.964), np.float32(0.8818)] 
2024-11-10 13:50:27.883600: Epoch time: 40.11 s 
2024-11-10 13:50:29.158852:  
2024-11-10 13:50:29.161521: Epoch 920 
2024-11-10 13:50:29.164123: Current learning rate: 0.00103 
2024-11-10 13:51:09.272043: train_loss -0.9542 
2024-11-10 13:51:09.276596: val_loss -0.8825 
2024-11-10 13:51:09.278842: Pseudo dice [np.float32(0.9602), np.float32(0.88)] 
2024-11-10 13:51:09.281200: Epoch time: 40.11 s 
2024-11-10 13:51:10.552389:  
2024-11-10 13:51:10.555217: Epoch 921 
2024-11-10 13:51:10.557772: Current learning rate: 0.00102 
2024-11-10 13:51:50.665348: train_loss -0.9564 
2024-11-10 13:51:50.670325: val_loss -0.8543 
2024-11-10 13:51:50.672705: Pseudo dice [np.float32(0.9595), np.float32(0.8721)] 
2024-11-10 13:51:50.675200: Epoch time: 40.11 s 
2024-11-10 13:51:51.942616:  
2024-11-10 13:51:51.945045: Epoch 922 
2024-11-10 13:51:51.947594: Current learning rate: 0.00101 
2024-11-10 13:52:32.051580: train_loss -0.9589 
2024-11-10 13:52:32.056728: val_loss -0.8585 
2024-11-10 13:52:32.059362: Pseudo dice [np.float32(0.9611), np.float32(0.8586)] 
2024-11-10 13:52:32.061644: Epoch time: 40.11 s 
2024-11-10 13:52:33.332786:  
2024-11-10 13:52:33.335330: Epoch 923 
2024-11-10 13:52:33.337897: Current learning rate: 0.001 
2024-11-10 13:53:13.451513: train_loss -0.962 
2024-11-10 13:53:13.454993: val_loss -0.8364 
2024-11-10 13:53:13.457469: Pseudo dice [np.float32(0.9601), np.float32(0.8164)] 
2024-11-10 13:53:13.459813: Epoch time: 40.12 s 
2024-11-10 13:53:14.735656:  
2024-11-10 13:53:14.738469: Epoch 924 
2024-11-10 13:53:14.741015: Current learning rate: 0.00098 
2024-11-10 13:53:54.873247: train_loss -0.9585 
2024-11-10 13:53:54.877885: val_loss -0.8763 
2024-11-10 13:53:54.880557: Pseudo dice [np.float32(0.9585), np.float32(0.8832)] 
2024-11-10 13:53:54.883000: Epoch time: 40.14 s 
2024-11-10 13:53:56.166781:  
2024-11-10 13:53:56.170152: Epoch 925 
2024-11-10 13:53:56.172714: Current learning rate: 0.00097 
2024-11-10 13:54:36.274705: train_loss -0.9568 
2024-11-10 13:54:36.278391: val_loss -0.8982 
2024-11-10 13:54:36.280887: Pseudo dice [np.float32(0.9628), np.float32(0.8892)] 
2024-11-10 13:54:36.283309: Epoch time: 40.11 s 
2024-11-10 13:54:37.554618:  
2024-11-10 13:54:37.557269: Epoch 926 
2024-11-10 13:54:37.559623: Current learning rate: 0.00096 
2024-11-10 13:55:17.658864: train_loss -0.9583 
2024-11-10 13:55:17.665507: val_loss -0.9023 
2024-11-10 13:55:17.668261: Pseudo dice [np.float32(0.9637), np.float32(0.8861)] 
2024-11-10 13:55:17.670572: Epoch time: 40.11 s 
2024-11-10 13:55:18.943271:  
2024-11-10 13:55:18.945912: Epoch 927 
2024-11-10 13:55:18.948531: Current learning rate: 0.00095 
2024-11-10 13:55:59.055403: train_loss -0.9594 
2024-11-10 13:55:59.058835: val_loss -0.8928 
2024-11-10 13:55:59.061249: Pseudo dice [np.float32(0.9605), np.float32(0.8815)] 
2024-11-10 13:55:59.063723: Epoch time: 40.11 s 
2024-11-10 13:56:00.333580:  
2024-11-10 13:56:00.337176: Epoch 928 
2024-11-10 13:56:00.339685: Current learning rate: 0.00094 
2024-11-10 13:56:40.425340: train_loss -0.9597 
2024-11-10 13:56:40.430440: val_loss -0.8736 
2024-11-10 13:56:40.432936: Pseudo dice [np.float32(0.9587), np.float32(0.8873)] 
2024-11-10 13:56:40.435528: Epoch time: 40.09 s 
2024-11-10 13:56:41.703122:  
2024-11-10 13:56:41.705975: Epoch 929 
2024-11-10 13:56:41.708982: Current learning rate: 0.00092 
2024-11-10 13:57:21.786073: train_loss -0.9579 
2024-11-10 13:57:21.789608: val_loss -0.8752 
2024-11-10 13:57:21.792027: Pseudo dice [np.float32(0.9612), np.float32(0.8683)] 
2024-11-10 13:57:21.794414: Epoch time: 40.08 s 
2024-11-10 13:57:23.102068:  
2024-11-10 13:57:23.104692: Epoch 930 
2024-11-10 13:57:23.107404: Current learning rate: 0.00091 
2024-11-10 13:58:03.167578: train_loss -0.9585 
2024-11-10 13:58:03.172227: val_loss -0.8951 
2024-11-10 13:58:03.174866: Pseudo dice [np.float32(0.9659), np.float32(0.8833)] 
2024-11-10 13:58:03.177325: Epoch time: 40.07 s 
2024-11-10 13:58:05.140307:  
2024-11-10 13:58:05.143104: Epoch 931 
2024-11-10 13:58:05.146036: Current learning rate: 0.0009 
2024-11-10 13:58:45.203860: train_loss -0.9578 
2024-11-10 13:58:45.207553: val_loss -0.8885 
2024-11-10 13:58:45.209925: Pseudo dice [np.float32(0.9618), np.float32(0.8717)] 
2024-11-10 13:58:45.212521: Epoch time: 40.06 s 
2024-11-10 13:58:46.479563:  
2024-11-10 13:58:46.482329: Epoch 932 
2024-11-10 13:58:46.484971: Current learning rate: 0.00089 
2024-11-10 13:59:26.543632: train_loss -0.9567 
2024-11-10 13:59:26.548271: val_loss -0.8877 
2024-11-10 13:59:26.550711: Pseudo dice [np.float32(0.958), np.float32(0.88)] 
2024-11-10 13:59:26.553122: Epoch time: 40.07 s 
2024-11-10 13:59:27.828867:  
2024-11-10 13:59:27.831637: Epoch 933 
2024-11-10 13:59:27.834278: Current learning rate: 0.00088 
2024-11-10 14:00:07.880901: train_loss -0.9574 
2024-11-10 14:00:07.894017: val_loss -0.8696 
2024-11-10 14:00:07.896425: Pseudo dice [np.float32(0.9596), np.float32(0.872)] 
2024-11-10 14:00:07.898807: Epoch time: 40.05 s 
2024-11-10 14:00:09.170931:  
2024-11-10 14:00:09.174453: Epoch 934 
2024-11-10 14:00:09.177320: Current learning rate: 0.00087 
2024-11-10 14:00:49.224712: train_loss -0.9602 
2024-11-10 14:00:49.229325: val_loss -0.8815 
2024-11-10 14:00:49.231805: Pseudo dice [np.float32(0.9583), np.float32(0.8713)] 
2024-11-10 14:00:49.234343: Epoch time: 40.06 s 
2024-11-10 14:00:50.506285:  
2024-11-10 14:00:50.509438: Epoch 935 
2024-11-10 14:00:50.512151: Current learning rate: 0.00085 
2024-11-10 14:01:30.555706: train_loss -0.9614 
2024-11-10 14:01:30.559576: val_loss -0.8595 
2024-11-10 14:01:30.561998: Pseudo dice [np.float32(0.9584), np.float32(0.8761)] 
2024-11-10 14:01:30.564339: Epoch time: 40.05 s 
2024-11-10 14:01:31.833061:  
2024-11-10 14:01:31.836437: Epoch 936 
2024-11-10 14:01:31.839142: Current learning rate: 0.00084 
2024-11-10 14:02:11.902122: train_loss -0.9617 
2024-11-10 14:02:11.907263: val_loss -0.8754 
2024-11-10 14:02:11.909734: Pseudo dice [np.float32(0.9591), np.float32(0.8778)] 
2024-11-10 14:02:11.912753: Epoch time: 40.07 s 
2024-11-10 14:02:13.186747:  
2024-11-10 14:02:13.189420: Epoch 937 
2024-11-10 14:02:13.191887: Current learning rate: 0.00083 
2024-11-10 14:02:53.276587: train_loss -0.9556 
2024-11-10 14:02:53.280232: val_loss -0.8586 
2024-11-10 14:02:53.283057: Pseudo dice [np.float32(0.9595), np.float32(0.8594)] 
2024-11-10 14:02:53.285977: Epoch time: 40.09 s 
2024-11-10 14:02:54.568903:  
2024-11-10 14:02:54.571833: Epoch 938 
2024-11-10 14:02:54.574466: Current learning rate: 0.00082 
2024-11-10 14:03:34.673294: train_loss -0.9586 
2024-11-10 14:03:34.678266: val_loss -0.8593 
2024-11-10 14:03:34.680817: Pseudo dice [np.float32(0.9595), np.float32(0.8644)] 
2024-11-10 14:03:34.683142: Epoch time: 40.11 s 
2024-11-10 14:03:36.062508:  
2024-11-10 14:03:36.065285: Epoch 939 
2024-11-10 14:03:36.068022: Current learning rate: 0.00081 
2024-11-10 14:04:16.147502: train_loss -0.9566 
2024-11-10 14:04:16.150828: val_loss -0.8688 
2024-11-10 14:04:16.153456: Pseudo dice [np.float32(0.9553), np.float32(0.8551)] 
2024-11-10 14:04:16.155714: Epoch time: 40.09 s 
2024-11-10 14:04:17.429156:  
2024-11-10 14:04:17.431987: Epoch 940 
2024-11-10 14:04:17.434653: Current learning rate: 0.00079 
2024-11-10 14:04:57.520567: train_loss -0.9614 
2024-11-10 14:04:57.525423: val_loss -0.8616 
2024-11-10 14:04:57.528001: Pseudo dice [np.float32(0.9594), np.float32(0.8701)] 
2024-11-10 14:04:57.532321: Epoch time: 40.09 s 
2024-11-10 14:04:58.799973:  
2024-11-10 14:04:58.802780: Epoch 941 
2024-11-10 14:04:58.805501: Current learning rate: 0.00078 
2024-11-10 14:05:38.869157: train_loss -0.9573 
2024-11-10 14:05:38.873017: val_loss -0.8942 
2024-11-10 14:05:38.875847: Pseudo dice [np.float32(0.9603), np.float32(0.8833)] 
2024-11-10 14:05:38.878384: Epoch time: 40.07 s 
2024-11-10 14:05:40.149522:  
2024-11-10 14:05:40.152142: Epoch 942 
2024-11-10 14:05:40.154698: Current learning rate: 0.00077 
2024-11-10 14:06:20.237491: train_loss -0.9577 
2024-11-10 14:06:20.242252: val_loss -0.8744 
2024-11-10 14:06:20.244826: Pseudo dice [np.float32(0.9634), np.float32(0.854)] 
2024-11-10 14:06:20.247203: Epoch time: 40.09 s 
2024-11-10 14:06:21.521046:  
2024-11-10 14:06:21.523779: Epoch 943 
2024-11-10 14:06:21.526206: Current learning rate: 0.00076 
2024-11-10 14:07:01.599591: train_loss -0.9578 
2024-11-10 14:07:01.603058: val_loss -0.8543 
2024-11-10 14:07:01.605821: Pseudo dice [np.float32(0.9597), np.float32(0.8366)] 
2024-11-10 14:07:01.613808: Epoch time: 40.08 s 
2024-11-10 14:07:02.888654:  
2024-11-10 14:07:02.891182: Epoch 944 
2024-11-10 14:07:02.893760: Current learning rate: 0.00075 
2024-11-10 14:07:42.970618: train_loss -0.9607 
2024-11-10 14:07:42.974949: val_loss -0.8482 
2024-11-10 14:07:42.977244: Pseudo dice [np.float32(0.9567), np.float32(0.8677)] 
2024-11-10 14:07:42.979579: Epoch time: 40.08 s 
2024-11-10 14:07:44.252111:  
2024-11-10 14:07:44.255563: Epoch 945 
2024-11-10 14:07:44.258270: Current learning rate: 0.00074 
2024-11-10 14:08:24.343137: train_loss -0.9538 
2024-11-10 14:08:24.347032: val_loss -0.8665 
2024-11-10 14:08:24.349456: Pseudo dice [np.float32(0.9611), np.float32(0.8637)] 
2024-11-10 14:08:24.351782: Epoch time: 40.09 s 
2024-11-10 14:08:25.630528:  
2024-11-10 14:08:25.633240: Epoch 946 
2024-11-10 14:08:25.635899: Current learning rate: 0.00072 
2024-11-10 14:09:05.689299: train_loss -0.9577 
2024-11-10 14:09:05.694016: val_loss -0.884 
2024-11-10 14:09:05.696517: Pseudo dice [np.float32(0.9592), np.float32(0.8833)] 
2024-11-10 14:09:05.698807: Epoch time: 40.06 s 
2024-11-10 14:09:06.974214:  
2024-11-10 14:09:06.977053: Epoch 947 
2024-11-10 14:09:06.979613: Current learning rate: 0.00071 
2024-11-10 14:09:47.026088: train_loss -0.9594 
2024-11-10 14:09:47.029423: val_loss -0.8704 
2024-11-10 14:09:47.031734: Pseudo dice [np.float32(0.958), np.float32(0.8599)] 
2024-11-10 14:09:47.033973: Epoch time: 40.05 s 
2024-11-10 14:09:48.302682:  
2024-11-10 14:09:48.305390: Epoch 948 
2024-11-10 14:09:48.307784: Current learning rate: 0.0007 
2024-11-10 14:10:28.323753: train_loss -0.9551 
2024-11-10 14:10:28.328527: val_loss -0.8606 
2024-11-10 14:10:28.330953: Pseudo dice [np.float32(0.9565), np.float32(0.8389)] 
2024-11-10 14:10:28.333086: Epoch time: 40.02 s 
2024-11-10 14:10:29.601594:  
2024-11-10 14:10:29.604204: Epoch 949 
2024-11-10 14:10:29.606752: Current learning rate: 0.00069 
2024-11-10 14:11:09.634988: train_loss -0.9575 
2024-11-10 14:11:09.638421: val_loss -0.8485 
2024-11-10 14:11:09.641223: Pseudo dice [np.float32(0.9574), np.float32(0.8572)] 
2024-11-10 14:11:09.643504: Epoch time: 40.03 s 
2024-11-10 14:11:11.746095:  
2024-11-10 14:11:11.748668: Epoch 950 
2024-11-10 14:11:11.751224: Current learning rate: 0.00067 
2024-11-10 14:11:51.767841: train_loss -0.9533 
2024-11-10 14:11:51.772997: val_loss -0.8776 
2024-11-10 14:11:51.775346: Pseudo dice [np.float32(0.9578), np.float32(0.8759)] 
2024-11-10 14:11:51.777853: Epoch time: 40.02 s 
2024-11-10 14:11:53.048474:  
2024-11-10 14:11:53.051487: Epoch 951 
2024-11-10 14:11:53.054449: Current learning rate: 0.00066 
2024-11-10 14:12:33.077995: train_loss -0.9573 
2024-11-10 14:12:33.081725: val_loss -0.8937 
2024-11-10 14:12:33.084041: Pseudo dice [np.float32(0.9616), np.float32(0.8781)] 
2024-11-10 14:12:33.086537: Epoch time: 40.03 s 
2024-11-10 14:12:35.046981:  
2024-11-10 14:12:35.049494: Epoch 952 
2024-11-10 14:12:35.052642: Current learning rate: 0.00065 
2024-11-10 14:13:15.067917: train_loss -0.9559 
2024-11-10 14:13:15.078864: val_loss -0.8832 
2024-11-10 14:13:15.081403: Pseudo dice [np.float32(0.9598), np.float32(0.8869)] 
2024-11-10 14:13:15.083805: Epoch time: 40.02 s 
2024-11-10 14:13:16.352094:  
2024-11-10 14:13:16.354925: Epoch 953 
2024-11-10 14:13:16.357627: Current learning rate: 0.00064 
2024-11-10 14:13:56.373365: train_loss -0.9595 
2024-11-10 14:13:56.376791: val_loss -0.8905 
2024-11-10 14:13:56.379188: Pseudo dice [np.float32(0.9598), np.float32(0.8977)] 
2024-11-10 14:13:56.381525: Epoch time: 40.02 s 
2024-11-10 14:13:57.672067:  
2024-11-10 14:13:57.674914: Epoch 954 
2024-11-10 14:13:57.677603: Current learning rate: 0.00063 
2024-11-10 14:14:37.708239: train_loss -0.9633 
2024-11-10 14:14:37.712940: val_loss -0.8773 
2024-11-10 14:14:37.715375: Pseudo dice [np.float32(0.96), np.float32(0.8803)] 
2024-11-10 14:14:37.717661: Epoch time: 40.04 s 
2024-11-10 14:14:39.007560:  
2024-11-10 14:14:39.010063: Epoch 955 
2024-11-10 14:14:39.012630: Current learning rate: 0.00061 
2024-11-10 14:15:19.048473: train_loss -0.9588 
2024-11-10 14:15:19.051781: val_loss -0.887 
2024-11-10 14:15:19.054115: Pseudo dice [np.float32(0.9608), np.float32(0.8656)] 
2024-11-10 14:15:19.056839: Epoch time: 40.04 s 
2024-11-10 14:15:20.349160:  
2024-11-10 14:15:20.351871: Epoch 956 
2024-11-10 14:15:20.354356: Current learning rate: 0.0006 
2024-11-10 14:16:00.392421: train_loss -0.958 
2024-11-10 14:16:00.397094: val_loss -0.8896 
2024-11-10 14:16:00.399478: Pseudo dice [np.float32(0.9623), np.float32(0.8876)] 
2024-11-10 14:16:00.401794: Epoch time: 40.04 s 
2024-11-10 14:16:01.696152:  
2024-11-10 14:16:01.698673: Epoch 957 
2024-11-10 14:16:01.701133: Current learning rate: 0.00059 
2024-11-10 14:16:41.762651: train_loss -0.9625 
2024-11-10 14:16:41.765978: val_loss -0.8668 
2024-11-10 14:16:41.768243: Pseudo dice [np.float32(0.9594), np.float32(0.8865)] 
2024-11-10 14:16:41.770656: Epoch time: 40.07 s 
2024-11-10 14:16:43.052281:  
2024-11-10 14:16:43.054684: Epoch 958 
2024-11-10 14:16:43.057292: Current learning rate: 0.00058 
2024-11-10 14:17:23.105104: train_loss -0.9595 
2024-11-10 14:17:23.110085: val_loss -0.8517 
2024-11-10 14:17:23.112449: Pseudo dice [np.float32(0.9545), np.float32(0.8479)] 
2024-11-10 14:17:23.114943: Epoch time: 40.05 s 
2024-11-10 14:17:24.404112:  
2024-11-10 14:17:24.406864: Epoch 959 
2024-11-10 14:17:24.409235: Current learning rate: 0.00056 
2024-11-10 14:18:04.445493: train_loss -0.961 
2024-11-10 14:18:04.449087: val_loss -0.8831 
2024-11-10 14:18:04.451448: Pseudo dice [np.float32(0.9617), np.float32(0.8798)] 
2024-11-10 14:18:04.454060: Epoch time: 40.04 s 
2024-11-10 14:18:05.782499:  
2024-11-10 14:18:05.785010: Epoch 960 
2024-11-10 14:18:05.787753: Current learning rate: 0.00055 
2024-11-10 14:18:45.841463: train_loss -0.9582 
2024-11-10 14:18:45.846333: val_loss -0.8622 
2024-11-10 14:18:45.848981: Pseudo dice [np.float32(0.9612), np.float32(0.8741)] 
2024-11-10 14:18:45.851663: Epoch time: 40.06 s 
2024-11-10 14:18:47.146984:  
2024-11-10 14:18:47.149606: Epoch 961 
2024-11-10 14:18:47.152241: Current learning rate: 0.00054 
2024-11-10 14:19:27.184765: train_loss -0.9601 
2024-11-10 14:19:27.188444: val_loss -0.8703 
2024-11-10 14:19:27.191014: Pseudo dice [np.float32(0.9615), np.float32(0.8725)] 
2024-11-10 14:19:27.193444: Epoch time: 40.04 s 
2024-11-10 14:19:28.481714:  
2024-11-10 14:19:28.484451: Epoch 962 
2024-11-10 14:19:28.486795: Current learning rate: 0.00053 
2024-11-10 14:20:08.526278: train_loss -0.9567 
2024-11-10 14:20:08.542167: val_loss -0.8745 
2024-11-10 14:20:08.544897: Pseudo dice [np.float32(0.962), np.float32(0.884)] 
2024-11-10 14:20:08.547291: Epoch time: 40.05 s 
2024-11-10 14:20:09.843583:  
2024-11-10 14:20:09.846207: Epoch 963 
2024-11-10 14:20:09.848922: Current learning rate: 0.00051 
2024-11-10 14:20:49.886324: train_loss -0.9578 
2024-11-10 14:20:49.890444: val_loss -0.8607 
2024-11-10 14:20:49.893080: Pseudo dice [np.float32(0.9631), np.float32(0.8582)] 
2024-11-10 14:20:49.895441: Epoch time: 40.04 s 
2024-11-10 14:20:51.192460:  
2024-11-10 14:20:51.195488: Epoch 964 
2024-11-10 14:20:51.198277: Current learning rate: 0.0005 
2024-11-10 14:21:31.225751: train_loss -0.9621 
2024-11-10 14:21:31.237249: val_loss -0.8709 
2024-11-10 14:21:31.239988: Pseudo dice [np.float32(0.9569), np.float32(0.8692)] 
2024-11-10 14:21:31.242277: Epoch time: 40.03 s 
2024-11-10 14:21:32.534591:  
2024-11-10 14:21:32.537596: Epoch 965 
2024-11-10 14:21:32.540354: Current learning rate: 0.00049 
2024-11-10 14:22:12.577052: train_loss -0.9578 
2024-11-10 14:22:12.580796: val_loss -0.8837 
2024-11-10 14:22:12.583536: Pseudo dice [np.float32(0.9608), np.float32(0.8732)] 
2024-11-10 14:22:12.585916: Epoch time: 40.04 s 
2024-11-10 14:22:13.915710:  
2024-11-10 14:22:13.918494: Epoch 966 
2024-11-10 14:22:13.921168: Current learning rate: 0.00048 
2024-11-10 14:22:53.966214: train_loss -0.9588 
2024-11-10 14:22:53.971078: val_loss -0.8645 
2024-11-10 14:22:53.973346: Pseudo dice [np.float32(0.9591), np.float32(0.8398)] 
2024-11-10 14:22:53.975657: Epoch time: 40.05 s 
2024-11-10 14:22:55.274783:  
2024-11-10 14:22:55.277489: Epoch 967 
2024-11-10 14:22:55.279919: Current learning rate: 0.00046 
2024-11-10 14:23:35.346084: train_loss -0.9571 
2024-11-10 14:23:35.349690: val_loss -0.8602 
2024-11-10 14:23:35.352034: Pseudo dice [np.float32(0.9546), np.float32(0.8489)] 
2024-11-10 14:23:35.354357: Epoch time: 40.07 s 
2024-11-10 14:23:36.686699:  
2024-11-10 14:23:36.689561: Epoch 968 
2024-11-10 14:23:36.692107: Current learning rate: 0.00045 
2024-11-10 14:24:16.770925: train_loss -0.9618 
2024-11-10 14:24:16.781827: val_loss -0.8853 
2024-11-10 14:24:16.784385: Pseudo dice [np.float32(0.9568), np.float32(0.8928)] 
2024-11-10 14:24:16.786920: Epoch time: 40.09 s 
2024-11-10 14:24:18.114357:  
2024-11-10 14:24:18.117431: Epoch 969 
2024-11-10 14:24:18.120075: Current learning rate: 0.00044 
2024-11-10 14:24:58.153502: train_loss -0.9613 
2024-11-10 14:24:58.157056: val_loss -0.8665 
2024-11-10 14:24:58.159547: Pseudo dice [np.float32(0.9609), np.float32(0.8603)] 
2024-11-10 14:24:58.161950: Epoch time: 40.04 s 
2024-11-10 14:24:59.458665:  
2024-11-10 14:24:59.461323: Epoch 970 
2024-11-10 14:24:59.463854: Current learning rate: 0.00043 
2024-11-10 14:25:39.545640: train_loss -0.9614 
2024-11-10 14:25:39.550182: val_loss -0.8582 
2024-11-10 14:25:39.552620: Pseudo dice [np.float32(0.9547), np.float32(0.8438)] 
2024-11-10 14:25:39.554858: Epoch time: 40.09 s 
2024-11-10 14:25:41.544840:  
2024-11-10 14:25:41.547602: Epoch 971 
2024-11-10 14:25:41.550343: Current learning rate: 0.00041 
2024-11-10 14:26:21.587069: train_loss -0.9617 
2024-11-10 14:26:21.593913: val_loss -0.8867 
2024-11-10 14:26:21.596448: Pseudo dice [np.float32(0.9575), np.float32(0.8758)] 
2024-11-10 14:26:21.598766: Epoch time: 40.04 s 
2024-11-10 14:26:22.924370:  
2024-11-10 14:26:22.927080: Epoch 972 
2024-11-10 14:26:22.929629: Current learning rate: 0.0004 
2024-11-10 14:27:02.982634: train_loss -0.9605 
2024-11-10 14:27:02.987654: val_loss -0.8724 
2024-11-10 14:27:02.990163: Pseudo dice [np.float32(0.9605), np.float32(0.8774)] 
2024-11-10 14:27:02.992599: Epoch time: 40.06 s 
2024-11-10 14:27:04.321086:  
2024-11-10 14:27:04.324017: Epoch 973 
2024-11-10 14:27:04.326907: Current learning rate: 0.00039 
2024-11-10 14:27:44.360381: train_loss -0.9586 
2024-11-10 14:27:44.363950: val_loss -0.8794 
2024-11-10 14:27:44.366534: Pseudo dice [np.float32(0.9572), np.float32(0.8719)] 
2024-11-10 14:27:44.369038: Epoch time: 40.04 s 
2024-11-10 14:27:45.666441:  
2024-11-10 14:27:45.670758: Epoch 974 
2024-11-10 14:27:45.673258: Current learning rate: 0.00037 
2024-11-10 14:28:25.715470: train_loss -0.9572 
2024-11-10 14:28:25.720599: val_loss -0.8653 
2024-11-10 14:28:25.723284: Pseudo dice [np.float32(0.96), np.float32(0.8768)] 
2024-11-10 14:28:25.725750: Epoch time: 40.05 s 
2024-11-10 14:28:27.018904:  
2024-11-10 14:28:27.021893: Epoch 975 
2024-11-10 14:28:27.024520: Current learning rate: 0.00036 
2024-11-10 14:29:07.023920: train_loss -0.9572 
2024-11-10 14:29:07.028189: val_loss -0.8894 
2024-11-10 14:29:07.030602: Pseudo dice [np.float32(0.9589), np.float32(0.8895)] 
2024-11-10 14:29:07.033006: Epoch time: 40.01 s 
2024-11-10 14:29:08.365786:  
2024-11-10 14:29:08.368989: Epoch 976 
2024-11-10 14:29:08.371872: Current learning rate: 0.00035 
2024-11-10 14:29:48.369539: train_loss -0.9559 
2024-11-10 14:29:48.374188: val_loss -0.8705 
2024-11-10 14:29:48.376872: Pseudo dice [np.float32(0.9576), np.float32(0.8639)] 
2024-11-10 14:29:48.379275: Epoch time: 40.01 s 
2024-11-10 14:29:49.679934:  
2024-11-10 14:29:49.682770: Epoch 977 
2024-11-10 14:29:49.685465: Current learning rate: 0.00034 
2024-11-10 14:30:29.680502: train_loss -0.9623 
2024-11-10 14:30:29.684336: val_loss -0.8758 
2024-11-10 14:30:29.686914: Pseudo dice [np.float32(0.9622), np.float32(0.895)] 
2024-11-10 14:30:29.689430: Epoch time: 40.0 s 
2024-11-10 14:30:30.986461:  
2024-11-10 14:30:30.989155: Epoch 978 
2024-11-10 14:30:30.991587: Current learning rate: 0.00032 
2024-11-10 14:31:11.004186: train_loss -0.9607 
2024-11-10 14:31:11.017576: val_loss -0.8709 
2024-11-10 14:31:11.020001: Pseudo dice [np.float32(0.9593), np.float32(0.8662)] 
2024-11-10 14:31:11.022342: Epoch time: 40.02 s 
2024-11-10 14:31:12.326042:  
2024-11-10 14:31:12.328684: Epoch 979 
2024-11-10 14:31:12.331187: Current learning rate: 0.00031 
2024-11-10 14:31:52.345451: train_loss -0.9592 
2024-11-10 14:31:52.348855: val_loss -0.8408 
2024-11-10 14:31:52.351143: Pseudo dice [np.float32(0.9616), np.float32(0.8642)] 
2024-11-10 14:31:52.353448: Epoch time: 40.02 s 
2024-11-10 14:31:53.646598:  
2024-11-10 14:31:53.649639: Epoch 980 
2024-11-10 14:31:53.652375: Current learning rate: 0.0003 
2024-11-10 14:32:33.653840: train_loss -0.9604 
2024-11-10 14:32:33.660372: val_loss -0.8851 
2024-11-10 14:32:33.662769: Pseudo dice [np.float32(0.9575), np.float32(0.8798)] 
2024-11-10 14:32:33.664994: Epoch time: 40.01 s 
2024-11-10 14:32:34.956145:  
2024-11-10 14:32:34.958881: Epoch 981 
2024-11-10 14:32:34.961508: Current learning rate: 0.00028 
2024-11-10 14:33:14.963671: train_loss -0.9615 
2024-11-10 14:33:14.966993: val_loss -0.8673 
2024-11-10 14:33:14.969238: Pseudo dice [np.float32(0.9578), np.float32(0.8583)] 
2024-11-10 14:33:14.972063: Epoch time: 40.01 s 
2024-11-10 14:33:16.267259:  
2024-11-10 14:33:16.269924: Epoch 982 
2024-11-10 14:33:16.272666: Current learning rate: 0.00027 
2024-11-10 14:33:56.302610: train_loss -0.9629 
2024-11-10 14:33:56.309074: val_loss -0.8555 
2024-11-10 14:33:56.311653: Pseudo dice [np.float32(0.9589), np.float32(0.8505)] 
2024-11-10 14:33:56.313948: Epoch time: 40.04 s 
2024-11-10 14:33:57.601815:  
2024-11-10 14:33:57.604362: Epoch 983 
2024-11-10 14:33:57.606863: Current learning rate: 0.00026 
2024-11-10 14:34:37.609152: train_loss -0.9597 
2024-11-10 14:34:37.612678: val_loss -0.8955 
2024-11-10 14:34:37.615154: Pseudo dice [np.float32(0.9615), np.float32(0.8786)] 
2024-11-10 14:34:37.617598: Epoch time: 40.01 s 
2024-11-10 14:34:38.915025:  
2024-11-10 14:34:38.917752: Epoch 984 
2024-11-10 14:34:38.920235: Current learning rate: 0.00024 
2024-11-10 14:35:18.962645: train_loss -0.9564 
2024-11-10 14:35:18.967956: val_loss -0.8572 
2024-11-10 14:35:18.970263: Pseudo dice [np.float32(0.957), np.float32(0.8613)] 
2024-11-10 14:35:18.972830: Epoch time: 40.05 s 
2024-11-10 14:35:20.268178:  
2024-11-10 14:35:20.270891: Epoch 985 
2024-11-10 14:35:20.273470: Current learning rate: 0.00023 
2024-11-10 14:36:00.315012: train_loss -0.9631 
2024-11-10 14:36:00.321770: val_loss -0.8884 
2024-11-10 14:36:00.324639: Pseudo dice [np.float32(0.9601), np.float32(0.8769)] 
2024-11-10 14:36:00.327287: Epoch time: 40.05 s 
2024-11-10 14:36:01.627091:  
2024-11-10 14:36:01.630353: Epoch 986 
2024-11-10 14:36:01.633016: Current learning rate: 0.00021 
2024-11-10 14:36:41.690076: train_loss -0.9608 
2024-11-10 14:36:41.695406: val_loss -0.8793 
2024-11-10 14:36:41.697941: Pseudo dice [np.float32(0.9586), np.float32(0.8822)] 
2024-11-10 14:36:41.700461: Epoch time: 40.06 s 
2024-11-10 14:36:42.995170:  
2024-11-10 14:36:42.998347: Epoch 987 
2024-11-10 14:36:43.000994: Current learning rate: 0.0002 
2024-11-10 14:37:23.048287: train_loss -0.9618 
2024-11-10 14:37:23.052028: val_loss -0.8545 
2024-11-10 14:37:23.054788: Pseudo dice [np.float32(0.9602), np.float32(0.8743)] 
2024-11-10 14:37:23.057290: Epoch time: 40.05 s 
2024-11-10 14:37:24.357864:  
2024-11-10 14:37:24.360572: Epoch 988 
2024-11-10 14:37:24.363698: Current learning rate: 0.00019 
2024-11-10 14:38:04.406726: train_loss -0.9622 
2024-11-10 14:38:04.411762: val_loss -0.8823 
2024-11-10 14:38:04.414378: Pseudo dice [np.float32(0.9614), np.float32(0.8602)] 
2024-11-10 14:38:04.417292: Epoch time: 40.05 s 
2024-11-10 14:38:05.710306:  
2024-11-10 14:38:05.713051: Epoch 989 
2024-11-10 14:38:05.715701: Current learning rate: 0.00017 
2024-11-10 14:38:45.744929: train_loss -0.962 
2024-11-10 14:38:45.760881: val_loss -0.8451 
2024-11-10 14:38:45.763302: Pseudo dice [np.float32(0.9545), np.float32(0.8563)] 
2024-11-10 14:38:45.765900: Epoch time: 40.04 s 
2024-11-10 14:38:47.066964:  
2024-11-10 14:38:47.069662: Epoch 990 
2024-11-10 14:38:47.072272: Current learning rate: 0.00016 
2024-11-10 14:39:27.126864: train_loss -0.9604 
2024-11-10 14:39:27.131787: val_loss -0.8778 
2024-11-10 14:39:27.134083: Pseudo dice [np.float32(0.9566), np.float32(0.8717)] 
2024-11-10 14:39:27.136559: Epoch time: 40.06 s 
2024-11-10 14:39:29.120579:  
2024-11-10 14:39:29.122951: Epoch 991 
2024-11-10 14:39:29.125260: Current learning rate: 0.00014 
2024-11-10 14:40:09.180893: train_loss -0.9612 
2024-11-10 14:40:09.184395: val_loss -0.8857 
2024-11-10 14:40:09.186800: Pseudo dice [np.float32(0.9606), np.float32(0.8911)] 
2024-11-10 14:40:09.189025: Epoch time: 40.06 s 
2024-11-10 14:40:10.502736:  
2024-11-10 14:40:10.505405: Epoch 992 
2024-11-10 14:40:10.508397: Current learning rate: 0.00013 
2024-11-10 14:40:50.571461: train_loss -0.9539 
2024-11-10 14:40:50.576296: val_loss -0.8878 
2024-11-10 14:40:50.578697: Pseudo dice [np.float32(0.9619), np.float32(0.8959)] 
2024-11-10 14:40:50.581123: Epoch time: 40.07 s 
2024-11-10 14:40:51.915278:  
2024-11-10 14:40:51.918140: Epoch 993 
2024-11-10 14:40:51.921008: Current learning rate: 0.00011 
2024-11-10 14:41:31.989555: train_loss -0.9639 
2024-11-10 14:41:31.993664: val_loss -0.8875 
2024-11-10 14:41:31.995985: Pseudo dice [np.float32(0.9619), np.float32(0.881)] 
2024-11-10 14:41:31.998356: Epoch time: 40.08 s 
2024-11-10 14:41:33.292258:  
2024-11-10 14:41:33.295020: Epoch 994 
2024-11-10 14:41:33.297623: Current learning rate: 0.0001 
2024-11-10 14:42:13.377803: train_loss -0.9635 
2024-11-10 14:42:13.382793: val_loss -0.8881 
2024-11-10 14:42:13.385269: Pseudo dice [np.float32(0.9595), np.float32(0.8651)] 
2024-11-10 14:42:13.387643: Epoch time: 40.09 s 
2024-11-10 14:42:14.683154:  
2024-11-10 14:42:14.686154: Epoch 995 
2024-11-10 14:42:14.689006: Current learning rate: 8e-05 
2024-11-10 14:42:54.737597: train_loss -0.9601 
2024-11-10 14:42:54.741170: val_loss -0.8899 
2024-11-10 14:42:54.744389: Pseudo dice [np.float32(0.9617), np.float32(0.8995)] 
2024-11-10 14:42:54.746978: Epoch time: 40.06 s 
2024-11-10 14:42:56.041683:  
2024-11-10 14:42:56.044438: Epoch 996 
2024-11-10 14:42:56.047194: Current learning rate: 7e-05 
2024-11-10 14:43:36.111989: train_loss -0.9632 
2024-11-10 14:43:36.117067: val_loss -0.891 
2024-11-10 14:43:36.119630: Pseudo dice [np.float32(0.9629), np.float32(0.8878)] 
2024-11-10 14:43:36.122027: Epoch time: 40.07 s 
2024-11-10 14:43:37.419013:  
2024-11-10 14:43:37.421982: Epoch 997 
2024-11-10 14:43:37.425034: Current learning rate: 5e-05 
2024-11-10 14:44:17.489118: train_loss -0.9644 
2024-11-10 14:44:17.492402: val_loss -0.8635 
2024-11-10 14:44:17.494971: Pseudo dice [np.float32(0.9622), np.float32(0.8638)] 
2024-11-10 14:44:17.497823: Epoch time: 40.07 s 
2024-11-10 14:44:18.790048:  
2024-11-10 14:44:18.792757: Epoch 998 
2024-11-10 14:44:18.795268: Current learning rate: 4e-05 
2024-11-10 14:44:58.854465: train_loss -0.9601 
2024-11-10 14:44:58.859063: val_loss -0.8788 
2024-11-10 14:44:58.861530: Pseudo dice [np.float32(0.9603), np.float32(0.8553)] 
2024-11-10 14:44:58.863914: Epoch time: 40.07 s 
2024-11-10 14:45:00.154638:  
2024-11-10 14:45:00.157342: Epoch 999 
2024-11-10 14:45:00.160512: Current learning rate: 2e-05 
2024-11-10 14:45:40.251840: train_loss -0.9575 
2024-11-10 14:45:40.262360: val_loss -0.8904 
2024-11-10 14:45:40.264684: Pseudo dice [np.float32(0.9599), np.float32(0.8849)] 
2024-11-10 14:45:40.267264: Epoch time: 40.1 s 
2024-11-10 14:45:42.456420: Training done. 
2024-11-10 14:45:42.524107: Using splits from existing split file: /srv/scratch/z5362216/kits19/nnUNet_db/nnUNet_preprocessed/Dataset001_Kits19/splits_final.json 
2024-11-10 14:45:42.533237: The split file contains 5 splits. 
2024-11-10 14:45:42.536124: Desired fold for training: 2 
2024-11-10 14:45:42.538901: This split has 80 training and 20 validation cases. 
2024-11-10 14:45:42.545040: predicting imaging_012 
2024-11-10 14:45:42.554749: imaging_012, shape torch.Size([1, 89, 485, 485]), rank 0 
2024-11-10 14:45:58.713019: predicting imaging_016 
2024-11-10 14:45:58.771435: imaging_016, shape torch.Size([1, 178, 419, 419]), rank 0 
2024-11-10 14:46:02.877436: predicting imaging_018 
2024-11-10 14:46:02.891314: imaging_018, shape torch.Size([1, 121, 555, 555]), rank 0 
2024-11-10 14:46:27.933485: predicting imaging_019 
2024-11-10 14:46:27.959089: imaging_019, shape torch.Size([1, 129, 605, 605]), rank 0 
2024-11-10 14:46:40.097494: predicting imaging_021 
2024-11-10 14:46:40.126168: imaging_021, shape torch.Size([1, 38, 530, 530]), rank 0 
2024-11-10 14:46:43.480752: predicting imaging_022 
2024-11-10 14:46:43.493401: imaging_022, shape torch.Size([1, 541, 538, 538]), rank 0 
2024-11-10 14:47:30.047748: predicting imaging_024 
2024-11-10 14:47:30.077724: imaging_024, shape torch.Size([1, 85, 428, 428]), rank 0 
2024-11-10 14:47:32.126659: predicting imaging_027 
2024-11-10 14:47:32.138384: imaging_027, shape torch.Size([1, 723, 577, 577]), rank 0 
2024-11-10 14:48:33.758390: predicting imaging_032 
2024-11-10 14:48:33.797062: imaging_032, shape torch.Size([1, 189, 503, 503]), rank 0 
2024-11-10 14:48:38.293317: predicting imaging_048 
2024-11-10 14:48:38.307961: imaging_048, shape torch.Size([1, 85, 671, 671]), rank 0 
2024-11-10 14:48:45.596490: predicting imaging_058 
2024-11-10 14:48:45.621934: imaging_058, shape torch.Size([1, 103, 613, 613]), rank 0 
2024-11-10 14:48:55.376871: predicting imaging_062 
2024-11-10 14:48:56.124254: imaging_062, shape torch.Size([1, 86, 630, 630]), rank 0 
2024-11-10 14:49:03.630975: predicting imaging_068 
2024-11-10 14:49:04.007979: imaging_068, shape torch.Size([1, 626, 453, 453]), rank 0 
2024-11-10 14:49:19.950517: predicting imaging_074 
2024-11-10 14:49:20.134808: imaging_074, shape torch.Size([1, 80, 418, 418]), rank 0 
2024-11-10 14:49:23.901486: predicting imaging_079 
2024-11-10 14:49:24.266942: imaging_079, shape torch.Size([1, 124, 416, 416]), rank 0 
2024-11-10 14:49:28.908617: predicting imaging_083 
2024-11-10 14:49:29.589991: imaging_083, shape torch.Size([1, 94, 630, 630]), rank 0 
2024-11-10 14:49:41.853093: predicting imaging_084 
2024-11-10 14:49:42.039662: imaging_084, shape torch.Size([1, 274, 630, 630]), rank 0 
2024-11-10 14:50:08.083484: predicting imaging_085 
2024-11-10 14:50:08.290489: imaging_085, shape torch.Size([1, 87, 524, 524]), rank 0 
2024-11-10 14:50:17.430964: predicting imaging_089 
2024-11-10 14:50:17.589342: imaging_089, shape torch.Size([1, 55, 586, 586]), rank 0 
2024-11-10 14:50:22.348492: predicting imaging_095 
2024-11-10 14:50:22.540082: imaging_095, shape torch.Size([1, 314, 602, 602]), rank 0 
2024-11-10 14:52:49.534384: Validation complete 
2024-11-10 14:52:49.537203: Mean Validation Dice:  0.8488710938436888 
