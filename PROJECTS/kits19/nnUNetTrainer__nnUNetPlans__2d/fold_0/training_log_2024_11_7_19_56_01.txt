
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2024-11-07 19:56:03.936547: Using torch.compile... 
2024-11-07 19:56:20.910358: do_dummy_2d_data_aug: False 
2024-11-07 19:56:20.980052: Using splits from existing split file: /srv/scratch/z5362216/kits19/nnUNet_db/nnUNet_preprocessed/Dataset001_Kits19/splits_final.json 
2024-11-07 19:56:21.067672: The split file contains 5 splits. 
2024-11-07 19:56:21.070030: Desired fold for training: 0 
2024-11-07 19:56:21.072334: This split has 80 training and 20 validation cases. 

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 12, 'patch_size': [512, 512], 'median_image_size_in_voxels': [512.0, 512.0], 'spacing': [0.7939453125, 0.7939453125], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 8, 'features_per_stage': [32, 64, 128, 256, 512, 512, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset001_Kits19', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [3.0, 0.7939453125, 0.7939453125], 'original_median_shape_after_transp': [104, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [2, 0, 1], 'transpose_backward': [1, 2, 0], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 2553.0, 'mean': 104.46720886230469, 'median': 104.0, 'min': -277.0, 'percentile_00_5': -73.0, 'percentile_99_5': 292.0, 'std': 74.68063354492188}}} 
 
2024-11-07 19:56:30.076349: unpacking dataset... 
2024-11-07 19:56:44.813126: unpacking done... 
2024-11-07 19:56:44.893567: Unable to plot network architecture: nnUNet_compile is enabled! 
2024-11-07 19:56:44.991432:  
2024-11-07 19:56:44.993971: Epoch 850 
2024-11-07 19:56:44.996525: Current learning rate: 0.00181 
2024-11-07 19:59:38.548558: train_loss -0.951 
2024-11-07 19:59:38.556803: val_loss -0.691 
2024-11-07 19:59:38.585313: Pseudo dice [np.float32(0.9472), np.float32(0.5473)] 
2024-11-07 19:59:38.587821: Epoch time: 173.56 s 
2024-11-07 19:59:40.276683:  
2024-11-07 19:59:40.279112: Epoch 851 
2024-11-07 19:59:40.281594: Current learning rate: 0.0018 
2024-11-07 20:00:19.825778: train_loss -0.9561 
2024-11-07 20:00:19.832685: val_loss -0.7769 
2024-11-07 20:00:19.835124: Pseudo dice [np.float32(0.9475), np.float32(0.6955)] 
2024-11-07 20:00:19.837603: Epoch time: 39.55 s 
2024-11-07 20:00:21.070626:  
2024-11-07 20:00:21.073703: Epoch 852 
2024-11-07 20:00:21.079382: Current learning rate: 0.00179 
2024-11-07 20:01:00.760896: train_loss -0.9544 
2024-11-07 20:01:00.767051: val_loss -0.702 
2024-11-07 20:01:00.769379: Pseudo dice [np.float32(0.9513), np.float32(0.5975)] 
2024-11-07 20:01:00.771895: Epoch time: 39.69 s 
2024-11-07 20:01:02.517404:  
2024-11-07 20:01:02.520540: Epoch 853 
2024-11-07 20:01:02.523043: Current learning rate: 0.00178 
2024-11-07 20:01:42.043996: train_loss -0.9453 
2024-11-07 20:01:42.046886: val_loss -0.7089 
2024-11-07 20:01:42.049304: Pseudo dice [np.float32(0.9447), np.float32(0.5736)] 
2024-11-07 20:01:42.051744: Epoch time: 39.53 s 
2024-11-07 20:01:43.288680:  
2024-11-07 20:01:43.291733: Epoch 854 
2024-11-07 20:01:43.294173: Current learning rate: 0.00177 
2024-11-07 20:02:22.967192: train_loss -0.9481 
2024-11-07 20:02:22.973014: val_loss -0.7156 
2024-11-07 20:02:22.975286: Pseudo dice [np.float32(0.9413), np.float32(0.6095)] 
2024-11-07 20:02:22.977651: Epoch time: 39.68 s 
2024-11-07 20:02:24.410408:  
2024-11-07 20:02:24.412846: Epoch 855 
2024-11-07 20:02:24.415117: Current learning rate: 0.00176 
2024-11-07 20:03:03.955275: train_loss -0.9525 
2024-11-07 20:03:03.958069: val_loss -0.7576 
2024-11-07 20:03:03.960640: Pseudo dice [np.float32(0.9534), np.float32(0.6422)] 
2024-11-07 20:03:03.963152: Epoch time: 39.55 s 
2024-11-07 20:03:05.170498:  
2024-11-07 20:03:05.172745: Epoch 856 
2024-11-07 20:03:05.175102: Current learning rate: 0.00175 
2024-11-07 20:03:44.771389: train_loss -0.9564 
2024-11-07 20:03:44.777279: val_loss -0.7737 
2024-11-07 20:03:44.779525: Pseudo dice [np.float32(0.9534), np.float32(0.7243)] 
2024-11-07 20:03:44.782018: Epoch time: 39.6 s 
2024-11-07 20:03:46.011839:  
2024-11-07 20:03:46.014240: Epoch 857 
2024-11-07 20:03:46.016691: Current learning rate: 0.00174 
2024-11-07 20:04:25.570657: train_loss -0.9558 
2024-11-07 20:04:25.573615: val_loss -0.7584 
2024-11-07 20:04:25.576287: Pseudo dice [np.float32(0.9449), np.float32(0.7139)] 
2024-11-07 20:04:25.578748: Epoch time: 39.56 s 
2024-11-07 20:04:26.808010:  
2024-11-07 20:04:26.810724: Epoch 858 
2024-11-07 20:04:26.813793: Current learning rate: 0.00173 
2024-11-07 20:05:06.352071: train_loss -0.9499 
2024-11-07 20:05:06.357218: val_loss -0.7921 
2024-11-07 20:05:06.359496: Pseudo dice [np.float32(0.9457), np.float32(0.7248)] 
2024-11-07 20:05:06.361551: Epoch time: 39.55 s 
2024-11-07 20:05:07.588654:  
2024-11-07 20:05:07.591182: Epoch 859 
2024-11-07 20:05:07.593688: Current learning rate: 0.00172 
2024-11-07 20:05:47.256417: train_loss -0.9533 
2024-11-07 20:05:47.259161: val_loss -0.7673 
2024-11-07 20:05:47.261380: Pseudo dice [np.float32(0.9534), np.float32(0.6878)] 
2024-11-07 20:05:47.263614: Epoch time: 39.67 s 
2024-11-07 20:05:48.490498:  
2024-11-07 20:05:48.493191: Epoch 860 
2024-11-07 20:05:48.495646: Current learning rate: 0.0017 
2024-11-07 20:06:28.037314: train_loss -0.9584 
2024-11-07 20:06:28.042887: val_loss -0.802 
2024-11-07 20:06:28.045228: Pseudo dice [np.float32(0.954), np.float32(0.7132)] 
2024-11-07 20:06:28.047450: Epoch time: 39.55 s 
2024-11-07 20:06:29.262858:  
2024-11-07 20:06:29.265212: Epoch 861 
2024-11-07 20:06:29.267470: Current learning rate: 0.00169 
2024-11-07 20:07:08.827434: train_loss -0.9547 
2024-11-07 20:07:08.830060: val_loss -0.6752 
2024-11-07 20:07:08.832532: Pseudo dice [np.float32(0.9477), np.float32(0.5338)] 
2024-11-07 20:07:08.834870: Epoch time: 39.57 s 
2024-11-07 20:07:10.065984:  
2024-11-07 20:07:10.068505: Epoch 862 
2024-11-07 20:07:10.070972: Current learning rate: 0.00168 
2024-11-07 20:07:49.677979: train_loss -0.9514 
2024-11-07 20:07:49.684138: val_loss -0.7248 
2024-11-07 20:07:49.686812: Pseudo dice [np.float32(0.9459), np.float32(0.6467)] 
2024-11-07 20:07:49.689492: Epoch time: 39.61 s 
2024-11-07 20:07:50.908875:  
2024-11-07 20:07:50.911610: Epoch 863 
2024-11-07 20:07:50.914462: Current learning rate: 0.00167 
2024-11-07 20:08:30.439700: train_loss -0.9552 
2024-11-07 20:08:30.442543: val_loss -0.7618 
2024-11-07 20:08:30.445256: Pseudo dice [np.float32(0.9513), np.float32(0.683)] 
2024-11-07 20:08:30.447523: Epoch time: 39.53 s 
2024-11-07 20:08:31.672172:  
2024-11-07 20:08:31.674410: Epoch 864 
2024-11-07 20:08:31.676598: Current learning rate: 0.00166 
2024-11-07 20:09:11.334295: train_loss -0.9523 
2024-11-07 20:09:11.339093: val_loss -0.7308 
2024-11-07 20:09:11.341794: Pseudo dice [np.float32(0.9421), np.float32(0.6436)] 
2024-11-07 20:09:11.344041: Epoch time: 39.66 s 
2024-11-07 20:09:12.577700:  
2024-11-07 20:09:12.580500: Epoch 865 
2024-11-07 20:09:12.583076: Current learning rate: 0.00165 
2024-11-07 20:09:52.131680: train_loss -0.9488 
2024-11-07 20:09:52.134951: val_loss -0.7354 
2024-11-07 20:09:52.137217: Pseudo dice [np.float32(0.9537), np.float32(0.6247)] 
2024-11-07 20:09:52.139539: Epoch time: 39.56 s 
2024-11-07 20:09:53.359773:  
2024-11-07 20:09:53.362164: Epoch 866 
2024-11-07 20:09:53.364467: Current learning rate: 0.00164 
2024-11-07 20:10:33.088949: train_loss -0.9529 
2024-11-07 20:10:33.095370: val_loss -0.7525 
2024-11-07 20:10:33.098042: Pseudo dice [np.float32(0.9462), np.float32(0.706)] 
2024-11-07 20:10:33.100410: Epoch time: 39.73 s 
2024-11-07 20:10:34.317284:  
2024-11-07 20:10:34.319702: Epoch 867 
2024-11-07 20:10:34.322079: Current learning rate: 0.00163 
2024-11-07 20:11:13.931131: train_loss -0.9525 
2024-11-07 20:11:13.933754: val_loss -0.6767 
2024-11-07 20:11:13.936072: Pseudo dice [np.float32(0.9432), np.float32(0.5452)] 
2024-11-07 20:11:13.938411: Epoch time: 39.62 s 
2024-11-07 20:11:15.161133:  
2024-11-07 20:11:15.163725: Epoch 868 
2024-11-07 20:11:15.166167: Current learning rate: 0.00162 
2024-11-07 20:11:54.781178: train_loss -0.9514 
2024-11-07 20:11:54.794444: val_loss -0.7106 
2024-11-07 20:11:54.797028: Pseudo dice [np.float32(0.9408), np.float32(0.6161)] 
2024-11-07 20:11:54.799261: Epoch time: 39.62 s 
2024-11-07 20:11:56.002297:  
2024-11-07 20:11:56.005243: Epoch 869 
2024-11-07 20:11:56.007725: Current learning rate: 0.00161 
2024-11-07 20:12:35.726192: train_loss -0.9544 
2024-11-07 20:12:35.728816: val_loss -0.7439 
2024-11-07 20:12:35.731091: Pseudo dice [np.float32(0.9385), np.float32(0.6416)] 
2024-11-07 20:12:35.733702: Epoch time: 39.73 s 
2024-11-07 20:12:36.962687:  
2024-11-07 20:12:36.965312: Epoch 870 
2024-11-07 20:12:36.968081: Current learning rate: 0.00159 
2024-11-07 20:13:16.570918: train_loss -0.9579 
2024-11-07 20:13:16.577202: val_loss -0.7251 
2024-11-07 20:13:16.579700: Pseudo dice [np.float32(0.9457), np.float32(0.6375)] 
2024-11-07 20:13:16.582413: Epoch time: 39.61 s 
2024-11-07 20:13:17.813298:  
2024-11-07 20:13:17.815703: Epoch 871 
2024-11-07 20:13:17.818236: Current learning rate: 0.00158 
2024-11-07 20:13:57.437951: train_loss -0.9514 
2024-11-07 20:13:57.441049: val_loss -0.6924 
2024-11-07 20:13:57.443300: Pseudo dice [np.float32(0.9423), np.float32(0.5584)] 
2024-11-07 20:13:57.445629: Epoch time: 39.63 s 
2024-11-07 20:13:58.657116:  
2024-11-07 20:13:58.659578: Epoch 872 
2024-11-07 20:13:58.661952: Current learning rate: 0.00157 
2024-11-07 20:14:38.257431: train_loss -0.9596 
2024-11-07 20:14:38.264674: val_loss -0.7183 
2024-11-07 20:14:38.267349: Pseudo dice [np.float32(0.9469), np.float32(0.5949)] 
2024-11-07 20:14:38.269745: Epoch time: 39.6 s 
2024-11-07 20:14:40.138657:  
2024-11-07 20:14:40.141590: Epoch 873 
2024-11-07 20:14:40.144314: Current learning rate: 0.00156 
2024-11-07 20:15:19.709947: train_loss -0.9565 
2024-11-07 20:15:19.712902: val_loss -0.6536 
2024-11-07 20:15:19.715521: Pseudo dice [np.float32(0.9463), np.float32(0.5255)] 
2024-11-07 20:15:19.717983: Epoch time: 39.57 s 
2024-11-07 20:15:20.953381:  
2024-11-07 20:15:20.956292: Epoch 874 
2024-11-07 20:15:20.958665: Current learning rate: 0.00155 
2024-11-07 20:16:00.535486: train_loss -0.9563 
2024-11-07 20:16:00.541042: val_loss -0.7614 
2024-11-07 20:16:00.543621: Pseudo dice [np.float32(0.9518), np.float32(0.6897)] 
2024-11-07 20:16:00.545956: Epoch time: 39.58 s 
2024-11-07 20:16:01.776795:  
2024-11-07 20:16:01.779789: Epoch 875 
2024-11-07 20:16:01.782675: Current learning rate: 0.00154 
2024-11-07 20:16:41.421924: train_loss -0.9573 
2024-11-07 20:16:41.427185: val_loss -0.7316 
2024-11-07 20:16:41.429921: Pseudo dice [np.float32(0.9447), np.float32(0.6321)] 
2024-11-07 20:16:41.432603: Epoch time: 39.65 s 
2024-11-07 20:16:42.693899:  
2024-11-07 20:16:42.696632: Epoch 876 
2024-11-07 20:16:42.699131: Current learning rate: 0.00153 
2024-11-07 20:17:22.349701: train_loss -0.9585 
2024-11-07 20:17:22.355336: val_loss -0.7222 
2024-11-07 20:17:22.357817: Pseudo dice [np.float32(0.9449), np.float32(0.5954)] 
2024-11-07 20:17:22.360067: Epoch time: 39.66 s 
2024-11-07 20:17:23.595492:  
2024-11-07 20:17:23.597847: Epoch 877 
2024-11-07 20:17:23.600391: Current learning rate: 0.00152 
2024-11-07 20:18:03.318096: train_loss -0.9577 
2024-11-07 20:18:03.321405: val_loss -0.6725 
2024-11-07 20:18:03.323982: Pseudo dice [np.float32(0.9426), np.float32(0.5571)] 
2024-11-07 20:18:03.326630: Epoch time: 39.72 s 
2024-11-07 20:18:04.549190:  
2024-11-07 20:18:04.551337: Epoch 878 
2024-11-07 20:18:04.553593: Current learning rate: 0.00151 
2024-11-07 20:18:44.183259: train_loss -0.9554 
2024-11-07 20:18:44.188843: val_loss -0.7254 
2024-11-07 20:18:44.191316: Pseudo dice [np.float32(0.9436), np.float32(0.6456)] 
2024-11-07 20:18:44.194034: Epoch time: 39.64 s 
2024-11-07 20:18:45.422499:  
2024-11-07 20:18:45.424845: Epoch 879 
2024-11-07 20:18:45.427440: Current learning rate: 0.00149 
2024-11-07 20:19:25.056729: train_loss -0.9576 
2024-11-07 20:19:25.059642: val_loss -0.7438 
2024-11-07 20:19:25.062344: Pseudo dice [np.float32(0.951), np.float32(0.6882)] 
2024-11-07 20:19:25.064551: Epoch time: 39.64 s 
2024-11-07 20:19:26.289697:  
2024-11-07 20:19:26.292158: Epoch 880 
2024-11-07 20:19:26.294405: Current learning rate: 0.00148 
2024-11-07 20:20:05.991266: train_loss -0.9544 
2024-11-07 20:20:05.998492: val_loss -0.7279 
2024-11-07 20:20:06.000831: Pseudo dice [np.float32(0.9433), np.float32(0.6111)] 
2024-11-07 20:20:06.003479: Epoch time: 39.7 s 
2024-11-07 20:20:07.238048:  
2024-11-07 20:20:07.240705: Epoch 881 
2024-11-07 20:20:07.246894: Current learning rate: 0.00147 
2024-11-07 20:20:46.906951: train_loss -0.9606 
2024-11-07 20:20:46.910041: val_loss -0.7607 
2024-11-07 20:20:46.912752: Pseudo dice [np.float32(0.9497), np.float32(0.6586)] 
2024-11-07 20:20:46.915225: Epoch time: 39.67 s 
2024-11-07 20:20:48.134577:  
2024-11-07 20:20:48.137067: Epoch 882 
2024-11-07 20:20:48.139413: Current learning rate: 0.00146 
2024-11-07 20:21:27.825435: train_loss -0.9541 
2024-11-07 20:21:27.830977: val_loss -0.7107 
2024-11-07 20:21:27.833477: Pseudo dice [np.float32(0.9443), np.float32(0.6045)] 
2024-11-07 20:21:27.835758: Epoch time: 39.69 s 
2024-11-07 20:21:29.085534:  
2024-11-07 20:21:29.088120: Epoch 883 
2024-11-07 20:21:29.090703: Current learning rate: 0.00145 
2024-11-07 20:22:08.819333: train_loss -0.9582 
2024-11-07 20:22:08.822291: val_loss -0.7058 
2024-11-07 20:22:08.824790: Pseudo dice [np.float32(0.9447), np.float32(0.6065)] 
2024-11-07 20:22:08.827035: Epoch time: 39.73 s 
2024-11-07 20:22:10.049366:  
2024-11-07 20:22:10.051681: Epoch 884 
2024-11-07 20:22:10.054064: Current learning rate: 0.00144 
2024-11-07 20:22:49.795227: train_loss -0.9546 
2024-11-07 20:22:49.801292: val_loss -0.7806 
2024-11-07 20:22:49.804105: Pseudo dice [np.float32(0.952), np.float32(0.7568)] 
2024-11-07 20:22:49.806730: Epoch time: 39.75 s 
2024-11-07 20:22:51.027486:  
2024-11-07 20:22:51.029947: Epoch 885 
2024-11-07 20:22:51.032217: Current learning rate: 0.00143 
2024-11-07 20:23:30.748824: train_loss -0.9548 
2024-11-07 20:23:30.751462: val_loss -0.7595 
2024-11-07 20:23:30.753931: Pseudo dice [np.float32(0.9471), np.float32(0.6459)] 
2024-11-07 20:23:30.756242: Epoch time: 39.72 s 
2024-11-07 20:23:31.980724:  
2024-11-07 20:23:31.983288: Epoch 886 
2024-11-07 20:23:31.986022: Current learning rate: 0.00142 
2024-11-07 20:24:11.728073: train_loss -0.9509 
2024-11-07 20:24:11.760978: val_loss -0.741 
2024-11-07 20:24:11.763475: Pseudo dice [np.float32(0.951), np.float32(0.6057)] 
2024-11-07 20:24:11.766169: Epoch time: 39.75 s 
2024-11-07 20:24:12.999870:  
2024-11-07 20:24:13.002131: Epoch 887 
2024-11-07 20:24:13.004474: Current learning rate: 0.00141 
2024-11-07 20:24:52.669509: train_loss -0.9553 
2024-11-07 20:24:52.672267: val_loss -0.7211 
2024-11-07 20:24:52.674572: Pseudo dice [np.float32(0.942), np.float32(0.6104)] 
2024-11-07 20:24:52.676848: Epoch time: 39.67 s 
2024-11-07 20:24:53.898004:  
2024-11-07 20:24:53.900329: Epoch 888 
2024-11-07 20:24:53.902685: Current learning rate: 0.00139 
2024-11-07 20:25:33.507827: train_loss -0.9551 
2024-11-07 20:25:33.512636: val_loss -0.7366 
2024-11-07 20:25:33.515158: Pseudo dice [np.float32(0.9434), np.float32(0.6568)] 
2024-11-07 20:25:33.517457: Epoch time: 39.61 s 
2024-11-07 20:25:34.753308:  
2024-11-07 20:25:34.755838: Epoch 889 
2024-11-07 20:25:34.758297: Current learning rate: 0.00138 
2024-11-07 20:26:14.502557: train_loss -0.949 
2024-11-07 20:26:14.505303: val_loss -0.7267 
2024-11-07 20:26:14.507785: Pseudo dice [np.float32(0.9517), np.float32(0.604)] 
2024-11-07 20:26:14.510196: Epoch time: 39.75 s 
2024-11-07 20:26:15.743037:  
2024-11-07 20:26:15.745706: Epoch 890 
2024-11-07 20:26:15.748179: Current learning rate: 0.00137 
2024-11-07 20:26:55.336543: train_loss -0.9566 
2024-11-07 20:26:55.341637: val_loss -0.731 
2024-11-07 20:26:55.344007: Pseudo dice [np.float32(0.9489), np.float32(0.6203)] 
2024-11-07 20:26:55.346431: Epoch time: 39.59 s 
2024-11-07 20:26:56.574189:  
2024-11-07 20:26:56.576569: Epoch 891 
2024-11-07 20:26:56.578983: Current learning rate: 0.00136 
2024-11-07 20:27:36.180791: train_loss -0.9564 
2024-11-07 20:27:36.183784: val_loss -0.7265 
2024-11-07 20:27:36.186244: Pseudo dice [np.float32(0.951), np.float32(0.6243)] 
2024-11-07 20:27:36.188934: Epoch time: 39.61 s 
2024-11-07 20:27:37.419111:  
2024-11-07 20:27:37.421539: Epoch 892 
2024-11-07 20:27:37.423909: Current learning rate: 0.00135 
2024-11-07 20:28:17.037658: train_loss -0.9481 
2024-11-07 20:28:17.043615: val_loss -0.7577 
2024-11-07 20:28:17.046351: Pseudo dice [np.float32(0.9521), np.float32(0.669)] 
2024-11-07 20:28:17.048855: Epoch time: 39.62 s 
2024-11-07 20:28:18.930995:  
2024-11-07 20:28:18.933820: Epoch 893 
2024-11-07 20:28:18.936329: Current learning rate: 0.00134 
2024-11-07 20:28:58.527721: train_loss -0.9522 
2024-11-07 20:28:58.530233: val_loss -0.7423 
2024-11-07 20:28:58.532706: Pseudo dice [np.float32(0.9457), np.float32(0.6457)] 
2024-11-07 20:28:58.535351: Epoch time: 39.6 s 
2024-11-07 20:28:59.765359:  
2024-11-07 20:28:59.768189: Epoch 894 
2024-11-07 20:28:59.771140: Current learning rate: 0.00133 
2024-11-07 20:29:39.398457: train_loss -0.9493 
2024-11-07 20:29:39.403793: val_loss -0.6891 
2024-11-07 20:29:39.405909: Pseudo dice [np.float32(0.9414), np.float32(0.5699)] 
2024-11-07 20:29:39.408576: Epoch time: 39.63 s 
2024-11-07 20:29:40.662988:  
2024-11-07 20:29:40.666938: Epoch 895 
2024-11-07 20:29:40.669467: Current learning rate: 0.00132 
2024-11-07 20:30:20.353375: train_loss -0.9557 
2024-11-07 20:30:20.356467: val_loss -0.6635 
2024-11-07 20:30:20.358968: Pseudo dice [np.float32(0.9459), np.float32(0.5255)] 
2024-11-07 20:30:20.361367: Epoch time: 39.69 s 
2024-11-07 20:30:21.594833:  
2024-11-07 20:30:21.597705: Epoch 896 
2024-11-07 20:30:21.600251: Current learning rate: 0.0013 
2024-11-07 20:31:01.296563: train_loss -0.9564 
2024-11-07 20:31:01.301788: val_loss -0.6926 
2024-11-07 20:31:01.304380: Pseudo dice [np.float32(0.9461), np.float32(0.6018)] 
2024-11-07 20:31:01.306719: Epoch time: 39.7 s 
2024-11-07 20:31:02.533410:  
2024-11-07 20:31:02.536213: Epoch 897 
2024-11-07 20:31:02.538704: Current learning rate: 0.00129 
2024-11-07 20:31:42.215027: train_loss -0.9577 
2024-11-07 20:31:42.219407: val_loss -0.6667 
2024-11-07 20:31:42.221636: Pseudo dice [np.float32(0.9474), np.float32(0.5559)] 
2024-11-07 20:31:42.224214: Epoch time: 39.68 s 
2024-11-07 20:31:43.458882:  
2024-11-07 20:31:43.461813: Epoch 898 
2024-11-07 20:31:43.464388: Current learning rate: 0.00128 
2024-11-07 20:32:23.249669: train_loss -0.9564 
2024-11-07 20:32:23.255903: val_loss -0.7313 
2024-11-07 20:32:23.258416: Pseudo dice [np.float32(0.9487), np.float32(0.6394)] 
2024-11-07 20:32:23.260945: Epoch time: 39.79 s 
2024-11-07 20:32:24.502049:  
2024-11-07 20:32:24.504315: Epoch 899 
2024-11-07 20:32:24.506824: Current learning rate: 0.00127 
2024-11-07 20:33:04.209215: train_loss -0.9519 
2024-11-07 20:33:04.212290: val_loss -0.7196 
2024-11-07 20:33:04.214780: Pseudo dice [np.float32(0.945), np.float32(0.6465)] 
2024-11-07 20:33:04.217004: Epoch time: 39.71 s 
2024-11-07 20:33:06.283162:  
2024-11-07 20:33:06.286246: Epoch 900 
2024-11-07 20:33:06.288633: Current learning rate: 0.00126 
2024-11-07 20:33:45.963213: train_loss -0.9561 
2024-11-07 20:33:45.968516: val_loss -0.705 
2024-11-07 20:33:45.970666: Pseudo dice [np.float32(0.9507), np.float32(0.6131)] 
2024-11-07 20:33:45.972933: Epoch time: 39.68 s 
2024-11-07 20:33:47.200357:  
2024-11-07 20:33:47.202887: Epoch 901 
2024-11-07 20:33:47.205706: Current learning rate: 0.00125 
2024-11-07 20:34:26.829724: train_loss -0.9553 
2024-11-07 20:34:26.833106: val_loss -0.7175 
2024-11-07 20:34:26.835906: Pseudo dice [np.float32(0.9487), np.float32(0.6175)] 
2024-11-07 20:34:26.838645: Epoch time: 39.63 s 
2024-11-07 20:34:28.061899:  
2024-11-07 20:34:28.064248: Epoch 902 
2024-11-07 20:34:28.066584: Current learning rate: 0.00124 
2024-11-07 20:35:07.716102: train_loss -0.9569 
2024-11-07 20:35:07.721741: val_loss -0.7404 
2024-11-07 20:35:07.724254: Pseudo dice [np.float32(0.9444), np.float32(0.6723)] 
2024-11-07 20:35:07.726513: Epoch time: 39.66 s 
2024-11-07 20:35:08.946467:  
2024-11-07 20:35:08.950597: Epoch 903 
2024-11-07 20:35:08.953212: Current learning rate: 0.00122 
2024-11-07 20:35:48.664188: train_loss -0.9558 
2024-11-07 20:35:48.668777: val_loss -0.6929 
2024-11-07 20:35:48.671289: Pseudo dice [np.float32(0.9392), np.float32(0.5874)] 
2024-11-07 20:35:48.673502: Epoch time: 39.72 s 
2024-11-07 20:35:49.906231:  
2024-11-07 20:35:49.908678: Epoch 904 
2024-11-07 20:35:49.910770: Current learning rate: 0.00121 
2024-11-07 20:36:29.647324: train_loss -0.9562 
2024-11-07 20:36:29.652662: val_loss -0.662 
2024-11-07 20:36:29.655217: Pseudo dice [np.float32(0.9439), np.float32(0.5454)] 
2024-11-07 20:36:29.657563: Epoch time: 39.74 s 
2024-11-07 20:36:30.893477:  
2024-11-07 20:36:30.895960: Epoch 905 
2024-11-07 20:36:30.898311: Current learning rate: 0.0012 
2024-11-07 20:37:10.590640: train_loss -0.9564 
2024-11-07 20:37:10.593675: val_loss -0.7081 
2024-11-07 20:37:10.595947: Pseudo dice [np.float32(0.9502), np.float32(0.6185)] 
2024-11-07 20:37:10.598527: Epoch time: 39.7 s 
2024-11-07 20:37:11.825498:  
2024-11-07 20:37:11.828289: Epoch 906 
2024-11-07 20:37:11.830488: Current learning rate: 0.00119 
2024-11-07 20:37:51.485718: train_loss -0.9537 
2024-11-07 20:37:51.492055: val_loss -0.6778 
2024-11-07 20:37:51.494898: Pseudo dice [np.float32(0.9448), np.float32(0.5869)] 
2024-11-07 20:37:51.497467: Epoch time: 39.66 s 
2024-11-07 20:37:52.719233:  
2024-11-07 20:37:52.721639: Epoch 907 
2024-11-07 20:37:52.723971: Current learning rate: 0.00118 
2024-11-07 20:38:32.364012: train_loss -0.9573 
2024-11-07 20:38:32.367279: val_loss -0.7064 
2024-11-07 20:38:32.369978: Pseudo dice [np.float32(0.9487), np.float32(0.5887)] 
2024-11-07 20:38:32.372554: Epoch time: 39.65 s 
2024-11-07 20:38:33.599828:  
2024-11-07 20:38:33.602723: Epoch 908 
2024-11-07 20:38:33.605193: Current learning rate: 0.00117 
2024-11-07 20:39:13.290675: train_loss -0.9592 
2024-11-07 20:39:13.300052: val_loss -0.7181 
2024-11-07 20:39:13.302350: Pseudo dice [np.float32(0.9447), np.float32(0.6144)] 
2024-11-07 20:39:13.304590: Epoch time: 39.69 s 
2024-11-07 20:39:14.523155:  
2024-11-07 20:39:14.525778: Epoch 909 
2024-11-07 20:39:14.528384: Current learning rate: 0.00116 
2024-11-07 20:39:54.242217: train_loss -0.9581 
2024-11-07 20:39:54.244762: val_loss -0.6817 
2024-11-07 20:39:54.247100: Pseudo dice [np.float32(0.9425), np.float32(0.5738)] 
2024-11-07 20:39:54.249340: Epoch time: 39.72 s 
2024-11-07 20:39:55.461668:  
2024-11-07 20:39:55.463981: Epoch 910 
2024-11-07 20:39:55.466264: Current learning rate: 0.00115 
2024-11-07 20:40:35.163677: train_loss -0.9586 
2024-11-07 20:40:35.169398: val_loss -0.6816 
2024-11-07 20:40:35.171645: Pseudo dice [np.float32(0.9441), np.float32(0.5964)] 
2024-11-07 20:40:35.173697: Epoch time: 39.7 s 
2024-11-07 20:40:36.388196:  
2024-11-07 20:40:36.390494: Epoch 911 
2024-11-07 20:40:36.392854: Current learning rate: 0.00113 
2024-11-07 20:41:16.170083: train_loss -0.955 
2024-11-07 20:41:16.172944: val_loss -0.6613 
2024-11-07 20:41:16.175695: Pseudo dice [np.float32(0.946), np.float32(0.5086)] 
2024-11-07 20:41:16.178242: Epoch time: 39.78 s 
2024-11-07 20:41:17.397098:  
2024-11-07 20:41:17.399318: Epoch 912 
2024-11-07 20:41:17.401500: Current learning rate: 0.00112 
2024-11-07 20:41:57.113746: train_loss -0.959 
2024-11-07 20:41:57.118459: val_loss -0.7433 
2024-11-07 20:41:57.120691: Pseudo dice [np.float32(0.9499), np.float32(0.6513)] 
2024-11-07 20:41:57.122788: Epoch time: 39.72 s 
2024-11-07 20:41:59.024762:  
2024-11-07 20:41:59.027052: Epoch 913 
2024-11-07 20:41:59.029336: Current learning rate: 0.00111 
2024-11-07 20:42:38.767062: train_loss -0.9592 
2024-11-07 20:42:38.769777: val_loss -0.7106 
2024-11-07 20:42:38.772098: Pseudo dice [np.float32(0.9458), np.float32(0.5785)] 
2024-11-07 20:42:38.774505: Epoch time: 39.74 s 
2024-11-07 20:42:40.007444:  
2024-11-07 20:42:40.010239: Epoch 914 
2024-11-07 20:42:40.012746: Current learning rate: 0.0011 
2024-11-07 20:43:19.626324: train_loss -0.9579 
2024-11-07 20:43:19.634517: val_loss -0.6675 
2024-11-07 20:43:19.636575: Pseudo dice [np.float32(0.9476), np.float32(0.5689)] 
2024-11-07 20:43:19.638960: Epoch time: 39.62 s 
2024-11-07 20:43:20.870370:  
2024-11-07 20:43:20.872929: Epoch 915 
2024-11-07 20:43:20.875663: Current learning rate: 0.00109 
2024-11-07 20:44:00.583100: train_loss -0.9594 
2024-11-07 20:44:00.585598: val_loss -0.6668 
2024-11-07 20:44:00.588216: Pseudo dice [np.float32(0.9464), np.float32(0.5479)] 
2024-11-07 20:44:00.590401: Epoch time: 39.71 s 
2024-11-07 20:44:01.824826:  
2024-11-07 20:44:01.827450: Epoch 916 
2024-11-07 20:44:01.829931: Current learning rate: 0.00108 
2024-11-07 20:44:41.560032: train_loss -0.9589 
2024-11-07 20:44:41.565930: val_loss -0.6953 
2024-11-07 20:44:41.568703: Pseudo dice [np.float32(0.9495), np.float32(0.5539)] 
2024-11-07 20:44:41.571449: Epoch time: 39.74 s 
2024-11-07 20:44:42.801511:  
2024-11-07 20:44:42.803945: Epoch 917 
2024-11-07 20:44:42.806497: Current learning rate: 0.00106 
2024-11-07 20:45:22.554701: train_loss -0.9571 
2024-11-07 20:45:22.557666: val_loss -0.6886 
2024-11-07 20:45:22.560240: Pseudo dice [np.float32(0.9461), np.float32(0.5366)] 
2024-11-07 20:45:22.562648: Epoch time: 39.75 s 
2024-11-07 20:45:23.780273:  
2024-11-07 20:45:23.782940: Epoch 918 
2024-11-07 20:45:23.785991: Current learning rate: 0.00105 
2024-11-07 20:46:03.539397: train_loss -0.9573 
2024-11-07 20:46:03.544905: val_loss -0.7101 
2024-11-07 20:46:03.547117: Pseudo dice [np.float32(0.9467), np.float32(0.5785)] 
2024-11-07 20:46:03.549414: Epoch time: 39.76 s 
2024-11-07 20:46:04.796043:  
2024-11-07 20:46:04.799007: Epoch 919 
2024-11-07 20:46:04.801348: Current learning rate: 0.00104 
2024-11-07 20:46:44.574161: train_loss -0.9598 
2024-11-07 20:46:44.577229: val_loss -0.7534 
2024-11-07 20:46:44.579774: Pseudo dice [np.float32(0.9501), np.float32(0.66)] 
2024-11-07 20:46:44.582293: Epoch time: 39.78 s 
2024-11-07 20:46:45.813539:  
2024-11-07 20:46:45.815802: Epoch 920 
2024-11-07 20:46:45.818319: Current learning rate: 0.00103 
2024-11-07 20:47:25.658240: train_loss -0.9589 
2024-11-07 20:47:25.665676: val_loss -0.7387 
2024-11-07 20:47:25.668181: Pseudo dice [np.float32(0.9473), np.float32(0.677)] 
2024-11-07 20:47:25.670393: Epoch time: 39.85 s 
2024-11-07 20:47:26.909685:  
2024-11-07 20:47:26.912704: Epoch 921 
2024-11-07 20:47:26.915259: Current learning rate: 0.00102 
2024-11-07 20:48:06.738275: train_loss -0.954 
2024-11-07 20:48:06.741129: val_loss -0.7533 
2024-11-07 20:48:06.743454: Pseudo dice [np.float32(0.9447), np.float32(0.6498)] 
2024-11-07 20:48:06.745661: Epoch time: 39.83 s 
2024-11-07 20:48:07.965400:  
2024-11-07 20:48:07.968073: Epoch 922 
2024-11-07 20:48:07.970542: Current learning rate: 0.00101 
2024-11-07 20:48:47.705046: train_loss -0.9592 
2024-11-07 20:48:47.711000: val_loss -0.6781 
2024-11-07 20:48:47.713626: Pseudo dice [np.float32(0.9501), np.float32(0.523)] 
2024-11-07 20:48:47.716050: Epoch time: 39.74 s 
2024-11-07 20:48:48.942485:  
2024-11-07 20:48:48.945197: Epoch 923 
2024-11-07 20:48:48.947697: Current learning rate: 0.001 
2024-11-07 20:49:28.704046: train_loss -0.9581 
2024-11-07 20:49:28.706875: val_loss -0.7041 
2024-11-07 20:49:28.709262: Pseudo dice [np.float32(0.9481), np.float32(0.5294)] 
2024-11-07 20:49:28.711786: Epoch time: 39.76 s 
2024-11-07 20:49:29.939076:  
2024-11-07 20:49:29.941677: Epoch 924 
2024-11-07 20:49:29.944069: Current learning rate: 0.00098 
2024-11-07 20:50:09.751271: train_loss -0.9583 
2024-11-07 20:50:09.757188: val_loss -0.7594 
2024-11-07 20:50:09.759544: Pseudo dice [np.float32(0.9497), np.float32(0.6491)] 
2024-11-07 20:50:09.761796: Epoch time: 39.81 s 
2024-11-07 20:50:10.999608:  
2024-11-07 20:50:11.002328: Epoch 925 
2024-11-07 20:50:11.005414: Current learning rate: 0.00097 
2024-11-07 20:50:50.690241: train_loss -0.9576 
2024-11-07 20:50:50.693134: val_loss -0.7199 
2024-11-07 20:50:50.695763: Pseudo dice [np.float32(0.9511), np.float32(0.6199)] 
2024-11-07 20:50:50.698034: Epoch time: 39.69 s 
2024-11-07 20:50:51.922769:  
2024-11-07 20:50:51.925445: Epoch 926 
2024-11-07 20:50:51.928055: Current learning rate: 0.00096 
2024-11-07 20:51:31.653773: train_loss -0.9564 
2024-11-07 20:51:31.667400: val_loss -0.7118 
2024-11-07 20:51:31.669890: Pseudo dice [np.float32(0.9466), np.float32(0.5974)] 
2024-11-07 20:51:31.672193: Epoch time: 39.73 s 
2024-11-07 20:51:32.901514:  
2024-11-07 20:51:32.903987: Epoch 927 
2024-11-07 20:51:32.906402: Current learning rate: 0.00095 
2024-11-07 20:52:12.625334: train_loss -0.9551 
2024-11-07 20:52:12.628003: val_loss -0.7022 
2024-11-07 20:52:12.630327: Pseudo dice [np.float32(0.9509), np.float32(0.5687)] 
2024-11-07 20:52:12.633250: Epoch time: 39.72 s 
2024-11-07 20:52:13.865121:  
2024-11-07 20:52:13.868249: Epoch 928 
2024-11-07 20:52:13.871157: Current learning rate: 0.00094 
2024-11-07 20:52:53.553162: train_loss -0.9553 
2024-11-07 20:52:53.558742: val_loss -0.6646 
2024-11-07 20:52:53.561278: Pseudo dice [np.float32(0.9477), np.float32(0.5347)] 
2024-11-07 20:52:53.563777: Epoch time: 39.69 s 
2024-11-07 20:52:54.776846:  
2024-11-07 20:52:54.779404: Epoch 929 
2024-11-07 20:52:54.781907: Current learning rate: 0.00092 
2024-11-07 20:53:34.457727: train_loss -0.9587 
2024-11-07 20:53:34.461052: val_loss -0.696 
2024-11-07 20:53:34.463632: Pseudo dice [np.float32(0.9467), np.float32(0.5988)] 
2024-11-07 20:53:34.465861: Epoch time: 39.68 s 
2024-11-07 20:53:35.696691:  
2024-11-07 20:53:35.699345: Epoch 930 
2024-11-07 20:53:35.701961: Current learning rate: 0.00091 
2024-11-07 20:54:15.413400: train_loss -0.9558 
2024-11-07 20:54:15.418672: val_loss -0.6572 
2024-11-07 20:54:15.421051: Pseudo dice [np.float32(0.9385), np.float32(0.4902)] 
2024-11-07 20:54:15.423502: Epoch time: 39.72 s 
2024-11-07 20:54:16.650653:  
2024-11-07 20:54:16.653223: Epoch 931 
2024-11-07 20:54:16.655678: Current learning rate: 0.0009 
2024-11-07 20:54:56.316307: train_loss -0.9555 
2024-11-07 20:54:56.319723: val_loss -0.7224 
2024-11-07 20:54:56.322478: Pseudo dice [np.float32(0.9492), np.float32(0.618)] 
2024-11-07 20:54:56.325052: Epoch time: 39.67 s 
2024-11-07 20:54:57.552229:  
2024-11-07 20:54:57.555036: Epoch 932 
2024-11-07 20:54:57.557589: Current learning rate: 0.00089 
2024-11-07 20:55:37.199049: train_loss -0.9585 
2024-11-07 20:55:37.204409: val_loss -0.7208 
2024-11-07 20:55:37.207356: Pseudo dice [np.float32(0.9522), np.float32(0.6266)] 
2024-11-07 20:55:37.209745: Epoch time: 39.65 s 
2024-11-07 20:55:39.096984:  
2024-11-07 20:55:39.099386: Epoch 933 
2024-11-07 20:55:39.102172: Current learning rate: 0.00088 
2024-11-07 20:56:18.823683: train_loss -0.9579 
2024-11-07 20:56:18.826873: val_loss -0.6813 
2024-11-07 20:56:18.829519: Pseudo dice [np.float32(0.9396), np.float32(0.5961)] 
2024-11-07 20:56:18.832364: Epoch time: 39.73 s 
2024-11-07 20:56:20.065674:  
2024-11-07 20:56:20.068367: Epoch 934 
2024-11-07 20:56:20.071014: Current learning rate: 0.00087 
2024-11-07 20:56:59.777026: train_loss -0.959 
2024-11-07 20:56:59.782033: val_loss -0.6811 
2024-11-07 20:56:59.784172: Pseudo dice [np.float32(0.9482), np.float32(0.5226)] 
2024-11-07 20:56:59.786621: Epoch time: 39.71 s 
2024-11-07 20:57:01.021065:  
2024-11-07 20:57:01.023786: Epoch 935 
2024-11-07 20:57:01.026834: Current learning rate: 0.00085 
2024-11-07 20:57:40.691544: train_loss -0.961 
2024-11-07 20:57:40.697846: val_loss -0.7282 
2024-11-07 20:57:40.700432: Pseudo dice [np.float32(0.95), np.float32(0.6145)] 
2024-11-07 20:57:40.702881: Epoch time: 39.67 s 
2024-11-07 20:57:41.915621:  
2024-11-07 20:57:41.918603: Epoch 936 
2024-11-07 20:57:41.921073: Current learning rate: 0.00084 
2024-11-07 20:58:21.572675: train_loss -0.9583 
2024-11-07 20:58:21.728953: val_loss -0.6755 
2024-11-07 20:58:21.731592: Pseudo dice [np.float32(0.9492), np.float32(0.5502)] 
2024-11-07 20:58:21.734345: Epoch time: 39.66 s 
2024-11-07 20:58:22.961180:  
2024-11-07 20:58:22.963923: Epoch 937 
2024-11-07 20:58:22.966854: Current learning rate: 0.00083 
2024-11-07 20:59:02.607800: train_loss -0.9545 
2024-11-07 20:59:02.610554: val_loss -0.7101 
2024-11-07 20:59:02.612849: Pseudo dice [np.float32(0.9479), np.float32(0.6091)] 
2024-11-07 20:59:02.615488: Epoch time: 39.65 s 
2024-11-07 20:59:03.847600:  
2024-11-07 20:59:03.850341: Epoch 938 
2024-11-07 20:59:03.852837: Current learning rate: 0.00082 
2024-11-07 20:59:43.501420: train_loss -0.9599 
2024-11-07 20:59:43.506781: val_loss -0.6973 
2024-11-07 20:59:43.509002: Pseudo dice [np.float32(0.9442), np.float32(0.5988)] 
2024-11-07 20:59:43.511554: Epoch time: 39.66 s 
2024-11-07 20:59:44.747976:  
2024-11-07 20:59:44.750661: Epoch 939 
2024-11-07 20:59:44.753157: Current learning rate: 0.00081 
2024-11-07 21:00:24.526435: train_loss -0.9625 
2024-11-07 21:00:24.529292: val_loss -0.7069 
2024-11-07 21:00:24.531464: Pseudo dice [np.float32(0.9514), np.float32(0.6261)] 
2024-11-07 21:00:24.533978: Epoch time: 39.78 s 
2024-11-07 21:00:25.793894:  
2024-11-07 21:00:25.796641: Epoch 940 
2024-11-07 21:00:25.799629: Current learning rate: 0.00079 
2024-11-07 21:01:05.532186: train_loss -0.9596 
2024-11-07 21:01:05.567607: val_loss -0.6861 
2024-11-07 21:01:05.569983: Pseudo dice [np.float32(0.9459), np.float32(0.5553)] 
2024-11-07 21:01:05.572063: Epoch time: 39.74 s 
2024-11-07 21:01:06.808461:  
2024-11-07 21:01:06.812230: Epoch 941 
2024-11-07 21:01:06.814935: Current learning rate: 0.00078 
2024-11-07 21:01:46.462172: train_loss -0.9544 
2024-11-07 21:01:46.464881: val_loss -0.6912 
2024-11-07 21:01:46.467356: Pseudo dice [np.float32(0.9442), np.float32(0.5681)] 
2024-11-07 21:01:46.469488: Epoch time: 39.65 s 
2024-11-07 21:01:47.701896:  
2024-11-07 21:01:47.704445: Epoch 942 
2024-11-07 21:01:47.707408: Current learning rate: 0.00077 
2024-11-07 21:02:27.407601: train_loss -0.9584 
2024-11-07 21:02:27.413422: val_loss -0.699 
2024-11-07 21:02:27.415946: Pseudo dice [np.float32(0.9488), np.float32(0.5523)] 
2024-11-07 21:02:27.418371: Epoch time: 39.71 s 
2024-11-07 21:02:28.693655:  
2024-11-07 21:02:28.696193: Epoch 943 
2024-11-07 21:02:28.698558: Current learning rate: 0.00076 
2024-11-07 21:03:08.361017: train_loss -0.9606 
2024-11-07 21:03:08.363651: val_loss -0.757 
2024-11-07 21:03:08.366119: Pseudo dice [np.float32(0.9478), np.float32(0.6385)] 
2024-11-07 21:03:08.368553: Epoch time: 39.67 s 
2024-11-07 21:03:09.806737:  
2024-11-07 21:03:09.809768: Epoch 944 
2024-11-07 21:03:09.812922: Current learning rate: 0.00075 
2024-11-07 21:03:49.571559: train_loss -0.9607 
2024-11-07 21:03:49.576625: val_loss -0.7241 
2024-11-07 21:03:49.579334: Pseudo dice [np.float32(0.9503), np.float32(0.6236)] 
2024-11-07 21:03:49.581732: Epoch time: 39.77 s 
2024-11-07 21:03:50.803173:  
2024-11-07 21:03:50.806736: Epoch 945 
2024-11-07 21:03:50.808787: Current learning rate: 0.00074 
2024-11-07 21:04:30.542039: train_loss -0.96 
2024-11-07 21:04:30.545013: val_loss -0.6888 
2024-11-07 21:04:30.547508: Pseudo dice [np.float32(0.9495), np.float32(0.5645)] 
2024-11-07 21:04:30.549783: Epoch time: 39.74 s 
2024-11-07 21:04:31.773304:  
2024-11-07 21:04:31.776074: Epoch 946 
2024-11-07 21:04:31.779057: Current learning rate: 0.00072 
2024-11-07 21:05:11.449766: train_loss -0.9607 
2024-11-07 21:05:11.455190: val_loss -0.7122 
2024-11-07 21:05:11.457607: Pseudo dice [np.float32(0.948), np.float32(0.6102)] 
2024-11-07 21:05:11.462344: Epoch time: 39.68 s 
2024-11-07 21:05:12.712773:  
2024-11-07 21:05:12.715232: Epoch 947 
2024-11-07 21:05:12.717522: Current learning rate: 0.00071 
2024-11-07 21:05:52.387699: train_loss -0.9602 
2024-11-07 21:05:52.391103: val_loss -0.6812 
2024-11-07 21:05:52.393533: Pseudo dice [np.float32(0.9486), np.float32(0.5032)] 
2024-11-07 21:05:52.395700: Epoch time: 39.68 s 
2024-11-07 21:05:53.628500:  
2024-11-07 21:05:53.631027: Epoch 948 
2024-11-07 21:05:53.633461: Current learning rate: 0.0007 
2024-11-07 21:06:33.342721: train_loss -0.9568 
2024-11-07 21:06:33.347963: val_loss -0.67 
2024-11-07 21:06:33.350248: Pseudo dice [np.float32(0.9426), np.float32(0.5374)] 
2024-11-07 21:06:33.352501: Epoch time: 39.72 s 
2024-11-07 21:06:34.581795:  
2024-11-07 21:06:34.584239: Epoch 949 
2024-11-07 21:06:34.586904: Current learning rate: 0.00069 
2024-11-07 21:07:14.299861: train_loss -0.9613 
2024-11-07 21:07:14.302960: val_loss -0.7315 
2024-11-07 21:07:14.305508: Pseudo dice [np.float32(0.9475), np.float32(0.6196)] 
2024-11-07 21:07:14.307720: Epoch time: 39.72 s 
2024-11-07 21:07:16.305434:  
2024-11-07 21:07:16.308111: Epoch 950 
2024-11-07 21:07:16.310783: Current learning rate: 0.00067 
2024-11-07 21:07:55.963999: train_loss -0.9627 
2024-11-07 21:07:55.969789: val_loss -0.7394 
2024-11-07 21:07:55.972076: Pseudo dice [np.float32(0.9455), np.float32(0.6492)] 
2024-11-07 21:07:55.974504: Epoch time: 39.66 s 
2024-11-07 21:07:57.206446:  
2024-11-07 21:07:57.208787: Epoch 951 
2024-11-07 21:07:57.211240: Current learning rate: 0.00066 
2024-11-07 21:08:36.895360: train_loss -0.9591 
2024-11-07 21:08:36.898069: val_loss -0.7513 
2024-11-07 21:08:36.900439: Pseudo dice [np.float32(0.9557), np.float32(0.6102)] 
2024-11-07 21:08:36.902684: Epoch time: 39.69 s 
2024-11-07 21:08:38.136500:  
2024-11-07 21:08:38.140342: Epoch 952 
2024-11-07 21:08:38.142904: Current learning rate: 0.00065 
2024-11-07 21:09:17.768507: train_loss -0.9633 
2024-11-07 21:09:17.773963: val_loss -0.7 
2024-11-07 21:09:17.776333: Pseudo dice [np.float32(0.9522), np.float32(0.5514)] 
2024-11-07 21:09:17.779063: Epoch time: 39.63 s 
2024-11-07 21:09:19.664527:  
2024-11-07 21:09:19.667276: Epoch 953 
2024-11-07 21:09:19.669785: Current learning rate: 0.00064 
2024-11-07 21:09:59.365505: train_loss -0.9603 
2024-11-07 21:09:59.369548: val_loss -0.6801 
2024-11-07 21:09:59.372062: Pseudo dice [np.float32(0.9489), np.float32(0.5652)] 
2024-11-07 21:09:59.374358: Epoch time: 39.7 s 
2024-11-07 21:10:00.624089:  
2024-11-07 21:10:00.626678: Epoch 954 
2024-11-07 21:10:00.629182: Current learning rate: 0.00063 
2024-11-07 21:10:40.339093: train_loss -0.9596 
2024-11-07 21:10:40.344504: val_loss -0.7236 
2024-11-07 21:10:40.346818: Pseudo dice [np.float32(0.943), np.float32(0.6678)] 
2024-11-07 21:10:40.349423: Epoch time: 39.72 s 
2024-11-07 21:10:41.591531:  
2024-11-07 21:10:41.593816: Epoch 955 
2024-11-07 21:10:41.596255: Current learning rate: 0.00061 
2024-11-07 21:11:21.286799: train_loss -0.9531 
2024-11-07 21:11:21.289824: val_loss -0.7765 
2024-11-07 21:11:21.292335: Pseudo dice [np.float32(0.9439), np.float32(0.7099)] 
2024-11-07 21:11:21.294654: Epoch time: 39.7 s 
2024-11-07 21:11:22.535282:  
2024-11-07 21:11:22.537647: Epoch 956 
2024-11-07 21:11:22.540377: Current learning rate: 0.0006 
2024-11-07 21:12:02.229620: train_loss -0.9563 
2024-11-07 21:12:02.235513: val_loss -0.7358 
2024-11-07 21:12:02.237972: Pseudo dice [np.float32(0.946), np.float32(0.6367)] 
2024-11-07 21:12:02.240124: Epoch time: 39.7 s 
2024-11-07 21:12:03.481674:  
2024-11-07 21:12:03.484798: Epoch 957 
2024-11-07 21:12:03.487652: Current learning rate: 0.00059 
2024-11-07 21:12:43.190673: train_loss -0.9573 
2024-11-07 21:12:43.193583: val_loss -0.7031 
2024-11-07 21:12:43.195788: Pseudo dice [np.float32(0.9443), np.float32(0.6031)] 
2024-11-07 21:12:43.197924: Epoch time: 39.71 s 
2024-11-07 21:12:44.442603:  
2024-11-07 21:12:44.445043: Epoch 958 
2024-11-07 21:12:44.448723: Current learning rate: 0.00058 
2024-11-07 21:13:24.125679: train_loss -0.9564 
2024-11-07 21:13:24.130936: val_loss -0.7362 
2024-11-07 21:13:24.133303: Pseudo dice [np.float32(0.951), np.float32(0.6317)] 
2024-11-07 21:13:24.135404: Epoch time: 39.68 s 
2024-11-07 21:13:25.385101:  
2024-11-07 21:13:25.387717: Epoch 959 
2024-11-07 21:13:25.390073: Current learning rate: 0.00056 
2024-11-07 21:14:05.102000: train_loss -0.9586 
2024-11-07 21:14:05.104904: val_loss -0.7431 
2024-11-07 21:14:05.107265: Pseudo dice [np.float32(0.9443), np.float32(0.6437)] 
2024-11-07 21:14:05.109786: Epoch time: 39.72 s 
2024-11-07 21:14:06.359328:  
2024-11-07 21:14:06.361744: Epoch 960 
2024-11-07 21:14:06.363943: Current learning rate: 0.00055 
2024-11-07 21:14:46.027400: train_loss -0.9612 
2024-11-07 21:14:46.032393: val_loss -0.7228 
2024-11-07 21:14:46.034635: Pseudo dice [np.float32(0.9526), np.float32(0.6356)] 
2024-11-07 21:14:46.036894: Epoch time: 39.67 s 
2024-11-07 21:14:47.276003:  
2024-11-07 21:14:47.278533: Epoch 961 
2024-11-07 21:14:47.280813: Current learning rate: 0.00054 
2024-11-07 21:15:26.926235: train_loss -0.9622 
2024-11-07 21:15:26.929350: val_loss -0.7267 
2024-11-07 21:15:26.931778: Pseudo dice [np.float32(0.9523), np.float32(0.628)] 
2024-11-07 21:15:26.934176: Epoch time: 39.65 s 
2024-11-07 21:15:28.185971:  
2024-11-07 21:15:28.188305: Epoch 962 
2024-11-07 21:15:28.190709: Current learning rate: 0.00053 
2024-11-07 21:16:07.898111: train_loss -0.9624 
2024-11-07 21:16:07.903295: val_loss -0.6765 
2024-11-07 21:16:07.905953: Pseudo dice [np.float32(0.9428), np.float32(0.6055)] 
2024-11-07 21:16:07.908452: Epoch time: 39.71 s 
2024-11-07 21:16:09.152409:  
2024-11-07 21:16:09.155116: Epoch 963 
2024-11-07 21:16:09.157846: Current learning rate: 0.00051 
2024-11-07 21:16:48.913854: train_loss -0.9565 
2024-11-07 21:16:48.916971: val_loss -0.6633 
2024-11-07 21:16:48.919403: Pseudo dice [np.float32(0.9424), np.float32(0.5663)] 
2024-11-07 21:16:48.921758: Epoch time: 39.76 s 
2024-11-07 21:16:50.162447:  
2024-11-07 21:16:50.164886: Epoch 964 
2024-11-07 21:16:50.167268: Current learning rate: 0.0005 
2024-11-07 21:17:29.978919: train_loss -0.9601 
2024-11-07 21:17:29.983965: val_loss -0.6884 
2024-11-07 21:17:29.986273: Pseudo dice [np.float32(0.9417), np.float32(0.5881)] 
2024-11-07 21:17:29.988607: Epoch time: 39.82 s 
2024-11-07 21:17:31.220029:  
2024-11-07 21:17:31.222744: Epoch 965 
2024-11-07 21:17:31.225333: Current learning rate: 0.00049 
2024-11-07 21:18:10.948064: train_loss -0.9632 
2024-11-07 21:18:10.958182: val_loss -0.6971 
2024-11-07 21:18:10.960687: Pseudo dice [np.float32(0.9476), np.float32(0.5861)] 
2024-11-07 21:18:10.963413: Epoch time: 39.73 s 
2024-11-07 21:18:12.210102:  
2024-11-07 21:18:12.212805: Epoch 966 
2024-11-07 21:18:12.215361: Current learning rate: 0.00048 
2024-11-07 21:18:51.864597: train_loss -0.962 
2024-11-07 21:18:51.869755: val_loss -0.7046 
2024-11-07 21:18:51.872089: Pseudo dice [np.float32(0.9452), np.float32(0.612)] 
2024-11-07 21:18:51.874778: Epoch time: 39.66 s 
2024-11-07 21:18:53.114504:  
2024-11-07 21:18:53.116919: Epoch 967 
2024-11-07 21:18:53.119228: Current learning rate: 0.00046 
2024-11-07 21:19:32.918703: train_loss -0.9621 
2024-11-07 21:19:32.921256: val_loss -0.7142 
2024-11-07 21:19:32.924041: Pseudo dice [np.float32(0.9429), np.float32(0.6414)] 
2024-11-07 21:19:32.926957: Epoch time: 39.81 s 
2024-11-07 21:19:34.179432:  
2024-11-07 21:19:34.181829: Epoch 968 
2024-11-07 21:19:34.184228: Current learning rate: 0.00045 
2024-11-07 21:20:13.920338: train_loss -0.9625 
2024-11-07 21:20:13.926133: val_loss -0.7166 
2024-11-07 21:20:13.930079: Pseudo dice [np.float32(0.9482), np.float32(0.5691)] 
2024-11-07 21:20:13.932503: Epoch time: 39.74 s 
2024-11-07 21:20:15.178858:  
2024-11-07 21:20:15.181064: Epoch 969 
2024-11-07 21:20:15.183376: Current learning rate: 0.00044 
2024-11-07 21:20:54.836504: train_loss -0.9616 
2024-11-07 21:20:54.841237: val_loss -0.7389 
2024-11-07 21:20:54.844780: Pseudo dice [np.float32(0.9415), np.float32(0.6757)] 
2024-11-07 21:20:54.848408: Epoch time: 39.66 s 
2024-11-07 21:20:56.100388:  
2024-11-07 21:20:56.103338: Epoch 970 
2024-11-07 21:20:56.106256: Current learning rate: 0.00043 
2024-11-07 21:21:35.788704: train_loss -0.9563 
2024-11-07 21:21:35.794195: val_loss -0.7079 
2024-11-07 21:21:35.796633: Pseudo dice [np.float32(0.9465), np.float32(0.5972)] 
2024-11-07 21:21:35.798863: Epoch time: 39.69 s 
2024-11-07 21:21:37.026099:  
2024-11-07 21:21:37.028497: Epoch 971 
2024-11-07 21:21:37.030855: Current learning rate: 0.00041 
2024-11-07 21:22:16.663352: train_loss -0.9596 
2024-11-07 21:22:16.666756: val_loss -0.7174 
2024-11-07 21:22:16.668969: Pseudo dice [np.float32(0.9477), np.float32(0.6031)] 
2024-11-07 21:22:16.671690: Epoch time: 39.64 s 
2024-11-07 21:22:17.920882:  
2024-11-07 21:22:17.923652: Epoch 972 
2024-11-07 21:22:17.925861: Current learning rate: 0.0004 
2024-11-07 21:22:57.604023: train_loss -0.959 
2024-11-07 21:22:57.616634: val_loss -0.6857 
2024-11-07 21:22:57.618905: Pseudo dice [np.float32(0.9472), np.float32(0.557)] 
2024-11-07 21:22:57.621549: Epoch time: 39.68 s 
2024-11-07 21:22:59.491180:  
2024-11-07 21:22:59.493651: Epoch 973 
2024-11-07 21:22:59.495997: Current learning rate: 0.00039 
2024-11-07 21:23:39.234267: train_loss -0.9571 
2024-11-07 21:23:39.237098: val_loss -0.7433 
2024-11-07 21:23:39.239587: Pseudo dice [np.float32(0.9471), np.float32(0.6791)] 
2024-11-07 21:23:39.241923: Epoch time: 39.74 s 
2024-11-07 21:23:40.477449:  
2024-11-07 21:23:40.480828: Epoch 974 
2024-11-07 21:23:40.483565: Current learning rate: 0.00037 
2024-11-07 21:24:20.129267: train_loss -0.9608 
2024-11-07 21:24:20.135944: val_loss -0.726 
2024-11-07 21:24:20.139143: Pseudo dice [np.float32(0.9433), np.float32(0.5953)] 
2024-11-07 21:24:20.141641: Epoch time: 39.65 s 
2024-11-07 21:24:21.380303:  
2024-11-07 21:24:21.382966: Epoch 975 
2024-11-07 21:24:21.385582: Current learning rate: 0.00036 
2024-11-07 21:25:01.158307: train_loss -0.958 
2024-11-07 21:25:01.163017: val_loss -0.7182 
2024-11-07 21:25:01.165274: Pseudo dice [np.float32(0.9485), np.float32(0.6054)] 
2024-11-07 21:25:01.167692: Epoch time: 39.78 s 
2024-11-07 21:25:02.410754:  
2024-11-07 21:25:02.413858: Epoch 976 
2024-11-07 21:25:02.416716: Current learning rate: 0.00035 
2024-11-07 21:25:42.131395: train_loss -0.9618 
2024-11-07 21:25:42.137394: val_loss -0.7154 
2024-11-07 21:25:42.139895: Pseudo dice [np.float32(0.9465), np.float32(0.6142)] 
2024-11-07 21:25:42.142154: Epoch time: 39.72 s 
2024-11-07 21:25:43.395943:  
2024-11-07 21:25:43.398851: Epoch 977 
2024-11-07 21:25:43.401137: Current learning rate: 0.00034 
2024-11-07 21:26:23.096464: train_loss -0.9647 
2024-11-07 21:26:23.099298: val_loss -0.7196 
2024-11-07 21:26:23.101819: Pseudo dice [np.float32(0.9452), np.float32(0.6577)] 
2024-11-07 21:26:23.104838: Epoch time: 39.7 s 
2024-11-07 21:26:24.356666:  
2024-11-07 21:26:24.359641: Epoch 978 
2024-11-07 21:26:24.362386: Current learning rate: 0.00032 
2024-11-07 21:27:03.994375: train_loss -0.9569 
2024-11-07 21:27:04.000381: val_loss -0.7523 
2024-11-07 21:27:04.003889: Pseudo dice [np.float32(0.9466), np.float32(0.6463)] 
2024-11-07 21:27:04.007165: Epoch time: 39.64 s 
2024-11-07 21:27:05.258877:  
2024-11-07 21:27:05.261898: Epoch 979 
2024-11-07 21:27:05.264281: Current learning rate: 0.00031 
2024-11-07 21:27:44.937511: train_loss -0.9636 
2024-11-07 21:27:44.941167: val_loss -0.6939 
2024-11-07 21:27:44.943995: Pseudo dice [np.float32(0.9481), np.float32(0.5726)] 
2024-11-07 21:27:44.946697: Epoch time: 39.68 s 
2024-11-07 21:27:46.196395:  
2024-11-07 21:27:46.198889: Epoch 980 
2024-11-07 21:27:46.201378: Current learning rate: 0.0003 
2024-11-07 21:28:25.876008: train_loss -0.961 
2024-11-07 21:28:25.881733: val_loss -0.6948 
2024-11-07 21:28:25.884946: Pseudo dice [np.float32(0.9465), np.float32(0.58)] 
2024-11-07 21:28:25.887354: Epoch time: 39.68 s 
2024-11-07 21:28:27.136253:  
2024-11-07 21:28:27.138716: Epoch 981 
2024-11-07 21:28:27.140981: Current learning rate: 0.00028 
2024-11-07 21:29:06.823420: train_loss -0.9597 
2024-11-07 21:29:06.826399: val_loss -0.6594 
2024-11-07 21:29:06.829188: Pseudo dice [np.float32(0.9457), np.float32(0.5336)] 
2024-11-07 21:29:06.831793: Epoch time: 39.69 s 
2024-11-07 21:29:08.083241:  
2024-11-07 21:29:08.086170: Epoch 982 
2024-11-07 21:29:08.089001: Current learning rate: 0.00027 
2024-11-07 21:29:47.697879: train_loss -0.9606 
2024-11-07 21:29:47.703796: val_loss -0.7186 
2024-11-07 21:29:47.706451: Pseudo dice [np.float32(0.9464), np.float32(0.5903)] 
2024-11-07 21:29:47.708968: Epoch time: 39.62 s 
2024-11-07 21:29:48.941062:  
2024-11-07 21:29:48.943879: Epoch 983 
2024-11-07 21:29:48.946589: Current learning rate: 0.00026 
2024-11-07 21:30:28.621172: train_loss -0.9659 
2024-11-07 21:30:28.625374: val_loss -0.6746 
2024-11-07 21:30:28.628103: Pseudo dice [np.float32(0.9524), np.float32(0.5256)] 
2024-11-07 21:30:28.630705: Epoch time: 39.68 s 
2024-11-07 21:30:29.872958:  
2024-11-07 21:30:29.875750: Epoch 984 
2024-11-07 21:30:29.878757: Current learning rate: 0.00024 
2024-11-07 21:31:09.565738: train_loss -0.9636 
2024-11-07 21:31:09.573077: val_loss -0.6866 
2024-11-07 21:31:09.575578: Pseudo dice [np.float32(0.9487), np.float32(0.5324)] 
2024-11-07 21:31:09.577967: Epoch time: 39.69 s 
2024-11-07 21:31:10.817057:  
2024-11-07 21:31:10.819395: Epoch 985 
2024-11-07 21:31:10.821801: Current learning rate: 0.00023 
2024-11-07 21:31:50.505815: train_loss -0.9599 
2024-11-07 21:31:50.508711: val_loss -0.7558 
2024-11-07 21:31:50.511186: Pseudo dice [np.float32(0.9489), np.float32(0.6922)] 
2024-11-07 21:31:50.513679: Epoch time: 39.69 s 
2024-11-07 21:31:51.750592:  
2024-11-07 21:31:51.753689: Epoch 986 
2024-11-07 21:31:51.756500: Current learning rate: 0.00021 
2024-11-07 21:32:31.401540: train_loss -0.964 
2024-11-07 21:32:31.407524: val_loss -0.742 
2024-11-07 21:32:31.409722: Pseudo dice [np.float32(0.9491), np.float32(0.6562)] 
2024-11-07 21:32:31.412069: Epoch time: 39.65 s 
2024-11-07 21:32:32.661280:  
2024-11-07 21:32:32.663972: Epoch 987 
2024-11-07 21:32:32.666732: Current learning rate: 0.0002 
2024-11-07 21:33:12.282401: train_loss -0.9638 
2024-11-07 21:33:12.285020: val_loss -0.7091 
2024-11-07 21:33:12.287262: Pseudo dice [np.float32(0.9483), np.float32(0.6126)] 
2024-11-07 21:33:12.289524: Epoch time: 39.62 s 
2024-11-07 21:33:13.535270:  
2024-11-07 21:33:13.538100: Epoch 988 
2024-11-07 21:33:13.540300: Current learning rate: 0.00019 
2024-11-07 21:33:53.225069: train_loss -0.9591 
2024-11-07 21:33:53.230813: val_loss -0.7201 
2024-11-07 21:33:53.233391: Pseudo dice [np.float32(0.9492), np.float32(0.5967)] 
2024-11-07 21:33:53.235761: Epoch time: 39.69 s 
2024-11-07 21:33:54.485509:  
2024-11-07 21:33:54.488167: Epoch 989 
2024-11-07 21:33:54.490742: Current learning rate: 0.00017 
2024-11-07 21:34:34.144442: train_loss -0.9619 
2024-11-07 21:34:34.147868: val_loss -0.6743 
2024-11-07 21:34:34.150442: Pseudo dice [np.float32(0.9424), np.float32(0.577)] 
2024-11-07 21:34:34.153063: Epoch time: 39.66 s 
2024-11-07 21:34:35.393876:  
2024-11-07 21:34:35.396843: Epoch 990 
2024-11-07 21:34:35.399539: Current learning rate: 0.00016 
2024-11-07 21:35:15.103929: train_loss -0.9618 
2024-11-07 21:35:15.109397: val_loss -0.6853 
2024-11-07 21:35:15.111736: Pseudo dice [np.float32(0.9442), np.float32(0.5573)] 
2024-11-07 21:35:15.114141: Epoch time: 39.71 s 
2024-11-07 21:35:16.357579:  
2024-11-07 21:35:16.360265: Epoch 991 
2024-11-07 21:35:16.362774: Current learning rate: 0.00014 
2024-11-07 21:35:56.002873: train_loss -0.9627 
2024-11-07 21:35:56.014181: val_loss -0.6984 
2024-11-07 21:35:56.016827: Pseudo dice [np.float32(0.9443), np.float32(0.5905)] 
2024-11-07 21:35:56.019385: Epoch time: 39.65 s 
2024-11-07 21:35:57.915764:  
2024-11-07 21:35:57.918088: Epoch 992 
2024-11-07 21:35:57.920619: Current learning rate: 0.00013 
2024-11-07 21:36:37.566585: train_loss -0.9629 
2024-11-07 21:36:37.572316: val_loss -0.7083 
2024-11-07 21:36:37.574709: Pseudo dice [np.float32(0.9481), np.float32(0.5792)] 
2024-11-07 21:36:37.577105: Epoch time: 39.65 s 
2024-11-07 21:36:38.828459:  
2024-11-07 21:36:38.832365: Epoch 993 
2024-11-07 21:36:38.834822: Current learning rate: 0.00011 
2024-11-07 21:37:18.499187: train_loss -0.961 
2024-11-07 21:37:18.501888: val_loss -0.6933 
2024-11-07 21:37:18.504214: Pseudo dice [np.float32(0.9471), np.float32(0.5504)] 
2024-11-07 21:37:18.506575: Epoch time: 39.67 s 
2024-11-07 21:37:19.746899:  
2024-11-07 21:37:19.749440: Epoch 994 
2024-11-07 21:37:19.751888: Current learning rate: 0.0001 
2024-11-07 21:37:59.351414: train_loss -0.9632 
2024-11-07 21:37:59.356541: val_loss -0.7223 
2024-11-07 21:37:59.358877: Pseudo dice [np.float32(0.9499), np.float32(0.5993)] 
2024-11-07 21:37:59.361373: Epoch time: 39.61 s 
2024-11-07 21:38:00.605935:  
2024-11-07 21:38:00.608931: Epoch 995 
2024-11-07 21:38:00.611396: Current learning rate: 8e-05 
2024-11-07 21:38:40.262313: train_loss -0.964 
2024-11-07 21:38:40.269531: val_loss -0.6774 
2024-11-07 21:38:40.272153: Pseudo dice [np.float32(0.9517), np.float32(0.5427)] 
2024-11-07 21:38:40.274498: Epoch time: 39.66 s 
2024-11-07 21:38:41.527223:  
2024-11-07 21:38:41.530043: Epoch 996 
2024-11-07 21:38:41.532750: Current learning rate: 7e-05 
2024-11-07 21:39:21.182113: train_loss -0.9596 
2024-11-07 21:39:21.187906: val_loss -0.7144 
2024-11-07 21:39:21.190212: Pseudo dice [np.float32(0.9539), np.float32(0.5776)] 
2024-11-07 21:39:21.192694: Epoch time: 39.66 s 
2024-11-07 21:39:22.442219:  
2024-11-07 21:39:22.444709: Epoch 997 
2024-11-07 21:39:22.447090: Current learning rate: 5e-05 
2024-11-07 21:40:02.107889: train_loss -0.9607 
2024-11-07 21:40:02.145357: val_loss -0.6966 
2024-11-07 21:40:02.147981: Pseudo dice [np.float32(0.9506), np.float32(0.5655)] 
2024-11-07 21:40:02.150583: Epoch time: 39.67 s 
2024-11-07 21:40:03.405574:  
2024-11-07 21:40:03.408232: Epoch 998 
2024-11-07 21:40:03.410638: Current learning rate: 4e-05 
2024-11-07 21:40:43.096469: train_loss -0.9646 
2024-11-07 21:40:43.102409: val_loss -0.6695 
2024-11-07 21:40:43.104789: Pseudo dice [np.float32(0.9534), np.float32(0.498)] 
2024-11-07 21:40:43.108175: Epoch time: 39.69 s 
2024-11-07 21:40:44.363516:  
2024-11-07 21:40:44.367376: Epoch 999 
2024-11-07 21:40:44.369841: Current learning rate: 2e-05 
2024-11-07 21:41:24.042604: train_loss -0.9632 
2024-11-07 21:41:24.045483: val_loss -0.7124 
2024-11-07 21:41:24.047788: Pseudo dice [np.float32(0.947), np.float32(0.6028)] 
2024-11-07 21:41:24.050185: Epoch time: 39.68 s 
2024-11-07 21:41:26.091370: Training done. 
2024-11-07 21:41:26.175565: Using splits from existing split file: /srv/scratch/z5362216/kits19/nnUNet_db/nnUNet_preprocessed/Dataset001_Kits19/splits_final.json 
2024-11-07 21:41:26.192130: The split file contains 5 splits. 
2024-11-07 21:41:26.194375: Desired fold for training: 0 
2024-11-07 21:41:26.199327: This split has 80 training and 20 validation cases. 
2024-11-07 21:41:26.202719: predicting imaging_004 
2024-11-07 21:41:26.210714: imaging_004, shape torch.Size([1, 64, 630, 630]), rank 0 
2024-11-07 21:41:55.416756: predicting imaging_009 
2024-11-07 21:41:55.457898: imaging_009, shape torch.Size([1, 77, 521, 521]), rank 0 
2024-11-07 21:42:01.034932: predicting imaging_013 
2024-11-07 21:42:01.047269: imaging_013, shape torch.Size([1, 92, 441, 441]), rank 0 
2024-11-07 21:42:15.155728: predicting imaging_020 
2024-11-07 21:42:15.167260: imaging_020, shape torch.Size([1, 96, 542, 542]), rank 0 
2024-11-07 21:42:23.378042: predicting imaging_025 
2024-11-07 21:42:23.394305: imaging_025, shape torch.Size([1, 103, 475, 475]), rank 0 
2024-11-07 21:42:25.838976: predicting imaging_028 
2024-11-07 21:42:25.851969: imaging_028, shape torch.Size([1, 98, 542, 542]), rank 0 
2024-11-07 21:42:34.204597: predicting imaging_033 
2024-11-07 21:42:34.219443: imaging_033, shape torch.Size([1, 423, 521, 521]), rank 0 
2024-11-07 21:43:15.089250: predicting imaging_035 
2024-11-07 21:43:15.109378: imaging_035, shape torch.Size([1, 98, 622, 622]), rank 0 
2024-11-07 21:43:23.847268: predicting imaging_040 
2024-11-07 21:43:23.860783: imaging_040, shape torch.Size([1, 207, 478, 478]), rank 0 
2024-11-07 21:43:28.888393: predicting imaging_042 
2024-11-07 21:43:28.903537: imaging_042, shape torch.Size([1, 301, 554, 554]), rank 0 
2024-11-07 21:44:02.340008: predicting imaging_049 
2024-11-07 21:44:02.356792: imaging_049, shape torch.Size([1, 670, 555, 555]), rank 0 
2024-11-07 21:45:01.782086: predicting imaging_051 
2024-11-07 21:45:01.812284: imaging_051, shape torch.Size([1, 68, 620, 620]), rank 0 
2024-11-07 21:45:07.728048: predicting imaging_060 
2024-11-07 21:45:07.740053: imaging_060, shape torch.Size([1, 145, 538, 538]), rank 0 
2024-11-07 21:45:20.400296: predicting imaging_063 
2024-11-07 21:45:20.413613: imaging_063, shape torch.Size([1, 527, 554, 554]), rank 0 
2024-11-07 21:46:10.039809: predicting imaging_065 
2024-11-07 21:46:10.070358: imaging_065, shape torch.Size([1, 103, 529, 529]), rank 0 
2024-11-07 21:46:18.896117: predicting imaging_069 
2024-11-07 21:46:18.909952: imaging_069, shape torch.Size([1, 90, 441, 441]), rank 0 
2024-11-07 21:46:21.030044: predicting imaging_075 
2024-11-07 21:46:21.041476: imaging_075, shape torch.Size([1, 90, 456, 456]), rank 0 
2024-11-07 21:46:23.403309: predicting imaging_078 
2024-11-07 21:46:23.428199: imaging_078, shape torch.Size([1, 326, 621, 621]), rank 0 
2024-11-07 21:46:55.826779: predicting imaging_086 
2024-11-07 21:46:55.846682: imaging_086, shape torch.Size([1, 199, 509, 509]), rank 0 
2024-11-07 21:47:00.879368: predicting imaging_088 
2024-11-07 21:47:00.921468: imaging_088, shape torch.Size([1, 99, 282, 282]), rank 0 
2024-11-07 21:48:24.736599: Validation complete 
2024-11-07 21:48:24.739747: Mean Validation Dice:  0.7304501643553679 
